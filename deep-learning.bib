@article{delaRosa2015,
abstract = {Abstract Both randomized algorithms and deep learning techniques have been successfully used for regression and classification problems. However, the random hidden weights of the randomized algorithms require suitable distributions in advance, and the deep learning methods do not use the output information in system identification. In this paper, the distributions of the hidden weights are obtained by the restricted Boltzmann machines. This deep learning method uses input data to construct the statistical features of the hidden weights. The output weights of the neural model are trained by normal randomized algorithms. So we successfully combine the unsupervised training (deep learning) and the supervised learning method (randomized algorithm), and take advantages from both of them. The proposed randomized algorithms with deep learning modification are validated with three benchmark problems.},
title = {Randomized algorithms for nonlinear system identification with deep learning modification },
journal = {Information Sciences},
year = {2015},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2015.09.048},
url = {http://www.sciencedirect.com/science/article/pii/S0020025515007033},
author = {Erick de la Rosa and Wen Yu}}
@article{Bengio20151,
title = {Editorial introduction to the Neural Networks special issue on Deep Learning of Representations },
journal = {Neural Networks },
volume = {64},
number = {},
pages = {1 - 3},
year = {2015},
note = {Special Issue on Deep Learning of Representations },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2014.12.006},
url = {http://www.sciencedirect.com/science/article/pii/S089360801400286X},
author = {Yoshua Bengio and Honglak Lee}}
@article{SanchezRiera20161,
title = {A comparative study of data fusion for RGB-D based visual recognition },
journal = {Pattern Recognition Letters },
volume = {73},
number = {},
pages = {1 - 6},
year = {2016},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.12.006},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515004298},
author = {Jordi Sanchez-Riera and Kai-Lung Hua and Yuan-Sheng Hsiao and Tekoing Lim and Shintami C. Hidayati and Wen-Huang Cheng},

abstract = {Abstract Data fusion from different modalities has been extensively studied for a better understanding of multimedia contents. On one hand, the emergence of new devices and decreasing storage costs cause growing amounts of data being collected. Though bigger data makes it easier to mine information, methods for big data analytics are not well investigated. On the other hand, new machine learning techniques, such as deep learning, have been shown to be one of the key elements in achieving state-of-the-art inference performances in a variety of applications. Therefore, some of the old questions in data fusion are in need to be addressed again for these new changes. These questions are: What is the most effective way to combine data for various modalities? Does the fusion method affect the performance with different classifiers? To answer these questions, in this paper, we present a comparative study for evaluating early and late fusion schemes with several types of SVM and deep learning classifiers on two challenging RGB-D based visual recognition tasks: hand gesture recognition and generic object recognition. The findings from this study provide useful policy and practical guidance for the development of visual recognition systems. }}
@article{tagkey2015IFC,
title = {Editorial Board },
journal = {Neural Networks },
volume = {64},
number = {},
pages = {IFC - },
year = {2015},
note = {Special Issue on Deep Learning of Representations },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/S0893-6080(15)00015-5},
url = {http://www.sciencedirect.com/science/article/pii/S0893608015000155},
key = {tagkey2015IFC}}
@article{Xia2015333,
title = {Recognizing multi-view objects with occlusions using a deep architecture },
journal = {Information Sciences },
volume = {320},
number = {},
pages = {333 - 345},
year = {2015},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2015.01.038},
url = {http://www.sciencedirect.com/science/article/pii/S0020025515000766},
author = {Yingjie Xia and Luming Zhang and Weiwei Xu and Zhenyu Shan and Yuncai Liu},
abstract = {Image-based object recognition is employed widely in many computer vision applications such as image semantic annotation and object location. However, traditional object recognition algorithms based on the 2D features of RGB data have difficulty when objects overlap and image occlusion occurs. At present, RGB-D cameras are being used more widely and the RGB-D depth data can provide auxiliary information to address these challenges. In this study, we propose a deep learning approach for the efficient recognition of 3D objects with occlusion. First, this approach constructs a multi-view shape model based on 3D objects by using an encode–decode deep learning network to represent the features. Next, 3D object recognition in indoor scenes is performed using random forests. The application of deep learning to RGB-D data is beneficial for recovering missing information due to image occlusion. Our experimental results demonstrate that this approach can significantly improve the efficiency of feature representation and the performance of object recognition with occlusion. }}
@article{Rere2015137,
title = {Simulated Annealing Algorithm for Deep Learning },
journal = {Procedia Computer Science },
volume = {72},
number = {},
pages = {137 - 144},
year = {2015},
note = {The Third Information Systems International Conference 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.12.114},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915035759},
author = {L.M. Rasdi Rere and Mohamad Ivan Fanany and Aniati Murni Arymurthy},



abstract = {Abstract Deep learning (DL) is a new area of research in machine learning, in which the objective is moving us closer to the goal of artificial intelligent. This method can learn many levels of abstraction and representation to create a common sense of data such as text, sound and image. Although DL is useful for a variety of tasks, it's hard to train. Some methods in training deep learning to make it optimal have been proposed, including Stochastic Gradient Descent, Conjugate Gradient, Hessian-free optimization, and Krylov Subspace Descent. In this paper, we proposed Simulated Annealing (SA) to improve the performance of Convolution Neural Network (CNN), as an alternative approach for optimal DL using modern optimization technique, i.e. metaheuristic algorithm. MNIST dataset is used to ensure the accuracy and efficiency of the proposed method. Moreover, we also compare our proposed method with the original of CNN. Although there is an increase in computation time, the experiment results show that the proposed method can improve the performance of original CNN. }}
@article{Zhong20158146,
title = {Query-oriented unsupervised multi-document summarization via deep learning model },
journal = {Expert Systems with Applications },
volume = {42},
number = {21},
pages = {8146 - 8155},
year = {2015},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2015.05.034},
url = {http://www.sciencedirect.com/science/article/pii/S0957417415003620},
author = {Sheng-hua Zhong and Yan Liu and Bin Li and Jing Long},abstract = {Abstract Capturing the compositional process from words to documents is a key challenge in natural language processing and information retrieval. Extractive style query-oriented multi-document summarization generates a summary by extracting a proper set of sentences from multiple documents based on pre-given query. This paper proposes a novel document summarization framework based on deep learning model, which has been shown outstanding extraction ability in many real-world applications. The framework consists of three parts: concepts extraction, summary generation, and reconstruction validation. A new query-oriented extraction technique is proposed to extract information distributed in multiple documents. Then, the whole deep architecture is fine-tuned by minimizing the information loss in reconstruction validation. According to the concepts extracted from deep architecture layer by layer, dynamic programming is used to seek most informative set of sentences for the summary. Experiment on three benchmark datasets (DUC 2005, 2006, and 2007) assess and confirm the effectiveness of the proposed framework and algorithms. Experiment results show that the proposed method outperforms state-of-the-art extractive summarization approaches. Moreover, we also provide the statistical analysis of query words based on Amazon’s Mechanical Turk (MTurk) crowdsourcing platform. There exists underlying relationships from topic words to the content which can contribute to summarization task. }}
@article{Huerta2015239,
title = {A deep analysis on age estimation },
journal = {Pattern Recognition Letters },
volume = {68, Part 2},
number = {},
pages = {239 - 249},
year = {2015},
note = {Special Issue on Soft Biometrics },
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.06.006},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515001683},
author = {Ivan Huerta and Carles Fernández and Carlos Segura and Javier Hernando and Andrea Prati},

abstract = {Abstract The automatic estimation of age from face images is increasingly gaining attention, as it facilitates applications including advanced video surveillance, demographic statistics collection, customer profiling, or search optimization in large databases. Nevertheless, it becomes challenging to estimate age from uncontrollable environments, with insufficient and incomplete training data, dealing with strong person-specificity and high within-range variance. These difficulties have been recently addressed with complex and strongly hand-crafted descriptors, difficult to replicate and compare. This paper presents two novel approaches: first, a simple yet effective fusion of descriptors based on texture and local appearance; and second, a deep learning scheme for accurate age estimation. These methods have been evaluated under a diversity of settings, and the extensive experiments carried out on two large databases (MORPH and FRGC) demonstrate state-of-the-art results over previous work. }}
@article{Guo201627,
title = {Deep learning for visual understanding: A review },
journal = {Neurocomputing },
volume = {187},
number = {},
pages = {27 - 48},
year = {2016},
note = {Recent Developments on Deep Big Vision },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.09.116},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017634},
author = {Yanming Guo and Yu Liu and Ard Oerlemans and Songyang Lao and Song Wu and Michael S. Lew},

abstract = {Abstract Deep learning algorithms are a subset of the machine learning algorithms, which aim at discovering multiple levels of distributed representations. Recently, numerous deep learning algorithms have been proposed to solve traditional artificial intelligence problems. This work aims to review the state-of-the-art in deep learning algorithms in computer vision by highlighting the contributions and challenges from over 210 recent research papers. It first gives an overview of various deep learning approaches and their recent developments, and then briefly describes their applications in diverse vision tasks, such as image classification, object detection, image retrieval, semantic segmentation and human pose estimation. Finally, the paper summarizes the future trends and challenges in designing and training deep neural networks. }}
@article{Zhu2015103,
title = {Deep neural network based image annotation },
journal = {Pattern Recognition Letters },
volume = {65},
number = {},
pages = {103 - 108},
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.07.037},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515002469},
author = {Songhao Zhu and Zhe Shi and Chengjian Sun and Shuhan Shen},abstract = {Abstract Multilabel image annotation is one of the most important open problems in computer vision field. Unlike existing works that usually use conventional visual features to annotate images, features based on deep learning have shown potential to achieve outstanding performance. In this work, we propose a multimodal deep learning framework, which aims to optimally integrate multiple deep neural networks pretrained with convolutional neural networks. In particular, the proposed framework explores a unified two-stage learning scheme that consists of (i) learning to fine-tune the parameters of deep neural network with respect to each individual modality, and (ii) learning to find the optimal combination of diverse modalities simultaneously in a coherent process. Experiments conducted on a variety of public datasets evaluate the performance of the proposed framework for multilabel image annotation, in which the encouraging results validate the effectiveness of the proposed algorithms. }}
@article{Längkvist201411,
title = {A review of unsupervised feature learning and deep learning for time-series modeling },
journal = {Pattern Recognition Letters },
volume = {42},
number = {},
pages = {11 - 24},
year = {2014},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2014.01.008},
url = {http://www.sciencedirect.com/science/article/pii/S0167865514000221},
author = {Martin Längkvist and Lars Karlsson and Amy Loutfi},



abstract = {Abstract This paper gives a review of the recent developments in deep learning and unsupervised feature learning for time-series problems. While these techniques have shown promise for modeling static data, such as computer vision, applying them to time-series data is gaining increasing attention. This paper overviews the particular challenges present in time-series data and provides a review of the works that have either applied time-series data to unsupervised feature learning algorithms or alternatively have contributed to modifications of feature learning algorithms to take into account the challenges present in time-series data. }}
@article{Kim201519,
title = {Deep learning of support vector machines with class probability output networks },
journal = {Neural Networks },
volume = {64},
number = {},
pages = {19 - 28},
year = {2015},
note = {Special Issue on Deep Learning of Representations },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2014.09.007},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002172},
author = {Sangwook Kim and Zhibin Yu and Rhee Man Kil and Minho Lee},abstract = {Abstract Deep learning methods endeavor to learn features automatically at multiple levels and allow systems to learn complex functions mapping from the input space to the output space for the given data. The ability to learn powerful features automatically is increasingly important as the volume of data and range of applications of machine learning methods continues to grow. This paper proposes a new deep architecture that uses support vector machines (SVMs) with class probability output networks (CPONs) to provide better generalization power for pattern classification problems. As a result, deep features are extracted without additional feature engineering steps, using multiple layers of the SVM classifiers with CPONs. The proposed structure closely approaches the ideal Bayes classifier as the number of layers increases. Using a simulation of classification problems, the effectiveness of the proposed method is demonstrated. }}
@article{Wang2016232,
title = {Auto-encoder based dimensionality reduction },
journal = {Neurocomputing },
volume = {184},
number = {},
pages = {232 - 242},
year = {2016},
note = {RoLoD: Robust Local Descriptors for Computer Vision 2014 },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.08.104},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017671},
author = {Yasi Wang and Hongxun Yao and Sicheng Zhao},
abstract = {Abstract Auto-encoder—a tricky three-layered neural network, known as auto-association before, constructs the building block of deep learning, which has been demonstrated to achieve good performance in various domains. In this paper, we try to investigate the dimensionality reduction ability of auto-encoder, and see if it has some kind of good property that might accumulate when being stacked and thus contribute to the success of deep learning. Based on the above idea, this paper starts from auto-encoder and focuses on its ability to reduce the dimensionality, trying to understand the difference between auto-encoder and state-of-the-art dimensionality reduction methods. Experiments are conducted both on the synthesized data for an intuitive understanding of the method, mainly on two and three-dimensional spaces for better visualization, and on some real datasets, including MNIST and Olivetti face datasets. The results show that auto-encoder can indeed learn something different from other methods. Besides, we preliminarily investigate the influence of the number of hidden layer nodes on the performance of auto-encoder and its possible relation with the intrinsic dimensionality of input data. }}
@article{Qin201649,
title = {DeepFish: Accurate underwater live fish recognition with a deep architecture },
journal = {Neurocomputing },
volume = {187},
number = {},
pages = {49 - 58},
year = {2016},
note = {Recent Developments on Deep Big Vision },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.10.122},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017312},
author = {Hongwei Qin and Xiu Li and Jian Liang and Yigang Peng and Changshui Zhang},abstract = {Abstract Underwater object recognition is in great demand, while the research is far from enough. The unrestricted natural environment makes it a challenging task. We propose a framework to recognize fish from videos captured by underwater cameras deployed in the ocean observation network. First, we extract the foreground via sparse and low-rank matrix decomposition. Then, a deep architecture is used to extract features of the foreground fish images. In this architecture, principal component analysis (PCA) is used in two convolutional layers, followed by binary hashing in the non-linear layer and block-wise histograms in the feature pooling layer. Then spatial pyramid pooling (SPP) is used to extract information invariant to large poses. Finally, a linear SVM classifier is used for the classification. This deep network model can be trained efficiently. On a real-world fish recognition dataset, we achieve the state-of-the-art accuracy of 98.64%. }}
@article{Dong20164,
title = {Automatic age estimation based on deep learning algorithm },
journal = {Neurocomputing },
volume = {187},
number = {},
pages = {4 - 10},
year = {2016},
note = {Recent Developments on Deep Big Vision },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.09.115},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017348},
author = {Yuan Dong and Yinan Liu and Shiguo Lian},abstract = {Abstract Automatic age estimation has attracted much attention due to its potential applications. Most of the proposed approaches have mainly used low-level handcraft features to encode facial age related visual information and train an age estimation model. In this paper, we focus on age classification task in which face image is assigned to a label that represents an age range. We proposed a deep learning based framework for age classification task. In our proposed algorithm, Deep Convolutional Neural Networks (Deep ConvNets) are used to extract high-level complex age related visual features and predict age range of input face image. Due to lack of age labeled face images, we use the transfer learning strategy to train the Deep ConvNets. In addition, to describe the relationships between labels that compose an ordered sequence, we define a new loss function in the training process of age classification task. The experiments are conducted on a widely used age estimation dataset-Images of Groups of People. The experimental results demonstrate the excellent performance of our proposed algorithm against the state-of-the-art methods. }}
@article{Zhang2015454,
title = {Deep learning driven blockwise moving object detection with binary scene modeling },
journal = {Neurocomputing },
volume = {168},
number = {},
pages = {454 - 463},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.05.082},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215007808},
author = {Yaqing Zhang and Xi Li and Zhongfei Zhang and Fei Wu and Liming Zhao},



abstract = {Abstract As an important and challenging topic in computer vision, moving object detection is typically posed as a problem of scene analysis, which usually requires both robust feature description and effective statistical modeling. In general, the conventional detection methods make use of pre-defined hand-crafted features and sophisticated background models for scene analysis. Therefore, they usually have a low generalization capability of adapting to different scenes with diverse spatio-temporal motion information. In the face of high-definition video data, sophisticated statistical modeling often suffers from an expensive computation or memory cost because of its low efficiency in evaluation and parallelization. In order to address this issue, we propose a deep learning based block-wise scene analysis method equipped with a binary spatio-temporal scene model. Based on the stacked denoising autoencoder, the deep learning module of the proposed method aims to learn an effective deep image representation encoding the intrinsic scene information, which leads to the robustness of feature description. Furthermore, the proposed binary scene model captures the spatio-temporal scene distribution information in the Hamming space, which ensures the high efficiency of moving object detection. Experimental results on several datasets demonstrate the effectiveness and efficiency of the proposed method. }}
@article{Mansanet201680,
title = {Local Deep Neural Networks for gender recognition },
journal = {Pattern Recognition Letters },
volume = {70},
number = {},
pages = {80 - 86},
year = {2016},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.11.015},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515004018},
author = {Jordi Mansanet and Alberto Albiol and Roberto Paredes},
abstract = {Abstract Deep learning methods are able to automatically discover better representations of the data to improve the performance of the classifiers. However, in computer vision tasks, such as the gender recognition problem, sometimes it is difficult to directly learn from the entire image. In this work we propose a new model called Local Deep Neural Network (Local-DNN), which is based on two key concepts: local features and deep architectures. The model learns from small overlapping regions in the visual field using discriminative feed-forward networks with several layers. We evaluate our approach on two well-known gender benchmarks, showing that our Local-DNN outperforms other deep learning methods also evaluated and obtains state-of-the-art results in both benchmarks. }}
@article{Nithin2015202,
title = {Generic Feature Learning in Computer Vision },
journal = {Procedia Computer Science },
volume = {58},
number = {},
pages = {202 - 209},
year = {2015},
note = {Second International Symposium on Computer Vision and the Internet (VisionNet’15) },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.08.054},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915021651},
author = {D. Kanishka Nithin and P. Bagavathi Sivakumar},
abstract = {Abstract Current Machine learning algorithms are highly dependent on manually designing features and the Performance of such algo- rithms predominantly depend on how good our representations are. Manually we might never be able to produce best and diverse set of features that closely describe all the variations that occur in our data. Understanding this, vision community is moving towards learning the optimum features itself instead of learning from the features. Traditional hand engineered features lack in generalizing well to other domains/Problems, are time consuming, expensive, requires expert knowledge on the problem domain and doesn’t facilitate learning from previous learnings/Representations(Transfer learning). All these issues are resolved in learning deep representations. Since 2006 a wide range of representation learning algorithms has been proposed but by the recent success and breakthroughs of few deep learning models, the representation learning algorithms have gained the spotlight. This paper aims to give short overview of deep learning approaches available for vision tasks. We also discuss their applicability (With respect to their properties) in vision field. }}
@article{Kim2015111,
title = {Deep learning with support vector data description },
journal = {Neurocomputing },
volume = {165},
number = {},
pages = {111 - 117},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.09.086},
url = {http://www.sciencedirect.com/science/article/pii/S092523121500380X},
author = {Sangwook Kim and Yonghwa Choi and Minho Lee},abstract = {Abstract One of the most critical problems for machine learning methods is overfitting. The overfitting problem is a phenomenon in which the accuracy of the model on unseen data is poor whereas the training accuracy is nearly perfect. This problem is particularly severe in complex models that have a large set of parameters. In this paper, we propose a deep learning neural network model that adopts the support vector data description (SVDD). The SVDD is a variant of the support vector machine, which has high generalization performance by acquiring a maximal margin in one-class classification problems. The proposed model strives to obtain the representational power of deep learning. Generalization performance is maintained using the SVDD. The experimental results showed that the proposed model can learn multiclass data without severe overfitting problems. }}
@article{Li2015119,
title = {Multimodal deep support vector classification with homologous features and its application to gearbox fault diagnosis },
journal = {Neurocomputing },
volume = {168},
number = {},
pages = {119 - 127},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.06.008},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215008280},
author = {Chuan Li and René-Vinicio Sanchez and Grover Zurita and Mariela Cerrada and Diego Cabrera and Rafael E. Vásquez},
abstract = {Abstract Gearboxes are crucial transmission components in mechanical systems. Fault diagnosis is an important tool to maintain gearboxes in healthy conditions. It is challenging to recognize fault existences and, if any, failure patterns in such transmission elements due to their complicated configurations. This paper addresses a multimodal deep support vector classification (MDSVC) approach, which employs separation–fusion based deep learning in order to perform fault diagnosis tasks for gearboxes. Considering that different modalities can be made to describe same object, multimodal homologous features of the gearbox vibration measurements are first separated in time, frequency and wavelet modalities, respectively. A Gaussian-Bernoulli deep Boltzmann machine (GDBM) without final output is subsequently suggested to learn pattern representations for features in each modality. A support vector classifier is finally applied to fuse GDBMs in different modalities towards the construction of the MDSVC model. With the present model, deep representations from wide modalities improve fault diagnosis capabilities. Fault diagnosis experiments were carried out to evaluate the proposed method on both spur and helical gearboxes. The proposed model achieves the best fault classification rate in experiments when compared to representative deep and shallow learning methods. Results indicate that the proposed separation–fusion based deep learning strategy is effective for the gearbox fault diagnosis. }}
@article{Biswas2015335,
title = {Learning Morphological Transformations with Recurrent Neural Networks },
journal = {Procedia Computer Science },
volume = {53},
number = {},
pages = {335 - 344},
year = {2015},
note = {INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.326},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915018293},
author = {Saurav Biswas and Thomas Breuel},



abstract = {Abstract Deep learning techniques have been successfully used in recent years to learn useful image trans- formations and features, thus contributing significantly to the advancements in neural networks. However deep nets suffer from the drawback that they require large training times and mul- tifarious parameters that need to be hand tuned for optimal performance. In this paper we investigate the use Recurrent neural network architectures to learn useful transformations of an image(object), progressively over time. Learning these latent transformations enables the recur- rent architecture to correctly predict, to a high degree of accuracy, the original representation of an object from its transformed representations. }}
@article{Berglund201512,
title = {Measuring the usefulness of hidden units in Boltzmann machines with mutual information },
journal = {Neural Networks },
volume = {64},
number = {},
pages = {12 - 18},
year = {2015},
note = {Special Issue on Deep Learning of Representations },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2014.09.004},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002147},
author = {Mathias Berglund and Tapani Raiko and Kyunghyun Cho},

abstract = {Abstract Restricted Boltzmann machines (RBMs) and deep Boltzmann machines (DBMs) are important models in deep learning, but it is often difficult to measure their performance in general, or measure the importance of individual hidden units in specific. We propose to use mutual information to measure the usefulness of individual hidden units in Boltzmann machines. The measure is fast to compute, and serves as an upper bound for the information the neuron can pass on, enabling detection of a particular kind of poor training results. We confirm experimentally that the proposed measure indicates how much the performance of the model drops when some of the units of an RBM are pruned away. We demonstrate the usefulness of the measure for early detection of poor training in DBMs. }}
@article{Boyle20121224,
title = {Context and deep learning design },
journal = {Computers & Education },
volume = {59},
number = {4},
pages = {1224 - 1233},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.06.007},
url = {http://www.sciencedirect.com/science/article/pii/S0360131512001492},
author = {Tom Boyle and Andrew Ravenscroft},abstract = {Conceptual clarification is essential if we are to establish a stable and deep discipline of technology enhanced learning. The technology is alluring; this can distract from deep design in a surface rush to exploit the affordances of the new technology. We need a basis for design, and a conceptual unit of organization, that are applicable across constant technological change. These are the issues addressed in this article. The article first explores the nature of ‘deep learning design’ where the aim is to shape the possibilities of the technology to most effectively enhance learning. These design insights need to be applied to a unit of organization that is not dependent on any particular technology. They should interact with and shape technology possibilities rather than be narrowly defined by them. The key unit of organization proposed is that of context. At a theoretical level, the article explores context as a shared interpretation of situation. The implications of the nested nature of contextual interpretation on design, implementation and evaluation are explored in depth. The internal dynamics of learning contexts are then discussed initially in terms of principles, heuristics and scripts. The contribution of this article is to present a coherent argument for context as the central unit for deep learning design, and to articulate the incisive theoretical and practical consequences of this position. }}
@article{Niwa2014515,
title = {An Associative Memorization Architecture of Extracted Musical Features from Audio Signals by Deep Learning Architecture },
journal = {Procedia Computer Science },
volume = {36},
number = {},
pages = {515 - 522},
year = {2014},
note = {Complex Adaptive Systems Philadelphia, PA November 3-5, 2014 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2014.09.032},
url = {http://www.sciencedirect.com/science/article/pii/S1877050914012812},
author = {Tadaaki Niwa and Keitaro Naruse and Ryosuke Ooe and Masahiro Kinoshita and Tamotsu Mitamura and Takashi Kawakami},
abstract = {Abstract In this paper, we develop associative memorization architecture of the musical features from time sequential data of the music audio signals. This associative memorization architecture is constructed by using deep learning architecture. Challenging purpose of our research is the development of the new composition system that automatically creates a new music based on some existing music. How does a human composer make musical compositions or pieces? Generally speaking, music piece is generated by the cyclic analysis process and re-synthesis process of musical features in music creation procedures. This process can be simulated by learning models using Artificial Neural Network (ANN) architecture. The first and critical problem is how to describe the music data, because, in those models, description format for this data has a great influence on learning performance and function. Almost of related works adopt symbolic representation methods of music data. However, we believe human composers never treat a music piece as a symbol. Therefore raw music audio signals are input to our system. The constructed associative model memorizes musical features of music audio signals, and regenerates sequential data of that music. Based on experimental results of memorizing music audio data, we verify the performances and effectiveness of our system. }}
@article{Wu2016310,
title = {Regional deep learning model for visual tracking },
journal = {Neurocomputing },
volume = {175, Part A},
number = {},
pages = {310 - 323},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.10.064},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215015234},
author = {Guoxing Wu and Wenjie Lu and Guangwei Gao and Chunxia Zhao and Jiayin Liu},



abstract = {Abstract Deep learning has been successfully applied to visual tracking due to its powerful feature learning characteristic. However, existing deep learning trackers rely on single observation model and focus on the holistic representation of the tracking object. When occlusion occurs, the trackers suffer from the contaminated features obtained in occluded areas. In this paper, we propose a regional deep learning tracker that observes the target by multiple sub-regions and each region is observed by a deep learning model. In particular, we devise a stable factor, modeled as a hidden variable of the Factorial Hidden Markov Model, to characterize the stability of these sub-models. The stability indicator not only provides a confidence degree for the response score of each model during inference stage, but also determines the online training criteria for each deep learning model. This online training strategy enables the tracker to achieve more accurate local features compared with those fixed training trackers. In addition, to improve the computational efficiency, we exploit the structurized response property of the customized deep learning model to approximate the final tracking results by the weighted Gaussian Mixture Model under the particle filter framework. Qualitative and quantitative evaluations on the recent public benchmark dataset show that our approach outperforms most state-of-the-art trackers. }}
@article{Jiu2014122,
title = {Human body part estimation from depth images via spatially-constrained deep learning },
journal = {Pattern Recognition Letters },
volume = {50},
number = {},
pages = {122 - 129},
year = {2014},
note = {Depth Image Analysis },
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2013.09.021},
url = {http://www.sciencedirect.com/science/article/pii/S0167865513003577},
author = {Mingyuan Jiu and Christian Wolf and Graham Taylor and Atilla Baskurt},
abstract = {Abstract Object recognition, human pose estimation and scene recognition are applications which are frequently solved through a decomposition into a collection of parts. The resulting local representation has significant advantages, especially in the case of occlusions and when the subject is non-rigid. Detection and recognition require modelling the appearance of the different object parts as well as their spatial layout. This representation has been particularly successful in body part estimation from depth images. Integrating the spatial layout of parts may require the minimization of complex energy functions. This is prohibitive in most real world applications and therefore often omitted. However, ignoring the spatial layout puts all the burden on the classifier, whose only available information is local appearance. We propose a new method to integrate spatial layout into parts classification without costly pairwise terms during testing. Spatial relationships are exploited in the training algorithm, but not during testing. As with competing methods, the proposed method classifies pixels independently, which makes real-time processing possible. We show that training a classifier with spatial relationships increases generalization performance when compared to classical training minimizing classification error on the training set. We present an application to human body part estimation from depth images. }}
@article{Liem2012222,
title = {Personal best goals and academic and social functioning: A longitudinal perspective },
journal = {Learning and Instruction },
volume = {22},
number = {3},
pages = {222 - 230},
year = {2012},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2011.11.003},
url = {http://www.sciencedirect.com/science/article/pii/S0959475211000909},
author = {Gregory Arief D. Liem and Paul Ginns and Andrew J. Martin and Barbara Stone and Maree Herrett},abstract = {Personal best goals (PB goals) articulate a target performance standard that matches or exceeds one’s previous best. This study examined the role of PB goals in academic and social functioning. Alongside academic and social outcome measures, PB goal items were administered to 249 high-school students at the beginning and end of their school year. Longitudinal structural equation modeling suggested, at Time 1, PB goals significantly predicted students’ deep learning, academic flow, academic buoyancy, positive teacher relationship, and favorable attitudes toward peer cooperation. Further, at Time 2, the effects of PB goals on deep learning, academic flow, and positive teacher relationship remained significant after controlling for prior variance of corresponding Time-1 factors, suggesting sustained benefits of PB goals in students’ academic and social development. These findings hold substantive, applied, and methodological implications for researchers and practitioners seeking to examine and harness PB goals in educational settings. }}
@article{Young2014115,
title = {Hierarchical spatiotemporal feature extraction using recurrent online clustering },
journal = {Pattern Recognition Letters },
volume = {37},
number = {},
pages = {115 - 123},
year = {2014},
note = {Partially Supervised Learning for Pattern Recognition },
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2013.07.013},
url = {http://www.sciencedirect.com/science/article/pii/S0167865513002869},
author = {S.R. Young and A. Davis and A. Mishtal and I. Arel},

abstract = {Abstract Deep machine learning offers a comprehensive framework for extracting meaningful features from complex observations in an unsupervised manner. The majority of deep learning architectures described in the literature primarily focus on extracting spatial features. However, in real-world settings, capturing temporal dependencies in observations is critical for accurate inference. This paper introduces an enhancement to DeSTIN – a compositional deep learning architecture in which each layer consists of multiple instantiations of a common node – that learns to represent spatiotemporal patterns in data based on a novel recurrent clustering algorithm. Contrary to mainstream deep architectures, such as deep belief networks where layer-by-layer training is assumed, each of the nodes in the proposed architecture is trained independently and in parallel. Moreover, top-down and bottom-up information flows facilitate rich feature formation. A semi-supervised setting is demonstrated achieving state-of-the-art results on the MNIST classification benchmarks. A GPU implementation is discussed further accentuating the scalability properties of the proposed framework. }}
@article{Zou2014146,
title = {Chronological classification of ancient paintings using appearance and shape features },
journal = {Pattern Recognition Letters },
volume = {49},
number = {},
pages = {146 - 154},
year = {2014},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2014.07.002},
url = {http://www.sciencedirect.com/science/article/pii/S0167865514002086},
author = {Qin Zou and Yu Cao and Qingquan Li and Chuanhe Huang and Song Wang},abstract = {Abstract Ancient paintings are valuable for historians and archeologists to study the humanities, customs and economy of the corresponding eras. For this purpose, it is important to first determine the era in which a painting was drawn. This problem can be very challenging when the paintings from different eras present a same topic and only show subtle difference in terms of the painting styles. In this paper, we propose a novel computational approach to address this problem by using the appearance and shape features extracted from the paintings. In this approach, we first extract the appearance and shape features using the SIFT and kAS descriptors, respectively. We then encode these features with deep learning in an unsupervised way. Finally, we combine all the features in the form of bag-of-visual-words and train a classifier in a supervised fashion. In the experiments, we collect 660 Flying-Apsaras paintings from Mogao Grottoes in Dunhuang, China and classify them into three different eras, with very promising results. }}
@article{Rahhal2016340,
title = {Deep learning approach for active classification of electrocardiogram signals },
journal = {Information Sciences },
volume = {345},
number = {},
pages = {340 - 354},
year = {2016},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2016.01.082},
url = {http://www.sciencedirect.com/science/article/pii/S0020025516300184},
author = {M.M. Al Rahhal and Yakoub Bazi and Haikel AlHichri and Naif Alajlan and Farid Melgani and R.R. Yager},
abstract = {Abstract In this paper, we propose a novel approach based on deep learning for active classification of electrocardiogram (ECG) signals. To this end, we learn a suitable feature representation from the raw ECG data in an unsupervised way using stacked denoising autoencoders (SDAEs) with sparsity constraint. After this feature learning phase, we add a softmax regression layer on the top of the resulting hidden representation layer yielding the so-called deep neural network (DNN). During the interaction phase, we allow the expert at each iteration to label the most relevant and uncertain ECG beats in the test record, which are then used for updating the DNN weights. As ranking criteria, the method relies on the DNN posterior probabilities to associate confidence measures such as entropy and Breaking-Ties (BT) to each test beat in the ECG record under analysis. In the experiments, we validate the method on the well-known MIT-BIH arrhythmia database as well as two other databases called INCART, and SVDB, respectively. Furthermore, we follow the recommendations of the Association for the Advancement of Medical Instrumentation (AAMI) for class labeling and results presentation. The results obtained show that the newly proposed approach provides significant accuracy improvements with less expert interaction and faster online retraining compared to state-of-the-art methods. }}
@article{Ren2016427,
title = {Local visual feature fusion via maximum margin multimodal deep neural network },
journal = {Neurocomputing },
volume = {175, Part A},
number = {},
pages = {427 - 432},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.10.076},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215015350},
author = {Zhiquan Ren and Yue Deng and Qionghai Dai},abstract = {Abstract In this letter, we consider improving the image categorization performance by exploiting multiple local descriptors on the image. To achieve this goal, a novel deep learning configuration called maximum margin multimodal deep neural network (3mDNN) is proposed to learn joint feature from different data views. The local feature representations encoded by 3mDNN exhibit two significant advantages: (1) involving the information of multiple descriptors and (2) exhibiting discriminative ability. The whole deep architecture is well solved by the typical back propagation (BP) method and its performances are verified on three benchmark image datasets. }}
@article{AfaqAliShah2016866,
title = {Iterative deep learning for image set based face and object recognition },
journal = {Neurocomputing },
volume = {174, Part B},
number = {},
pages = {866 - 874},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.10.004},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215014605},
author = {Syed Afaq Ali Shah and Mohammed Bennamoun and Farid Boussaid},


abstract = {Abstract We present a novel technique for image set based face/object recognition, where each gallery and query example contains a face/object image set captured from different viewpoints, background, facial expressions, resolution and illumination levels. While several image set classification approaches have been proposed in recent years, most of them represent each image set as a single linear subspace, mixture of linear subspaces or Lie group of Riemannian manifold. These techniques make prior assumptions in regards to the specific category of the geometric surface on which images of the set are believed to lie. This could result in a loss of discriminative information for classification. This paper alleviates these limitations by proposing an Iterative Deep Learning Model (IDLM) that automatically and hierarchically learns discriminative representations from raw face and object images. In the proposed approach, low level translationally invariant features are learnt by the Pooled Convolutional Layer (PCL). The latter is followed by Artificial Neural Networks (ANNs) applied iteratively in a hierarchical fashion to learn a discriminative non-linear feature representation of the input image sets. The proposed technique was extensively evaluated for the task of image set based face and object recognition on YouTube Celebrities, Honda/UCSD, CMU Mobo and ETH-80 (object) dataset, respectively. Experimental results and comparisons with state-of-the-art methods show that our technique achieves the best performance on all these datasets. }}
@article{Guo201678,
title = {Convolutional feature learning and Hybrid CNN-HMM for scene number recognition },
journal = {Neurocomputing },
volume = {184},
number = {},
pages = {78 - 90},
year = {2016},
note = {RoLoD: Robust Local Descriptors for Computer Vision 2014 },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.135},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215018950},
author = {Qiang Guo and Fenglei Wang and Jun Lei and Dan Tu and Guohui Li},

abstract = {Abstract In this work, we investigate to recognize house numbers captured in street view images. We formulate the problem as sequence recognition and present an integrated model by combining Convolutional Neural Network (CNN) and Hidden Markov Model (HMM). Our method utilizes representation capability of CNN to model the highly variable appearance of digits. Meanwhile, HMM is used to handle the dynamics of the image sequence. They are combined in a hybrid way to form the Hybrid CNN-HMM. Using this model, we can perform training and recognition both at the whole image level without explicit segmentation. The model makes CNN applicable to dynamic problems. Experiments show that the Hybrid CNN-HMM can dramatically boost the performance of Gaussian Mixture Model (GMM)-HMM. We evaluate different local features, e.g. LBP, SIFT and HOG, as observations fed into HMM and find CNN features consistently surpass those hand-engineered features with respect to recognition accuracy. To gain insight into performance difference of the features, we map them from the high-dimensional space to a 2-D plane by the t-SNE algorithm to visualize their semantic clustering with respect to the task. The visualization clearly justified the efficiency of features learnt by CNN. }}
@article{Gu2015282,
title = {Semi-supervised deep extreme learning machine for Wi-Fi based localization },
journal = {Neurocomputing },
volume = {166},
number = {},
pages = {282 - 293},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.04.011},
url = {http://www.sciencedirect.com/science/article/pii/S092523121500418X},
author = {Yang Gu and Yiqiang Chen and Junfa Liu and Xinlong Jiang},abstract = {Abstract Along with the proliferation of mobile devices and wireless signal coverage, indoor localization based on Wi-Fi gets great popularity. Fingerprint based method is the mainstream approach for Wi-Fi indoor localization, for it can achieve high localization performance as long as labeled data are sufficient. However, the number of labeled data is always limited due to the high cost of data acquisition. Nowadays, crowd sourcing becomes an effective approach to gather large number of data; meanwhile, most of them are unlabeled. Therefore, it is worth studying the use of unlabeled data to improve localization performance. To achieve this goal, a novel algorithm Semi-supervised Deep Extreme Learning Machine (SDELM) is proposed, which takes the advantages of semi-supervised learning, Deep Leaning (DL), and Extreme Learning Machine (ELM), so that the localization performance can be improved both in the feature extraction procedure and in the classifier. The experimental results in real indoor environments show that the proposed SDELM not only outperforms other compared methods but also reduces the calibration effort with the help of unlabeled data. }}
@article{Wang2016988,
title = {An efficient and effective convolutional auto-encoder extreme learning machine network for 3d feature learning },
journal = {Neurocomputing },
volume = {174, Part B},
number = {},
pages = {988 - 998},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.10.035},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215014940},
author = {Yueqing Wang and Zhige Xie and Kai Xu and Yong Dou and Yuanwu Lei},abstract = {Abstract 3D shape features play a crucial role in graphics applications, such as 3D shape matching, recognition, and retrieval. Various 3D shape descriptors have been developed over the last two decades; however, existing descriptors are handcrafted features that are labor-intensively designed and cannot extract discriminative information for a large set of data. In this paper, we propose a rapid 3D feature learning method, namely, a convolutional auto-encoder extreme learning machine (CAE-ELM) that combines the advantages of the convolutional neuron network, auto-encoder, and extreme learning machine (ELM). This method performs better and faster than other methods. In addition, we define a novel architecture based on CAE-ELM. The architecture accepts two types of 3D shape representation, namely, voxel data and signed distance field data (SDF), as inputs to extract the global and local features of 3D shapes. Voxel data describe structural information, whereas SDF data contain details on 3D shapes. Moreover, the proposed CAE-ELM can be used in practical graphics applications, such as 3D shape completion. Experiments show that the features extracted by CAE-ELM are superior to existing hand-crafted features and other deep learning methods or ELM models. Moreover, the classification accuracy of the proposed architecture is superior to that of other methods on ModelNet10 (91.4%) and ModelNet40 (84.35%). The training process also runs faster than existing deep learning methods by approximately two orders of magnitude. }}
@article{Zhan201619,
title = {Face detection using representation learning },
journal = {Neurocomputing },
volume = {187},
number = {},
pages = {19 - 26},
year = {2016},
note = {Recent Developments on Deep Big Vision },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.130},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215018573},
author = {Shu Zhan and Qin-Qin Tao and Xiao-Hong Li},
abstract = {Abstract Face representation is a crucial step of face detection system. In this paper, we present a fast face detection algorithm based on representation learnt using convolutional neural network (CNN) so as to explicitly capture various latent facial features. Firstly, in order to improve the speed of detection in the system, we train an Adaboost background filter which can remove the background most quickly. Secondly, we use the CNN to extract more distinctive features for those face and non-face patterns that have not been filtered by Adaboost. CNN can automatically learn and synthesize a problem-specific feature extractor from a training set, without making any assumptions or using any hand-made design concerning the features to extract or the areas of the face pattern to analyze. Finally, support vector machines (SVM) are used to detect instead of using the classification function of CNN itself. Extensive experiments demonstrate the robustness and efficiency of our system by comparing it with several popular face detection algorithms on the widely used CMU+MIT frontal face dataset and FDDB dataset. }}
@article{Vos2011127,
title = {Effects of constructing versus playing an educational game on student motivation and deep learning strategy use },
journal = {Computers & Education },
volume = {56},
number = {1},
pages = {127 - 137},
year = {2011},
note = {Serious Games },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.08.013},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510002344},
author = {Nienke Vos and Henny van der Meijden and Eddie Denessen},
abstract = {In this study the effects of two different interactive learning tasks, in which simple games were included were described with respect to student motivation and deep strategy use. The research involved 235 students from four elementary schools in The Netherlands. One group of students (N = 128) constructed their own memory ‘drag and drop’ game, whereas the other group (N = 107) played an existing ‘drag and drop’ memory game. Analyses of covariance demonstrated a significant difference between the two conditions both on intrinsic motivation and deep strategy use. The large effect sizes for both motivation and deep strategy use were in favour of the construction condition. The results suggest that constructing a game might be a better way to enhance student motivation and deep learning than playing an existing game. Despite the promising results, the low level of complexity of the games used is a study limitation. }}
@article{Schulz20154,
title = {Two-layer contractive encodings for learning stable nonlinear features },
journal = {Neural Networks },
volume = {64},
number = {},
pages = {4 - 11},
year = {2015},
note = {Special Issue on Deep Learning of Representations },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2014.09.008},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002184},
author = {Hannes Schulz and Kyunghyun Cho and Tapani Raiko and Sven Behnke},

abstract = {Abstract Unsupervised learning of feature hierarchies is often a good strategy to initialize deep architectures for supervised learning. Most existing deep learning methods build these feature hierarchies layer by layer in a greedy fashion using either auto-encoders or restricted Boltzmann machines. Both yield encoders which compute linear projections of input followed by a smooth thresholding function. In this work, we demonstrate that these encoders fail to find stable features when the required computation is in the exclusive-or class. To overcome this limitation, we propose a two-layer encoder which is less restricted in the type of features it can learn. The proposed encoder is regularized by an extension of previous work on contractive regularization. This proposed two-layer contractive encoder potentially poses a more difficult optimization problem, and we further propose to linearly transform hidden neurons of the encoder to make learning easier. We demonstrate the advantages of the two-layer encoders qualitatively on artificially constructed datasets as well as commonly used benchmark datasets. We also conduct experiments on a semi-supervised learning task and show the benefits of the proposed two-layer encoders trained with the linear transformation of perceptrons. }}
@article{Liu2015,
title = {DeepIris: Learning pairwise filter bank for heterogeneous iris verification },
journal = {Pattern Recognition Letters },
volume = {},
number = {},
pages = { - },
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.09.016},
url = {http://www.sciencedirect.com/science/article/pii/S016786551500327X},
author = {Nianfeng Liu and Man Zhang and Haiqing Li and Zhenan Sun and Tieniu Tan},
abstract = {Abstract Heterogeneous iris recognition (HIR) is in great demand for a large-scale identity management system. Iris images acquired in heterogeneous environment have large intra-class variations, such as different resolutions or different sensor optics, etc. Therefore, it is challenging to manually design a robust encoding filter to face the complex intra-class variations of heterogeneous iris images. This paper proposes a deep learning based framework for heterogeneous iris verification, namely DeepIris, which learns relational features to measure the similarity between pairs of iris images based on convolutional neural networks. DeepIris is a novel solution to iris recognition in two main aspects. (1) DeepIris learns a pairwise filter bank to establish the relationship between heterogeneous iris images, where pairs of filters are learned from two heterogeneous sources. (2) Different from two separate steps in terms of handcrafted feature extraction and feature matching in conventional solutions, DeepIris directly learns a nonlinear mapping function between pairs of iris images and their identity supervision with a pairwise filter bank (PFB) from different sources. Thus, the learned pairwise filters can adapt to new sources when given new training data. Extensive experimental results on the Q-FIRE and the CASIA cross sensor datasets demonstrate that EER (Equal Error Rate) of heterogeneous iris verification is reduced by 90% using DeepIris compared to traditional methods. }}
@article{Cavalcante2016194,
title = {Computational Intelligence and Financial Markets: A Survey and Future Directions },
journal = {Expert Systems with Applications },
volume = {55},
number = {},
pages = {194 - 211},
year = {2016},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2016.02.006},
url = {http://www.sciencedirect.com/science/article/pii/S095741741630029X},
author = {Rodolfo C. Cavalcante and Rodrigo C. Brasileiro and Victor L.F. Souza and Jarley P. Nobrega and Adriano L.I. Oliveira},
abstract = {Abstract Financial markets play an important role on the economical and social organization of modern society. In these kinds of markets, information is an invaluable asset. However, with the modernization of the financial transactions and the information systems, the large amount of information available for a trader can make prohibitive the analysis of a financial asset. In the last decades, many researchers have attempted to develop computational intelligent methods and algorithms to support the decision-making in different financial market segments. In the literature, there is a huge number of scientific papers that investigate the use of computational intelligence techniques to solve financial market problems. However, only few studies have focused on review the literature of this topic. Most of the existing review articles have a limited scope, either by focusing on a specific financial market application or by focusing on a family of machine learning algorithms. This paper presents a review of the application of several computational intelligent methods in several financial applications. This paper gives an overview of the most important primary studies published from 2009 to 2015, which cover techniques for preprocessing and clustering of financial data, for forecasting future market movements, for mining financial text information, among others. The main contributions of this paper are: (i) a comprehensive review of the literature of this field, (ii) the definition of a systematic procedure for guiding the task of building an intelligent trading system and (iii) a discussion about the main challenges and open problems in this scientific field. }}
@article{Jiao2016,
title = {A deep feature based framework for breast masses classification },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2016.02.060},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216003611},
author = {Zhicheng Jiao and Xinbo Gao and Ying Wang and Jie Li},
abstract = {Abstract Characteristic classification of mass plays a role of vital importance in diagnosis of breast cancer. The existing computer aided diagnosis (CAD) methods used to benefit a lot from low-level or middle-level features which are not that good at the simulation of real diagnostic processes, adding difficulties in improving the classification performance. In this paper, we design a deep feature based framework for breast mass classification task. It mainly contains a convolutional neural network (CNN) and a decision mechanism. Combining intensity information and deep features automatically extracted by the trained CNN from the original image, our proposed method could better simulate the diagnostic procedure operated by doctors and achieved state-of-art performance. In this framework, doctors׳ global and local impressions left by mass images were represented by deep features extracted from two different layers called high-level and middle-level features. Meanwhile, the original images were regarded as detailed descriptions of the breast mass. Then, classifiers based on features above were used in combination to predict classes of test images. And outcomes of classifiers based on different features were analyzed jointly to determine the types of test images. With the help of two kinds of feature visualization methods, deep features extracted from different layers illustrate effective in classification performance and diagnosis simulation. In addition, our method was applied to DDSM dataset and achieved high accuracy under two objective evaluation measures. }}
@article{Zhang2016,
title = {Deep Neural Networks for wireless localization in indoor and outdoor environments },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2016.02.055},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216003027},
author = {Wei Zhang and Kan Liu and Weidong Zhang and Youmei Zhang and Jason Gu},
abstract = {Abstract In this paper, we propose a wireless positioning method based on Deep Learning. To deal with the variant and unpredictable wireless signals, the positioning is casted in a four-layer Deep Neural Network (DNN) structure pre-trained by Stacked Denoising Autoencoder (SDA) that is capable of learning reliable features from a large set of noisy samples and avoids hand-engineering. Also, to maintain the temporal coherence, a Hidden Markov Model (HMM)-based fine localizer is introduced to smooth the initial positioning estimate obtained by the DNN-based coarse localizer. The data required for the experiments is collected from the real world in different periods to meet the actual environment. Experimental results indicate that the proposed system leads to substantial improvement on localization accuracy in coping with the turbulent wireless signals. }}
@article{Kawaguchi2015976,
title = {Analog Neural Circuit and Hardware Design of Deep Learning Model },
journal = {Procedia Computer Science },
volume = {60},
number = {},
pages = {976 - 985},
year = {2015},
note = {Knowledge-Based and Intelligent Information &amp; Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.08.137},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915022644},
author = {Masashi Kawaguchi and Naohiro Ishii and Masayoshi Umeno},



abstract = {Abstract In the neural network field, many application models have been proposed. Previous analog neural network models were composed of the operational amplifier and fixed resistance. It is difficult to change the connecting weight of a network. In this study, we used analog electronic multiple and sample hold circuits. The connecting weights describe the input voltage. It is easy to change the connection coefficient. This model works only on analog electronic circuits. It can finish the learning process in a very short time and this model will enable more flexible learning. However, the structure of this model includes only one input and one output network. We improved the number of unit and network layers. Moreover, we suggest the possibility of the realization the hardware implementation of the deep learning model. }}
@article{Gupta201624,
title = {A deep source-context feature for lexical selection in statistical machine translation },
journal = {Pattern Recognition Letters },
volume = {75},
number = {},
pages = {24 - 29},
year = {2016},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2016.02.014},
url = {http://www.sciencedirect.com/science/article/pii/S0167865516000738},
author = {Parth Gupta and Marta R. Costa-jussà and Paolo Rosso and Rafael E. Banchs},



abstract = {Abstract This paper presents a methodology to address lexical disambiguation in a standard phrase-based statistical machine translation system. Similarity among source contexts is used to select appropriate translation units. The information is introduced as a novel feature of the phrase-based model and it is used to select the translation units extracted from the training sentence more similar to the sentence to translate. The similarity is computed through a deep autoencoder representation, which allows to obtain effective low-dimensional embedding of data and statistically significant BLEU score improvements on two different tasks (English-to-Spanish and English-to-Hindi). }}
@article{Zhang2016,
title = {MapReduce based distributed learning algorithm for Restricted Boltzmann Machine },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.09.129},
url = {http://www.sciencedirect.com/science/article/pii/S092523121600326X},
author = {Chun-Yang Zhang and C.L. Philip Chen and Dewang Chen and Kin Tek NG},abstract = {Abstract Deep learning is recently regarded as the closest artificial intelligence model to human brain. It is about learning multiple levels of representation and abstraction that help to make sense of data such as images, sound, and text. One deep model often consists of a hierarchical architecture that has the capability to model super non-linear and stochastic problems. Restricted Boltzmann Machine (RBM) is the main constructing block of current deep networks, as most of deep architectures are built with it. Based on MapReduce framework and Hadoop distributed file system, this paper proposes a distributed algorithm for training the RBM model. Its implementation and performance are evaluated on Big Data platform-Hadoop. The main contribution of the new learning algorithm is that it solves the scalability problem that limits the development of deep learning. The intelligence growing process of human brain requires learning from Big Data. The distributed learning mechanism for RBM makes it possible to abstract sophisticated and informative features from Big Data to achieve high-level intelligence. The evaluations of the proposed learning algorithm are carried out on image inpainting and classification problems based on the BAS dataset and MNIST hand-written digits dataset. }}
@article{Wu20151,
title = {Towards dropout training for convolutional neural networks },
journal = {Neural Networks },
volume = {71},
number = {},
pages = {1 - 10},
year = {2015},
note = {},
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2015.07.007},
url = {http://www.sciencedirect.com/science/article/pii/S0893608015001446},
author = {Haibing Wu and Xiaodong Gu},



abstract = {Abstract Recently, dropout has seen increasing use in deep learning. For deep convolutional neural networks, dropout is known to work well in fully-connected layers. However, its effect in convolutional and pooling layers is still not clear. This paper demonstrates that max-pooling dropout is equivalent to randomly picking activation based on a multinomial distribution at training time. In light of this insight, we advocate employing our proposed probabilistic weighted pooling, instead of commonly used max-pooling, to act as model averaging at test time. Empirical evidence validates the superiority of probabilistic weighted pooling. We also empirically show that the effect of convolutional dropout is not trivial, despite the dramatically reduced possibility of over-fitting due to the convolutional architecture. Elaborately designing dropout training simultaneously in max-pooling and fully-connected layers, we achieve state-of-the-art performance on MNIST, and very competitive results on CIFAR-10 and CIFAR-100, relative to other approaches without data augmentation. Finally, we compare max-pooling dropout and stochastic pooling, both of which introduce stochasticity based on multinomial distributions at pooling stage. }}
@article{Zhou2015408,
title = {Combining heterogeneous deep neural networks with conditional random fields for Chinese dialogue act recognition },
journal = {Neurocomputing },
volume = {168},
number = {},
pages = {408 - 417},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.05.086},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215007845},
author = {Yucan Zhou and Qinghua Hu and Jie Liu and Yuan Jia},abstract = {Abstract Dialogue act (DA) recognition is a fundamental step for computers to understand natural-language dialogues because it can reflect the intention of a speaker. However, it is difficult to adapt traditional machine learning models to the dialogue act recognition task due to the heterogeneous features, statistical dependence between the DA tags, and complex relationship between features and the DA tags. In this paper, we propose a new model which combines heterogeneous deep neural networks with conditional random fields (HDNN-CRF) to solve this problem. The proposed model has two main advantages. First, the heterogeneous deep neural networks (HDNN) model, which is extended from the deep neural networks (DNN), retains the powerful ability of representation learning and adds a new skill of dealing with heterogeneous features effectively. Second, the conditional random fields (CRF) can capture the statistical dependence between the DA tags which carries important information to determine the DA tag of the current utterance. To verify the effectiveness of the proposed model, we conduct several experiments on a Chinese corpus, called CASIA-CASSIL corpus. Ten kinds of features are extracted from the utterances. In the experiment, we give some quantitative analysis of these kinds of features. What׳s more, when comparing classification accuracies of the proposed model and some other models, the proposed model has achieved the best performance. }}
@article{Zhang20161066,
title = {Denoising Laplacian multi-layer extreme learning machine },
journal = {Neurocomputing },
volume = {171},
number = {},
pages = {1066 - 1074},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.058},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215010644},
author = {Nan Zhang and Shifei Ding and Zhongzhi Shi},
abstract = {Abstract Most of semi-supervised learning algorithms based on manifold regularization framework are surface learning algorithms, such as semi-supervised ELM (SS-ELM) and Laplacian smooth twin support vector machine (Lap-STSVM). Multi-layer extreme learning machine (ML-ELM) stacks extreme learning machine based auto encoder (ELM-AE) to create a multi-layer neural network. ML-ELM not only approximates the complicated function but also achieves fast training time. The outputs of ELM-AE are the same as inputs, which cannot guarantee the effectiveness of the learning feature representations. We put forward extreme learning machine based denoising auto encoder (ELM-DAE) which introduces local denoising criterion into ELM-AE and is used as the basic component for Denoising ML-ELM. Resembling ML-ELM, Denoising ML-ELM stacks ELM-DAE to create a deep network. And then we introduce manifold regularization into the model of Denoising ML-ELM and propose denoising Laplacian ML-ELM (Denoising Lap-ML-ELM). Denoising Lap-ML-ELM is more efficient than SS-ELM in classification and does not need to spend too much time. Experimental results show that Denoising ML-ELM and Denoising Lap-ML-ELM are effective learning algorithms. }}
@article{Bai2015280,
title = {Subset based deep learning for RGB-D object recognition },
journal = {Neurocomputing },
volume = {165},
number = {},
pages = {280 - 292},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.03.017},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215002891},
author = {Jing Bai and Yan Wu and Junming Zhang and Fuqiang Chen},
abstract = {Abstract RGB-D camera can easily record both color and depth images and previous works have proved that combining them together could dramatically improve the RGB-D based object recognition accuracy. In this paper, a new method based on a subset approach was introduced to learn higher level features from the raw data. The raw RGB and depth images were divided into several subsets according to their shapes and colors, guaranteeing that any two different objects in each subset are nearly not similar. Then a RGB-Subset-Sparse auto-encoder was trained to extract features from RGB images and a Depth-Subset-Sparse auto-encoder was trained to extract features from depth images for each subset. Then the learned features were transmitted to recursive neural networks (RNNs) to reduce the dimensionality of the features and learn robust hierarchical feature representations. The feature representations learned from RGB images and depth images were concatenated as the final features and then sent to a softmax classifier for classification. The proposed method is evaluated on three benchmark RGB-D datasets, RGB-D dataset of Lai et al., 2D3D dataset of Browatzki et al. and Aharon dataset of Aharon et al. Compared with other methods, ours achieves state-of-the-art performance on the first two datasets. Furthermore, to validate the generalization of our subset approach, we also do some extra experiments of applying the subsets approach to several previous works, these accuracies improved significantly. }}
@article{Hu201663,
title = {A new deep neural network based on a stack of single-hidden-layer feedforward neural networks with randomly fixed hidden neurons },
journal = {Neurocomputing },
volume = {171},
number = {},
pages = {63 - 72},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.06.017},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215008395},
author = {Junying Hu and Jiangshe Zhang and Chunxia Zhang and Juan Wang},
abstract = {Abstract Single-hidden layer feedforward neural networks with randomly fixed hidden neurons (RHN-SLFNs) have been shown, both theoretically and experimentally, to be fast and accurate. Besides, it is well known that deep architectures can find higher-level representations, thus can potentially capture relevant higher-level abstractions. But most of current deep learning methods require a long time to solve a non-convex optimization problem. In this paper, we propose a stacked deep neural network, St-URHN-SLFNs, via unsupervised RHN-SLFNs according to stacked generalization philosophy to deal with unsupervised problems. Empirical study on a wide range of data sets demonstrates that the proposed algorithm outperforms the state-of-the-art unsupervised algorithms in terms of accuracy. On the computational effectiveness, the proposed algorithm runs much faster than other deep learning methods, i.e. deep autoencoder (DA) and stacked autoencoder (SAE), and little slower than other methods. }}
@article{Xu2014328,
title = {Improving mixing rate with tempered transition for learning restricted Boltzmann machines },
journal = {Neurocomputing },
volume = {139},
number = {},
pages = {328 - 335},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.02.024},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214004196},
author = {Jungang Xu and Hui Li and Shilong Zhou},abstract = {Abstract Recently, as the building block of deep generative models such as Deep Belief Networks (DBNs), Restricted Boltzmann Machines (RBMs) have attracted much attention. RBM is a Markov Random Field (MRF) associated with a bipartite undirected graph which is famous for powerful expression and tractable inference. While training an RBM, we need to sample from the model. The larger the mixing rate is, the smaller the bias of the samples is. However, neither Gibbs sampling based training methods such as Contrastive Divergence (CD) nor Parallel Tempering based training methods can achieve satisfying mixing rate, which causes poor rendering of the diversity of the modes captured by these trained models. This property may hinder the existing methods to approximate the likelihood gradient. In order to alleviate this problem, we attempt to introduce Tempered Transition, an advanced tempered Markov Chain Monte Carlo method, into training RBMs to replace Gibbs sampling or Parallel Tempering for sampling from RBMs. Experimental results show that our proposed method outperforms the existing methods to achieve better mixing rate and to help approximate the likelihood gradient. }}
@article{Schmidhuber201585,
title = {Deep learning in neural networks: An overview },
journal = {Neural Networks },
volume = {61},
number = {},
pages = {85 - 117},
year = {2015},
note = {},
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2014.09.003},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002135},
author = {Jürgen Schmidhuber},
abstract = {Abstract In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning &amp; evolutionary computation, and indirect search for short programs encoding deep and large networks. }}
@article{DeMarsico2016,
title = {Iris Recognition through Machine Learning Techniques: a Survey },
journal = {Pattern Recognition Letters },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2016.02.001},
url = {http://www.sciencedirect.com/science/article/pii/S0167865516000477},
author = {Maria De Marsico and Alfredo Petrosino and Stefano Ricciardi},abstract = {Abstract Iris recognition is one of the most promising fields in biometrics. Notwithstanding this, there are not so many research works addressing it by Machine Learning techniques. In this survey, we especially focus on recognition, and leave the detection and feature extraction problems in the background. However, the kind of features used to code the iris pattern may significantly influence the complexity of the methods and their performance. In other words, complexity affects learning, and iris patterns require relatively complex feature vectors, even if their size can be optimized. A cross-comparison of these two parameters, feature complexity vs. learning effectiveness, in the context of different learning algorithms, would require an unbiased common benchmark. Moreover, at present it is still very difficult to reproduce techniques and experiments due to the lack of either sufficient implementation details or reliable shared code. }}
@article{An2015137,
title = {Split and merge algorithm for deep learning and its application for additional classes },
journal = {Pattern Recognition Letters },
volume = {65},
number = {},
pages = {137 - 144},
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.07.024},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515002330},
author = {Hongsub An and Hyeon-min Shim and Sang-il Na and Sangmin Lee},abstract = {Abstract In this paper, we propose a novel split training and merge algorithm for deep learning. The proposed algorithm improves recognition accuracy and suggests a new approach for retraining. The algorithm is motivated by the genetic algorithm (GA) and is composed of two procedures. The first procedure initializes two individual networks using deep belief networks (DBNs), and the second procedure merges the two networks using the GA. Biases and weights of the network that is trained using DBNs are represented as a matrix between each layer, and each row of this matrix is used as a chromosome in the merge procedure. To evaluate the performance, we conduct two set of experiments. The first set is to recognize accuracy of the proposed algorithm, and the second set is for a new retraining approach. The results show that the proposed algorithm has a lower average error rate (6.84 ± 4.57%) than the DBNs, and it can add classes at a lower average error rate (9.06 ± 6.17% and 10.17 ± 4.51%) without pre-training using the restrict Boltzmann machines (RBMs) for existing classes data. }}
@article{Santoni2015493,
title = {Cattle Race Classification Using Gray Level Co-occurrence Matrix Convolutional Neural Networks },
journal = {Procedia Computer Science },
volume = {59},
number = {},
pages = {493 - 502},
year = {2015},
note = {International Conference on Computer Science and Computational Intelligence (ICCSCI 2015) },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.525},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915020542},
author = {Mayanda Mega Santoni and Dana Indra Sensuse and Aniati Murni Arymurthy and Mohamad Ivan Fanany},abstract = {Abstract In e-Livestock management system, practical and accurate cattle race identification is paramount. This paper presents a cattle race identification system from their images. We propose a deep learning architecture, which is called as Gray Level Co-occurrence Matrix Convolutional Neural Networks (GLCM-CNN), to semi-unsupervisedly identify a cattles race given thousands of its images with complex background settings. We introduce and evaluate GLCM features, i.e., contrast, energy, and homogeneity into CNN learning for GLCMs capability to recognize pattern with diverse variations, robustness to geometric distortion, and simple transformation. Our experiments show that GLCM-CNN is gives higher classification accuracy and requires less number of learning iterations than the original CNN. In our approach, the data input layer has better distinguishing features than the original image. In addition, our method does not require any prior segmentation process. In this paper, we also address the reduction of computation overhead using saliency maps. }}
@article{Kuen20152964,
title = {Self-taught learning of a deep invariant representation for visual tracking via temporal slowness principle },
journal = {Pattern Recognition },
volume = {48},
number = {10},
pages = {2964 - 2982},
year = {2015},
note = {Discriminative Feature Learning from Big Data for Visual Recognition },
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.02.012},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315000722},
author = {Jason Kuen and Kian Ming Lim and Chin Poo Lee},
abstract = {Abstract Visual representation is crucial for visual tracking method׳s performances. Conventionally, visual representations adopted in visual tracking rely on hand-crafted computer vision descriptors. These descriptors were developed generically without considering tracking-specific information. In this paper, we propose to learn complex-valued invariant representations from tracked sequential image patches, via strong temporal slowness constraint and stacked convolutional autoencoders. The deep slow local representations are learned offline on unlabeled data and transferred to the observational model of our proposed tracker. The proposed observational model retains old training samples to alleviate drift, and collect negative samples which are coherent with target׳s motion pattern for better discriminative tracking. With the learned representation and online training samples, a logistic regression classifier is adopted to distinguish target from background, and retrained online to adapt to appearance changes. Subsequently, the observational model is integrated into a particle filter framework to perform visual tracking. Experimental results on various challenging benchmark sequences demonstrate that the proposed tracker performs favorably against several state-of-the-art trackers. }}
@article{Yu2015308,
title = {Learning deep representations via extreme learning machines },
journal = {Neurocomputing },
volume = {149, Part A},
number = {},
pages = {308 - 315},
year = {2015},
note = {Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.03.077},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214011461},
author = {Wenchao Yu and Fuzhen Zhuang and Qing He and Zhongzhi Shi},

abstract = {Abstract Extreme learning machine (ELM) as an emerging technology has achieved exceptional performance in large-scale settings, and is well suited to binary and multi-class classification, as well as regression tasks. However, existing ELM and its variants predominantly employ single hidden layer feedforward networks, leaving the popular and potentially powerful stacked generalization principle unexploited for seeking predictive deep representations of input data. Deep architectures can find higher-level representations, thus can potentially capture relevant higher-level abstractions. But most of current deep learning methods require solving a difficult and non-convex optimization problem. In this paper, we propose a stacked model, DrELM, to learn deep representations via extreme learning machine according to stacked generalization philosophy. The proposed model utilizes ELM as a base building block and incorporates random shift and kernelization as stacking elements. Specifically, in each layer, DrELM integrates a random projection of the predictions obtained by ELM into the original feature, and then applies kernel functions to generate the resultant feature. To verify the classification and regression performance of DrELM, we conduct the experiments on both synthetic and real-world data sets. The experimental results show that DrELM outperforms ELM and kernel ELMs, which appear to demonstrate that DrELM could yield predictive features that are suitable for prediction tasks. The performances of the deep models (i.e. Stacked Auto-encoder) are comparable. However, due to the utilization of ELM, DrELM is easier to learn and faster in testing. }}
@article{Zhang2016,
title = {A survey of randomized algorithms for training neural networks },
journal = {Information Sciences },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2016.01.039},
url = {http://www.sciencedirect.com/science/article/pii/S002002551600058X},
author = {Le Zhang and P.N. Suganthan},abstract = {Abstract As a powerful tool for data regression and classification, neural networks have received considerable attention from researchers in fields such as machine learning, statistics, computer vision and so on. There exists a large body of research work on network training, among which most of them tune the parameters iteratively. Such methods often suffer from local minima and slow convergence. It has been shown that randomization based training methods can significantly boost the performance or efficiency of neural networks. Among these methods, most approaches use randomization either to change the data distributions, and/or to fix a part of the parameters or network configurations. This article presents a comprehensive survey of the earliest work and recent advances as well as some suggestions for future research. }}
@article{Cox2015349,
title = {A Signal Processing Approach for Cyber Data Classification with Deep Neural Networks },
journal = {Procedia Computer Science },
volume = {61},
number = {},
pages = {349 - 354},
year = {2015},
note = {Complex Adaptive Systems San Jose, CA November 2-4, 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.09.156},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915029865},
author = {Jonathan A. Cox and Conrad D. James and James B. Aimone},
abstract = {Abstract Recent cyber security events have demonstrated the need for algorithms that adapt to the rapidly evolving threat landscape of complex network systems. In particular, human analysts often fail to identify data exfiltration when it is encrypted or disguised as innocuous data. Signature-based approaches for identifying data types are easily fooled and analysts can only investigate a small fraction of network events. However, neural networks can learn to identify subtle patterns in a suitably chosen input space. To this end, we have developed a signal processing approach for classifying data files which readily adapts to new data formats. We evaluate the performance for three input spaces consisting of the power spectral density, byte probability distribution and sliding-window entropy of the byte sequence in a file. By combining all three, we trained a deep neural network to discriminate amongst nine common data types found on the Internet with 97.4% accuracy. }}
@article{AbdelZaher2016139,
title = {Breast cancer classification using deep belief networks },
journal = {Expert Systems with Applications },
volume = {46},
number = {},
pages = {139 - 144},
year = {2016},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2015.10.015},
url = {http://www.sciencedirect.com/science/article/pii/S0957417415007101},
author = {Ahmed M. Abdel-Zaher and Ayman M. Eldeib},
abstract = {Abstract Over the last decade, the ever increasing world-wide demand for early detection of breast cancer at many screening sites and hospitals has resulted in the need of new research avenues. According to the World Health Organization (WHO), an early detection of cancer greatly increases the chances of taking the right decision on a successful treatment plan. The Computer-Aided Diagnosis (CAD) systems are applied widely in the detection and differential diagnosis of many different kinds of abnormalities. Therefore, improving the accuracy of a CAD system has become one of the major research areas. In this paper, a CAD scheme for detection of breast cancer has been developed using deep belief network unsupervised path followed by back propagation supervised path. The construction is back-propagation neural network with Liebenberg Marquardt learning function while weights are initialized from the deep belief network path (DBN-NN). Our technique was tested on the Wisconsin Breast Cancer Dataset (WBCD). The classifier complex gives an accuracy of 99.68% indicating promising results over previously-published studies. The proposed system provides an effective classification model for breast cancer. In addition, we examined the architecture at several train-test partitions. }}
@article{Altahhan2015478,
title = {Navigating a Robot through Big Visual Sensory Data },
journal = {Procedia Computer Science },
volume = {53},
number = {},
pages = {478 - 485},
year = {2015},
note = {INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.325},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915018281},
author = {Abdulrahman Altahhan},
abstract = {Abstract This paper describes a reinforcement learning architecture that is capable of incorporating deeply learned feature representation of a robot's unknown working environment. An autoencoder is used along with convolutional and pooling layers to deduce the reduced feature representation based on a set of images taken by the agent. This representation is used to discover and learn the best route to navigate to a goal. The features are fed to an actor layer that can learn from a value function calculated by a second output layer. The policy is ɛ-greedy and the effect is similar to actor-critic architecture where temporal difference error is back propagated from the critic to the actor. This compact architecture helps in reducing the overhead of setting up a desired fully fledged actor-critic architecture that typically needs extra processing time. Hence, the model is ideal for dealing with lots of data coming from visual sensor that needs speedy processing. The processing is accomplished off board due to the limitation of the used robot but latency was compensated by the speedy processing. Adaptability for the different data sizes, critical to big data processing, is realized by the ability to shrink or expand the whole architecture to fit different deeply learned feature dimensions. This added flexibility is crucial for setting up such model since the space dimensionality is not known prior to operating in the environment. Initial experimental results on real robot show that the agent accomplished good level of accuracy and efficacy in reaching the goal. }}
@article{Roy2016,
title = {Sparsity-inducing dictionaries for effective action classification },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.03.011},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316001060},
author = {Debaditya Roy and M. Srinivas and C. Krishna Mohan},abstract = {Abstract Action recognition in unconstrained videos is one of the most important challenges in computer vision. In this paper, we propose sparsity-inducing dictionaries as an effective representation for action classification in videos. We demonstrate that features obtained from sparsity based representation provide discriminative information useful for classification of action videos into various action classes. We show that the constructed dictionaries are distinct for a large number of action classes resulting in a significant improvement in classification accuracy on the HMDB51 dataset. We further demonstrate the efficacy of dictionaries and sparsity based classification on other large action video datasets like UCF50. }}
@article{Xin201687,
title = {ARCH: Adaptive recurrent-convolutional hybrid networks for long-term action recognition },
journal = {Neurocomputing },
volume = {178},
number = {},
pages = {87 - 102},
year = {2016},
note = {Smart Computing for Large Scale Visual Data Sensing and ProcessingSelected papers from the 2014 International Conference on Smart Computing (SMARTCOMP 2014) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.09.112},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215016100},
author = {Miao Xin and Hong Zhang and Helong Wang and Mingui Sun and Ding Yuan},



abstract = {Abstract Recognition of human actions from digital video is a challenging task due to complex interfering factors in uncontrolled realistic environments. In this paper, we propose a learning framework using static, dynamic and sequential mixed features to solve three fundamental problems: spatial domain variation, temporal domain polytrope, and intra- and inter-class diversities. Utilizing a cognitive-based data reduction method and a hybrid network upon networks architecture, we extract human action representations which are robust against spatial and temporal interferences and adaptive to variations in both action speed and duration. We evaluated our method on the UCF101 and other three challenging datasets. Our results demonstrated a superior performance of the proposed algorithm in human action recognition. }}
@article{Yang201691,
title = {Sparse Robust Filters for scene classification of Synthetic Aperture Radar (SAR) images },
journal = {Neurocomputing },
volume = {184},
number = {},
pages = {91 - 98},
year = {2016},
note = {RoLoD: Robust Local Descriptors for Computer Vision 2014 },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.08.103},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017646},
author = {Shuyuan Yang and Min Wang and Hezhao Long and Zhi Liu},abstract = {Abstract With the increasing resolution of Synthetic Aperture Radar (SAR) images, extracting their discriminative features for scenes classification has become a challenging task, because SAR images are very sensitive to target aspect brought by shadowing effects, interaction of the signature with the environment, and so on. Moreover, SAR images are remarkably polluted by the multiplicative speckle noise, which makes the conventional feature extractors inefficient. In this paper we advance new Sparse Robust Filters (SRFs) for automatic learning of discriminant features of scenes. A Hierarchical Group Sparse Coding (HGSC) model is proposed to learn a set of sparse and robust filters, to capture the multiscale local descriptors that are robust to noises. Some experiments are taken on a TerraSAR-X images dataset (in the middle of the Swabian Jura, the Nördlinger Ries, HH, observed on July, 2007), and a Moving and Stationary Target Acquisition and Recognition (MSTAR) dataset, to evaluate the performance of our proposed method. The experimental results show that our method can achieve higher classification accuracy compared with other related approaches. }}
@article{Zhou2013536,
title = {Active deep learning method for semi-supervised sentiment classification },
journal = {Neurocomputing },
volume = {120},
number = {},
pages = {536 - 546},
year = {2013},
note = {Image Feature Detection and Description },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.04.017},
url = {http://www.sciencedirect.com/science/article/pii/S0925231213004888},
author = {Shusen Zhou and Qingcai Chen and Xiaolong Wang},abstract = {Abstract In natural language processing community, sentiment classification based on insufficient labeled data is a well-known challenging problem. In this paper, a novel semi-supervised learning algorithm called active deep network (ADN) is proposed to address this problem. First, we propose the semi-supervised learning framework of ADN. ADN is constructed by restricted Boltzmann machines (RBM) with unsupervised learning based on labeled reviews and abundant of unlabeled reviews. Then the constructed structure is fine-tuned by gradient-descent based supervised learning with an exponential loss function. Second, in the semi-supervised learning framework, we apply active learning to identify reviews that should be labeled as training data, then using the selected labeled reviews and all unlabeled reviews to train ADN architecture. Moreover, we combine the information density with ADN, and propose information ADN (IADN) method, which can apply the information density of all unlabeled reviews in choosing the manual labeled reviews. Experiments on five sentiment classification datasets show that ADN and IADN outperform classical semi-supervised learning algorithms, and deep learning techniques applied for sentiment classification. }}
@article{Erhel2013156,
title = {Digital game-based learning: Impact of instructions and feedback on motivation and learning effectiveness },
journal = {Computers & Education },
volume = {67},
number = {},
pages = {156 - 167},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.02.019},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513000699},
author = {S. Erhel and E. Jamet},abstract = {Abstract Although many studies have investigated the effects of digital game-based learning (DGBL) on learning and motivation, its benefits have never been systematically demonstrated. In our first experiment, we sought to identify the conditions under which DGBL is most effective, by analyzing the effects of two different types of instructions (learning instruction vs. entertainment instruction). Results showed that the learning instruction elicited deeper learning than the entertainment one, without impacting negatively on motivation. In our second experiment, we showed that if learners are given regular feedback about their performance, the entertainment instruction results in deep learning. These two experiments demonstrate that a serious game environment can promote learning and motivation, providing it includes features that prompt learners to actively process the educational content. }}
@article{Byeon201523,
title = {Scene analysis by mid-level attribute learning using 2D LSTM networks and an application to web-image tagging },
journal = {Pattern Recognition Letters },
volume = {63},
number = {},
pages = {23 - 29},
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.06.003},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515001634},
author = {Wonmin Byeon and Marcus Liwicki and Thomas M. Breuel},
abstract = {Abstract This paper describes an approach to scene analysis based on supervised training of 2D Long Short-Term Memory recurrent neural networks (LSTM networks). Unlike previous methods, our approach requires no manual construction of feature hierarchies or incorporation of other prior knowledge. Rather, like deep learning approaches using convolutional networks, our recognition networks are trained directly on raw pixel values. However, in contrast to convolutional neural networks, our approach uses 2D LSTM networks at all levels. Our networks yield per pixel mid-level classifications of input images; since training data for such applications is not available in large numbers, we describe an approach to generating artificial training data, and then evaluate the trained networks on real-world images. Our approach performed significantly better than others methods including Convolutional Neural Networks (ConvNet), yet using two orders of magnitude fewer parameters. We further show the experiment on a recently published dataset, outdoor scene attribute dataset for fair comparisons of scene attribute learning which had significant performance improvement (ca. 21%). Finally, our approach is successfully applied on a real-world application, automatic web-image tagging. }}
@article{Zlatović201532,
title = {Using online assessments to stimulate learning strategies and achievement of learning goals },
journal = {Computers & Education },
volume = {91},
number = {},
pages = {32 - 45},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.09.012},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515300488},
author = {Miran Zlatović and Igor Balaban and Dragutin Kermek},
abstract = {Abstract The main goals of this research are: (i) to explore the influence that announcement of certain type of online assessment has on students' learning strategies and (ii) to explore the influence of stimulated learning strategies on achievement levels that students exhibit during assessments. Research has been conducted by testing and surveying 351 students from higher education institutions. Results indicate that students' learning strategies can be influenced in a relatively short period of time by announcing various types of online assessments and that steering to more desirable deep learning strategies has positive impact on both formal and perceived levels of success in achieving the desired learning goals. These findings can be used to create a novel adaptive online assessment system that incorporates the elements of adaptivity within a series of assessments and uses post-assessment feedback to steer students’ learning strategies. }}
@article{Offir20081172,
title = {Surface and deep learning processes in distance education: Synchronous versus asynchronous systems },
journal = {Computers & Education },
volume = {51},
number = {3},
pages = {1172 - 1183},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2007.10.009},
url = {http://www.sciencedirect.com/science/article/pii/S0360131507001406},
author = {Baruch Offir and Yossi Lev and Rachel Bezalel},


abstract = {Distance learning is different from regular learning in the classroom. One of the main factors which influence the effectiveness of the learning process is the interaction that exists between the teacher and the student. Our research indicates that different interactions have different effects. There are two methods used for implementing distance learning systems, i.e. synchronous and asynchronous. Our research is based on the model developed by Oliver and McLaughlin. According to this model, there exist five types of teacher–student interactions: social, procedural, expository, explanatory and cognitive. The present study refers to the cognitive interaction and differentiates between surface processes and deep processes. The study presents different variables and their influences on the students’ achievements and their satisfaction from learning via a synchronous versus an asynchronous distance learning system. The interaction level between the students and the teacher and among the students was found to be a significant factor in determining the effectiveness of the teaching method. The observations and interviews which we held with the students helped clarify the information that was obtained using the quantitative research tools, and showed that the presence of a teacher–student interaction which accompanies the learning process is very important for all learners. However, students with high-level thinking can overcome the low-level of interactions in asynchronous learning. }}
@article{Liang2016,
title = {Incorporating image priors with deep convolutional neural networks for image super-resolution },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2016.02.046},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216002836},
author = {Yudong Liang and Jinjun Wang and Sanping Zhou and Yihong Gong and Nanning Zheng},abstract = {Abstract Deep convolutional neural network has been applied for single image super-resolution problem and demonstrated state-of-the-art quality. This paper presents several prior information that could be utilized during the training process of the deep convolutional neural network. The first type of prior focuses on edges and texture restoration in the output, and the second type of prior utilizes multiple upscaling factors to consider the structure recurrence across different scales. As demonstrated by our experimental results, the proposed framework could significantly accelerate the training speed for more than ten times and at the same time lead to better image quality. The generated super-resolution image achieves visually sharper and more pleasant restoration as well as superior objectively evaluation results compared to state-of-the-art methods. }}
@article{Leng2015,
title = {3D object understanding with 3D Convolutional Neural Networks },
journal = {Information Sciences },
volume = {},
number = {},
pages = { - },
year = {2015},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2015.08.007},
url = {http://www.sciencedirect.com/science/article/pii/S0020025515005812},
author = {Biao Leng and Yu Liu and Kai Yu and Xiangyang Zhang and Zhang Xiong},



abstract = {Abstract Feature engineering plays an important role in object understanding. Expressive discriminative features can guarantee the success of object understanding tasks. With remarkable ability of data abstraction, deep hierarchy architecture has the potential to represent objects. For 3D objects with multiple views, the existing deep learning methods can not handle all the views with high quality. In this paper, we propose a 3D convolutional neural network, a deep hierarchy model which has a similar structure with convolutional neural network. We employ stochastic gradient descent (SGD) method to pretrain the convolutional layer, and then a back-propagation method is proposed to fine-tune the whole network. Finally, we use the result of the two phases for 3D object retrieval. The proposed method is shown to out-perform the state-of-the-art approaches by experiments conducted on publicly available 3D object datasets. }}
@article{Liu20112287,
title = {Discriminative deep belief networks for visual data classification },
journal = {Pattern Recognition },
volume = {44},
number = {10–11},
pages = {2287 - 2296},
year = {2011},
note = {Semi-Supervised Learning for Visual Content Analysis and Understanding },
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2010.12.012},
url = {http://www.sciencedirect.com/science/article/pii/S0031320310005789},
author = {Yan Liu and Shusen Zhou and Qingcai Chen},abstract = {Visual data classification using insufficient labeled data is a well-known hard problem. Semi-supervise learning, which attempts to exploit the unlabeled data in additional to the labeled ones, has attracted much attention in recent years. This paper proposes a novel semi-supervised classifier called discriminative deep belief networks (DDBN). DDBN utilizes a new deep architecture to integrate the abstraction ability of deep belief nets (DBN) and discriminative ability of backpropagation strategy. For unsupervised learning, DDBN inherits the advantage of DBN, which preserves the information well from high-dimensional features space to low-dimensional embedding. For supervised learning, through a well designed objective function, the backpropagation strategy directly optimizes the classification results in training dataset by refining the parameter space. Moreover, we apply DDBN to visual data classification task and observe an important fact that the learning ability of deep architecture is seriously underrated in real-world applications, especially in visual data analysis. The comparative experiments on standard datasets of different types and different scales demonstrate that the proposed algorithm outperforms both representative semi-supervised classifiers and existing deep learning techniques. For visual dataset, we can further improve the DDBN performance with much larger and deeper architecture. }}
@article{Cao20153016,
title = {Large scale crowd analysis based on convolutional neural network },
journal = {Pattern Recognition },
volume = {48},
number = {10},
pages = {3016 - 3024},
year = {2015},
note = {Discriminative Feature Learning from Big Data for Visual Recognition },
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.04.001},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315001259},
author = {Lijun Cao and Xu Zhang and Weiqiang Ren and Kaiqi Huang},abstract = {Abstract Nowadays crowd surveillance is an active area of research. Crowd surveillance is always affected by various conditions, such as different scenes, weather, or density of crowd, which restricts the real application. This paper proposes a convolutional neural network (CNN) based method to monitor the number of crowd flow, such as the number of entering or leaving people in high density crowd. It uses an indirect strategy of combining classification CNN with regression CNN, which is more robust than the direct way. A large enough database is built with lots of real videos of public gates, and plenty of experiments show that the proposed method performs well under various weather conditions no matter either in daytime or at night. }}
@article{Mishra201630,
title = {Enhancing energy minimization framework for scene text recognition with top-down cues },
journal = {Computer Vision and Image Understanding },
volume = {145},
number = {},
pages = {30 - 42},
year = {2016},
note = {Light Field for Computer Vision },
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2016.01.002},
url = {http://www.sciencedirect.com/science/article/pii/S107731421600014X},
author = {Anand Mishra and Karteek Alahari and C.V. Jawahar},
abstract = {Abstract Recognizing scene text is a challenging problem, even more so than the recognition of scanned documents. This problem has gained significant attention from the computer vision community in recent years, and several methods based on energy minimization frameworks and deep learning approaches have been proposed. In this work, we focus on the energy minimization framework and propose a model that exploits both bottom-up and top-down cues for recognizing cropped words extracted from street images. The bottom-up cues are derived from individual character detections from an image. We build a conditional random field model on these detections to jointly model the strength of the detections and the interactions between them. These interactions are top-down cues obtained from a lexicon-based prior, i.e., language statistics. The optimal word represented by the text image is obtained by minimizing the energy function corresponding to the random field model. We evaluate our proposed algorithm extensively on a number of cropped scene text benchmark datasets, namely Street View Text, ICDAR 2003, 2011 and 2013 datasets, and IIIT 5K-word, and show better performance than comparable methods. We perform a rigorous analysis of all the steps in our approach and analyze the results. We also show that state-of-the-art convolutional neural network features can be integrated in our framework to further improve the recognition performance. }}
@article{Zabalza20161,
title = {Novel segmented stacked autoencoder for effective dimensionality reduction and feature extraction in hyperspectral imaging },
journal = {Neurocomputing },
volume = {185},
number = {},
pages = {1 - 10},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.11.044},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017798},
author = {Jaime Zabalza and Jinchang Ren and Jiangbin Zheng and Huimin Zhao and Chunmei Qing and Zhijing Yang and Peijun Du and Stephen Marshall},abstract = {Abstract Stacked autoencoders (SAEs), as part of the deep learning (DL) framework, have been recently proposed for feature extraction in hyperspectral remote sensing. With the help of hidden nodes in deep layers, a high-level abstraction is achieved for data reduction whilst maintaining the key information of the data. As hidden nodes in SAEs have to deal simultaneously with hundreds of features from hypercubes as inputs, this increases the complexity of the process and leads to limited abstraction and performance. As such, segmented SAE (S-SAE) is proposed by confronting the original features into smaller data segments, which are separately processed by different smaller SAEs. This has resulted in reduced complexity but improved efficacy of data abstraction and accuracy of data classification. }}
@article{Shi2016,
title = {Stacked deep polynomial network based representation learning for tumor classification with small ultrasound image dataset },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2016.01.074},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216002344},
author = {Jun Shi and Shichong Zhou and Xiao Liu and Qi Zhang and Minhua Lu and Tianfu Wang},

abstract = {Abstract Ultrasound imaging has been widely used for tumor detection and diagnosis. In ultrasound based computer-aided diagnosis, feature representation is a crucial step. In recent years, deep learning (DL) has achieved great success in feature representation learning. However, it generally suffers from the small sample size problem. Since the medical datasets usually have small training samples, texture features are still very commonly used for small ultrasound image datasets. Compared with the commonly used DL algorithms, the newly proposed deep polynomial network (DPN) algorithm not only shows superior performance on large scale data, but also has the potential to learn effective feature representation from a relatively small dataset. In this work, a stacked DPN (S-DPN) algorithm is proposed to further improve the representation performance of the original DPN, and S-DPN is then applied to the task of texture feature learning for ultrasound based tumor classification with small dataset. The task tumor classification is performed on two image dataset, namely the breast B-mode ultrasound dataset and prostate ultrasound elastography dataset. In both cases, experimental results show that S-DPN achieves the best performance with classification accuracies of 92.40±1.1% and 90.28±2.78% on breast and prostate ultrasound datasets, respectively. This level of accuracy is significantly superior to all other compared algorithms in this work, including stacked auto-encoder and deep belief network. It suggests that S-DPN can be a strong candidate for the texture feature representation learning on small ultrasound datasets. }}
@article{MenchónLara2015161,
title = {Fully automatic segmentation of ultrasound common carotid artery images based on machine learning },
journal = {Neurocomputing },
volume = {151, Part 1},
number = {},
pages = {161 - 167},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.09.066},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214013034},
author = {Rosa-María Menchón-Lara and José-Luis Sancho-Gómez},

abstract = {Abstract Atherosclerosis is responsible for a large proportion of cardiovascular diseases (CVD), which are the leading cause of death in the world. The atherosclerotic process is a complex degenerative condition mainly affecting the medium- and large-size arteries, which begins in childhood and may remain unnoticed during decades. It causes thickening and the reduction of elasticity in the blood vessels. An early diagnosis of this condition is crucial to prevent patients from suffering more serious pathologies (heart attacks and strokes). The evaluation of the Intima-Media Thickness (IMT) of the Common Carotid Artery (CCA) in B-mode ultrasound images is considered the most useful tool for the investigation of preclinical atherosclerosis. Usually, it is manually measured by the radiologists. This paper proposes a fully automatic segmentation technique based on Machine Learning and Statistical Pattern Recognition to measure IMT from ultrasound CCA images. The pixels are classified by means of artificial neural networks to identify the IMT boundaries. Moreover, the concepts of Auto-Encoders (AE) and Deep Learning have been included in the classification strategy. The suggested approach is tested on a set of 55 longitudinal ultrasound images of the CCA by comparing the automatic segmentation with four manual tracings. }}
@article{Chen201548,
title = {Bio-inspired homogeneous multi-scale place recognition },
journal = {Neural Networks },
volume = {72},
number = {},
pages = {48 - 61},
year = {2015},
note = {Neurobiologically Inspired Robotics: Enhanced Autonomy through Neuromorphic Cognition },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2015.10.002},
url = {http://www.sciencedirect.com/science/article/pii/S0893608015002002},
author = {Zetao Chen and Stephanie Lowry and Adam Jacobson and Michael E. Hasselmo and Michael Milford},abstract = {Abstract Robotic mapping and localization systems typically operate at either one fixed spatial scale, or over two, combining a local metric map and a global topological map. In contrast, recent high profile discoveries in neuroscience have indicated that animals such as rodents navigate the world using multiple parallel maps, with each map encoding the world at a specific spatial scale. While a number of theoretical-only investigations have hypothesized several possible benefits of such a multi-scale mapping system, no one has comprehensively investigated the potential mapping and place recognition performance benefits for navigating robots in large real world environments, especially using more than two homogeneous map scales. In this paper we present a biologically-inspired multi-scale mapping system mimicking the rodent multi-scale map. Unlike hybrid metric-topological multi-scale robot mapping systems, this new system is homogeneous, distinguishable only by scale, like rodent neural maps. We present methods for training each network to learn and recognize places at a specific spatial scale, and techniques for combining the output from each of these parallel networks. This approach differs from traditional probabilistic robotic methods, where place recognition spatial specificity is passively driven by models of sensor uncertainty. Instead we intentionally create parallel learning systems that learn associations between sensory input and the environment at different spatial scales. We also conduct a systematic series of experiments and parameter studies that determine the effect on performance of using different neural map scaling ratios and different numbers of discrete map scales. The results demonstrate that a multi-scale approach universally improves place recognition performance and is capable of producing better than state of the art performance compared to existing robotic navigation algorithms. We analyze the results and discuss the implications with respect to several recent discoveries and theories regarding how multi-scale neural maps are learnt and used in the mammalian brain. }}
@article{Snaider2014188,
title = {Vector LIDA },
journal = {Procedia Computer Science },
volume = {41},
number = {},
pages = {188 - 203},
year = {2014},
note = {5th Annual International Conference on Biologically Inspired Cognitive Architectures, 2014 BICA },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2014.11.103},
url = {http://www.sciencedirect.com/science/article/pii/S1877050914015488},
author = {Javier Snaider and Stan Franklin},abstract = {Abstract The representation paradigm used by a cognitive architecture helps to determine the kind of processes that it can perform more efficiently. Vector LIDA is a variation of the LIDA cognitive architecture that employs high-dimensional Modular Composite Representation (MCR) vectors as its main representation model and Integer Sparse Distributed Memory as its main memory implementation technology. The advantages of this new model include a more realistic and biologically plausible model, better integration with its episodic memory, better integration with other low level perceptual processing (such as deep learning systems), better scalability, and easier learning mechanisms. Here, after briefly recapping the LIDA model and MCR, we describe Vector LIDA and argue for its several advantages. }}
@article{Ijjina2016,
title = {Human action recognition using genetic algorithms and convolutional neural networks },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.01.012},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316000169},
author = {Earnest Paul Ijjina and Krishna Mohan Chalavadi},abstract = {Abstract In this paper, an approach for human action recognition using genetic algorithms (GA) and deep convolutional neural networks (CNN) is proposed. We demonstrate that initializing the weights of a convolutional neural network (CNN) classifier based on solutions generated by genetic algorithms (GA) minimizes the classification error. A gradient descent algorithm is used to train the CNN classifiers (to find a local minimum) during fitness evaluations of GA chromosomes. The global search capabilities of genetic algorithms and the local search ability of gradient descent algorithm are exploited to find a solution that is closer to global-optimum. We show that combining the evidences of classifiers generated using genetic algorithms helps to improve the performance. We demonstrate the efficacy of the proposed classification system for human action recognition on UCF50 dataset. }}
@article{Chandra20161205,
title = {Fast learning in Deep Neural Networks },
journal = {Neurocomputing },
volume = {171},
number = {},
pages = {1205 - 1215},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.093},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215011017},
author = {B. Chandra and Rajesh K. Sharma},



abstract = {Abstract The paper aims at speeding up Deep Neural Networks (DNN) since this is one of the major bottlenecks in deep learning. This has been achieved by parameterizing the weight matrix using low rank factorization and periodic functions. By parameterization, the weight matrix is split into two matrices of smaller size of rank K with periodic functions. A shrinkage parameter has been introduced which helps in reducing the number of parameters and thus helps in increasing the speed to a great extent. Performance of the proposed parameterization is compared with standard DNN, DNN based on weight factorization alone and on periodic-bounded weights. This has been demonstrated on benchmark datasets MNIST and MNIST variants. }}
@article{Wang201667,
title = {Unsupervised local deep feature for image recognition },
journal = {Information Sciences },
volume = {351},
number = {},
pages = {67 - 75},
year = {2016},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2016.02.044},
url = {http://www.sciencedirect.com/science/article/pii/S0020025516301268},
author = {Yang Wang and Xinggang Wang and Wenyu Liu},abstract = {Abstract Unsupervised feature learning is an important problem in computer vision and machine learning. Various unsupervised learning methods, e.g., PCA, KMeans, autoencoder, have been applied for visual recognition tasks. Especially, autoencoder has superior image recognition performance, which is usually used as a global feature extractor. To make better use of autoencoder for image recognition, we propose unsupervised local deep feature (ULDF). We collect patches from training images and use autoencoder to transform vectorized patches into short codes. Then these codes are encoded using Fisher Vector with spatial pyramid. Image recognition with ULDF only requires an efficient linear SVM classifier. Finally, we perform multi-scale voting to achieve more accurate classification performance. In the experiments, we evaluate ULDF on the handwritten digit recognition task and the shape classification task, and show that it achieves highly competitive performance comparing to the state-of-the-art image recognition methods. The results suggest that the proposed local deep feature is superior than traditional global autoencoder. }}
@article{Bai201515,
title = {Neural shape codes for 3D model retrieval },
journal = {Pattern Recognition Letters },
volume = {65},
number = {},
pages = {15 - 21},
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.06.022},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515001944},
author = {Song Bai and Xiang Bai and Wenyu Liu and Fabio Roli},abstract = {Abstract The paradigm of Convolutional Neural Network (CNN) has already shown its potential for many challenging applications of computer vision, such as image classification, object detection and action recognition. In this paper, the task of 3D model retrieval is addressed by exploiting such promising paradigm. However, 3D models are usually represented with a collection of orderless points, lines and surfaces in a three dimensional space, which makes it difficult to involve the operation of convolution, pooling, etc. Yet, we propose a practical and effective way for applying CNN to 3D model retrieval, by training the network with the depth projections of 3D model. This CNN is regarded as a generic feature extractor for depth image. With large amounts of training data, the learned feature, which is called Neural Shape Codes, can handle various deformation changes that exist in shape analysis. The reported experimental results on several 3D shape benchmark datasets show the superior performance of the proposed method. }}
@article{Zhang2016176,
title = {Face recognition using part-based dense sampling local features },
journal = {Neurocomputing },
volume = {184},
number = {},
pages = {176 - 187},
year = {2016},
note = {RoLoD: Robust Local Descriptors for Computer Vision 2014 },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.141},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215019104},
author = {Jiaqi Zhang and Yao Deng and Zhenhua Guo and Youbin Chen},abstract = {Abstract For years, researchers have made great efforts to find an appropriate face representation for face recognition. A fusion strategy of Local Binary Pattern (LBP) and Gabor filters yields great achievements. LBP is good at coding fine details of facial appearance and texture, whereas Gabor features can encode facial shape and appearance over a range of coarser scales. Despite the great performance, this fusion representation suffers from low effectiveness and resolution variance. In this paper, we propose a novel representation strategy of face images which is fast and robust to resolution variance. We apply dense sampling around each detected feature point, extract Local Difference Feature (LDF) for face representation, then utilize Principal Component Analysis (PCA)+Linear Discriminant Analysis (LDA) to reduce feature dimension and finally use cosine similarity evaluation for recognition. We have utilized our proposed face representation strategy on two databases, namely self-collected Second Generation ID Card of China and Driver׳s License (SGIDCDL) database and public Facial Recognition Technology (FERET) database. Our experimental results show that the proposed strategy has good performance on face recognition with fast speed. }}
@article{Qin2016,
title = {An empirical convolutional neural network approach for semantic relation classification },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.12.091},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216000023},
author = {Pengda Qin and Weiran Xu and Jun Guo},abstract = {Abstract In industry, relation classification plays a significant role in today׳s search engine. Up to now, the state-of-the-art systems have the problems of over-reliance on the quality of handcrafted features annotated by experts and linguistic knowledge derived from linguistic analysis modules, which is costly and leads to the issue of error propagation. Currently, with the data-driven approaches attracting wide attention, deep learning achieves impressive performance in semantic processing tasks without much effort on costly features. In this work, we deal with the relation classification task utilizing a convolutional neural network (CNN) approach to automatically control feature learning from raw sentences and minimize the application of external toolkits and resources. Our proposed method has several distinct features. First, we exploit a simple but rational way to specify which input tokens are the target nominals in the input sentence, instead of Position Feature that used in other neural network relation classification systems. Secondly, a most suitable dropout strategy is used to prevent units in the neural network from co-adapting too much, which significantly reduces over-fitting and improves the performance. Eventually, using only word embedding as input features is sufficient to achieve desirable performance. Our experiments on the SemEval-2010 Task-8 dataset show that our CNN architecture without using any additional extracted features significantly outperforms the state-of-the-art systems and achieves an F1-score of 84.8% only considering the context between the two target nominals. }}
@article{Liu201658,
title = {Adaptive spatial pooling for image classification },
journal = {Pattern Recognition },
volume = {55},
number = {},
pages = {58 - 67},
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.01.030},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316000510},
author = {Yinglu Liu and Yan-Ming Zhang and Xu-Yao Zhang and Cheng-Lin Liu},abstract = {Abstract In this paper, we propose an adaptive spatial pooling method for enhancing the discriminability of feature representation for image classification. The core idea is to adopt a spatial distribution matrix to define how the image patches are pooled together. By formulating the pooling distribution learning and classifier training jointly, our method can extract multiple spatial layouts of arbitrary shapes rather than regular rectangular regions. By proper mathematical transformation, the distributions can be learned via a boosting-like algorithm, which improves the efficiency of learning especially for large distribution matrices. Further, our method allows category-specific pooling operations to take advantage of the different spatial layouts of different categories. Experimental results on three benchmark datasets UIUC-Sports, 21-Land-Use and Scene 15 demonstrate the effectiveness of our method. }}
@article{Song201666,
title = {Event-based large scale surveillance video summarization },
journal = {Neurocomputing },
volume = {187},
number = {},
pages = {66 - 74},
year = {2016},
note = {Recent Developments on Deep Big Vision },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.131},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215018603},
author = {Xinhui Song and Li Sun and Jie Lei and Dapeng Tao and Guanhong Yuan and Mingli Song},



abstract = {Abstract Recent advances in sensor manufacture and computer vision technologies have simulated the applications of intelligent transportation systems, while a key yet under-addressed issue in these systems is the semantic summarization of large scale surveillance video. The main difficulty of large scale surveillance video summarization arises from the contradiction between the high-degree spatiotemporal redundancies and the limited storage budget. In this paper, we propose a novel approach of large scale surveillance video summarization on the basis of event detection. In the proposed approach, we firstly obtain the trajectories of vehicles and pedestrians in a tracking-by-detection manner, and then detect the abnormal events using the trajectories. Finally, we design a disjoint max-coverage algorithm to generate a summarized sequence with maximum coverage of interested events and minimum number of frames. Compared with traditional key frame-based approaches, our approach enjoys the following favorable features. First, important information can be efficiently extracted from the redundant contents since the approach is event-centric and those interested events contain almost all the important information. Second, abnormal events are successfully detected by combining the Random Forest classifier and the trajectory features. Third, the abnormal events are designed to display, and hence further reduces the compression ratio. Due to the above features, the proposed approach is suitable for different scenarios, ranges from highway to crowded crossings. Experiments on 12 surveillance sequences validate the effectiveness and efficiency of the proposed approach. }}
@article{Luo2015209,
title = {Higher-level feature combination via multiple kernel learning for image classification },
journal = {Neurocomputing },
volume = {167},
number = {},
pages = {209 - 217},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.04.075},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215005561},
author = {Wei Luo and Jian Yang and Wei Xu and Jun Li and Jian Zhang},abstract = {Abstract Feature combination is an effective way for image classification. Most of the work in this line mainly considers feature combination based on different low-level image descriptors, while ignoring the complementary property of different higher-level image features derived from the same type of low-level descriptor. In this paper, we explore the complementary property of different image features generated from one single type of low-level descriptor for image classification. Specifically, we propose a soft salient coding (SSaC) method, which overcomes the information suppression problem in the original salient coding (SaC) method. We analyse the physical meaning of the SSaC feature and the other two types of image features in the framework of Spatial Pyramid Matching (SPM), and propose using multiple kernel learning (MKL) to combine these features for classification tasks. Experiments on three image databases (Caltech-101, UIUC 8-Sports and 15-Scenes) not only verify the effectiveness of the proposed MKL combination method, but also reveal that collaboration is more important than selection for classification when limited types of image features are employed. }}
@article{Ding20152993,
title = {Deep feature learning with relative distance comparison for person re-identification },
journal = {Pattern Recognition },
volume = {48},
number = {10},
pages = {2993 - 3003},
year = {2015},
note = {Discriminative Feature Learning from Big Data for Visual Recognition },
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.04.005},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315001296},
author = {Shengyong Ding and Liang Lin and Guangrun Wang and Hongyang Chao},



abstract = {Abstract Identifying the same individual across different scenes is an important yet difficult task in intelligent video surveillance. Its main difficulty lies in how to preserve similarity of the same person against large appearance and structure variation while discriminating different individuals. In this paper, we present a scalable distance driven feature learning framework based on the deep neural network for person re-identification, and demonstrate its effectiveness to handle the existing challenges. Specifically, given the training images with the class labels (person IDs), we first produce a large number of triplet units, each of which contains three images, i.e. one person with a matched reference and a mismatched reference. Treating the units as the input, we build the convolutional neural network to generate the layered representations, and follow with the L 2 distance metric. By means of parameter optimization, our framework tends to maximize the relative distance between the matched pair and the mismatched pair for each triplet unit. Moreover, a nontrivial issue arising with the framework is that the triplet organization cubically enlarges the number of training triplets, as one image can be involved into several triplet units. To overcome this problem, we develop an effective triplet generation scheme and an optimized gradient descent algorithm, making the computational load mainly depend on the number of original images instead of the number of triplets. On several challenging databases, our approach achieves very promising results and outperforms other state-of-the-art approaches. }}
@article{Zhang2015383,
title = {A New Multi-channels Sequence Recognition Framework Using Deep Convolutional Neural Network },
journal = {Procedia Computer Science },
volume = {53},
number = {},
pages = {383 - 390},
year = {2015},
note = {INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.315},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915018189},
author = {Runfeng Zhang and Chunping Li and Daoyuan Jia},



abstract = {Abstract Nowadays, a variety of sequences could be recorded and used with the rapid development of intelligent devices and sensors’ integrated technology. Several analysis of the sequences are based on the sequence recognition or classification and most of them are implemented via traditional machine learning models or their variants, such as Dynamic Time Warping, Hidden Markov Model and Support Vector Machine. Some of them could achieve a relatively high classification accuracy but with a time-consuming training process. Some other models are just the opposite. In this paper, we proposed a novel framework to solve the recognition task for sequences with multi-channels with a higher accuracy in less training time. In our framework, we designed a novel deep Convolutional Neural Network using Data-Bands as inputs. We conducted contrast experiments between our framework and several baseline methods and the results demonstrate that our framework could outperform state-of-art models. }}
@article{Wang2016806,
title = {Semantic expansion using word embedding clustering and convolutional neural network for improving short text classification },
journal = {Neurocomputing },
volume = {174, Part B},
number = {},
pages = {806 - 814},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.09.096},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215014502},
author = {Peng Wang and Bo Xu and Jiaming Xu and Guanhua Tian and Cheng-Lin Liu and Hongwei Hao},

abstract = {Abstract Text classification can help users to effectively handle and exploit useful information hidden in large-scale documents. However, the sparsity of data and the semantic sensitivity to context often hinder the classification performance of short texts. In order to overcome the weakness, we propose a unified framework to expand short texts based on word embedding clustering and convolutional neural network (CNN). Empirically, the semantically related words are usually close to each other in embedding spaces. Thus, we first discover semantic cliques via fast clustering. Then, by using additive composition over word embeddings from context with variable window width, the representations of multi-scale semantic units11 Semantic units are defined as n-grams which have dominant meaning of text. With n varying, multi-scale contextual information can be exploited. in short texts are computed. In embedding spaces, the restricted nearest word embeddings (NWEs)22 In order to prevent outliers, a Euclidean distance threshold is preset between semantic cliques and semantic units, which is used as restricted condition. of the semantic units are chosen to constitute expanded matrices, where the semantic cliques are used as supervision information. Finally, for a short text, the projected matrix33 The projected matrix is obtained by table looking up, which encodes Unigram level features. and expanded matrices are combined and fed into CNN in parallel. Experimental results on two open benchmarks validate the effectiveness of the proposed method. }}
@article{Liu201523,
title = {Learning representative and discriminative image representation by deep appearance and spatial coding },
journal = {Computer Vision and Image Understanding },
volume = {136},
number = {},
pages = {23 - 31},
year = {2015},
note = {Generative Models in Computer Vision and Medical Imaging },
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2015.03.006},
url = {http://www.sciencedirect.com/science/article/pii/S1077314215000521},
author = {Bingyuan Liu and Jing Liu and Hanqing Lu},



abstract = {Abstract How to build a suitable image representation remains a critical problem in computer vision. Traditional Bag-of-Feature (BoF) based models build image representation by the pipeline of local feature extraction, feature coding and spatial pooling. However, three major shortcomings hinder the performance, i.e., the limitation of hand-designed features, the discrimination loss in local appearance coding and the lack of spatial information. To overcome the above limitations, in this paper, we propose a generalized BoF-based framework, which is hierarchically learned by exploring recently developed deep learning methods. First, with raw images as input, we densely extract local patches and learn local features by stacked Independent Subspace Analysis network. The learned features are then transformed to appearance codes by sparse Restricted Boltzmann Machines. Second, we perform spatial max-pooling on a set of over-complete spatial regions, which is generated by covering various spatial distributions, to incorporate more flexible spatial information. Third, a structured sparse Auto-encoder is proposed to explore the region representations into the image-level signature. To learn the proposed hierarchy, we layerwise pre-train the network in unsupervised manner, followed by supervised fine-tuning with image labels. Extensive experiments on different benchmarks, i.e., UIUC-Sports, Caltech-101, Caltech-256, Scene-15 and MIT Indoor-67, demonstrate the effectiveness of our proposed model. }}
@article{Jia2015250,
title = {Laplacian Auto-Encoders: An explicit learning of nonlinear data manifold },
journal = {Neurocomputing },
volume = {160},
number = {},
pages = {250 - 260},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.02.023},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215001721},
author = {Kui Jia and Lin Sun and Shenghua Gao and Zhan Song and Bertram E. Shi},abstract = {Abstract A key factor contributing to the success of many auto-encoders based deep learning techniques is the implicit consideration of the underlying data manifold in their training criteria. In this paper, we aim to make this consideration more explicit by training auto-encoders completely from the manifold learning perspective. We propose a novel unsupervised manifold learning method termed Laplacian Auto-Encoders (LAEs). Starting from a general regularized function learning framework, LAE regularizes training of auto-encoders so that the learned encoding function has the locality-preserving property for data points on the manifold. By exploiting the analog relation between the graph Laplacian and the Laplace–Beltrami operator on the continuous manifold, we derive discrete approximations of the first- and higher-order auto-encoder regularizers that can be applied in practical scenarios, where only data points sampled from the distribution on the manifold are available. Our proposed LAE has potentially better generalization capability, due to its explicit respect of the underlying data manifold. Extensive experiments on benchmark visual classification datasets show that LAE consistently outperforms alternative auto-encoders recently proposed in deep learning literature, especially when training samples are relatively scarce. }}
@article{Ji20143179,
title = {A sparse-response deep belief network based on rate distortion theory },
journal = {Pattern Recognition },
volume = {47},
number = {9},
pages = {3179 - 3191},
year = {2014},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2014.03.025},
url = {http://www.sciencedirect.com/science/article/pii/S003132031400123X},
author = {Nan-Nan Ji and Jiang-She Zhang and Chun-Xia Zhang},
abstract = {Abstract Deep belief networks (DBNs) are currently the dominant technique for modeling the architectural depth of brain, and can be trained efficiently in a greedy layer-wise unsupervised learning manner. However, DBNs without a narrow hidden bottleneck typically produce redundant, continuous-valued codes and unstructured weight patterns. Taking inspiration from rate distortion (RD) theory, which encodes original data using as few bits as possible, we introduce in this paper a variant of DBN, referred to as sparse-response DBN (SR-DBN). In this approach, Kullback–Leibler divergence between the distribution of data and the equilibrium distribution defined by the building block of DBN is considered as a distortion function, and the sparse response regularization induced by L1-norm of codes is used to achieve a small code rate. Several experiments by extracting features from different scale image datasets show that our approach SR-DBN learns codes with small rate, extracts features at multiple levels of abstraction mimicking computations in the cortical hierarchy, and obtains more discriminative representation than PCA and several basic algorithms of DBNs. }}
@article{Maniak2015600,
title = {Automated intelligent system for sound signalling device quality assurance },
journal = {Information Sciences },
volume = {294},
number = {},
pages = {600 - 611},
year = {2015},
note = {Innovative Applications of Artificial Neural Networks in Engineering },
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2014.09.042},
url = {http://www.sciencedirect.com/science/article/pii/S0020025514009542},
author = {Tomasz Maniak and Chrisina Jayne and Rahat Iqbal and Faiyaz Doctor},

abstract = {Abstract This paper presents a novel approach to the detection and recognition of faulty audio signalling devices as part of an automated industrial manufacturing quality assurance process. The proposed system outperforms other well-established automated systems based on mel-frequency cepstrum coefficients (MFCC) and multi-layer perceptron (MLP). It uses both unlabelled sound data and labelled historical data acquired from human experts in detecting faulty signalling devices. The unlabelled data is used to train a deep neural network generative model to create multiple levels of hierarchical feature extractors which are used to train an MLP classifier, with the intent to model the human reasoning and judging processes in respect to sound classification. This paper presents the results of real world experiments based on data pertaining to the audio signalling quality assurance process for car instrument cluster manufacturing. These results show that the proposed system is able to successfully classify speakers into two groups: Good and No good depending on the part quality. The proposed system proves to be capable enough to eliminate the need for a manual inspection within the manufacturing process and is shown to be able to diagnose a fault with a high degree of accuracy. This work can be extended to other areas of automotive inspection where there is a need for a robust solution to sound detection and where an output signal is represented by a complex and changing frequency spectrum even with significant environmental noise. }}
@article{Houthooft2016,
title = {Integrated Inference and Learning of Neural Factors in Structural Support Vector Machines },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.03.014},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316001096},
author = {Rein Houthooft and Filip De Turck},
abstract = {Abstract Tackling pattern recognition problems in areas such as computer vision, bioinformatics, speech or text recognition is often done best by taking into account task-specific statistical relations between output variables. In structured prediction, this internal structure is used to predict multiple outputs simultaneously, leading to more accurate and coherent predictions. Structural support vector machines (SSVMs) are nonprobabilistic models that optimize a joint input-output function through margin-based learning. Because SSVMs generally disregard the interplay between unary and interaction factors during the training phase, final parameters are suboptimal. Moreover, its factors are often restricted to linear combinations of input features, limiting its generalization power. To improve prediction accuracy, this paper proposes: (i) Joint inference and learning by integration of back-propagation and loss-augmented inference in SSVM subgradient descent; (ii) Extending SSVM factors to neural networks that form highly nonlinear functions of input features. Image segmentation benchmark results demonstrate improvements over conventional SSVM training methods in terms of accuracy, highlighting the feasibility of end-to-end SSVM training with neural factors. }}
@article{Li2015565,
title = {Feature learning based on SAE–PCA network for human gesture recognition in RGBD images },
journal = {Neurocomputing },
volume = {151, Part 2},
number = {},
pages = {565 - 573},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.06.086},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214013794},
author = {Shao-Zi Li and Bin Yu and Wei Wu and Song-Zhi Su and Rong-Rong Ji},abstract = {Abstract Coming with the emerging of depth sensors link Microsoft Kinect, human hand gesture recognition has received ever increasing research interests recently. A successful gesture recognition system has usually heavily relied on having a good feature representation of data, which is expected to be task-dependent as well as coping with the challenges and opportunities induced by depth sensor. In this paper, a feature learning approach based on sparse auto-encoder (SAE) and principle component analysis is proposed for recognizing human actions, i.e. finger-spelling or sign language, for RGB-D inputs. The proposed model of feature learning is consisted of two components: First, features are learned respectively from the RGB and depth channels, using sparse auto-encoder with convolutional neural networks. Second, the learned features from both channels is concatenated and fed into a multiple layer PCA to get the final feature. Experimental results on American sign language (ASL) dataset demonstrate that the proposed feature learning model is significantly effective, which improves the recognition rate from 75% to 99.05% and outperforms the state-of-the-art. }}
@article{Zou2015603,
title = {Supervised feature learning via l2-norm regularized logistic regression for 3D object recognition },
journal = {Neurocomputing },
volume = {151, Part 2},
number = {},
pages = {603 - 611},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.06.089},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214013903},
author = {Fuhao Zou and Yunfei Wang and Yang Yang and Ke Zhou and Yunpeng Chen and Jingkuan Song},abstract = {Abstract With the advance of 3D digitalization techniques, it has produced a large number of digital 3D objects, which are usually present in graph, image or video format. In this paper, we focus on designing a novel feature extraction method towards 2D image of 3D object for recognition task. Motivated by the fact that the responses generated by a classifier for two objects can highly reflect their semantic similarity, we attempt to exploit a set of classifiers to construct feature extraction method. The basic idea is as follows. We first learn a classifier for each class and then combine the outputs of all classifiers as object feature. Due to the label information being considered, the proposed method will be more powerful than the typical methods, such as SIFT based bag-of-feature and sparse coding, in terms of discovering the latent semantic information. This is helpful to improve the accuracy of the object recognition. In addition, to make the proposed method scalable to be trained over the massive data (so as to better its generalization ability), the ℓ 2 - norm logistic regression is selected as the classifier and trained with stochastic gradient ascent. At the aspect of time complexity, the proposed method is linear to the number of image pixels and less expensive than the other two methods. These arguments have been demonstrated by the obtained experimental results, which is performed over four 3D datasets, such as COIL-100, 3Ddata, ETH-80 and RGB-D dataset. }}
@article{Malmberg20101034,
title = {Tracing elementary school students’ study tactic use in gStudy by examining a strategic and self-regulated learning },
journal = {Computers in Human Behavior },
volume = {26},
number = {5},
pages = {1034 - 1042},
year = {2010},
note = {Advancing Educational Research on Computer-supported Collaborative Learning (CSCL) through the use of gStudy CSCL Tools },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2010.03.004},
url = {http://www.sciencedirect.com/science/article/pii/S0747563210000440},
author = {Jonna Malmberg and Hanna Järvenoja and Sanna Järvelä},

abstract = {This study investigated, with the help of log file traces (f = 172), how 20 elementary school students used study tactics when studying science within the gStudy learning environment and examined how tactic use contributed to the students’ achievement. The analysis of this study is divided into two parts. First, at the situational level, the focus is on capturing the tactics that were used in different gStudy sessions, classifying the gStudy sessions based on the tactic use, and illustrating the patterned use of tactics during these sessions. Second, at the individual level, the focus is on examining individual students’ typical methods of using tactics, which helps to illustrate how tactic use contributes to the students’ achievement. The gStudy sessions were classified into three categories on the basis of tactic use: rare, moderate, and frequent. Findings indicate that frequent tactic use did not contribute to deep learning. Moderate tactic use was fairly effective for learning, but rare tactic use contributed to deep learning. The results did not show that the use of many study tactics improves learning; rather, they suggest that the distinguishing feature in strategic learning is not the tactic use itself but the way the tactic is performed. }}
@article{Feng201550,
title = {Deep correspondence restricted Boltzmann machine for cross-modal retrieval },
journal = {Neurocomputing },
volume = {154},
number = {},
pages = {50 - 60},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.12.020},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214016841},
author = {Fangxiang Feng and Ruifan Li and Xiaojie Wang},
abstract = {Abstract The task of cross-modal retrieval, i.e., using a text query to search for images or vice versa, has received considerable attention with the rapid growth of multi-modal web data. Modeling the correlations between different modalities is the key to tackle this problem. In this paper, we propose a correspondence restricted Boltzmann machine (Corr-RBM) to map the original features of bimodal data, such as image and text in our setting, into a low-dimensional common space, in which the heterogeneous data are comparable. In our Corr-RBM, two RBMs built for image and text, respectively are connected at their individual hidden representation layers by a correlation loss function. A single objective function is constructed to trade off the correlation loss and likelihoods of both modalities. Through the optimization of this objective function, our Corr-RBM is able to capture the correlations between two modalities and learn the representation of each modality simultaneously. Furthermore, we construct two deep neural structures using Corr-RBM as the main building block for the task of cross-modal retrieval. A number of comparison experiments are performed on three public real-world data sets. All of our models show significantly better results than state-of-the-art models in both searching images via text query and vice versa. }}
@article{Sainath201539,
title = {Deep Convolutional Neural Networks for Large-scale Speech Tasks },
journal = {Neural Networks },
volume = {64},
number = {},
pages = {39 - 48},
year = {2015},
note = {Special Issue on Deep Learning of Representations },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2014.08.005},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002007},
author = {Tara N. Sainath and Brian Kingsbury and George Saon and Hagen Soltau and Abdel-rahman Mohamed and George Dahl and Bhuvana Ramabhadran},



abstract = {Abstract Convolutional Neural Networks (CNNs) are an alternative type of neural network that can be used to reduce spectral variations and model spectral correlations which exist in signals. Since speech signals exhibit both of these properties, we hypothesize that CNNs are a more effective model for speech compared to Deep Neural Networks (DNNs). In this paper, we explore applying CNNs to large vocabulary continuous speech recognition (LVCSR) tasks. First, we determine the appropriate architecture to make CNNs effective compared to DNNs for LVCSR tasks. Specifically, we focus on how many convolutional layers are needed, what is an appropriate number of hidden units, what is the best pooling strategy. Second, investigate how to incorporate speaker-adapted features, which cannot directly be modeled by CNNs as they do not obey locality in frequency, into the CNN framework. Third, given the importance of sequence training for speech tasks, we introduce a strategy to use ReLU+dropout during Hessian-free sequence training of CNNs. Experiments on 3 LVCSR tasks indicate that a CNN with the proposed speaker-adapted and ReLU+dropout ideas allow for a 12%–14% relative improvement in WER over a strong DNN system, achieving state-of-the art results in these 3 tasks. }}
@article{Li2016501,
title = {Multi-manifold Sparse Graph Embedding for Multi‐modal Image Classification },
journal = {Neurocomputing },
volume = {173, Part 3},
number = {},
pages = {501 - 510},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.06.041},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215008863},
author = {Jingjing Li and Yue Wu and Jidong Zhao and Ke Lu},



abstract = {Abstract Due to the drastic variations in illumination, occlusion or orientation, images of one object may vary widely. If we regard photos of one object with different appearances as different modalities, multi-modal images are common in reality. The multi-modal image classification can be considered as a learning problem about multi-manifold with possible intersections. General multi-manifold learning methods work on multiple independent subspaces, so it is difficult for them to balance the intra-class local manifold information and global inter-class discriminative structure. On the other hand, traditional supervised graph embedding algorithms neglect both the multi-modal multi-manifold structure and the importance of the feature selection in multi-modal image environment. In this paper, we propose a Multi-manifold Sparse Graph Embedding (MSGE) algorithm, which can explicitly capture multi-modal multi-manifold structure while considering both intra-class compactness and inter-class separability, and then learn an integral subspace model. Furthermore, a sparse embedding is achieved by using L 2 , 1 -norm, which makes the transformation matrix row-sparse, so MSGE can select relevant features and learn subspace transformation simultaneously. Experiments on several datasets demonstrate that MSGE can achieve better performance than the state-of-the-art reported in recent literature. }}
@article{Haghighat201623,
title = {Fully automatic face normalization and single sample face recognition in unconstrained environments },
journal = {Expert Systems with Applications },
volume = {47},
number = {},
pages = {23 - 34},
year = {2016},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2015.10.047},
url = {http://www.sciencedirect.com/science/article/pii/S0957417415007514},
author = {Mohammad Haghighat and Mohamed Abdel-Mottaleb and Wadee Alhalabi},

abstract = {Abstract Single sample face recognition have become an important problem because of the limitations on the availability of gallery images. In many real-world applications such as passport or driver license identification, there is only a single facial image per subject available. The variations between the single gallery face image and the probe face images, captured in unconstrained environments, make the single sample face recognition even more difficult. In this paper, we present a fully automatic face recognition system robust to most common face variations in unconstrained environments. Our proposed system is capable of recognizing faces from non-frontal views and under different illumination conditions using only a single gallery sample for each subject. It normalizes the face images for both in-plane and out-of-plane pose variations using an enhanced technique based on active appearance models (AAMs). We improve the performance of AAM fitting, not only by training it with in-the-wild images and using a powerful optimization technique, but also by initializing the AAM with estimates of the locations of the facial landmarks obtained by a method based on flexible mixture of parts. The proposed initialization technique results in significant improvement of AAM fitting to non-frontal poses and makes the normalization process robust, fast and reliable. Owing to the proper alignment of the face images, made possible by this approach, we can use local feature descriptors, such as Histograms of Oriented Gradients (HOG), for matching. The use of HOG features makes the system robust against illumination variations. In order to improve the discriminating information content of the feature vectors, we also extract Gabor features from the normalized face images and fuse them with HOG features using Canonical Correlation Analysis (CCA). Experimental results performed on various databases outperform the state-of-the-art methods and show the effectiveness of our proposed method in normalization and recognition of face images obtained in unconstrained environments. }}
@article{Shen201461,
title = {Learning to predict eye fixations for semantic contents using multi-layer sparse network },
journal = {Neurocomputing },
volume = {138},
number = {},
pages = {61 - 68},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.09.053},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214003440},
author = {Chengyao Shen and Qi Zhao},abstract = {Abstract In this paper, we present a novel model for saliency prediction under a unified framework of feature integration. The model distinguishes itself by directly learning from natural images and automatically incorporating higher-level semantic information in a scalable manner for gaze prediction. Unlike most existing saliency models that rely on specific features or object detectors, our model learns multiple stages of features that mimic the hierarchical organization of the ventral stream in the visual cortex and integrate them by adapting their weights based on the ground-truth fixation data. To accomplish this, we utilize a multi-layer sparse network to learn low-, mid- and high-level features from natural images and train a linear support vector machine (SVM) for weight adaption and feature integration. Experimental results show that our model could learn high-level semantic features like faces and texts and can perform competitively among existing approaches in predicting eye fixations. }}
@article{Liu2016,
title = {Convolutional Neural Random Fields for Action Recognition },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.03.019},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316300048},
author = {Caihua Liu and Jie Liu and Zhicheng He and Yujia Zhai and Qinghua Hu and Yalou Huang},abstract = {Abstract A deep discriminative structured model, Convolutional Neural Random Fields (CNRF), is proposed for action recognition problem. In the proposed model, a spatio-temporal convolutional neural network (CNN) is developed for invariant feature learning from raw input frames, and the CNN is combined with Conditional Random Fields (CRF) for capturing the interdependencies between outputs. The parameters from both CRF and CNN are learned in a joint fashion which enables structured prediction and feature learning as well. We also explore different combinations of observation and transition feature functions based on the learned high level features from convolution part. The approach enjoys the advantages of both CNN and CRF, it has the invariant feature learning ability possessed by the former and structured prediction ability of the latter. The experimental results on both segmented and unsegmented human action recognition datasets show that CNRF boosts the performance over the comparison methods by a large margin. }}
@article{Horita2013570,
title = {An FPGA-based multiple-weight-and-neuron-fault tolerant digital multilayer perceptron },
journal = {Neurocomputing },
volume = {99},
number = {},
pages = {570 - 574},
year = {2013},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2012.07.001},
url = {http://www.sciencedirect.com/science/article/pii/S0925231212005620},
author = {T. Horita and I. Takanami},

abstract = {A digital multilayer perceptron (DMLP) which is tolerant to simultaneous weight and neuron faults is implemented in an FPGA, where the weight faults are assumed to be between the hidden and output layers and the neuron faults are assumed to be in the hidden and output layers. In the implementation, a multilayer perceptron (MLP) trained by the deep learning method [1] is used to cope with the weight faults and the neuron faults in the hidden layer, and an error detecting and correcting code SECDED is used to cope with the neuron faults in the output layer. The implementation process named FTDMLP-gene is proposed which consists of three parts; the deep learning method, the VHDL source file generator and the outline of VHDL notation which describes an FTDMLP (fault-tolerant DMLP). The fault-tolerant ability of the FTDMLP implemented is shown. Further, The FTDMLP and the corresponding non-fault tolerant DMLP are compared in terms of hardware size, computing speed and electricity consumption. This paper is the extension of [2,3]. }}
@article{Gupta20161001,
title = {Squeezing bottlenecks: Exploring the limits of autoencoder semantic representation capabilities },
journal = {Neurocomputing },
volume = {175, Part B},
number = {},
pages = {1001 - 1008},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.06.091},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215015994},
author = {Parth Gupta and Rafael E. Banchs and Paolo Rosso},


abstract = {Abstract We present a comprehensive study on the use of autoencoders for modelling text data, in which (differently from previous studies) we focus our attention on the various issues. We explore the suitability of two different models binary deep autencoders (bDA) and replicated-softmax deep autencoders (rsDA) for constructing deep autoencoders for text data at the sentence level. We propose and evaluate two novel metrics for better assessing the text-reconstruction capabilities of autoencoders. We propose an automatic method to find the critical bottleneck dimensionality for text representations (below which structural information is lost); and finally we conduct a comparative evaluation across different languages, exploring the regions of critical bottleneck dimensionality and its relationship to language perplexity. }}
@article{Elfwing201529,
title = {Expected energy-based restricted Boltzmann machine for classification },
journal = {Neural Networks },
volume = {64},
number = {},
pages = {29 - 38},
year = {2015},
note = {Special Issue on Deep Learning of Representations },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2014.09.006},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002160},
author = {S. Elfwing and E. Uchibe and K. Doya},abstract = {Abstract In classification tasks, restricted Boltzmann machines (RBMs) have predominantly been used in the first stage, either as feature extractors or to provide initialization of neural networks. In this study, we propose a discriminative learning approach to provide a self-contained RBM method for classification, inspired by free-energy based function approximation (FE-RBM), originally proposed for reinforcement learning. For classification, the FE-RBM method computes the output for an input vector and a class vector by the negative free energy of an RBM. Learning is achieved by stochastic gradient-descent using a mean-squared error training objective. In an earlier study, we demonstrated that the performance and the robustness of FE-RBM function approximation can be improved by scaling the free energy by a constant that is related to the size of network. In this study, we propose that the learning performance of RBM function approximation can be further improved by computing the output by the negative expected energy (EE-RBM), instead of the negative free energy. To create a deep learning architecture, we stack several RBMs on top of each other. We also connect the class nodes to all hidden layers to try to improve the performance even further. We validate the classification performance of EE-RBM using the MNIST data set and the NORB data set, achieving competitive performance compared with other classifiers such as standard neural networks, deep belief networks, classification RBMs, and support vector machines. The purpose of using the NORB data set is to demonstrate that EE-RBM with binary input nodes can achieve high performance in the continuous input domain. }}
@article{Jiang2016163,
title = {Speed up deep neural network based pedestrian detection by sharing features across multi-scale models },
journal = {Neurocomputing },
volume = {185},
number = {},
pages = {163 - 170},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.12.042},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215019797},
author = {Xiaoheng Jiang and Yanwei Pang and Xuelong Li and Jing Pan},abstract = {Abstract Deep neural networks (DNNs) have now demonstrated state-of-the-art detection performance on pedestrian datasets. However, because of their high computational complexity, detection efficiency is still a frustrating problem even with the help of Graphics Processing Units (GPUs). To improve detection efficiency, this paper proposes to share features across a group of DNNs that correspond to pedestrian models of different sizes. By sharing features, the computational burden for extracting features from an image pyramid can be significantly reduced. Simultaneously, we can detect pedestrians of several different scales on one single layer of an image pyramid. Furthermore, the improvement of detection efficiency is achieved with negligible loss of detection accuracy. Experimental results demonstrate the robustness and efficiency of the proposed algorithm. }}
@article{Dobhal2015178,
title = {Human Activity Recognition using Binary Motion Image and Deep Learning },
journal = {Procedia Computer Science },
volume = {58},
number = {},
pages = {178 - 185},
year = {2015},
note = {Second International Symposium on Computer Vision and the Internet (VisionNet’15) },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.08.050},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915021614},
author = {Tushar Dobhal and Vivswan Shitole and Gabriel Thomas and Girisha Navada},
abstract = {Abstract View based recognition methods use visual templates for recognition and hence do not extract complex features from the image. Instead they retain the entire raw image as a single feature in high dimensional space. These example images or templates are learnt under different poses and illumination conditions for recognition. With this in mind, we build on the idea of 2-D representation of action video sequence by combining the image sequences into a single image called Binary Motion Image (BMI) to perform human activity recognition. For classification, we employ Convolutional Neural Networks which inherently provide slight invariance to translational and rotational shifts, partial occlusions as well as background noise. We test our method on Weizmann dataset focusing on actions that look similar like run, walk, jump, side and skip actions. We also extended our method to 3-D depth maps using MSR Action3D dataset by extracting three BMI projections namely the front view, the side view and the top view. From the results obtained, we believe that BMI is sufficient for activity recognition and has shown to be invariant to speed of the action performed in addition to the aforementioned variations. }}
@article{Gashler2015,
title = {Modeling time series data with deep Fourier neural networks },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.01.108},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017774},
author = {Michael S. Gashler and Stephen C. Ashmore},
abstract = {Abstract We present a method for training a deep neural network containing sinusoidal activation functions to fit to time-series data. Weights are initialized using a fast Fourier transform, then trained with regularization to improve generalization. A simple dynamic parameter tuning method is employed to adjust both the learning rate and the regularization term, such that both stability and efficient training are achieved. We show how deeper layers can be utilized to model the observed sequence using a sparser set of sinusoid units, and how non-uniform regularization can improve generalization by promoting the shifting of weight toward simpler units. The method is demonstrated with time-series problems to show that it leads to effective extrapolation of nonlinear trends. }}
@article{Barros2015140,
title = {Multimodal emotional state recognition using sequence-dependent deep hierarchical features },
journal = {Neural Networks },
volume = {72},
number = {},
pages = {140 - 151},
year = {2015},
note = {Neurobiologically Inspired Robotics: Enhanced Autonomy through Neuromorphic Cognition },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2015.09.009},
url = {http://www.sciencedirect.com/science/article/pii/S0893608015001847},
author = {Pablo Barros and Doreen Jirak and Cornelius Weber and Stefan Wermter},
abstract = {Abstract Emotional state recognition has become an important topic for human–robot interaction in the past years. By determining emotion expressions, robots can identify important variables of human behavior and use these to communicate in a more human-like fashion and thereby extend the interaction possibilities. Human emotions are multimodal and spontaneous, which makes them hard to be recognized by robots. Each modality has its own restrictions and constraints which, together with the non-structured behavior of spontaneous expressions, create several difficulties for the approaches present in the literature, which are based on several explicit feature extraction techniques and manual modality fusion. Our model uses a hierarchical feature representation to deal with spontaneous emotions, and learns how to integrate multiple modalities for non-verbal emotion recognition, making it suitable to be used in an HRI scenario. Our experiments show that a significant improvement of recognition accuracy is achieved when we use hierarchical features and multimodal information, and our model improves the accuracy of state-of-the-art approaches from 82.5% reported in the literature to 91.3% for a benchmark dataset on spontaneous emotion expressions. }}
@article{Zhou2016107,
title = {Active contour model based on local and global intensity information for medical image segmentation },
journal = {Neurocomputing },
volume = {186},
number = {},
pages = {107 - 118},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.12.073},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215020469},
author = {Sanping Zhou and Jinjun Wang and Shun Zhang and Yudong Liang and Yihong Gong},
abstract = {Abstract This paper proposes a novel region-based active contour model in the level set formulation for medical image segmentation. We define a unified fitting energy framework based on Gaussian probability distributions to obtain the maximum a posteriori probability (MAP) estimation. The energy term consists of a global energy term to characterize the fitting of global Gaussian distribution according to the intensities inside and outside the evolving curve, as well as a local energy term to characterize the fitting of local Gaussian distribution based on the local intensity information. In the resulting contour evolution that minimizes the associated energy, the global energy term accelerates the evolution of the evolving curve far away from the objects, while the local energy term guides the evolving curve near the objects to stop on the boundaries. In addition, a weighting function between the local energy term and the global energy term is proposed by using the local and global variances information, which enables the model to select the weights adaptively in segmenting images with intensity inhomogeneity. Extensive experiments on both synthetic and real medical images are provided to evaluate our method, show significant improvements on both efficiency and accuracy, as compared with the popular methods. }}
@article{Liu20152983,
title = {CRF learning with CNN features for image segmentation },
journal = {Pattern Recognition },
volume = {48},
number = {10},
pages = {2983 - 2992},
year = {2015},
note = {Discriminative Feature Learning from Big Data for Visual Recognition },
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.04.019},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315001582},
author = {Fayao Liu and Guosheng Lin and Chunhua Shen},abstract = {Abstract Conditional Random Rields (CRF) have been widely applied in image segmentations. While most studies rely on hand-crafted features, we here propose to exploit a pre-trained large convolutional neural network (CNN) to generate deep features for CRF learning. The deep CNN is trained on the ImageNet dataset and transferred to image segmentations here for constructing potentials of superpixels. Then the CRF parameters are learnt using a structured support vector machine (SSVM). To fully exploit context information in inference, we construct spatially related co-occurrence pairwise potentials and incorporate them into the energy function. This prefers labelling of object pairs that frequently co-occur in a certain spatial layout and at the same time avoids implausible labellings during the inference. Extensive experiments on binary and multi-class segmentation benchmarks demonstrate the promise of the proposed method. We thus provide new baselines for the segmentation performance on the Weizmann horse, Graz-02, MSRC-21, Stanford Background and PASCAL VOC 2011 datasets. }}
@article{Li20153542,
title = {Feature representation for statistical-learning-based object detection: A review },
journal = {Pattern Recognition },
volume = {48},
number = {11},
pages = {3542 - 3559},
year = {2015},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.04.018},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315001570},
author = {Yali Li and Shengjin Wang and Qi Tian and Xiaoqing Ding},
abstract = {Abstract Statistical-learning-based object detection is an important topic in computer vision. It learns visual representation from annotated exemplars to identify semantic defined objects in images. High-performance object detection is usually carried out in feature space and effective feature representation can improve the performance significantly. Feature representation is the encoding process which maps raw image pixels inside local regions into discriminant feature space. The motivation of this paper is to present a review on feature representation in recent object detection methods. Visual features applied in object detection are categorized according to the differences in computation and visual properties. The most valued features are introduced and discussed in detail. Representative extensions are introduced briefly for comparison. Descriptive power, robustness, compactness as well as computational efficiency are viewed as important properties. According to these properties, discussions are presented on the advantages and drawbacks of features. Besides, generic techniques such as dimension reduction and combination are introduced. Through this review, we would like to draw the feature sketch and provide new insights for feature utilization, in order to tackle future challenges of object detection. }}
@article{Yang201072,
title = {Conceptions of and approaches to learning through online peer assessment },
journal = {Learning and Instruction },
volume = {20},
number = {1},
pages = {72 - 83},
year = {2010},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2009.01.003},
url = {http://www.sciencedirect.com/science/article/pii/S095947520900005X},
author = {Yu-Fang Yang and Chin-Chung Tsai},abstract = {The present study investigated junior college students' conceptions of and approaches to learning via online peer assessment (PA) using a phenomenographic approach. Participants were 163 college students. Students were asked to accomplish a given learning task via an online PA system. Of the participants, 62 were interviewed after the activity. The interviews revealed hierarchically related and qualitatively different categories of conceptions and approaches to learning via online PA. The main and achieved levels of conceptions of and approaches to learning were determined. The results showed that, within each level, conceptions emphasizing a fragmented and cohesive learning tended to be associated with approaches focusing on surface and deep learning, respectively. In addition, students with cohesive learning conceptions and deep learning approaches were likely to make greater progress in the early stages of online PA activity. The present study finally found that approaches to learning via online PA were less related to the learning outcomes than conceptions of learning. }}
@article{Mocanu2015100,
title = {Factored four way conditional restricted Boltzmann machines for activity recognition },
journal = {Pattern Recognition Letters },
volume = {66},
number = {},
pages = {100 - 108},
year = {2015},
note = {Pattern Recognition in Human Computer Interaction },
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.01.013},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515000379},
author = {Decebal Constantin Mocanu and Haitham Bou Ammar and Dietwig Lowet and Kurt Driessens and Antonio Liotta and Gerhard Weiss and Karl Tuyls},



abstract = {Abstract This paper introduces a new learning algorithm for human activity recognition capable of simultaneous regression and classification. Building upon conditional restricted Boltzmann machines (CRBMs), Factored four way conditional restricted Boltzmann machines (FFW-CRBMs) incorporate a new label layer and four-way interactions among the neurons from the different layers. The additional layer gives the classification nodes a similar strong multiplicative effect compared to the other layers, and avoids that the classification neurons are overwhelmed by the (much larger set of) other neurons. This makes FFW-CRBMs capable of performing activity recognition, prediction and self auto evaluation of classification within one unified framework. As a second contribution, sequential Markov chain contrastive divergence (SMcCD) is introduced. SMcCD modifies Contrastive Divergence to compensate for the extra complexity of FFW-CRBMs during training. Two sets of experiments one on benchmark datasets and one a robotic platform for smart companions show the effectiveness of FFW-CRBMs. }}
@article{Coller2009900,
title = {Effectiveness of using a video game to teach a course in mechanical engineering },
journal = {Computers & Education },
volume = {53},
number = {3},
pages = {900 - 912},
year = {2009},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2009.05.012},
url = {http://www.sciencedirect.com/science/article/pii/S0360131509001201},
author = {B.D. Coller and M.J. Scott},
abstract = {One of the core courses in the undergraduate mechanical engineering curriculum has been completely redesigned. In the new numerical methods course, all assignments and learning experiences are built around a video/computer game. Students are given the task of writing computer programs to race a simulated car around a track. In doing so, students learn and implement numerical methods content. The design of the course, around a video game, is rooted in commonly accepted theories of how people learn. The article describes a study to assess the effectiveness of the video game-based course. Results show that students taking the game-based course, on average, spend roughly twice as much time, outside of class, on their course work. In a concept mapping exercise, students taking the game-based course demonstrate deeper learning compared to their counterparts taking traditional lecture/textbook-based numerical methods courses. }}
@article{Almási201631,
title = {Review of advances in neural networks: Neural design technology stack },
journal = {Neurocomputing },
volume = {174, Part A},
number = {},
pages = {31 - 41},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.02.092},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215010358},
author = {Adela-Diana Almási and Stanisław Woźniak and Valentin Cristea and Yusuf Leblebici and Ton Engbersen},
abstract = {Abstract This review provides a high-level synthesis of significant recent advances in artificial neural network research, as well as multi-disciplinary concepts connected to the far-reaching goal of obtaining intelligent systems. We assume that a global outlook of these interconnected fields can benefit researchers by providing alternative viewpoints. Therefore, we present different network and neuron models, we discuss model parameters and the means to obtain them, and we draw a quick outline of information encoding, before proceeding to an overview of the relevant learning mechanisms, ranging from established approaches to novel ideas. We specifically focus on comparing the classical artificial model with the biologically-feasible spiking neuron, and we take this comparison further into a discussion on the biological plausibility of various learning approaches. }}
@article{Goodfellow201559,
title = {Challenges in representation learning: A report on three machine learning contests },
journal = {Neural Networks },
volume = {64},
number = {},
pages = {59 - 63},
year = {2015},
note = {Special Issue on Deep Learning of Representations },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2014.09.005},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002159},
author = {Ian J. Goodfellow and Dumitru Erhan and Pierre Luc Carrier and Aaron Courville and Mehdi Mirza and Ben Hamner and Will Cukierski and Yichuan Tang and David Thaler and Dong-Hyun Lee and Yingbo Zhou and Chetan Ramaiah and Fangxiang Feng and Ruifan Li and Xiaojie Wang and Dimitris Athanasakis and John Shawe-Taylor and Maxim Milakov and John Park and Radu Ionescu and Marius Popescu and Cristian Grozea and James Bergstra and Jingjing Xie and Lukasz Romaszko and Bing Xu and Zhang Chuang and Yoshua Bengio},



abstract = {Abstract The ICML 2013 Workshop on Challenges in Representation Learning11 http://deeplearning.net/icml2013-workshop-competition. focused on three challenges: the black box learning challenge, the facial expression recognition challenge, and the multimodal learning challenge. We describe the datasets created for these challenges and summarize the results of the competitions. We provide suggestions for organizers of future challenges and some comments on what kind of knowledge can be gained from machine learning competitions. }}
@article{Liew201674,
title = {An optimized second order stochastic learning algorithm for neural network training },
journal = {Neurocomputing },
volume = {186},
number = {},
pages = {74 - 89},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.12.076},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215020494},
author = {Shan Sung Liew and Mohamed Khalil-Hani and Rabia Bakhteri},

abstract = {Abstract This paper proposes an improved stochastic second order learning algorithm for supervised neural network training. The proposed algorithm, named bounded stochastic diagonal Levenberg–Marquardt (B-SDLM), utilizes both gradient and curvature information to achieve fast convergence while requiring only minimal computational overhead than the stochastic gradient descent (SGD) method. B-SDLM has only a single hyperparameter as opposed to most other learning algorithms that suffer from the hyperparameter overfitting problem due to having more hyperparameters to be tuned. Experiments using the multilayer perceptron (MLP) and convolutional neural network (CNN) models have shown that B-SDLM outperforms other learning algorithms with regard to the classification accuracies and computational efficiency (about 5.3% faster than SGD on the mnist-rot-bg-img database). It can classify all testing samples correctly on the face recognition case study based on AR Purdue database. In addition, experiments on handwritten digit classification case studies show that significant improvements of 19.6% on MNIST database and 17.5% on mnist-rot-bg-img database can be achieved in terms of the testing misclassification error rates (MCRs). The computationally expensive Hessian calculations are kept to a minimum by using just 0.05% of the training samples in its estimation or updating the learning rates once per two training epochs, while maintaining or even achieving lower testing MCRs. It is also shown that B-SDLM works well in the mini-batch learning mode, and we are able to achieve 3.32 × performance speedup when deploying the proposed algorithm in a distributed learning environment with a quad-core processor. }}
@article{Gan2014295,
title = {Deep self-taught learning for facial beauty prediction },
journal = {Neurocomputing },
volume = {144},
number = {},
pages = {295 - 303},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.05.028},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214006468},
author = {Junying Gan and Lichen Li and Yikui Zhai and Yinhua Liu},abstract = {Abstract Most modern research of facial beauty prediction focuses on geometric features by traditional machine learning methods. Geometric features may easily lose much feature information characterizing facial beauty, rely heavily on accurate manual landmark localization of facial features and impose strict restrictions on training samples. Deep architectures have been recently demonstrated to be a promising area of research in statistical machine learning. In this paper, deep self-taught learning is utilized to obtain hierarchical representations, learn the concept of facial beauty and produce human-like predictor. Deep learning is helpful to recognize a broad range of visual concept effectively characterizing facial beauty. Through deep learning, reasonable apparent features of face images are extracted without depending completely on artificial feature selection. Self-taught learning, which has the ability of automatically improving network systems to understand the characteristics of data distribution and making recognition significantly easier and cheaper, is used to relax strict restrictions of training samples. Moreover, in order to choose a more appropriate method for mapping high-level representations into beauty ratings efficiently, we compare the performance of five regression methods and prove that support vector machine (SVM) regression is better. In addition, novel applications of deep self-taught learning on local binary pattern (LBP) and Gabor filters are presented, and the improvements on facial beauty prediction are shown by deep self-taught learning combined with LBP. Finally, human-like performance is obtained with learning features in full-sized and high-resolution images. }}
@article{Evans20071147,
title = {The interactivity effect in multimedia learning },
journal = {Computers & Education },
volume = {49},
number = {4},
pages = {1147 - 1160},
year = {2007},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2006.01.008},
url = {http://www.sciencedirect.com/science/article/pii/S0360131506000285},
author = {Chris Evans and Nicola J. Gibbons},
abstract = {The aim of this study was to determine whether the addition of interactivity to a computer-based learning package enhances the learning process. A sample of 33 (22 male and 11 female) undergraduates on a Business and Management degree used a multimedia system to learn about the operation of a bicycle pump. The system consisted of a labelled diagram of the pump, followed by a description of twelve stages in its operation. The sample was randomly divided into two groups who used either an interactive (I) or a non-interactive (NI) version involving both images and text. The I system differed from the NI system by the incorporation of control of pace, self-assessment questions and an interactive simulation. Students then undertook two different types of tests to assess their learning: one designed to evaluate their memory by recalling facts from the lesson, and another designed to assess their understanding through solving novel diagnostic problems. Students using the I system outperformed those using the NI system in the problem-solving test, and needed less time to complete both memory and problem-solving tests. This result is consistent with the hypothesis that interactive systems facilitate deep learning by actively engaging the learner in the learning process. This suggests that educational designers who seek to foster deep learning (as opposed to mere factual recall) should adopt the incorporation of interactivity as a design principle. }}
@article{Uluyol20121192,
title = {Integrating mobile multimedia into textbooks: 2D barcodes },
journal = {Computers & Education },
volume = {59},
number = {4},
pages = {1192 - 1198},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.05.018},
url = {http://www.sciencedirect.com/science/article/pii/S036013151200139X},
author = {Celebi Uluyol and R. Kagan Agca},



abstract = {The major goal of this study was to empirically compare text-plus-mobile phone learning using an integrated 2D barcode tag in a printed text with three other conditions described in multimedia learning theory. The method examined in the study involved modifications of the instructional material such that: a 2D barcode was used near the text, the learner scanned the tag with the camera on his/her mobile phone and reached the animation and narration on the mobile phone's screen. Using this method, we created a new approach that reinforces printed textbooks, which had the poorest retention and transfer results. The results suggest that supporting a printed textbook with camera-equipped mobile devices and 2D barcodes linked to supplemental information, may increase the effectiveness of learning. }}
@article{Shen201611,
title = {Face identification with second-order pooling in single-layer networks },
journal = {Neurocomputing },
volume = {187},
number = {},
pages = {11 - 18},
year = {2016},
note = {Recent Developments on Deep Big Vision },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.133},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215018767},
author = {Fumin Shen and Yang Yang and Xiang Zhou and Xianglong Liu and Jie Shao},



abstract = {Abstract Automatic face recognition has received significant performance improvement by developing specialized facial image representations. On the other hand, spatial pyramid pooling of features encoded by an over-complete dictionary has been the key component of many state-of-the-art generic objective classification systems. Inspired by its success, in this work we develop a new face image representation method under the framework of single-layer networks, where the key component is the second-order pooling layer. The proposed method differs from the previous methods in that, we encode the densely extracted local patches by a small-size dictionary; and the facial image signatures are obtained by pooling the second-order statistics of the encoded features. We show the importance of the encoding procedure, which is bypassed by the original second-order pooling method to avoid the high computational cost. Equipped with a simple linear classifier, the proposed method outperforms the state-of-the-art face identification performance by large margins. For example, on the LFW databases, the proposed method performs better than the previous best by around 13% accuracy. }}
@article{Kosmadoudi2012285,
title = {Game Interactivity in CAD as Productive Systems },
journal = {Procedia Computer Science },
volume = {15},
number = {},
pages = {285 - 288},
year = {2012},
note = {4th International Conference on Games and Virtual Worlds for Serious Applications(VS-GAMES’12) },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2012.10.081},
url = {http://www.sciencedirect.com/science/article/pii/S1877050912008435},
author = {Z. Kosmadoudi and T. Lim and J.M. Ritchie and R.C.W. Sung and Y. Liu and I.A. Stănescu and A. Ştefan},


abstract = {Over the past few years, the interest in using games to educate, motivate, and change behaviour has grown tremendously by international groups of practitioners, educators, gamers engineers, medical scientists, and many other researchers from a variety of disciplines. Games are driven by entertainment purposes but they represent more than an entertainment, fun value; they associate a context of deeper learning and enjo yable experience. Hence, the article focuses on the architecture characteristics of games and computer-aided design CAD with a particular interest in CAD systems as interactive and engaging systems. The researchers further underline the importance of interoperability in the perspective of integrating game systems and CAD. }}
@article{Kim20151,
title = {Factors influencing students' beliefs about the future in the context of tablet-based interactive classrooms },
journal = {Computers & Education },
volume = {89},
number = {},
pages = {1 - 15},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.08.014},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515300348},
author = {Hye Jeong Kim and Hwan Young Jang},
abstract = {Abstract With the distribution of easy-to-use tablet computers, tablet-based interactive classrooms have become popular environments for innovative learning activities in recent years. However, little research has investigated the relationship between technologically enhanced learning environments and students' beliefs about the future and self-efficacy for learning. In this study, young students' perceptions of tablet-based interactive classrooms, beliefs about the future, and self-efficacy for learning in rural areas of Korea were examined after the students engaged in tablet-based interactive classrooms. To develop the theoretical framework, we created a structural research model of ease of use, usefulness, satisfaction, deepened experiences through tablet use, beliefs about the future, and self-efficacy in tablet-based interactive classrooms based on a partial least squares (PLS) method. The results indicate that (1) students in tablet-based interactive classrooms perceive frequent experiences with tablet-based instructions as easy and useful and (2) student satisfaction is significantly influenced by their perceptions of deeper learning experiences through tablet use, which are significantly influenced by their future expectations and self-efficacy for learning. This study provides relevant implications for educators who design learning activities for students in rural schools in tablet-based interactive classroom environments. }}
@article{Liu20151283,
title = {Set-label modeling and deep metric learning on person re-identification },
journal = {Neurocomputing },
volume = {151, Part 3},
number = {},
pages = {1283 - 1292},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.11.002},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214014763},
author = {Hao Liu and Bingpeng Ma and Lei Qin and Junbiao Pang and Chunjie Zhang and Qingming Huang},
abstract = {Abstract Person re-identification aims at matching individuals across multiple non-overlapping adjacent cameras. By condensing multiple gallery images of a person as a whole, we propose a novel method named Set-Label Model (SLM) to improve the performance of person re-identification under the multi-shot setting. Moreover, we utilize mutual-information to measure the relevance between query image and gallery sets. To decrease the computational complexity, we apply a Naive–Bayes Nearest-Neighbor algorithm to approximate the mutual-information value. To overcome the limitations of traditional linear metric learning, we further develop a deep non-linear metric learning (DeepML) approach based on Neighborhood Component Analysis and Deep Belief Network. To evaluate the effectiveness of our proposed approaches, SLM and DeepML, we have carried out extensive experiments on two challenging datasets i-LIDS and ETHZ. The experimental results demonstrate that the proposed methods can obtain better performances compared with the state-of-the-art methods. }}
@article{Liu2016409,
title = {Exponential stability of Markovian jumping Cohen–Grossberg neural networks with mixed mode-dependent time-delays },
journal = {Neurocomputing },
volume = {177},
number = {},
pages = {409 - 415},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.11.046},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017816},
author = {Yurong Liu and Weibo Liu and Mustafa Ali Obaid and Ibrahim Atiatallah Abbas},abstract = {Abstract In this paper, the exponential stability problem is investigated for a class of Cohen–Grossberg neural networks with Markovian jumping parameter and mixed time-delays. The mixed time-delays under consideration consist of both the mode-dependent discrete time-delays and the mode-dependent distributed time-delays. By constructing a new Lyapunov–Krasovskii functional and employing the stochastic analysis techniques, sufficient conditions are proposed to guarantee that the addressed neural networks are exponentially stable in the mean square sense. It is shown that the developed stability criteria can be easily verified by using the standard numerical software. Finally, an illustrative example is provided to show the feasibility and usefulness of the developed results. }}
@article{GonzalezDominguez201549,
title = {Frame-by-frame language identification in short utterances using deep neural networks },
journal = {Neural Networks },
volume = {64},
number = {},
pages = {49 - 58},
year = {2015},
note = {Special Issue on Deep Learning of Representations },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2014.08.006},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002019},
author = {Javier Gonzalez-Dominguez and Ignacio Lopez-Moreno and Pedro J. Moreno and Joaquin Gonzalez-Rodriguez},



abstract = {Abstract This work addresses the use of deep neural networks (DNNs) in automatic language identification (LID) focused on short test utterances. Motivated by their recent success in acoustic modelling for speech recognition, we adapt DNNs to the problem of identifying the language in a given utterance from the short-term acoustic features. We show how DNNs are particularly suitable to perform LID in real-time applications, due to their capacity to emit a language identification posterior at each new frame of the test utterance. We then analyse different aspects of the system, such as the amount of required training data, the number of hidden layers, the relevance of contextual information and the effect of the test utterance duration. Finally, we propose several methods to combine frame-by-frame posteriors. Experiments are conducted on two different datasets: the public NIST Language Recognition Evaluation 2009 (3 s task) and a much larger corpus (of 5 million utterances) known as Google 5M LID, obtained from different Google Services. Reported results show relative improvements of DNNs versus the i -vector system of 40% in LRE09 3 second task and 76% in Google 5M LID. }}
@article{Cao201660,
title = {Building feature space of extreme learning machine with sparse denoising stacked-autoencoder },
journal = {Neurocomputing },
volume = {174, Part A},
number = {},
pages = {60 - 71},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.02.096},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215011674},
author = {Le-le Cao and Wen-bing Huang and Fu-chun Sun},

abstract = {Abstract The random-hidden-node extreme learning machine (ELM) is a much more generalized cluster of single-hidden-layer feed-forward neural networks (SLFNs) which has three parts: random projection, non-linear transformation, and ridge regression (RR) model. Networks with deep architectures have demonstrated state-of-the-art performance in a variety of settings, especially with computer vision tasks. Deep learning algorithms such as stacked autoencoder (SAE) and deep belief network (DBN) are built on learning several levels of representation of the input. Beyond simply learning features by stacking autoencoders (AE), there is a need for increasing its robustness to noise and reinforcing the sparsity of weights to make it easier to discover interesting and prominent features. The sparse AE and denoising AE was hence developed for this purpose. This paper proposes an approach: SSDAE-RR (stacked sparse denoising autoencoder – ridge regression) that effectively integrates the advantages in SAE, sparse AE, denoising AE, and the RR implementation in ELM algorithm. We conducted experimental study on real-world classification (binary and multiclass) and regression problems with different scales among several relevant approaches: SSDAE-RR, ELM, DBN, neural network (NN), and SAE. The performance analysis shows that the SSDAE-RR tends to achieve a better generalization ability on relatively large datasets (large sample size and high dimension) that were not pre-processed for feature abstraction. For 16 out of 18 tested datasets, the performance of SSDAE-RR is more stable than other tested approaches. We also note that the sparsity regularization and denoising mechanism seem to be mandatory for constructing interpretable feature representations. The fact that a SSDAE-RR approach often has a comparable training time to ELM makes it useful in some real applications. }}
@article{Nanni20161602,
title = {Combination of projectors, standard texture descriptors and bag of features for classifying images },
journal = {Neurocomputing },
volume = {173, Part 3},
number = {},
pages = {1602 - 1614},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.09.032},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215013405},
author = {Loris Nanni and Massimo Melucci},

abstract = {Abstract In this work we first propose a new approach to improve the information that can be extracted from the texture descriptors used for describing a given image. These descriptors are used to study the usefulness to combine a classifier trained with standard application of texture descriptors (i.e. a global extraction of descriptors from the whole image or a set of descriptors locally extracted from each sub-window of the image and then concatenated) and a bag-of-features approach. In our bag-of-features approach a set of features is extracted from each sub-window of the image, these sets are quantized, and the resulting global descriptor vectors are used to train a support vector machine based classifier. For improving the information that could be extracted from an image we propose to use projectors. A projector Pi maps a vector y to the subspace defined by Pi and a space of orthogonal projectors induce a probability distribution for every y. Since it is difficult to describe each class with only one projector we extract different clusters from each class and from each cluster a different projection space is found. The Matlab code for the bag of feature approach will be publicly available at https://www.dei.unipd.it/node/2357 }}
@article{Kalinin201580,
title = {A graph based approach to hierarchical image over-segmentation },
journal = {Computer Vision and Image Understanding },
volume = {130},
number = {},
pages = {80 - 86},
year = {2015},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2014.09.007},
url = {http://www.sciencedirect.com/science/article/pii/S1077314214001891},
author = {Pavel Kalinin and Aleksandr Sirota},



abstract = {Abstract The problem of image segmentation is formulated in terms of recursive partitioning of segments into subsegments by optimizing the proposed objective function via graph cuts. Our approach uses a special normalization of the objective function, which enables the production of a hierarchy of regular superpixels that adhere to image boundaries. To enforce compactness and visual homogeneity of segments a regularization strategy is proposed. Experiments on the Berkeley dataset show that the proposed algorithm is comparable in its performance to the state-of-the-art superpixel methods. }}
@article{Wang2014536,
title = {A data-driven study of image feature extraction and fusion },
journal = {Information Sciences },
volume = {281},
number = {},
pages = {536 - 558},
year = {2014},
note = {Multimedia Modeling },
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2014.02.030},
url = {http://www.sciencedirect.com/science/article/pii/S0020025514001364},
author = {Zhiyu Wang and Peng Cui and Fangtao Li and Edward Chang and Shiqiang Yang},abstract = {Abstract Feature analysis is the extraction and comparison of signals from multimedia data, which can subsequently be semantically analyzed. Feature analysis is the foundation of many multimedia computing tasks such as object recognition, image annotation, and multimedia information retrieval. In recent decades, considerable work has been devoted to the research of feature analysis. In this work, we use large-scale datasets to conduct a comparative study of four state-of-the-art, representative feature extraction algorithms: color-texture codebook (CT), SIFT codebook, HMAX, and convolutional networks (ConvNet). Our comparative evaluation demonstrates that different feature extraction algorithms enjoy their own advantages, and excel in different image categories. We provide key observations to explain where these algorithms excel and why. Based on these observations, we recommend feature extraction principles and identify several pitfalls for researchers and practitioners to avoid. Furthermore, we determine that in a large training dataset with more than 10,000 instances per image category, the four evaluated algorithms can converge to the same high level of category-prediction accuracy. This result supports the effectiveness of the data-driven approach. Finally, based on learned clues from each algorithm’s confusion matrix, we devise a fusion algorithm to harvest synergies between these four algorithms and further improve class-prediction accuracy. }}
@article{Chen201555,
title = {MOOC study group: Facilitation strategies, influential factors, and student perceived gains },
journal = {Computers & Education },
volume = {86},
number = {},
pages = {55 - 70},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.03.008},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515000779},
author = {Yang-Hsueh Chen and Pin-Ju Chen},
abstract = {Abstract Join a Meetup Group (face-to-face study group) has been propagated by Coursera to build rapport and provide mutual support among MOOC learners; however, studies remain scant regarding its effectiveness and sustainability. This interpretive case study documents our facilitation process, key influential factors, as well as student perceived gains in a six-week MOOC study group. Data sources include discussion recordings, end-of-course interviews, goal setting sheets, weekly reflection journals, and researchers' observation notes. Results showed that, cognitively, participants broadened their perspective of thinking, raised cultural awareness, and shared many learning strategies. Affectively, they established a strong sense of community and gained motivation for learning. Participants also increased action tendencies toward trying out Coursera functions, new courses, and learning strategies, and they became more cognizant of the benefits and procedures of the MOOC study group. Our findings suggest that, with proper design and facilitation, face-to-face study group would be a practicable and effective approach to leverage MOOC students' motivation, engagement, and deeper learning. Implications are discussed in terms of potential gains, challenges, key influential factors, as well as future design and implementation of MOOC study groups. }}
@article{Sun2014201,
title = {Real-time local stereo via edge-aware disparity propagation },
journal = {Pattern Recognition Letters },
volume = {49},
number = {},
pages = {201 - 206},
year = {2014},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2014.07.010},
url = {http://www.sciencedirect.com/science/article/pii/S016786551400227X},
author = {Xun Sun and Xing Mei and Shaohui Jiao and Mingcai Zhou and Zhihua Liu and Haitao Wang},



abstract = {Abstract This letter presents a novel method for real-time local stereo matching. Different from previous methods which have spent many efforts on cost aggregation, the proposed method re-solves the stereo problem by propagating disparities in the cost domain. It is started by pre-detecting the disparity priors, on which a new cost volume is built for disparity assignment. Then the reliable disparities are propagated via filtering on this cost volume. Specially, a new O ( 1 ) geodesic filter is proposed and demonstrated effective for the task of edge-aware disparity propagation. As can be expected, the proposed framework is highly efficient, due to leaving double aggregation on left–right views, as well as costly post-processing steps, out of account. Moreover, by properly designing a quadric cost function, our method could be extended to good sub-pixel accuracy with a simple quadratic polynomial interpolation. Quantitative evaluation shows that it outperforms all the other local methods both in terms of accuracy and speed on Middlebury benchmark. It ranks 8th out of over 150 submissions if sub-pixel precision is considered, and the average runtime is only 9 ms on a NVIDIA GeForce GTX 580 GPU. }}
@article{Zhang201520,
title = {Enhancing performance of the backpropagation algorithm via sparse response regularization },
journal = {Neurocomputing },
volume = {153},
number = {},
pages = {20 - 40},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.11.055},
url = {http://www.sciencedirect.com/science/article/pii/S092523121401649X},
author = {Jiangshe Zhang and Nannan Ji and Junmin Liu and Jiyuan Pan and Deyu Meng},abstract = {Abstract The backpropagation (BP) algorithm is the most commonly utilized training strategy for a feed-forward artificial neural network (FFANN). The BP algorithm, however, always leads to the problems of low convergence rate, high energy and poor generalization capability of FFANN. In this paper, motivated by the sparsity property of human neuron’ responses, we introduce a new sparse-response BP (SRBP) to improve the capacity of a FFANN by enforcing sparsity to its hidden units through imposing a supplemental L1 term on them. The FFANN model learned from our algorithm is closely related to the real human and thus its mechanism fully complies with the human nervous system, i.e., sparse representation and architectural depth. Experiments on several datasets demonstrate that SRBP yields good performances on convergence rate, energy saving and generalization capability. }}
@article{Zhang2015,
title = {Construction method of concept lattice based on improved variable precision rough set },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.05.136},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215018524},
author = {Ruiling Zhang and Shengwu Xiong and Zhong Chen},
abstract = {Abstract This paper mainly focuses on how to construct concept lattice effectively and efficiently based on improved variable precision rough set. On the basis of preprocessing formal concept, one algorithm that can determine the value range of variable precision parameter β according to the approximate classification quality is proposed. An improved β-upper and lower distribution attribute reduction algorithm is also proposed based on the improved variable precision rough set, the algorithm can be used for attribute reduction on the original data of the concept lattice, and to eliminate the redundant knowledge or noises of the formal context. For the reduced formal context, the paper combines the concept construction algorithm with an improved rule acquisition algorithm seamlessly, and proposes a novel approach of concept lattice construction based on improved variable precision rough set. Finally, a concept lattice generation prototype system is developed, this paper also performs comprehensive experiments, and the effectiveness of the improved algorithm is proved through the experimental results. }}
@article{Srinivas2015880,
title = {Content based medical image retrieval using dictionary learning },
journal = {Neurocomputing },
volume = {168},
number = {},
pages = {880 - 895},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.05.036},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215006967},
author = {M. Srinivas and R. Ramu Naidu and C.S. Sastry and C. Krishna Mohan},


abstract = {Abstract In this paper, a clustering method using dictionary learning is proposed to group large medical databases. An approach grouping similar images into clusters that are sparsely represented by the dictionaries and learning dictionaries simultaneously via K-SVD is proposed. A query image is matched with the existing dictionaries to identify the dictionary with the sparsest representation using an Orthogonal Matching Pursuit (OMP) algorithm. Then images in the cluster associated with this dictionary are compared using a similarity measure to retrieve images similar to the query image. The main features of the method are that it requires no training data and works well on the medical databases which are not restricted to specific context. The performance of the proposed method is examined on IRMA test image database. The experimental results demonstrate the efficacy of the proposed method in the retrieval of medical images. }}
@article{Mansanet2015375,
title = {Mask selective regularization for restricted Boltzmann machines },
journal = {Neurocomputing },
volume = {165},
number = {},
pages = {375 - 383},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.03.026},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215003112},
author = {Jordi Mansanet and Alberto Albiol and Roberto Paredes and Antonio Albiol},



abstract = {Abstract In the present work, we propose to deal with two important issues regarding to the RBM׳s learning capabilities. First, the topology of the input space, and second, the sparseness of the RBM obtained. One problem of RBMs is that they do not take advantage of the topology of the input space. In order to alleviate this lack, we propose to use a surrogate of the mutual information of the input representation space to build a set of binary masks. This approach is general and not only applicable to images, thus it can be extended to other layers in the standard layer-by-layer unsupervised learning. On the other hand, we propose a selective application of two different regularization terms, L1 and L2, in order to ensure the sparseness of the representation and the generalization capabilities. Additionally, another interesting capability of our approach is the adaptation of the topology of the network during the learning phase by means of selecting the best set of binary masks that fit the current weights configuration. The performance of these new ideas is assessed with a set of experiments on different well-known corpus. }}
@article{Huang201532,
title = {Trends in extreme learning machines: A review },
journal = {Neural Networks },
volume = {61},
number = {},
pages = {32 - 48},
year = {2015},
note = {},
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2014.10.001},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002214},
author = {Gao Huang and Guang-Bin Huang and Shiji Song and Keyou You},
abstract = {Abstract Extreme learning machine (ELM) has gained increasing interest from various research fields recently. In this review, we aim to report the current state of the theoretical research and practical advances on this subject. We first give an overview of ELM from the theoretical perspective, including the interpolation theory, universal approximation capability, and generalization ability. Then we focus on the various improvements made to ELM which further improve its stability, sparsity and accuracy under general or specific conditions. Apart from classification and regression, ELM has recently been extended for clustering, feature selection, representational learning and many other learning tasks. These newly emerging algorithms greatly expand the applications of ELM. From implementation aspect, hardware implementation and parallel computation techniques have substantially sped up the training of ELM, making it feasible for big data processing and real-time reasoning. Due to its remarkable efficiency, simplicity, and impressive generalization performance, ELM have been applied in a variety of domains, such as biomedical engineering, computer vision, system identification, and control and robotics. In this review, we try to provide a comprehensive view of these advances in ELM together with its future perspectives. }}
@article{Zhao2015376,
title = {Effective feature selection using feature vector graph for classification },
journal = {Neurocomputing },
volume = {151, Part 1},
number = {},
pages = {376 - 389},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.09.027},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214012107},
author = {Guodong Zhao and Yan Wu and Fuqiang Chen and Junming Zhang and Jing Bai},
abstract = {Abstract Optimal feature subset selection is often required as a preliminary work in machine learning and data mining. The choice of feature subset determines the classification accuracy. It is a crucial aspect to construct efficient feature selection algorithm. Here, by constructing the feature vector graph, a new feature evaluation criterion based on community modularity in complex network is proposed to select the most informative features. To eliminate the relevant redundancy among features, conditional mutual information-based criterion is used to capture information about relevant independency between features, which is the amount of information they can predict about label variable, but they do not share. The most informative features with maximum relevant independency are added to the optimal subset. Integrating these two points, a method named the community modularity Q value-based feature selection (CMQFS) is put forward in this paper. Furthermore, our method based on community modularity can be certified by k-means cluster theory. We compared the proposed algorithm with other state-of-the-art methods by several experiments to indicate that CMQFS is more efficient and accurate. }}
@article{Jiang20152961,
title = {Discriminative feature learning from big data for visual recognition },
journal = {Pattern Recognition },
volume = {48},
number = {10},
pages = {2961 - 2963},
year = {2015},
note = {Discriminative Feature Learning from Big Data for Visual Recognition },
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.05.013},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315001922},
author = {Zhuolin Jiang and Zhe Lin and Haibin Ling and Fatih Porikli and Ling Shao and Pavan Turaga}}
@article{D’Mello2012145,
title = {Dynamics of affective states during complex learning },
journal = {Learning and Instruction },
volume = {22},
number = {2},
pages = {145 - 157},
year = {2012},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2011.10.001},
url = {http://www.sciencedirect.com/science/article/pii/S0959475211000806},
author = {Sidney D’Mello and Art Graesser},
abstract = {We propose a model to explain the dynamics of affective states that emerge during deep learning activities. The model predicts that learners in a state of engagement/flow will experience cognitive disequilibrium and confusion when they face contradictions, incongruities, anomalies, obstacles to goals, and other impasses. Learners revert into the engaged/flow state if equilibrium is restored through thought, reflection, and problem solving. However, failure to restore equilibrium as well as obstacles that block goals trigger frustration, which, if unresolved, will eventually lead to boredom. The major hypotheses of the model were supported in two studies in which participants completed a 32–35 min tutoring session with a computer tutor. Their affective states were tracked at approximately 110 points in their tutoring sessions via a retrospective affect judgment protocol. Time series analyses confirmed the presence of confusion–engagement/flow, boredom–frustration, and confusion–frustration oscillations. We discuss enhancements of the model to address individual differences and pedagogical and motivational strategies that are inspired by the model. }}
@article{Hu20142729,
title = {Perception granular computing in visual haze-free task },
journal = {Expert Systems with Applications },
volume = {41},
number = {6},
pages = {2729 - 2741},
year = {2014},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2013.11.006},
url = {http://www.sciencedirect.com/science/article/pii/S0957417413009068},
author = {Hong Hu and Liang Pang and Dongping Tian and Zhongzhi Shi},

abstract = {Abstract In the past decade, granular computing (GrC) has been an active topic of research in machine learning and computer vision. However, the granularity division is itself an open and complex problem. Deep learning, at the same time, has been proposed by Geoffrey Hinton, which simulates the hierarchical structure of human brain, processes data from lower level to higher level and gradually composes more and more semantic concepts. The information similarity, proximity and functionality constitute the key points in the original insight of granular computing proposed by Zadeh. Many GrC researches are based on the equivalence relation or the more general tolerance relation, either of which can be described by some distance functions. The information similarity and proximity depended on the samples distribution can be easily described by the fuzzy logic. From this point of view, GrC can be considered as a set of fuzzy logical formulas, which is geometrically defined as a layered framework in a multi-scale granular system. The necessity of such kind multi-scale layered granular system can be supported by the columnar organization of the neocortex. So the granular system proposed in this paper can be viewed as a new explanation of deep learning that simulates the hierarchical structure of human brain. In view of this, a novel learning approach, which combines fuzzy logical designing with machine learning, is proposed in this paper to construct a GrC system to explore a novel direction for deep learning. Unlike those previous works on the theoretical framework of GrC, our granular system is abstracted from brain science and information science, so it can be used to guide the research of image processing and pattern recognition. Finally, we take the task of haze-free as an example to demonstrate that our multi-scale GrC has high ability to increase the texture information entropy and improve the effect of haze-removing. }}
@article{Han2016168,
title = {Dynamic aurora sequence recognition using Volume Local Directional Pattern with local and global features },
journal = {Neurocomputing },
volume = {184},
number = {},
pages = {168 - 175},
year = {2016},
note = {RoLoD: Robust Local Descriptors for Computer Vision 2014 },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.126},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215018408},
author = {Bing Han and Yating Song and Xinbo Gao and Xiumei Wang},
abstract = {Abstract Aurora event consists of the spatial structure and temporal evolution of aurora luminosity, which attributes to the effects of the solar wind-magnetosphere interaction and the physics of the magnetosphere-ionosphere interaction. Dynamic aurora event provides a meaningful projection of effects from plasma processes of outer space and also reveals some certain physical phenomenon and principle. Aurora sequence recognition is one of the key procedure in the analysis of dynamic aurora event. Lots of effective features for static aurora image classification are proposed. If these features for static image classification are utilized to recognize the dynamic aurora sequence, it will result in higher computational complexity. The dynamic features of aurora sequence are seldom proposed due to its complexity. To this end, this paper proposes an efficient aurora sequence descriptor which combines local and global spatial information with temporal location information, which is called as Volume Local Directional Patterns. The ring-section spatial pyramid partition structure is used in the VLDP code image which is coded by Volume Local Directional Patterns to obtain the local spatial feature. After combining the global feature of VLDP code image, the final RSPLDP feature is obtained. Finally, the STSC (self-tuning spectral clustering) method is used to classify the aurora sequence. The experimental results on the dataset which is captured from All-sky Imager (ASI) at the Chinese Yellow River Station demonstrate the effectiveness of the proposed classification scheme. }}
@article{Han2016145,
title = {Robust object tracking based on local region sparse appearance model },
journal = {Neurocomputing },
volume = {184},
number = {},
pages = {145 - 167},
year = {2016},
note = {RoLoD: Robust Local Descriptors for Computer Vision 2014 },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.122},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017725},
author = {Guang Han and Xingyue Wang and Jixin Liu and Ning Sun and Cailing Wang},



abstract = {Abstract We propose a robust object tracking algorithm based on local region sparse appearance model in this paper. In this algorithm, the object is divided into several sub-regions, and the sparse dictionaries are obtained by clustering in each sub-region. Therefore spatial structure information of the object can be captured well, and the change of object appearance can be also resisted effectively. First, the object is divided into many small patches. Then the object is divided into several sub-regions according to patch distribution again. The establishment of object dictionary base is based on combination of the dictionaries from all the sub-regions, and then space alignment between different parts of the object can be achieved. Meanwhile, noise removal and other operations in the existing sparse reconstruction error maps are performed to retain valuable information. In the updating framework, a novel flexible template set update mechanism is introduced in this paper. In this update mechanism, valuable object samples will be put into the template set. If samples are not valuable, they should not be put into the template set, even when the template set is not full. Then we use patch sparse coefficient histogram of updated templates to extract time domain information of the object in the form of weighted sum. Therefore, it can provide a reliable template basis for obtaining good candidate object. In addition, when tracking result deviates from the actual position of the object, we use a dynamic sub-region resampling method based on cosine angle to correct the position deviation timely. Therefore this method can effectively prevent the object from being completely lost. Both qualitative and quantitative evaluations on challenging video sequences demonstrate that the proposed tracking algorithm performs favorably against several state-of-the-art methods. }}
@article{Zhang2016231,
title = {Modified S transform and ELM algorithms and their applications in power quality analysis },
journal = {Neurocomputing },
volume = {185},
number = {},
pages = {231 - 241},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.12.050},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215019918},
author = {Shuqing Zhang and Pan Li and Liguo Zhang and Hongjin Li and Wanlu Jiang and Yongtao Hu},abstract = {Abstract Modified S transform (MST) and Extreme Learning Machine (ELM) algorithms are developed and are applied to power quality (PQ) analysis. Two adjustable parameters are introduced in MST to control the Gaussian window width, free from the limitation of time–frequency resolution in the standard S-transform (ST) with an uncontrollable window. Compared with ST, MST provides more convenient means for achieving desired time–frequency resolution for various PQ disturbances signals. In order to optimize the adjustable parameters, three optimization indexes are introduced to make the optimization process more adaptively. Based on the time–frequency matrix of MST, four disturbance features are enough to construct the feature vector, solving the problem of the statistical feature redundancy. Compared with the algorithms such as Back Propagation Neural Network (BPNN) and the Support Vector Machine (SVM), ELM has the advantages of simple structure, fast training speed and high precision, more suitable for engineering application. The simulation experiments show that the MST-ELM algorithms, could provide higher classification accuracy, better anti-noise property, less computational cost and independent of training set. }}
@article{Zhu201683,
title = {Large-scale video copy retrieval with temporal-concentration SIFT },
journal = {Neurocomputing },
volume = {187},
number = {},
pages = {83 - 91},
year = {2016},
note = {Recent Developments on Deep Big Vision },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.09.114},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017336},
author = {Yingying Zhu and Xiaoyan Huang and Qiang Huang and Qi Tian},abstract = {Abstract The scale-invariant feature transform (SIFT) feature plays a very important role in multimedia content analysis, such as near-duplicate image and video retrieval. However, the storage and query costs of SIFT become unbearable for large-scale databases. In this paper, SIFT features are robustly encoded with temporal information by tracking the SIFT to generate temporal-concentration SIFT (TCSIFT), which highly compresses the quantity of local features to reduce visual redundancy, and keeps the advantages of SIFT as much as possible at the same time. On the basis of TCSIFT, a novel framework for large-scale video copy retrieval is proposed in which the processes of retrieval and validation are implemented at the feature and frame level. Experimental results for two different datasets, i.e., CC_WEB_VIDEO and TRECVID, demonstrate that our method can yield comparable accuracy, compact storage size, and more efficient execution time, as well as adapt to various video transformations. }}
@article{Liu201659,
title = {HSAE: A Hessian regularized sparse auto-encoders },
journal = {Neurocomputing },
volume = {187},
number = {},
pages = {59 - 65},
year = {2016},
note = {Recent Developments on Deep Big Vision },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.119},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017683},
author = {Weifeng Liu and Tengzhou Ma and Dapeng Tao and Jane You},abstract = {Abstract Auto-encoders are one kinds of promising non-probabilistic representation learning paradigms that can efficiently learn stable deterministic features. Recently, auto-encoder algorithms are drawing more and more attentions because of its attractive performance in learning insensitive representation with respect to data changes. The most representative auto-encoder algorithms are the regularized auto-encoders including contractive auto-encoder, denoising auto-encoders, and sparse auto-encoders. In this paper, we incorporate both Hessian regularization and sparsity constraints into auto-encoders and then propose a new auto-encoder algorithm called Hessian regularized sparse auto-encoders (HSAE). The advantages of the proposed HSAE lie in two folds: (1) it employs Hessian regularization to well preserve local geometry for data points; (2) it also efficiently extracts the hidden structure in the data by using sparsity constraints. Finally, we stack the single-layer auto-encoders and form a deep architecture of HSAE. To evaluate the effectiveness, we construct extensive experiments on the popular datasets including MNIST and CIFAR-10 dataset and compare the proposed HSAE with the basic auto-encoders, sparse auto-encoders, Laplacian auto-encoders and Hessian auto-encoders. The experimental results demonstrate that HSAE outperforms the related baseline algorithms. }}
@article{Zhang201675,
title = {Hierarchical feature learning with dropout k-means for hyperspectral image classification },
journal = {Neurocomputing },
volume = {187},
number = {},
pages = {75 - 82},
year = {2016},
note = {Recent Developments on Deep Big Vision },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.132},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215018743},
author = {Fan Zhang and Bo Du and Liangpei Zhang and Lefei Zhang},abstract = {Abstract A huge volume of high spatial resolution hyperspectral imagery (HSI) data sets can currently be acquired. However, making full use of the information within the HSI is still a huge problem. The exploitation of spatial information is playing a more and more important role in the classification of remote sensing data. How to efficiently extract the spatial feature for HSI has become a critical task. In this paper, we propose a dropout k-means based framework to extract an effective hierarchical spatial feature for HSI. This paper focuses on unsupervised hierarchical feature learning representation. The proposed framework was tested on two HSIs. The extensive experimental results clearly show that the proposed dropout k-means based framework achieves a superior classification performance. }}
@article{Zhang2014161,
title = {Learning ensemble classifiers via restricted Boltzmann machines },
journal = {Pattern Recognition Letters },
volume = {36},
number = {},
pages = {161 - 170},
year = {2014},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2013.10.009},
url = {http://www.sciencedirect.com/science/article/pii/S0167865513003826},
author = {Chun-Xia Zhang and Jiang-She Zhang and Nan-Nan Ji and Gao Guo},

abstract = {Abstract Recently, restricted Boltzmann machines (RBMs) have attracted considerable interest in machine learning field due to their strong ability to extract features. Given some training data, an RBM or a stack of several RBMs can be used to extract informative features. Meanwhile, ensemble learning is an active research area in machine learning owing to their potential to greatly increase the prediction accuracy of a single classifier. However, RBMs have not been studied to work with ensemble learning so far. In this study, we present several methods for integrating RBMs with bagging to generate diverse and accurate individual classifiers. Taking a classification tree as the base learning algorithm, a thoroughly experimental study conducted on 31 real-world data sets yields some promising conclusions. When using the features extracted by RBMs in ensemble learning, the best way is to perform model combination respectively on the original feature set and the one extracted by a single RBM. However, the prediction performance becomes worse when the features detected by a stack of 2 RBMs are also considered. As for the features detected by RBMs, good classification can be obtained only when they are used together with the original features. }}
@article{Thompson201312,
title = {The digital natives as learners: Technology use patterns and approaches to learning },
journal = {Computers & Education },
volume = {65},
number = {},
pages = {12 - 33},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.12.022},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513000225},
author = {Penny Thompson},


abstract = {This study investigated the claims made in the popular press about the digital native generation as learners. Because students' lives today are saturated with digital media at a time when their brains are still developing, many popular press authors claim that this generation of students thinks and learns differently than any generation that has come before, but the evidence to support these claims is scarce. This study used a survey to gather data on the technology use of university freshmen, the degree to which they identified with the claims being made about their approaches to learning, and the productiveness (in terms of focused attention, deep processing, and persistence) of their approaches to learning. Valid surveys were received from 388 freshmen at a large Midwestern land grant university. A factor analysis was used to identify meaningful patterns of technology use, and descriptive statistics, analysis of correlations, and extreme group t-tests were used to explore the relationships between technology use patterns and learning characteristics. The findings indicate some positive correlations between use of digital technology and the characteristics ascribed in the popular press to the digital native learners, and negative correlations between some categories of technology use and the productiveness of student learning behaviors. Overall, however, the small to moderate relationships suggest a less deterministic relationship between technology and learning than what the popular press writers claim. }}
@article{Liu20152645,
title = {Detection guided deconvolutional network for hierarchical feature learning },
journal = {Pattern Recognition },
volume = {48},
number = {8},
pages = {2645 - 2655},
year = {2015},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.02.002},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315000503},
author = {Jing Liu and Bingyuan Liu and Hanqing Lu},



abstract = {Abstract Deep learning models have gained significant interest as a way of building hierarchical image representation. However, current models still perform far behind human vision system because of the lack of selective property, the lack of high-level guidance for learning and the weakness to learn from few examples. To address these problems, we propose a detection-guided hierarchical learning algorithm for image representation. First, we train a multi-layer deconvolutional network in an unsupervised bottom-up scheme. During the training process, we use each raw image as an input, and decompose an image using multiple alternating layers of non-negative convolutional sparse coding and max-pooling. Inspired from the observation that the filters in top layer can be selectively activated by different high-level structures of images, i.e., one or partial filters should correspond to a particular object class, we update the filters in network by minimizing the reconstruction errors of the corresponding feature maps with respect to certain object detection maps obtained by a set of pre-trained detectors. With the fine-tuned network, we can extract the features of given images in a purely unsupervised way with no need of detectors. We evaluate the proposed feature representation on the task of object recognition, for which an SVM classifier with spatial pyramid matching kernel is used. Experiments on the datasets of PASCAL VOC 2007, Caltech-101 and Caltech-256 demonstrate that our approach outperforms some recent hierarchical feature descriptors as well as classical hand-crafted features. }}
@article{Zheng2016,
title = {Improved Sparse Representation with Low-Rank Representation for Robust Face Recognition },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.146},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216003076},
author = {Chun-Hou Zheng and Yi-Fu Hou and Jun Zhang},
abstract = {Abstract In this paper, an approach to learn a robust sparse representation dictionary for face recognition is proposed. As well known, sparse representation algorithm can effectively tackle slight occlusion problems for face recognition. However, if images are corrupted by heavy noise, performance will be not guaranteed. In this paper, to enhance the robustness of sparse representation to serious noise in face images, we integrate low rank representation into dictionary learning to alleviate the influence of unfavorable factors such as large scale noise and occlusion. Among which we extract eigenfaces by singular value decomposition (SVD) from the low rank pictures to reduce dictionary atoms and, thereby, optimize the efficiency of improved algorithm. Otherwise, we characterize each image using the histogram of orientated gradient (HOG) feature which has been proven to be an effective descriptor for face recognition in particular. The performance of the proposed Low-rank and HOG feature based ESRC (LH_ESRC) algorithm on several popular face databases such as the Extended Yale B database and CMU_PIE face database shows the effectiveness of our method. In addition, we evaluate the robustness of our method by adding different proportions of randomly noise and block occlusion and real disgusts. Experimental results illustrate the benefits of our approach. }}
@article{Wishart2010669,
title = {MuseumScouts: Exploring how schools, museums and interactive technologies can work together to support learning },
journal = {Computers & Education },
volume = {54},
number = {3},
pages = {669 - 678},
year = {2010},
note = {Learning in Digital Worlds: Selected Contributions from the CAL 09 Conference },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2009.08.034},
url = {http://www.sciencedirect.com/science/article/pii/S0360131509002681},
author = {Jocelyn Wishart and Pat Triggs},abstract = {In this paper we report on the successes and challenges of a creative project involving museums, schools and interactive technologies. The MuseumScouts project is EU Comenius 2.1 funded and involves teachers, teacher educators, museum staff, students and researchers from five European countries: Germany (Berlin and Munich), Lithuania (Vilnius), Portugal (Porto), Austria (Linz), and the UK (Bristol and London). The MuseumScouts project arises from a European-wide desire to bring schools and cultural and educational institutions such as museums of different kinds, art galleries, science centres and historic buildings, together in collaborative learning experiences. The project aims to develop learner-centred approaches in the ‘museum’ environment: learners use information they collect during authentic learning opportunities to design short interactive multimedia teaching presentations with collaborative authoring tools. The focus is on knowledge acquisition, transformation and communication. During a ‘museum’ visit students (mainly 10–19 year olds but also, in some cases, adult learners) research specific artefacts, using a range of devices, from pencil and paper to Smartphones, to gather information in the form of notes and photographs. They then work in teams to create interactive multimedia presentations about the artefacts to inform and quiz their peers. The authoring tool, ‘Evolution’, which underpinned the project enables students to collaborate and work online. The principle is of ‘learning by teaching’: the idea that considering how to convey to others what you have understood yourself is an important process for ‘deep’ learning. The project has been run with groups of students at least once in each partner country and twice in several. Countries implemented the project activities in different subject areas, at different stages in the school curriculum and with differing amounts of available time. Student motivation and engagement were notable in all contexts. We present a review of findings common to all the partners in order to share experiences of implementing this pedagogic approach. }}
@article{Pasa2015323,
title = {Neural Networks for Sequential Data: a Pre‐training Approach based on Hidden Markov Models },
journal = {Neurocomputing },
volume = {169},
number = {},
pages = {323 - 333},
year = {2015},
note = {Learning for Visual Semantic Understanding in Big DataESANN 2014Industrial Data Processing and AnalysisSelected papers from the 22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2014)Selected papers from the 11th World Congress on Intelligent Control and Automation (WCICA2014) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.11.081},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215003689},
author = {Luca Pasa and Alberto Testolin and Alessandro Sperduti},

abstract = {Abstract In the last few years, research highlighted the critical role of unsupervised pre-training strategies to improve the performance of artificial neural networks. However, the scope of existing pre-training methods is limited to static data, whereas many learning tasks require to deal with temporal information. We propose a novel approach to pre-training sequential neural networks that exploits a simpler, first-order Hidden Markov Model to generate an approximate distribution of the original dataset. The learned distribution is used to generate a smoothed dataset that is used for pre-training. In this way, it is possible to drive the connection weights in a better region of the parameter space, where subsequent fine-tuning on the original dataset can be more effective. This novel pre-training approach is model-independent and can be readily applied to different network architectures. The benefits of the proposed method, both in terms of accuracy and training times, are demonstrated on a prediction task using four datasets of polyphonic music. The flexibility of the proposed strategy is shown by applying it to two different recurrent neural network architectures, and we also empirically investigate the impact of different hyperparameters on the performance of the proposed pre-training strategy. }}
@article{Beishuizen1999281,
title = {Study strategies in a computer assisted study environment },
journal = {Learning and Instruction },
volume = {9},
number = {3},
pages = {281 - 301},
year = {1999},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/S0959-4752(98)00027-9},
url = {http://www.sciencedirect.com/science/article/pii/S0959475298000279},
author = {Jos J Beishuizen and Evelien T. Stoutjesdijk},
abstract = {A Computer Assisted Study Environment (CASE) was developed as a tool for diagnosing study problems, to be used together with other sources of information, such as learning style questionnaires and clinical interviews. Forty-one students were observed during a 1 h period of studying a text book chapter in CASE. The stages of orientation, planning, and execution were clearly separated by dividing the 1 h study session into three periods. Students could spend an unlimited part of the hour on orientation (first period). Then, not included within the hour, a plan for the task had to be made (second period), after which the remaining time could be devoted to execution of the plan or to any other form of study (third period). We administered a learning style questionnaire, measured reading speed and pretested the students on prior knowledge of the content of the study task. These data were correlated with product and process indicators collected in CASE in order to find out whether various sources of information about learning styles and study strategies provided converging evidence about potential causes of study problems. Process and product indicators of study strategies in CASE revealed differences between deep and surface learning students in orientation and planning activities. However, their actual study behaviour did not vary according to learning style. So, the differences between surface and deep learning become more apparent when we look at study activities before and after actual reading and processing information. As far as learning outcomes are concerned, students with a deep learning style obtained better results than students with a surface learning style, even for factual knowledge. Deep learning students knew more about the subject of the diagnostic study task, and developed a higher reading speed. Both student characteristics significantly determined learning outcomes. }}
@article{Zhou2014312,
title = {Fuzzy deep belief networks for semi-supervised sentiment classification },
journal = {Neurocomputing },
volume = {131},
number = {},
pages = {312 - 322},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.10.011},
url = {http://www.sciencedirect.com/science/article/pii/S0925231213009697},
author = {Shusen Zhou and Qingcai Chen and Xiaolong Wang},abstract = {Abstract By embedding prior knowledge into the learning structure, this paper presents a two-step semi-supervised learning method called fuzzy deep belief networks (FDBN) for sentiment classification. First, we train the general deep belief networks (DBN) by the semi-supervised learning taken on training dataset. Then, we design a fuzzy membership function for each class of reviews based on the learned deep architecture. Since the training of DBN maps each review into the DBN output space, the distribution of all training samples in the space is treated as prior knowledge and is encoded by a series of fuzzy membership functions. Second, based on the fuzzy membership functions and the DBN obtained in the first step, a novel FDBN architecture is constructed and the supervised learning stage is applied to improve the classification performance of the FDBN. FDBN not only inherits the powerful abstraction ability of DBN, but also demonstrates the attractive fuzzy classification ability for handling sentiment data. To inherit the advantages of both active learning and FDBN, we also propose an active FDBN (AFD) semi-supervised learning method. The empirical validation on five sentiment classification datasets demonstrates the effectiveness of FDBN and AFD methods. }}
@article{Dong2016,
title = {LSI: Latent semantic inference for natural image segmentation },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.03.005},
url = {http://www.sciencedirect.com/science/article/pii/S003132031600100X},
author = {Le Dong and Ning Feng and Qianni Zhang},



abstract = {Abstract We propose a novel label inference approach for segmenting natural images into perceptually meaningful regions. Each pixel is assigned a serial label indicating its category using a Markov Random Field (MRF) model. To this end, we introduce a framework for latent semantic inference of serial labels, called LSI, by integrating local pixel, global region, and scale information of an natural image into a MRF-inspired model. The key difference from traditional MRF based image segmentation methods is that we infer semantic segments in the label space instead of the pixel space. We first design a serial label formation algorithm named Color and Location Density Clustering (CLDC) to capture the local pixel information. Then we propose a label merging strategy to combine global cues of labels in the Cross-Region potential to grasp the contextual information within an image. In addition, to align with the structure of segmentation, a hierarchical label alignment mechanism is designed to formulate the Cross-Scale potential by utilizing the scale information to catch the hierarchy of image at different scales for final segmentation optimization. We evaluate the performance of the proposed approach on the Berkeley Segmentation Dataset and preferable results are achieved. }}
@article{Yao2014145,
title = {A fast maximum likelihood nonlinear feature transformation method for GMM–HMM speaker adaptation },
journal = {Neurocomputing },
volume = {128},
number = {},
pages = {145 - 152},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.02.050},
url = {http://www.sciencedirect.com/science/article/pii/S0925231213010072},
author = {Kaisheng Yao and Dong Yu and Li Deng and Yifan Gong},

abstract = {Abstract We describe a novel maximum likelihood nonlinear feature bias compensation method for Gaussian mixture model–hidden Markov model (GMM–HMM) adaptation. Our approach exploits a single-hidden-layer neural network (SHLNN) that, similar to the extreme learning machine (ELM), uses randomly generated lower-layer weights and linear output units. Different from the conventional ELM, however, our approach optimizes the SHLNN parameters by maximizing the likelihood of observing the features given the speaker-independent GMM–HMM. We derive a novel and efficient learning algorithm for optimizing this criterion. We show, on a large vocabulary speech recognition task, that the proposed approach can cut the word error rate (WER) by 13% over the feature maximum likelihood linear regression (fMLLR) method with bias compensation, and can cut the WER by more than 5% over the fMLLR method with both bias and rotation transformations if applied on top of the fMLLR. Overall, it can reduce the WER by more than 27% over the speaker-independent system with 0.2 real-time adaptation time. }}
@article{Kong2015227,
title = {An experience of personalized learning hub initiative embedding BYOD for reflective engagement in higher education },
journal = {Computers & Education },
volume = {88},
number = {},
pages = {227 - 240},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.06.003},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515001311},
author = {Siu Cheung Kong and Yanjie Song},
abstract = {Abstract The article shares an experience in the implementation of the personalized learning hub initiative embedding Bring Your Own Device (BYOD) on learners' reflective engagement in flipped classrooms at a higher education institute. A reflective engagement framework was developed, consisting of three dimensions: intellectual, personal and social reflective engagement. Participants involved 26 in-service teachers for a teacher professional development programme on e-Learning. Participants were encouraged to bring and use their own portable computing devices as a personalized learning hub to support their reflective engagement. The analysis of qualitative and quantitative data collected provides evidence on learners' attainment of reflective engagement in the three dimensions. The designed initiative enabled learners to achieve a significant knowledge gain for enhancing their understanding of e-Learning. The learners perceived that the initiative could help achieving their learning outcomes. They also perceived that group interaction and experience sharing with peers, teachers and related experts in this context could help advance their knowledge. These results imply that the designed initiative can promote learners to be engaged in reflective inquiry for deep learning and personal growth. Directions of future work are discussed regarding validating the developed framework through extending the use of the reflective engagement framework and the personalized learning hub initiative embedding BYOD to more learning scenarios, and enhancing the related teacher professional development. }}
@article{Gao2016,
title = {Extended compressed tracking via random projection based on MSERs and online LS-SVM learning },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.02.012},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316000832},
author = {Yuefang Gao and Xin Shan and Zexi Hu and Dong Wang and Ya Li and Xuhong Tian},abstract = {Abstract The compressed tracking algorithm (CT tracker) is a well-known visual tracking method that models a target object׳s appearance through sparse random projection. However, the tracking results are not stable and robust due to the randomness of random projection. To solve this problem, a more stable and robust approach is proposed for visual tracking based on maximally stable extremal regions (MSERs), sparse random projection and online least squares SVM classifier (LS-SVM) learning. To obtain a relatively stable appearance model, the stable connected components of an object based on MSERs in image feature space are extracted. With the fusion of MSERs and sparse random projection, we model adaptive object appearance to adapt the variation of appearance. Additionally, an online closed-form LS-SVM is employed to quickly and robustly predict the target object location in a tracking by detection framework. Experimental results on benchmark sequences show the stability and robustness of the proposed algorithm compared with the existing CT-based trackers and other state-of-the-art trackers. }}
@article{Schulz20111411,
title = {Exploiting local structure in Boltzmann machines },
journal = {Neurocomputing },
volume = {74},
number = {9},
pages = {1411 - 1417},
year = {2011},
note = {Advances in artificial neural networks, machine learning, and computational intelligence -Selected papers from the 18th European Symposium on Artificial Neural Networks (ESANN 2010) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2010.12.014},
url = {http://www.sciencedirect.com/science/article/pii/S0925231211000580},
author = {Hannes Schulz and Andreas Müller and Sven Behnke},



abstract = {Restricted Boltzmann machines (RBM) are well-studied generative models. For image data, however, standard RBMs are suboptimal, since they do not exploit the local nature of image statistics. We modify RBMs to focus on local structure by restricting visible–hidden interactions. We model long-range dependencies using direct or indirect lateral interaction between hidden variables. While learning in our model is much faster, it retains generative and discriminative properties of RBMs of similar complexity. }}
@article{Lo20153,
title = {The normalized risk-averting error criterion for avoiding nonglobal local minima in training neural networks },
journal = {Neurocomputing },
volume = {149, Part A},
number = {},
pages = {3 - 12},
year = {2015},
note = {Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.11.056},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214009539},
author = {James Ting-Ho Lo and Yichuan Gui and Yun Peng},

abstract = {Abstract The convexification method for data fitting is capable of avoiding nonglobal local minima, but suffers from two shortcomings: the risk-averting error (RAE) criterion grows exponentially as its risk-sensitivity index λ increases, and the existing method of determining λ is often not effective. To eliminate these shortcomings, the normalized RAE (NRAE) is herein proposed. As NRAE is a monotone increasing function of RAE, the region without a nonglobal local minimum of NRAE expands as does that of RAE. However, NRAE does not grow unboundedly as does RAE. The performances of training with NRAE at a fixed λ are reported. Over a large range of the risk-sensitivity index, such training has a high rate of achieving a global or near global minimum starting with different initial weight vectors of the neural network under training. It is observed that at a large λ, the landscape of the NRAE is rather flat, which slows down the training to a halt. This observation motivates the development of the NRAE-MSE method that exploits the large region of an NRAE without a nonglobal local minimum and takes excursions from time to time for training with the standard mean squared error (MSE) to zero into a global or near global minimum. A number of examples of approximating functions that involve fine features or under-sampled segments are used to test the method. Numerical experiments show that the NRAE-MSE training method has a success rate of 100% in all the testing trials for each example, all starting with randomly selected initial weights. The method is also applied to classifying numerals in the well-known MNIST dataset. The new training method outperforms other methods reported in the literature under the same operating conditions. }}
@article{Gori2016,
title = {Semantic video labeling by developmental visual agents },
journal = {Computer Vision and Image Understanding },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2016.02.011},
url = {http://www.sciencedirect.com/science/article/pii/S1077314216000655},
author = {Marco Gori and Marco Lippi and Marco Maggini and Stefano Melacci},
abstract = {Abstract In the recent years, computer vision has been undergoing a period of great development, testified by the many successful applications that are currently available in a variety of industrial products. Yet, when we come to the most challenging and foundational problem of building autonomous agents capable of performing scene understanding in unrestricted videos, there is still a lot to be done. In this paper we focus on semantic labeling of video streams, in which a set of semantic classes must be predicted for each pixel of the video. We propose to attack the problem from bottom to top, by introducing Developmental Visual Agents (DVAs) as general purpose visual systems that can progressively acquire visual skills from video data and experience, by continuously interacting with the environment and following lifelong learning principles. DVAs gradually develop a hierarchy of architectural stages, from unsupervised feature extraction to the symbolic level, where supervisions are provided by external users, pixel-wise. Differently from classic machine learning algorithms applied to computer vision, which typically employ huge datasets of fully labeled images to perform recognition tasks, DVAs can exploit even a few supervisions per semantic category, by enforcing coherence constraints based on motion estimation. Experiments on different vision tasks, performed on a variety of heterogeneous visual worlds, confirm the great potential of the proposed approach. }}
@article{Karhunen2013153,
title = {Finding dependent and independent components from related data sets: A generalized canonical correlation analysis based method },
journal = {Neurocomputing },
volume = {113},
number = {},
pages = {153 - 167},
year = {2013},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.01.018},
url = {http://www.sciencedirect.com/science/article/pii/S0925231213001835},
author = {Juha Karhunen and Tele Hao and Jarkko Ylipaavalniemi},abstract = {In this paper, we consider an extension of independent component analysis (ICA) and blind source separation (BSS) techniques to several related data sets. The goal is to separate mutually dependent and independent components or source signals from these data sets. This problem is important in practice, because such data sets are common in real-world applications. We propose a new method which first uses a generalization of standard canonical correlation analysis (CCA) for detecting subspaces of independent and dependent components. For two data sets, this reduces to using standard CCA. Any ICA or BSS method can then be used for final separation of these components. The proposed method performs well for difficult synthetic data sets containing different types of source signals. It provides interesting and meaningful results for real-world robot grasping data and functional magnetic resonance imaging (fMRI) data. The method is straightforward to implement and computationally not too demanding. The proposed method clearly improves the separation results of several well-known ICA and BSS methods compared with the situation in which CCA or generalized CCA is not used. Not only are the signal-to-noise ratios of the separated sources often clearly higher, but our method also helps these ICA and BSS methods to separate sources that they alone cannot separate. }}
@article{Junco2012505,
title = {No A 4 U: The relationship between multitasking and academic performance },
journal = {Computers & Education },
volume = {59},
number = {2},
pages = {505 - 514},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.12.023},
url = {http://www.sciencedirect.com/science/article/pii/S036013151100340X},
author = {Reynol Junco and Shelia R. Cotten},


abstract = {The proliferation and ease of access to information and communication technologies (ICTs) such as Facebook, text messaging, and instant messaging has resulted in ICT users being presented with more real-time streaming data than ever before. Unfortunately, this has also resulted in individuals increasingly engaging in multitasking as an information management strategy. The purpose of this study was to examine how college students multitask with ICTs and to determine the impacts of this multitasking on their college grade point average (GPA). Using web survey data from a large sample of college students at one university (N = 1839), we found that students reported spending a large amount of time using ICTs on a daily basis. Students reported frequently searching for content not related to courses, using Facebook, emailing, talking on their cell phones, and texting while doing schoolwork. Hierarchical (blocked) linear regression analyses revealed that using Facebook and texting while doing schoolwork were negatively associated with overall college GPA. Engaging in Facebook use or texting while trying to complete schoolwork may tax students' capacity for cognitive processing and preclude deeper learning. Our research indicates that the type and purpose of ICT use matters in terms of the educational impacts of multitasking. }}
@article{Qin2016257,
title = {A novel negative sampling based on TFIDF for learning word representation },
journal = {Neurocomputing },
volume = {177},
number = {},
pages = {257 - 265},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.11.028},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017476},
author = {Pengda Qin and Weiran Xu and Jun Guo},abstract = {Abstract In recent years, continuous-valued word embedding learned by neural network attaches extensive attentions. Especially, Mikolov׳s Continuous Bag-of-Words (CBOW) model and Skip-gram model optimized by Negative Sampling (NEG) achieves impressive result in capturing word semantic and syntactic information. However, the property of NEG that samples over word frequency has the drawbacks of unbalanced training and tends to decrease the training times of medium-frequency words which have greater amount of information; furthermore, words with higher frequency are less probability of being the negative samples. Focus on these issues, this paper proposed a novel NEG strategy that samples negatives based on the notion of Term Frequency-Inverse Document Frequency (NEG-TFIDF). Two ideas are included in this method. First, Negative Sampling is considers as the more effective optimization approach for learning word representation; second, the concept of TFIDF is combined to optimize Negative Sampling, which is a classic and popular method to assess the discrimination of one word for a corpus. Statistical results prove that NEG-TFIDF feasibly reduces the interference of high-frequency words that have very less information and increases the training times of medium-frequency words keeping the total training times being constant and without more calculations. The experiment results show that NEG-TFIDF outperforms Mikolov׳s NEG on both word analogy and word similarity test tasks, particularly in terms of the performance of medium-frequency words. Meanwhile, it also achieves better effects on NLP tasks. Moreover, NEG-TFIDF is a reasonable solution to the problem that NEG׳s performance decreases when the number of negative samples increases beyond a boundary value. }}
@article{Shu2014378,
title = {Robust Differential Circle Patterns based on fuzzy membership-pooling: A novel local image descriptor },
journal = {Neurocomputing },
volume = {144},
number = {},
pages = {378 - 390},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.04.035},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214006262},
author = {Yucheng Shu and Tianjiang Wang and Guangpu Shao and Fang Liu and Qi Feng},

abstract = {Abstract This paper presents a novel image descriptor, which is robust to a variety of photometric and geometric image transformations. Specifically, the Robust Differential Circle Patterns (RDCP) are proposed to encode the continuous intensity changes along the circular-shaped structures around each pixel. Compared to the pixel-wise feature computing schemes, RDCP is capable of describing relatively large local structures in the image. While in the descriptor constructing stage, the proposed fuzzy membership-pooling algorithm can not only capture the local structure of the interest region but also achieve rotation invariance inherently. Experimental results on three popular datasets (Oxford dataset, Patch dataset, and Ukbench dataset) demonstrate the superiority of proposed method over the state-of-the-art algorithms under various image transformations such as rotation and scaling changes, viewpoint changes, image blurring, JPEG compression, illumination changes, and image noise. }}
@article{Zhang2016,
title = {Learning structure of stereoscopic image for no-reference quality assessment with convolutional neural network },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.01.034},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316000558},
author = {Wei Zhang and Chenfei Qu and Lin Ma and Jingwei Guan and Rui Huang},



abstract = {Abstract In this paper, we propose to learn the structures of stereoscopic image based on convolutional neural network (CNN) for no-reference quality assessment. Taking image patches from the stereoscopic images as inputs, the proposed CNN can learn the local structures which are sensitive to human perception and representative for perceptual quality evaluation. By stacking multiple convolution and max-pooling layers together, the learned structures in lower convolution layers can be composed and convolved to higher levels to form a fixed-length representation. Multilayer perceptron (MLP) is further employed to summarize the learned representation to a final value to indicate the perceptual quality of the stereo image patch pair. With different inputs, two different CNNs are designed, namely one-column CNN with only the image patch from the difference image as input, and three-column CNN with the image patches from left-view image, right-view image, and difference image as the input. The CNN parameters for stereoscopic images are learned and transferred based on the large number of 2D natural images. With the evaluation on public LIVE phase-I, LIVE phase-II, and IVC stereoscopic image databases, the proposed no-reference metric achieves the state-of-the-art performance for quality assessment of stereoscopic images, and is even competitive to existing full-reference quality metrics. }}
@article{Qi201628,
title = {LOAD: Local orientation adaptive descriptor for texture and material classification },
journal = {Neurocomputing },
volume = {184},
number = {},
pages = {28 - 35},
year = {2016},
note = {RoLoD: Robust Local Descriptors for Computer Vision 2014 },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.142},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215019396},
author = {Xianbiao Qi and Guoying Zhao and Linlin Shen and Qingquan Li and Matti Pietikäinen},
abstract = {Abstract In this paper, we propose a novel local feature, called Local Orientation Adaptive Descriptor (LOAD), to capture regional texture in an image. In LOAD, we proposed to define point description on an Adaptive Coordinate System (ACS), adopt a binary sequence descriptor to capture relationships between one point and its neighbors and use multi-scale strategy to enhance the discriminative power of the descriptor. The proposed LOAD enjoys not only discriminative power to capture the texture information, but also has strong robustness to illumination variation and image rotation. Extensive experiments on benchmark data sets of texture classification and real-world material recognition show that the LOAD yields the state-of-the-art performance. It is worth to mention that we achieve a superior classification accuracy on Flickr Material Database by using a single feature. Moreover, by combining LOAD with Convolutional Neural Networks (CNN), we obtain significantly better performance than both the LOAD and CNN. This result confirms that the LOAD is complementary to the learning-based features. }}
@article{Crisp20081509,
title = {The development of a formative scenario-based computer assisted assessment tool in psychology for teachers: The PePCAA project },
journal = {Computers & Education },
volume = {50},
number = {4},
pages = {1509 - 1526},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2007.02.004},
url = {http://www.sciencedirect.com/science/article/pii/S0360131507000188},
author = {Victoria Crisp and Christine Ward},
abstract = {Formative computer assisted assessment has become increasingly attractive in Higher Education where providing useful feedback to large numbers of students can be difficult. However, the nature of such assessments has often been limited to objective questions such as multiple-choice. This paper reports on the development and initial trialling of a more innovative, formative use of computer assisted assessment in a Higher Education context. The European funded PePCAA (Pedagogical Psychology Computer Assisted Assessment) project developed a series of scenario-based computer-delivered formative assessments of pedagogical psychology for teachers and trainee teachers, using a range of software features, including the addition of confidence measurement. The project had a two-fold aim: to provide a tool to improve understanding of pedagogical psychology and to explore the potential of more innovative techniques of computer assisted assessment to motivate students and to assess deeper learning. The combination of computer-delivered formative assessment with innovative question styles and confidence ratings is believed to be unique for pedagogical psychology. Scenarios were based on realistic classroom situations and focused on problem solving or on utilising best practice. The PePCAA Learning Assessment Circle (PLAC) provided a framework for indexing the kinds of processes required of users. In the UK, small scale trialling involved a total of 23 teacher trainees such that each assessment was attempted by about seven participants. Participants completed evaluation questionnaires after each assessment. Responses from learners indicated that the UK scenarios were generally very well received and had at least partly achieved the aim of stimulating deeper learning. Transfer of assessments between countries proved more difficult than expected. The next stage of development should be to conduct a larger pilot, thus allowing full investigation of the reliability and validity of the assessments. There is also scope for further development of the PePCAA approach and for its application in other subjects. }}
@article{Ke2010808,
title = {Examining online teaching, cognitive, and social presence for adult students },
journal = {Computers & Education },
volume = {55},
number = {2},
pages = {808 - 820},
year = {2010},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.03.013},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510000990},
author = {Fengfeng Ke},
abstract = {Drawing on the Community of Inquiry model (Garrison, Anderson, &amp; Archer, 2000), this mixed-method case study examined the nature and interactions of teaching, cognitive, and social presence created by online instructors and adult students in diverse course contexts. The study results indicated online instructional design and teaching elements that are crucial prerequisites for a successful online higher educational experience for adult students. The study also informed e-learning designers on the relations between online teaching, cognitive, and social presence. }}
@article{Fan201447,
title = {Learning a generative classifier from label proportions },
journal = {Neurocomputing },
volume = {139},
number = {},
pages = {47 - 55},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.09.057},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214003671},
author = {Kai Fan and Hongyi Zhang and Songbai Yan and Liwei Wang and Wensheng Zhang and Jufu Feng},



abstract = {Abstract Learning a classifier when only knowing the features and marginal distribution of class labels in each of the data groups is both theoretically interesting and practically useful. Specifically, we consider the case in which the ratio of the number of data instances to the number of classes is large. We prove sample complexity upper bound in this setting, which is inspired by an analysis of existing algorithms. We further formulate the problem in a density estimation framework to learn a generative classifier. We also develop a practical RBM-based algorithm which shows promising performance on benchmark datasets. }}
@article{Favier2012666,
title = {Exploring the characteristics of an optimal design for inquiry-based geography education with Geographic Information Systems },
journal = {Computers & Education },
volume = {58},
number = {1},
pages = {666 - 677},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.09.007},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511002247},
author = {Tim T. Favier and Joop A. van der Schee},

abstract = {Geographic Information Systems (GIS) is a kind of computer software that allows people to work with digital maps in a fast and flexible way. In the past decade, more and more geography teachers have become interested in the possibilities of using GIS in secondary education. However, teaching with GIS is complex, and little is known about how to do so in an optimal way. Therefore, an Educational Design Research study (EDR) was conducted with the aim to explore the characteristics of an optimal design for GIS-supported geographic inquiry projects. In this EDR study, a project was developed via progressive cycles of designing, testing, and evaluating, together with teachers from different schools. This paper summarizes the outcomes of the EDR study, and presents some design principles for GIS-supported inquiry-based geography education. Teachers could use these design principles to design and conduct GIS-supported geographic inquiry projects, and in such a way raise their geography lessons to a higher level. This paper also shows that although GIS provides many opportunities for enhancing inquiry-based geography projects, it also holds many conditions for its use to be optimal. GIS-supported inquiry-based geography education requires more than providing appropriate software, tasks, and coaching to ensure that students do not get stuck. In order to effectively raise students’ geographic thinking to a higher level, the project should offer a considerable amount of guidance: it should include several preparatory and evaluative tasks based on a good domain-specific theory for use in educational settings. In addition, teachers should coach students in structuring, correcting, and expanding their geographic thinking via dialogical teaching. }}
@article{D’Mello2014153,
title = {Confusion can be beneficial for learning },
journal = {Learning and Instruction },
volume = {29},
number = {},
pages = {153 - 170},
year = {2014},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2012.05.003},
url = {http://www.sciencedirect.com/science/article/pii/S0959475212000357},
author = {Sidney D’Mello and Blair Lehman and Reinhard Pekrun and Art Graesser},

abstract = {We tested key predictions of a theoretical model positing that confusion, which accompanies a state of cognitive disequilibrium that is triggered by contradictions, conflicts, anomalies, erroneous information, and other discrepant events, can be beneficial to learning if appropriately induced, regulated, and resolved. Hypotheses of the model were tested in two experiments where learners engaged in trialogues on scientific reasoning concepts in a simulated collaborative learning session with animated agents playing the role of a tutor and a peer student. Confusion was experimentally induced via a contradictory-information manipulation involving the animated agents expressing incorrect and/or contradictory opinions and asking the (human) learners to decide which opinion had more scientific merit. The results indicated that self-reports of confusion were largely insensitive to the manipulations. However, confusion was manifested by more objective measures that inferred confusion on the basis of learners’ responses immediately following contradictions. Furthermore, whereas the contradictions had no effect on learning when learners were not confused by the manipulations, performance on multiple-choice posttests and on transfer tests was substantially higher when the contradictions were successful in confusing learners. Theoretical and applied implications are discussed. }}
@article{Zhou20167,
title = {Discriminative quadratic feature learning for handwritten Chinese character recognition },
journal = {Pattern Recognition },
volume = {49},
number = {},
pages = {7 - 18},
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.07.007},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315002678},
author = {Ming-Ke Zhou and Xu-Yao Zhang and Fei Yin and Cheng-Lin Liu},
abstract = {Abstract In this paper, we propose a feature learning method for handwritten Chinese character recognition (HCCR), called discriminative quadratic feature learning (DQFL). Based on original gradient direction feature representation, quadratic correlation between features is used to promote the feature dimensionality, then discriminative feature extraction (DFE) is used for dimensionality reduction. By combining dimensionality promotion and reduction, we can learn a much more discriminative and nonlinear feature representation, which can then boost the classification accuracy significantly. For dimensionality promotion, two types of correlation are exploited, namely, statistical correlation and spatial correlation. Statistical correlation is computed on multiple local feature vectors in different regions of the character image; while spatial correlation encodes the dependency between features of two positions. Feature correlation increases the dimensionality by over 40,000. DFE then reduces the dimensionality to less than 300 without losing discriminability. Classification is performed using nearest prototype classifier (NPC), modified quadratic discriminant function (MQDF) and discriminative learning quadratic discriminant function (DLQDF). In experiments on the CASIA-HWDB1.1 standard dataset, the proposed DQFL method improves the test accuracies of NPC, MQDF and DLQDF by 4.94%, 1.83%, and 1.82%, respectively. The test accuracy is further improved by training set expansion. On the ICDAR 2013 Chinese handwriting recognition competition dataset, the proposed DQFL+DLQDF classifier outperforms the best participating system based on deep convolutional neural network (CNN), while the test speed is much faster. }}
@article{Hu20161108,
title = {A novel word embedding learning model using the dissociation between nouns and verbs },
journal = {Neurocomputing },
volume = {171},
number = {},
pages = {1108 - 1117},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.046},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215010280},
author = {Baotian Hu and Buzhou Tang and Qingcai Chen and Longbiao Kang},



abstract = {Abstract In recent years, there have been researches on using semantic knowledge and global statistical features to guide the learning of word embeddings. Though the syntax knowledge also plays an very important role in natural language understanding, its effectiveness on the word embedding learning is still far from well investigated. Inspired by the principle of the dissociation between nouns and verbs (DNV) in language acquisition observed in neuropsychology, we propose a novel model for word embeddings learning using DNV (named Continuous Dissociation between Nouns and Verbs Model, CDNV). CDNV uses a three-layer feed forward neural network to integrate DNV generated by auto-tagged noun/verb information into the word embeddings learning process, which can still preserve the word order of local context. The advantage of the CDNV lies in that it is able to learn high-quality word embeddings with relatively low time complexity. Experimental results show that: (1) CDNV takes about 1.5 h to learn word embeddings on a corpus of billions of words, which is comparable with CBOW and Skip-gram and more efficient than other models; (2) the nearest neighbors of some representative words derived from the word embeddings learnt by CDNV are more reasonable than other word embeddings; (3) the performance improvement on F1 measure from CDNV word embeddings is greater than other word embeddings on NER and Chunking. }}
@article{Chen20101222,
title = {Engaging online learners: The impact of Web-based learning technology on college student engagement },
journal = {Computers & Education },
volume = {54},
number = {4},
pages = {1222 - 1232},
year = {2010},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2009.11.008},
url = {http://www.sciencedirect.com/science/article/pii/S0360131509003285},
author = {Pu-Shih Daniel Chen and Amber D. Lambert and Kevin R. Guidry},


abstract = {Widespread use of the Web and other Internet technologies in postsecondary education has exploded in the last 15 years. Using a set of items developed by the National Survey of Student Engagement (NSSE), the researchers utilized the hierarchical linear model (HLM) and multiple regressions to investigate the impact of Web-based learning technology on student engagement and self-reported learning outcomes in face-to-face and online learning environments. The results show a general positive relationship between the use the learning technology and student engagement and learning outcomes. We also discuss the possible impact on minority and part-time students as they are more likely to enroll in online courses. }}
@article{Li2015251,
title = {A comparative study on selecting acoustic modeling units in deep neural networks based large vocabulary Chinese speech recognition },
journal = {Neurocomputing },
volume = {170},
number = {},
pages = {251 - 256},
year = {2015},
note = {Advances on Biological Rhythmic Pattern Generation: Experiments, Algorithms and ApplicationsSelected Papers from the 2013 International Conference on Intelligence Science and Big Data Engineering (IScIDE 2013)Computational Energy Management in Smart Grids },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.07.087},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215005664},
author = {Xiangang Li and Yuning Yang and Zaihu Pang and Xihong Wu},
abstract = {Abstract This paper compared the performance of different acoustic modeling units in deep neural networks (DNNs) based large vocabulary continuous speech recognition (LVCSR) systems for Chinese. Recently, the deep neural networks based acoustic modeling method has achieved very competitive performance for many speech recognition tasks, and has become the focus of current LVCSR research. Some previous work have studied the context independent and context dependent DNNs based acoustic models. For Chinese, a syllabic language, the choice of basic modeling units under the background of DNNs based LVCSR systems is a very important issue. Three basic modeling units, syllables, initial/finals, phones, are discussed and compared. Experimental results show that, in the DNNs based systems, the context dependent (CD) phones obtain the best performance, and the context independent (CI) syllables have the similar performance with the CD initial/finals. How the number of clustered states impacts on the performance of DNNs based systems is also discussed, which showed different properties from the GMMs based systems. Besides, through introducing the multi-task learning strategy, these multiple modeling units can be combined in the DNNs training procedure. The experimental results indicate that combining these multiple modeling units using multi-task learning outperforms each individual modeling unit. }}
@article{Yeh20121317,
title = {A co-creation blended KM model for cultivating critical-thinking skills },
journal = {Computers & Education },
volume = {59},
number = {4},
pages = {1317 - 1327},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.05.017},
url = {http://www.sciencedirect.com/science/article/pii/S0360131512001388},
author = {Yu-chu Yeh},abstract = {Both critical thinking (CT) and knowledge management (KM) skills are necessary elements for a university student’s success. Therefore, this study developed a co-creation blended KM model to cultivate university students’ CT skills and to explore the underlying mechanisms for achieving success. Thirty-one university students participated in this study. Findings from the 17-week training program suggest that scaffolding university students through knowledge sharing, internalization, and co-creation processes in a blended KM environment can effectively enhance their CT skills. Moreover, the attribute–treatment interaction (ATI) analysis suggests that judicial thinking style which relates to a deep learning approach may facilitate KM and help improve CT skills. Notably, the complex underlying mechanisms and paths of influence found in this study attest to the highly dynamic nature of the proposed KM processes. }}
@article{He20153160,
title = {Learning predictable binary codes for face indexing },
journal = {Pattern Recognition },
volume = {48},
number = {10},
pages = {3160 - 3168},
year = {2015},
note = {Discriminative Feature Learning from Big Data for Visual Recognition },
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.03.016},
url = {http://www.sciencedirect.com/science/article/pii/S003132031500117X},
author = {Ran He and Yinghao Cai and Tieniu Tan and Larry Davis},
abstract = {Abstract High dimensional dense features have been shown to be useful for face recognition, but result in high query time when searching a large-scale face database. Hence binary codes are often used to obtain fast query speeds as well as reduce storage requirements. However, binary codes for face features can become unstable and unpredictable due to face variations induced by pose, expression and illumination. This paper proposes a predictable hash code algorithm to map face samples in the original feature space to Hamming space. First, we discuss the ‘predictability’ of hash codes for face indexing. Second, we formulate the predictable hash coding problem as a non-convex combinatorial optimization problem, in which the distance between codes for samples from the same class is minimized while the distance between codes for samples from different classes is maximized. An Expectation Maximization method is introduced to iteratively find a sparse and predictable linear mapping. Lastly, a deep feature representation is learned to further enhance the predictability of binary codes. Experimental results on three commonly used face databases demonstrate the superiority of our predictable hash coding algorithm on large-scale problems. }}
@article{Lopes2014114,
title = {Towards adaptive learning with improved convergence of deep belief networks on graphics processing units },
journal = {Pattern Recognition },
volume = {47},
number = {1},
pages = {114 - 127},
year = {2014},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2013.06.029},
url = {http://www.sciencedirect.com/science/article/pii/S0031320313002811},
author = {Noel Lopes and Bernardete Ribeiro},

abstract = {Abstract In this paper we focus on two complementary approaches to significantly decrease pre-training time of a deep belief network (DBN). First, we propose an adaptive step size technique to enhance the convergence of the contrastive divergence (CD) algorithm, thereby reducing the number of epochs to train the restricted Boltzmann machine (RBM) that supports the DBN infrastructure. Second, we present a highly scalable graphics processing unit (GPU) parallel implementation of the CD-k algorithm, which boosts notably the training speed. Additionally, extensive experiments are conducted on the MNIST and the HHreco databases. The results suggest that the maximum useful depth of a DBN is related to the number and quality of the training samples. Moreover, it was found that the lower-level layer plays a fundamental role for building successful DBN models. Furthermore, the results contradict the pre-conceived idea that all the layers should be pre-trained. Finally, it is shown that by incorporating multiple back-propagation (MBP) layers, the DBNs generalization capability is remarkably improved. }}
@article{Turvey2006309,
title = {Towards deeper learning through creativity within online communities in primary education },
journal = {Computers & Education },
volume = {46},
number = {3},
pages = {309 - 321},
year = {2006},
note = {Virtual Learning? },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2005.11.004},
url = {http://www.sciencedirect.com/science/article/pii/S0360131505001648},
author = {Keith Turvey},
abstract = {Despite recent British government moves to equip all Primary Schools with fast broadband connections to the Internet, it would seem that many schools as yet make little use of the increased capacity this affords other than to incorporate more and more rich multimedia in the form of interactive games or animated presentations to illustrate particular concepts or practise specific skills. Whilst not wanting to deny the potential and value of such activities, this paper will focus on the potential use of online communities to reverse this rather unidirectional relationship children often experience with the Internet. That is, the potential within online communities to facilitate a more reciprocal relationship as children become benefactors as well as recipients of the wealth of web-based information, and the quality of learning that may ensue. A small-scale comparative case study was undertaken in two Primary Schools where children were given access to online tools allowing them to communicate and participate – in and out of school – within an online community. Methodological tools used included content analysis of children’s websites and semi-structured interviews with the students and their teachers. The type of learning that online communities may yield, I will argue, is one that is based upon a deep understanding of what it means to both be a learner, and to take responsibility for one’s learning. Furthermore, the findings appear to imply that the participation and role played by the teacher within the virtual community is vital to the quality of learning. }}
@article{Huang2014225,
title = {Multiple spatial pooling for visual object recognition },
journal = {Neurocomputing },
volume = {129},
number = {},
pages = {225 - 231},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.09.037},
url = {http://www.sciencedirect.com/science/article/pii/S0925231213009636},
author = {Yongzhen Huang and Zifeng Wu and Liang Wang and Chunfeng Song},



abstract = {Abstract Global spatial structure is an important factor for visual object recognition but has not attracted sufficient attention in recent studies. Especially, the problems of features' ambiguity and sensitivity to location change in the image space are not yet well solved. In this paper, we propose multiple spatial pooling (MSP) to address these problems. MSP models global spatial structure with multiple Gaussian distributions and then pools features according to the relations between features and Gaussian distributions. Such a process is further generalized into a unified framework, which formulates multiple pooling using matrix operation with structured sparsity. Experiments in terms of scene classification and object categorization demonstrate that MSP can enhance traditional algorithms with small extra computational cost. }}
@article{He2015614,
title = {Image tag-ranking via pairwise supervision based semi-supervised model },
journal = {Neurocomputing },
volume = {167},
number = {},
pages = {614 - 624},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.04.027},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215004749},
author = {Yonghao He and Cuicui Kang and Jian Wang and Shiming Xiang and Chunhong Pan},



abstract = {Abstract Image tag-ranking, the task to sort tags based on their relevance to the related images, has become a hot topic in the field of multimedia. Most existing methods do not incorporate the tag-ranking order information into the models, which is actually very important to solve the issue of image tag-ranking. In this paper, by taking advantage of such important information, we propose a novel model which uses images with ranked tag lists as its supervision information. In the proposed method, each ranked tag list is decomposed into a number of image–tag pairs, all of which are pooled together for training a scoring function. With this pairwise supervision, the model is able to capture the intrinsic ranking structures. In addition, unsupervised data, namely images with unranked tag lists, is also integrated for digging the binary order: relevant or irrelevant. By leveraging both the pairwise supervision and unsupervised structural information, our model sufficiently exploits the tag relevance to images as well as the ranking structures of tag lists. Extensive experiments are conducted on both image tag-ranking and tag-based image search with three benchmark datasets: SUNAttribute, Labelme and MSRC, demonstrating the effectiveness of the proposed model. }}
@article{Hu2014198,
title = {Modeling response properties of V2 neurons using a hierarchical K-means model },
journal = {Neurocomputing },
volume = {134},
number = {},
pages = {198 - 205},
year = {2014},
note = {Special issue on the 2011 Sino-foreign-interchange Workshop on Intelligence Science and Intelligent Data Engineering (IScIDE 2011)Learning Algorithms and ApplicationsSelected papers from the 19th International Conference on Neural Information Processing (ICONIP2012) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.07.052},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214000861},
author = {Xiaolin Hu and Jianwei Zhang and Peng Qi and Bo Zhang},
abstract = {Abstract Many computational models have been proposed for interpreting the properties of neurons in the primary visual cortex (V1). But relatively fewer models have been proposed for interpreting the properties of neurons beyond V1. Recently, it was found that the sparse deep belief network (DBN) could reproduce some properties of the secondary visual cortex (V2) neurons when trained on natural images. In this paper, by investigating the key factors that contribute to the success of the sparse DBN, we propose a hierarchical model based on a simple algorithm, K-means, which can be realized by competitive Hebbian learning. The resulting model exhibits some response properties of V2 neurons, and it is more biologically feasible and computationally efficient than the sparse DBN. }}
@article{Zuo20153004,
title = {Exemplar based Deep Discriminative and Shareable Feature Learning for scene image classification },
journal = {Pattern Recognition },
volume = {48},
number = {10},
pages = {3004 - 3015},
year = {2015},
note = {Discriminative Feature Learning from Big Data for Visual Recognition },
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.02.003},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315000515},
author = {Zhen Zuo and Gang Wang and Bing Shuai and Lifan Zhao and Qingxiong Yang},abstract = {Abstract In order to encode the class correlation and class specific information in image representation, we propose a new local feature learning approach named Deep Discriminative and Shareable Feature Learning (DDSFL). DDSFL aims to hierarchically learn feature transformation filter banks to transform raw pixel image patches to features. The learned filter banks are expected to (1) encode common visual patterns of a flexible number of categories; (2) encode discriminative information; and (3) hierarchically extract patterns at different visual levels. Particularly, in each single layer of DDSFL, shareable filters are jointly learned for classes which share the similar patterns. Discriminative power of the filters is achieved by enforcing the features from the same category to be close, while features from different categories to be far away from each other. Furthermore, we also propose two exemplar selection methods to iteratively select training data for more efficient and effective learning. Based on the experimental results, DDSFL can achieve very promising performance, and it also shows great complementary effect to the state-of-the-art Caffe features. }}
@article{Tong20153258,
title = {Salient object detection via global and local cues },
journal = {Pattern Recognition },
volume = {48},
number = {10},
pages = {3258 - 3267},
year = {2015},
note = {Discriminative Feature Learning from Big Data for Visual Recognition },
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2014.12.005},
url = {http://www.sciencedirect.com/science/article/pii/S0031320314004932},
author = {Na Tong and Huchuan Lu and Ying Zhang and Xiang Ruan},



abstract = {Abstract Previous saliency detection algorithms used to focus on low level features directly or utilize a bunch of sample images and manually labeled ground truth to train a high level learning model. In this paper, we propose a novel coding-based saliency measure by exploring both global and local cues for saliency computation. Firstly, we construct a bottom-up saliency map by considering global contrast information via low level features. Secondly, by using a locality-constrained linear coding algorithm, a top-down saliency map is formulated based on the reconstruction error. To better exploit the local and global information, we integrate the bottom-up and top-down maps as the final saliency map. Extensive experimental results on three large benchmark datasets demonstrate that the proposed approach outperforms 22 state-of-the-art methods in terms of three popular evaluation measures, i.e., the Precision and Recall curve, Area Under ROC Curve and F-measure value. Furthermore, the proposed coding-based method can be easily applied in other methods for significant improvement. }}
@article{Ekambaram2016463,
title = {Active cleaning of label noise },
journal = {Pattern Recognition },
volume = {51},
number = {},
pages = {463 - 480},
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.09.020},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315003519},
author = {Rajmadhan Ekambaram and Sergiy Fefilatyev and Matthew Shreve and Kurt Kramer and Lawrence O. Hall and Dmitry B. Goldgof and Rangachar Kasturi},



abstract = {Abstract Mislabeled examples in the training data can severely affect the performance of supervised classifiers. In this paper, we present an approach to remove any mislabeled examples in the dataset by selecting suspicious examples as targets for inspection. We show that the large margin and soft margin principles used in support vector machines (SVM) have the characteristic of capturing the mislabeled examples as support vectors. Experimental results on two character recognition datasets show that one-class and two-class SVMs are able to capture around 85% and 99% of label noise examples, respectively, as their support vectors. We propose another new method that iteratively builds two-class SVM classifiers on the non-support vector examples from the training data followed by an expert manually verifying the support vectors based on their classification score to identify any mislabeled examples. We show that this method reduces the number of examples to be reviewed, as well as providing parameter independence of this method, through experimental results on four data sets. So, by (re-)examining the labels of the selective support vectors, most noise can be removed. This can be quite advantageous when rapidly building a labeled data set. }}
@article{Jiang20161,
title = {The performance comparison of a new version of artificial raindrop algorithm on global numerical optimization },
journal = {Neurocomputing },
volume = {179},
number = {},
pages = {1 - 25},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.09.093},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215014472},
author = {Qiaoyong Jiang and Lei Wang and Xinhong Hei and Guolin Yu and Yanyan Lin},abstract = {Abstract Very recently, a new metaheuristic called artificial raindrop algorithm (ARA) was proposed. This search algorithm inspired from the phenomenon of natural rainfall, including the generation of raindrop, the descent of raindrop, the collision of raindrop, the flowing of raindrop and the updating of vapor. However, the original ARA only focused on the changing process of a raindrop. In this paper, we present an extension of ARA ( ARA E ) to more raindrops without any major conceptual change to its structure. In the proposed ARA E , all vapors are dynamically divided into several small-sized groups according to the relative distance of vapors in each generation. Each vapor has an associated weight proportion to the fitness value. The raindrop in the corresponding group is then generated based on weighted mean of the current vapors positions. But beyond that, some operators of ARA are further modified to enhance its exploration/exploitation capabilities. In order to thoroughly evaluate the performance of ARA E , a comprehensive comparative study has been carried on the CEC2005 contest benchmark functions. The obtained results indicate that ARA E has overall better performance than ARA, and is very competitive with respect to other twenty-four state-of-the-art original intelligent optimization algorithms and twenty-four improved metaheuristic algorithms. Finally, the proposed ARA E is also applied to artificial neural networks and the promising results on the nonlinear function approximation show the applicability of ARA E for problem solving. }}
@article{Lust20132013,
title = {Students’ tool-use within a web enhanced course: Explanatory mechanisms of students’ tool-use pattern },
journal = {Computers in Human Behavior },
volume = {29},
number = {5},
pages = {2013 - 2021},
year = {2013},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2013.03.014},
url = {http://www.sciencedirect.com/science/article/pii/S0747563213001039},
author = {Griet Lust and Jan Elen and Geraldine Clarebout},

abstract = {Abstract The popularity of content management systems (CMSs) in today’s higher education is driven by the assumption that providing a rich toolset and leaving the use of this toolset under learner control will stimulate self-regulated and deeper learning. Current evidence on students’ tool-use within CMS supported courses however tackles this assumption and indicates that CMSs may empower students’ learning only under particular learner-related conditions. The current study addresses this concern and investigates how students’ tool-use within a CMS supported course can be explained in terms of (a) students’ conceptions on the tool functionalities, (b) self-efficacy beliefs for self-regulated learning and (c) goal orientation. Data were collected within a first year undergraduate course ‘Learning and Instruction’. Students’ (n = 182) tool-use within the course was logged throughout the course episode and the influencing variables were measured through questionnaires. K-means cluster analyses revealed four clusters that reflected differences in students’ tool-choice and tool-use throughout the course. Multinominal regression analyses revealed that these tool-use differences could be explained in terms of students’ goal orientation. The study provides thus perspectives in order to capture students’ academic motivation through unobtrusive, behavioral, measures. Furthermore, questions are raised regarding the parallel between students’ tool-use pattern and study strategy use. }}
@article{Sun20152906,
title = {A robust approach for text detection from natural scene images },
journal = {Pattern Recognition },
volume = {48},
number = {9},
pages = {2906 - 2920},
year = {2015},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.04.002},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315001260},
author = {Lei Sun and Qiang Huo and Wei Jia and Kai Chen},abstract = {Abstract This paper presents a robust text detection approach based on color-enhanced contrasting extremal region (CER) and neural networks. Given a color natural scene image, six component-trees are built from its grayscale image, hue and saturation channel images in a perception-based illumination invariant color space, and their inverted images, respectively. From each component-tree, color-enhanced CERs are extracted as character candidates. By using a divide-and-conquer strategy, each candidate image patch is labeled reliably by rules as one of five types, namely, Long, Thin, Fill, Square-large and Square-small, and classified as text or non-text by a corresponding neural network, which is trained by an ambiguity-free learning strategy. After pruning unambiguous non-text components, repeating components in each component-tree are pruned further. Remaining components are then grouped into candidate text-lines and verified by another set of neural networks. Finally, results from six component-trees are combined, and a post-processing step is used to recover lost characters. Our proposed method achieves superior performance on both ICDAR-2011 and ICDAR-2013 Reading Text in Scene Images test sets. }}
@article{Lerouge20152847,
title = {IODA: An input/output deep architecture for image labeling },
journal = {Pattern Recognition },
volume = {48},
number = {9},
pages = {2847 - 2858},
year = {2015},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.03.017},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315001181},
author = {J. Lerouge and R. Herault and C. Chatelain and F. Jardin and R. Modzelewski},

abstract = {Abstract In this paper, we propose a deep neural network (DNN) architecture called Input Output Deep Architecture (IODA) for solving the problem of image labeling. IODA directly links a whole image to a whole label map, assigning a label to each pixel using a single neural network forward step. Instead of designing a handcrafted a priori model on labels (such as an atlas in the medical domain), we propose to automatically learn the dependencies between labels. The originality of IODA is to transpose DNN input pre-training trick to the output space, in order to learn a high level representation of labels. It allows a fast image labeling inside a fully neural network framework, without the need of any preprocessing such as feature designing or output coding. In this paper, IODA is applied on both a toy texture problem and a real-world medical image dataset, showing promising results. We provide an open source implementation of IODA.11 http://mloss.org/software/view/562/ ,22 https://github.com/jlerouge/crino }}
@article{Tsai2016529,
title = {Photo sundial: Estimating the time of capture in consumer photos },
journal = {Neurocomputing },
volume = {177},
number = {},
pages = {529 - 542},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.11.050},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215018457},
author = {Tsung-Hung Tsai and Wei-Cih Jhou and Wen-Huang Cheng and Min-Chun Hu and I-Chao Shen and Tekoing Lim and Kai-Lung Hua and Ahmed Ghoneim and M. Anwar Hossain and Shintami C. Hidayati},



abstract = {Abstract The time of capture of consumer photos provides rich information in temporal context and has been widely employed for solving various multimedia problems, such as multimedia retrieval and social media analysis. However, we observed that the recorded time stamp in a consumer photo does not often correspond to the true local time at which the photo was taken. This would greatly damage the robustness of time-aware multimedia applications, such as travel route recommendation. Therefore, motivated by the use of traditional sundials, this work proposes a system, Photo Sundial, for estimating the time of capture by exploiting the astronomical theory. In particular, we infer the time by establishing its relations to the measurable astronomical factors from a given outdoor photo, i.e. the sun position in the sky and the camera viewing direction in the photo-taken location. In practice, since it is more often that people would take multiple photos in a single trip, we further develop an optimization framework to jointly estimate the time from multiple photos. Experimental results show that the average estimated time error is less than 0.9 h by the proposed approach, with a significant 65% relative improvement compared to the state-of-the-art method (2.5 h). To the best of our knowledge, this work is the first study in multimedia research to explicitly address the problem of time of capture estimation in consumer photos, and the achieved performances highly encourage our system for practical applications. }}
@article{Zhang2012181,
title = {Scaffolding strategies for supporting middle school students’ online inquiry processes },
journal = {Computers & Education },
volume = {58},
number = {1},
pages = {181 - 196},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.07.016},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511001746},
author = {Meilan Zhang and Chris Quintana},abstract = {Online inquiry, use of the Web as an information resource to inquire into science, has become increasingly common in middle schools in recent years. However, prior research has found that middle school students tend to use the Web in a superficial manner. To address the challenges that students face in online inquiry, we designed the Digital IdeaKeeper, a scaffolded software tool to help students engage in online inquiry through support for inquiry planning, information search, analysis, and synthesis. This study examined the differences between regular and IdeaKeeper-supported online inquiry performed by 8 pairs of sixth graders in naturalistic classroom settings. Analysis of 80 screen videos of students’ computer activities and conversations found that IdeaKeeper-supported online inquiry was more integrated, efficient, continuous, metacognitive, and focused. This study has important implications for designing online learning environments for middle school students. }}
@article{Shu2016,
title = {Kinship-Guided Age Progression },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.12.015},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316000029},
author = {Xiangbo Shu and Jinhui Tang and Hanjiang Lai and Zhiheng Niu and Shuicheng Yan},abstract = {Abstract Age progression is defined as aesthetically re-rendering an aging face with identity preservation and high credibility at any future age for an input face. There are two main challenges in age progression: (1) age progression of a specific individual is stochastic and non-deterministic, though there exist some general changes and resemblances in this process for a relatively large population; (2) there may not be apparent identity information for people at the tender age. In this work, we present an efficient and effective Kinship-Guided Age Progression (KinGAP) approach for an individual, which can automatically generate personalized aging images by leveraging kinship, or more specifically, with guidance of the senior kinship face. The proposed approach mainly consists of three aging modules, which are designed to preserve individual aging characteristics, capture human aging tendency, and guide aging direction, respectively. Extensive experimental results and user study analysis on our constructed age-kinship face dataset validate the superiority of our approach. }}
@article{Wei2016,
title = {Learning to segment with image-level annotations },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.01.015},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316000364},
author = {Yunchao Wei and Xiaodan Liang and Yunpeng Chen and Zequn Jie and Yanhui Xiao and Yao Zhao and Shuicheng Yan},



abstract = {Abstract Recently, deep convolutional neural networks (DCNNs) have significantly promoted the development of semantic image segmentation. However, previous works on learning the segmentation network often rely on a large number of ground-truths with pixel-level annotations, which usually require considerable human effort. In this paper, we explore a more challenging problem by learning to segment under image-level annotations. Specifically, our framework consists of two components. First, reliable hypotheses based localization maps are generated by incorporating the hypotheses-aware classification and cross-image contextual refinement. Second, the segmentation network can be trained in a supervised manner by these generated localization maps. We explore two network training strategies for achieving good segmentation performance. For the first strategy, a novel multi-label cross-entropy loss is proposed to train the network by directly using multiple localization maps for all classes, where each pixel contributes to each class with different weights. For the second strategy, the rough segmentation mask can be inferred from the localization maps, and then the network is optimized based on the single-label cross-entropy loss with the produced masks. We evaluate our methods on the PASCAL VOC 2012 segmentation benchmark. Extensive experimental results demonstrate the effectiveness of the proposed methods compared with the state-of-the-arts. }}
@article{Siniscalchi2013148,
title = {Exploiting deep neural networks for detection-based speech recognition },
journal = {Neurocomputing },
volume = {106},
number = {},
pages = {148 - 157},
year = {2013},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2012.11.008},
url = {http://www.sciencedirect.com/science/article/pii/S0925231212008636},
author = {Sabato Marco Siniscalchi and Dong Yu and Li Deng and Chin-Hui Lee},
abstract = {In recent years deep neural networks (DNNs) – multilayer perceptrons (MLPs) with many hidden layers – have been successfully applied to several speech tasks, i.e., phoneme recognition, out of vocabulary word detection, confidence measure, etc. In this paper, we show that DNNs can be used to boost the classification accuracy of basic speech units, such as phonetic attributes (phonological features) and phonemes. This boosting leads to higher flexibility and has the potential to integrate both top-down and bottom-up knowledge into the Automatic Speech Attribute Transcription (ASAT) framework. ASAT is a new family of lattice-based speech recognition systems grounded on accurate detection of speech attributes. In this paper we compare DNNs and shallow MLPs within the ASAT framework to classify phonetic attributes and phonemes. Several DNN architectures ranging from five to seven hidden layers and up to 2048 hidden units per hidden layer will be presented and evaluated. Experimental evidence on the speaker-independent Wall Street Journal corpus clearly demonstrates that DNNs can achieve significant improvements over the shallow MLPs with a single hidden layer, producing greater than 90% frame-level attribute estimation accuracies for all 21 phonetic features tested. Similar improvement is also observed on the phoneme classification task with excellent frame-level accuracy of 86.6% by using DNNs. This improved phoneme prediction accuracy, when integrated into a standard large vocabulary continuous speech recognition (LVCSR) system through a word lattice rescoring framework, results in improved word recognition accuracy, which is better than previously reported word lattice rescoring results. }}
@article{Tu2015173,
title = {Posterior Distribution Learning (PDL): A novel supervised learning framework using unlabeled samples to improve classification performance },
journal = {Neurocomputing },
volume = {157},
number = {},
pages = {173 - 186},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.01.020},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215000417},
author = {Enmei Tu and Jie Yang and Nicola Kasabov and Yaqian Zhang},



abstract = {Abstract Building a supervised model with good generalization ability in data space using a tiny number of labeled samples is always practically significant and attractive, because labeled samples are generally very expensive to obtain, as the labeling process usually takes much time and resource. In this paper we propose a new supervised two-step learning framework, Posterior Distribution Learning (PDL), to build a robust supervised model in data space by first describing a new constrained graph method to estimate the posterior probability of the unlabeled samples in learning set and then extending a real function regression model to a vector-valued function model to fit a nonlinear function for the posterior probability distribution in the input data space. Compared with traditional supervised learning method, PDL can significantly reduce the demand upon training samples and exhibits the potential to perform nonlinear manifold classification. Experimental results on both synthetic and real world data sets are presented to demonstrate the validity of the proposed supervised architecture. }}
@article{Cui2015403,
title = {Sparsely encoded local descriptor for face verification },
journal = {Neurocomputing },
volume = {147},
number = {},
pages = {403 - 411},
year = {2015},
note = {Advances in Self-Organizing Maps Subtitle of the special issue: Selected Papers from the Workshop on Self-Organizing Maps 2012 (WSOM 2012) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.06.044},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214008169},
author = {Zhen Cui and Shiguang Shan and Ruiping Wang and Lei Zhang and Xilin Chen},
abstract = {Abstract A novel Sparsely Encoded Local Descriptor (SELD) is proposed for face verification. Different from traditional hard or soft quantization methods, we exploit linear regression (LR) model with sparsity and non-negativity constraints to extract more discriminative features (i.e. sparse codes) from local image patches sampled pixel-wisely. Sum-pooling is then imposed to integrate all the sparse codes within each block partitioned from the whole face image. Whitened Principal Component Analysis (WPCA) is finally used to suppress noises and reduce the dimensionality of the pooled features, which thus results in the so-called SELD. To validate the proposed method, comprehensive experiments are conducted on face verification task to compare SELD with the existing related methods in terms of three variable component modules: K-means or K-SVD for dictionary learning, hard/soft assignment or regression model for encoding, as well as sum-pooling or max-pooling for pooling. Experimental results show that our method achieves a competitive accuracy compared with the state-of-the-art methods on the challenging Labeled Faces in the Wild (LFW) database. }}
@article{Patwardhan2015292,
title = {When does higher degree of interaction lead to higher learning in visualizations? Exploring the role of ‘Interactivity Enriching Features’ },
journal = {Computers & Education },
volume = {82},
number = {},
pages = {292 - 305},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.11.018},
url = {http://www.sciencedirect.com/science/article/pii/S0360131514002711},
author = {Mrinal Patwardhan and Sahana Murthy},
abstract = {Abstract Interactive visualizations are being used extensively for effective teaching and learning. Higher degree of interaction in visualizations improves comprehension and leads to deeper learning. However, some research studies have reported ambiguous, inconclusive results in terms of learning benefits of interactive visualizations. The conditional results in such studies suggest some additional features to be instrumental in assisting learners in deriving benefits of interactivity in visualizations. We refer to these features as ‘Interactivity Enriching Features’. This study examines how degree of interaction of the user with the visualization affects learning outcome. The study proposes how interactivity in visualizations can be enriched by offering apt affordances and evaluates what additional features could make learning from interactive visualizations more effective at the same degree of interaction. The study has been carried out in the context of a course on Signals and Systems in Electrical Engineering on second year engineering students (N = 134). The subjects were assigned to one of the four conditions: a Non-Interactive Visualization, an Animation, a Simulation, and an Interactivity Enriched Visualization. The dependent variable was test-score for ‘Understand conceptual knowledge’, ‘Understand procedural knowledge’ and ‘Apply procedural knowledge’ categories. The research findings indicate that, i) different degrees of interaction are required for learning different types of knowledge and ii) interactive visualization could not deliver its learning benefits unless it was augmented by ‘Interactivity Enriching Features’ in the form of appropriate affordance for variable manipulation, especially for higher learning outcomes. This research study contributes towards the design of educationally effective interactive visualizations. }}
@article{Wang2015359,
title = {Saliency detection via background and foreground seed selection },
journal = {Neurocomputing },
volume = {152},
number = {},
pages = {359 - 368},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.10.056},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214014416},
author = {Jianpeng Wang and Huchuan Lu and Xiaohui Li and Na Tong and Wei Liu},

abstract = {Abstract In this paper, we propose a bottom-up visual saliency detection algorithm. Different from most previous methods that mainly concentrate on image object, we take both background and foreground into consideration. First, we collect background seeds from image border superpixels by boundary information and calculate a background-based saliency map. Second, we select foreground seeds by segmenting the first-stage saliency map via adaptive threshold and compute a foreground-based saliency map. Third, the two saliency maps are integrated by the proposed unified function. Finally, we refine the integrated result to obtain a more smooth and accurate saliency map. Moreover, the unified formula also proves to be effective in combining the proposed approach with other models. Experiments on publicly available data sets demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods. }}
@article{Guyon2012174,
title = {Analysis of the IJCNN 2011 UTL challenge },
journal = {Neural Networks },
volume = {32},
number = {},
pages = {174 - 178},
year = {2012},
note = {Selected Papers from IJCNN 2011 },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2012.02.010},
url = {http://www.sciencedirect.com/science/article/pii/S0893608012000391},
author = {Isabelle Guyon and Gideon Dror and Vincent Lemaire and Daniel L. Silver and Graham Taylor and David W. Aha},



abstract = {We organized a challenge in Unsupervised and Transfer Learning: the UTL challenge (http://clopinet.com/ul). We made available large datasets from various application domains: handwriting recognition, image recognition, video processing, text processing, and ecology. The goal was to learn data representations that capture regularities of an input space for re-use across tasks. The representations were evaluated on supervised learning target tasks unknown to the participants. The first phase of the challenge was dedicated to unsupervised transfer learning (the competitors were given only unlabeled data). The second phase was dedicated to cross-task transfer learning (the competitors were provided with a limited amount of labeled data from source tasks, distinct from the target tasks). The analysis indicates that learned data representations yield significantly better results than those obtained with original data or data preprocessed with standard normalizations and functional transforms. }}
@article{Chen201535,
title = {Lead curve detection in drawings with complex cross-points },
journal = {Neurocomputing },
volume = {168},
number = {},
pages = {35 - 46},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.06.018},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215008401},
author = {Jia Chen and Min Li and Qin Jin and Shenghua Bao and Zhong Su and Yong Yu},abstract = {Abstract Lead curve detection in design drawings is a critical problem in a wide range of applications ranging from checking similar drawings in patent granting to constructing hyperlinks between image and text description in digitalization. The difficulty of the problem are two folds: unknown end point of lead curve and complex crossings. However, most previous curve detection algorithms are usually applied in simple or no crossing situations. We make four contributions in solving the problem: (1) we transform the problem into a new problem that finds an optimal path with the best score in the cross-point graph. We introduce the cross-point graph representation which captures the topology of cross-point connectedness. Based on the original drawing and the corresponding cross-point graph, we introduce the coupling concept curve-path, which correlates the curve in the original drawing with the corresponding path in the cross-point graph. (2) we design a set of joint feature representations for curve-path which describes different characteristics of a curve and its corresponding path. (3) we define a task specific loss function for our customized structured SVM. We propose a mixed negative instance sampling strategy to learn the weights of different joint feature representations. We prune the search space effectively for fast lead curve detection. (4) we build a software to efficiently facilitate manual lead curve labeling. We release the patent drawing dataset with groundtruth to public for lead curve detection research. The extensive experimental results prove the effectiveness of our methods. }}
@article{Ng2014104,
title = {LG-Trader: Stock trading decision support based on feature selection by weighted localized generalization error model },
journal = {Neurocomputing },
volume = {146},
number = {},
pages = {104 - 112},
year = {2014},
note = {Bridging Machine learning and Evolutionary Computation (BMLEC)Computational Collective Intelligence },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.04.066},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214008765},
author = {Wing W.Y. Ng and Xue-Ling Liang and Jincheng Li and Daniel S. Yeung and Patrick P.K. Chan},

abstract = {Abstract Stock trading is an important financial activity of human society. Machine learning techniques are adopted to provide trading decision support by predicting the stock price or trading signals of the next day. Decisions are made by analyzing technical indices and fundamental analysis of companies. There are two major machine learning research problems for stock trading decision support: classifier architecture selection and feature selection. In this work, we propose the LG-Trader which will deal with these two problems simultaneously using a genetic algorithm minimizing a new Weighted Localized Generalization Error (wL-GEM). An issue being ignored in current machine learning based stock trading researches is the imbalance among buy, hold and sell decisions. Usually hold decision is the majority in comparison to both buy and sell decisions. So, the wL-GEM is proposed to balance classes by penalizing heavier for generalization error being made in minority classes. The feature selection based on wL-GEM helps to select most useful technical indices among choices for each stock. Experimental results demonstrate that the LG-Trader yields higher profits and rates of return in both stock and index trading. }}
@article{Cui2014306,
title = {Joint sparse representation for video-based face recognition },
journal = {Neurocomputing },
volume = {135},
number = {},
pages = {306 - 312},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.12.004},
url = {http://www.sciencedirect.com/science/article/pii/S092523121301148X},
author = {Zhen Cui and Hong Chang and Shiguang Shan and Bingpeng Ma and Xilin Chen},abstract = {Abstract Video-based Face Recognition (VFR) can be converted into the problem of measuring the similarity of two image sets, where the examples from a video clip construct one image set. In this paper, we consider face images from each clip as an ensemble and formulate VFR into the Joint Sparse Representation (JSR) problem. In JSR, to adaptively learn the sparse representation of a probe clip, we simultaneously consider the class-level and atom-level sparsity, where the former structurizes the enrolled clips using the structured sparse regularizer (i.e., L 2 , 1 -norm) and the latter seeks for a few related examples using the sparse regularizer (i.e., L 1 - norm ). Besides, we also consider to pre-train a compacted dictionary to accelerate the algorithm, and impose the non-negativity constraint on the recovered coefficients to encourage positive correlations of the representation. The classification is ruled in favor of the class that has the lowest accumulated reconstruction error. We conduct extensive experiments on three real-world databases: Honda, MoBo and YouTube Celebrities (YTC). The results demonstrate that our method is more competitive than those state-of-the-art VFR methods. }}
@article{Vitale2014231,
title = {Integrating intuitive and novel grounded concepts in a dynamic geometry learning environment },
journal = {Computers & Education },
volume = {72},
number = {},
pages = {231 - 248},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.11.004},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513003151},
author = {Jonathan M. Vitale and Michael I. Swart and John B. Black},abstract = {Abstract The development of geometry knowledge requires integration of intuitive and novel concepts. While instruction may take many representational forms we argue that grounding novel information in perception and action systems in the context of challenging activities will promote deeper learning. To facilitate learning we introduce a grounded integration pattern of instruction, focusing on (1) eliciting intuitive concepts, (2) introducing novel grounding metaphors, and (3) embedding challenges to promote distinguishing between ideas. To investigate this pattern we compared elementary school children in two conditions who engaged in variations of a computer-based dynamic geometry learning environment that was intended to elicit intuitive concepts of shapes. In the grounded integration condition children performed a procedure of explicitly identifying defining features of shapes (e.g. right angles) with the assistance of animated depictions of spatially-meaningful gestures (e.g. hands forming right angles). In a numerical integration condition children identified defining features with the assistance of a numerical representation. Children in the grounded integration were more likely to accurately identify target shapes in a posttest identification task. We discuss the relevancy of the grounded integration pattern on the development of instructional tools. }}
@article{Li2016,
title = {Class-driven concept factorization for image representation },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2016.01.017},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216000643},
author = {Huirong Li and Jiangshe Zhang and Junmin Liu},abstract = {Abstract Recently, concept factorization (CF), which is a variant of nonnegative matrix factorization, has attracted great attentions in image representation. In CF, each concept is modeled as a nonnegative linear combination of the data points, and each data point as a linear combination of the concepts. CF has impressive performances in data representation. However, it is an unsupervised learning method without considering the label information of the data points. In this paper, we propose a novel semi-supervised CF method, called class-driven concept factorization (CDCF), which associates the class labels of data points with their representations by introducing a class-driven constraint. This constraint forces the representations of data points to be more similar within the same class while different between classes. Thus, the discriminative abilities of the representations are enhanced in the image representation. Experimental results on several databases have shown the effectiveness of our proposed method in terms of clustering accuracy and mutual information. }}
@article{Reychav2015335,
title = {Are your users actively involved? A cognitive absorption perspective in mobile training },
journal = {Computers in Human Behavior },
volume = {44},
number = {},
pages = {335 - 346},
year = {2015},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2014.09.021},
url = {http://www.sciencedirect.com/science/article/pii/S0747563214004737},
author = {Iris Reychav and Dezhi Wu},
abstract = {Abstract The advancement of today’s mobile technologies makes mobile training possible. However, how to engage users in deep learning in a mobile environment remains a challenge, especially in critical training areas such as road safety training. This study aims to understand the role of five different dimensions of cognitive absorption (CA) (i.e., temporal dissociation, focused immersion, heightened enjoyment, control, and curiosity) in training outcomes and how affective and cognitive involvements leverage this learning process. In this study, we designed and implemented a mobile multimedia training system for users who need training for their license test in the field. We then conducted a field study with over five hundred road users with pre- and post-questionnaires. The study findings indicate that the cognitive absorption plays a significant role in affecting users’ deep involvement, which in turn impacts training outcomes. In addition, all CA constructs apart from control influence perceived technology usefulness, which is also a major contributor to perceived learning. The relationship between CA constructs and perceived usefulness is obtained through cognitive and affective involvement, while cognitive involvement is more dominant in this study context. }}
@article{Qu2015310,
title = {Improved perception-based spiking neuron learning rule for real-time user authentication },
journal = {Neurocomputing },
volume = {151, Part 1},
number = {},
pages = {310 - 318},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.09.034},
url = {http://www.sciencedirect.com/science/article/pii/S092523121401217X},
author = {Hong Qu and Xiurui Xie and Yongshuai Liu and Malu Zhang and Li Lu},abstract = {Abstract Spiking neural networks (SNNs) have been highly successful in spatiotemporal pattern recognition. As one of the most efficient supervised learning algorithms in spike sequences learning, the perceptron-based spiking neuron learning rule (PBSNLR) still has a relatively high computational complexity, which is difficult to use in a real-time system. In this paper, a novel method is presented to improve PBSNLR׳s efficiency without reducing its accuracy, and this method is applied to solve user authentication problem in real time. In our method, a user׳s behavioral biometric of sliding dynamic and finger pressure are selected as spatiotemporal features to recognize the user׳s identity. The temporal feature is obtained by the time coding of SNNs and the spatial feature is represented by the neurons׳ relative positions. Comprehensive experimental results demonstrate that our improved algorithm outperforms the traditional PBSNLR in terms of efficiency and exhibits excellent performance when identifying users of touch screen devices. }}
@article{Leung20151,
title = {Editorial for special issue on ICONIP 2013 },
journal = {Neurocomputing },
volume = {165},
number = {},
pages = {1 - 2},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.02.075},
url = {http://www.sciencedirect.com/science/article/pii/S092523121500377X},
author = {Chi Sing Leung}}
@article{Vatanen201560,
title = {Self-organization and missing values in SOM and GTM },
journal = {Neurocomputing },
volume = {147},
number = {},
pages = {60 - 70},
year = {2015},
note = {Advances in Self-Organizing Maps Subtitle of the special issue: Selected Papers from the Workshop on Self-Organizing Maps 2012 (WSOM 2012) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.02.061},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214007127},
author = {T. Vatanen and M. Osmala and T. Raiko and K. Lagus and M. Sysi-Aho and M. Orešič and T. Honkela and H. Lähdesmäki},
abstract = {Abstract In this paper, we study fundamental properties of the Self-Organizing Map (SOM) and the Generative Topographic Mapping (GTM), ramifications of the initialization of the algorithms and properties of the algorithms in the presence of missing data. We show that the commonly used principal component analysis (PCA) initialization of the GTM does not guarantee good learning results with high-dimensional data. Initializing the GTM with the SOM is shown to yield improvements in self-organization with three high-dimensional data sets: commonly used MNIST and ISOLET data sets and epigenomic ENCODE data set. We also propose a revision of handling missing data to the batch SOM algorithm called the Imputation SOM and show that the new algorithm is more robust in the presence of missing data. We benchmark the performance of the topographic mappings in the missing value imputation task and conclude that there are better methods for this particular task. Finally, we announce a revised version of the SOM Toolbox for Matlab with added GTM functionality. }}
@article{Hyun200569,
title = {A study of 5- to 6-year-old children’s peer dynamics and dialectical learning in a computer-based technology-rich classroom environment },
journal = {Computers & Education },
volume = {44},
number = {1},
pages = {69 - 91},
year = {2005},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2004.01.004},
url = {http://www.sciencedirect.com/science/article/pii/S0360131504000156},
author = {Eunsook Hyun},
abstract = {The aim of the study was to explore characteristics of 5- to 6-year-old kindergartners’ peer dynamics during a seven week learning experience in a computer-based technology-rich classroom in the US. The children (9 boys and 9 girls) were placed in pairs by the classroom teacher, based on her perception of the their friendships. Measures of each child’s computer proficiency were obtained at the beginning and conclusion of the experience, using a 20-item instrument called the individualized computer proficiency checklist (ICPC), developed for this study. Overall, the children showed an average gain of 38.5% on their ICPC scores. Paired children who differed in computer proficiencies but shared similar interests worked very well, exemplifying Vygotsky’s dialectical constructivist perspective on peer teaching and learning characteristics. Their conversations displayed self-confidence, multiple perspective-taking skills, and reflective self-assessment. The pairs demonstrating limited computer proficiency frequently engaged in serial turn taking and nonpurposeful clicking on the computer screen. The study concludes with pedagogical implications for teachers. }}
@article{Gikandi20112333,
title = {Online formative assessment in higher education: A review of the literature },
journal = {Computers & Education },
volume = {57},
number = {4},
pages = {2333 - 2351},
year = {2011},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.06.004},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511001333},
author = {J.W. Gikandi and D. Morrow and N.E. Davis},

abstract = {As online and blended learning has become common place educational strategy in higher education, educators need to reconceptualise fundamental issues of teaching, learning and assessment in non traditional spaces. These issues include concepts such as validity and reliability of assessment in online environments in relation to serving the intended purposes, as well as understanding how formative assessment functions within online and blended learning. This article provides a systematic qualitative review of the research literature on online formative assessment in higher education. As an integrative narrative review, the method applied in this review entailed systematic searching, reviewing, and writing this review of the literature to bring together key themes and findings of research in this field. The authors applied qualitative thematic criteria in selecting and reviewing the available literature from which they focused on identifying and analyzing the core themes that are central to the concept of formative assessment with a key focus on application of formative assessment within blended and online contexts. Various techniques were identified for formative assessment by the individual, peers and the teacher, many of which were linked with online tools such as self-test quiz tools, discussion forums and e-portfolios. The benefits identified include improvement of learner engagement and centrality in the process as key actors, including the development of a learning community. The key findings are that effective online formative assessment can foster a learner and assessment centered focus through formative feedback and enhanced learner engagement with valuable learning experiences. Ongoing authentic assessment activities and interactive formative feedback were identified as important characteristics that can address threats to validity and reliability within the context of online formative assessment. }}
@article{Tian201246,
title = {A multiple kernel framework for inductive semi-supervised SVM learning },
journal = {Neurocomputing },
volume = {90},
number = {},
pages = {46 - 58},
year = {2012},
note = {Advances in artificial neural networks, machine learning, and computational intelligence (ESANN 2011) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2011.12.036},
url = {http://www.sciencedirect.com/science/article/pii/S0925231212001877},
author = {Xilan Tian and Gilles Gasso and Stéphane Canu},
abstract = {We investigate the benefit of combining both cluster assumption and manifold assumption underlying most of the semi-supervised algorithms using the flexibility and the efficiency of multiple kernel learning. The multiple kernel version of Transductive SVM (a cluster assumption based approach) is proposed and it is solved based on DC (Difference of Convex functions) programming. Promising results on benchmark data sets and the BCI data analysis suggest and support the effectiveness of proposed work. }}
@article{Zhong2014344,
title = {Robust tracking via patch-based appearance model and local background estimation },
journal = {Neurocomputing },
volume = {123},
number = {},
pages = {344 - 353},
year = {2014},
note = {Contains Special issue articles: Advances in Pattern Recognition Applications and Methods },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.06.044},
url = {http://www.sciencedirect.com/science/article/pii/S0925231213007790},
author = {Bineng Zhong and Yan Chen and Yingju Shen and Yewang Chen and Zhen Cui and Rongrong Ji and Xiaotong Yuan and Duansheng Chen and Weibin Chen},



abstract = {Abstract In this paper, to simultaneously address the tracker drift and occlusion problem, we propose a robust visual tracking algorithm via a patch-based adaptive appearance model driven by local background estimation. Inspired by human visual mechanisms (i.e., context-awareness and attentional selection), an object is represented with a patch-based appearance model, in which each patch outputs a confidence map during the tracking. Then, these confidence maps are combined via a robust estimator to finally get more robust and accurate tracking results. Moreover, we present a local spatial co-occurrence based background modeling approach to automatically estimate the local context background model of an interested object captured from a single camera, which may be stationary or moving. Finally, we utilize local background estimation to provide supervision to an analysis of possible occlusions and the adaption of patch-based appearance model of an object. Qualitative and quantitative experimental results on challenging videos demonstrate the robustness of the proposed method. }}
@article{Zhong2015710,
title = {Online learning 3D context for robust visual tracking },
journal = {Neurocomputing },
volume = {151, Part 2},
number = {},
pages = {710 - 718},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.06.083},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214013757},
author = {Bineng Zhong and Yingju Shen and Yan Chen and Weibo Xie and Zhen Cui and Hongbo Zhang and Duansheng Chen and Tian Wang and Xin Liu and Shujuan Peng and Jin Gou and Jixiang Du and Jing Wang and Wenming Zheng},



abstract = {Abstract In this paper, we study the challenging problem of tracking single object in a complex dynamic scene. In contrast to most existing trackers which only exploit 2D color or gray images to learn the appearance model of the tracked object online, we take a different approach, inspired by the increased popularity of depth sensors, by putting more emphasis on the 3D Context to prevent model drift and handle occlusion. Specifically, we propose a 3D context-based object tracking method that learns a set of 3D context key-points, which have spatial–temporal co-occurrence correlations with the tracked object, for collaborative tracking in binocular video data. We first learn 3D context key-points via the spatial–temporal constrain in their spatial and depth coordinates. Then, the position of the object of interest is determined by a probability voting from the learnt 3D context key-points. Moreover, with depth information, a simple yet effective occlusion handling scheme is proposed to detect occlusion and recovery. Qualitative and quantitative experimental results on challenging video sequences demonstrate the robustness of the proposed method. }}
@article{Bu2016,
title = {Scene parsing using inference Embedded Deep Networks },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.01.027},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316000480},
author = {Shuhui Bu and Pengcheng Han and Zhenbao Liu and Junwei Han},abstract = {Abstract Effective features and graphical model are two key points for realizing high performance scene parsing. Recently, Convolutional Neural Networks (CNNs) have shown great ability of learning features and attained remarkable performance. However, most researches use CNNs and graphical model separately, and do not exploit full advantages of both methods. In order to achieve better performance, this work aims to design a novel neural network architecture called Inference Embedded Deep Networks (IEDNs), which incorporates a novel designed inference layer based on graphical model. Through the IEDNs, the network can learn hybrid features, the advantages of which are that they not only provide a powerful representation capturing hierarchical information, but also encapsulate spatial relationship information among adjacent objects. We apply the proposed networks to scene labeling, and several experiments are conducted on SIFT Flow and PASCAL VOC Dataset. The results demonstrate that the proposed IEDNs can achieve better performance. }}
@article{Giryes2016278,
title = {A greedy algorithm for the analysis transform domain },
journal = {Neurocomputing },
volume = {173, Part 2},
number = {},
pages = {278 - 289},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.02.100},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215012734},
author = {Raja Giryes},

abstract = {Abstract Many image processing applications benefited remarkably from the theory of sparsity. One model of sparsity is the cosparse analysis one. It was shown that using ℓ 1 -minimization one might stably recover a cosparse signal from a small set of random linear measurements if the operator is a frame. Another effort has provided guarantee for dictionaries that have a near optimal projection procedure using greedy-like algorithms. However, no claims have been given for frames. A common drawback of all these existing techniques is their high computational cost for large dimensional problems. In this work we propose a new greedy-like technique with theoretical recovery guarantees for frames as the analysis operator, closing the gap between greedy and relaxation techniques. Our results cover both the case of bounded adversarial noise, where we show that the algorithm provides us with a stable reconstruction, and the one of random Gaussian noise, for which we prove that it has a denoising effect, closing another gap in the analysis framework. Our proposed program, unlike the previous greedy-like ones that solely act in the signal domain, operates mainly in the analysis operator׳s transform domain. Besides the theoretical benefit, the main advantage of this strategy is its computational efficiency that makes it easily applicable to visually big data. We demonstrate its performance on several high dimensional images. }}
@article{Jiang2016146,
title = {A hierarchal BoW for image retrieval by enhancing feature salience },
journal = {Neurocomputing },
volume = {175, Part A},
number = {},
pages = {146 - 154},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.10.044},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215015039},
author = {Fan Jiang and Hai-Miao Hu and Jin Zheng and Bo Li},abstract = {Abstract Retrieving images with multiple features is an active research topic on boosting the performance of existing content-based image retrieval methods. The promising bags-of-words (BoW) models involve multiple features by applying feature fusion strategies in the early stage of image indexing. However, due to the different data forms of features, a simple joint may not guarantee a high retrieval performance. Moreover, a fused feature is not flexible enough to adapt to the variety of images. In order to avoid the submergence of feature salience, this letter proposes a hierarchal BoW to represent each feature in an individual codebook for obtaining the undisturbed ranks from each feature. Moreover, for feature salience enhancement, a query model based on ordinary-least-squared (OLS) regression is established for rank aggregation. The query model weighs each feature according to its retrieval performance and then selects the target images. The experimental results demonstrate that the proposed method improves the accuracy compared to the state-of-the-arts, meanwhile it maintains the stability. }}
@article{Zhong2014317,
title = {Structured partial least squares for simultaneous object tracking and segmentation },
journal = {Neurocomputing },
volume = {133},
number = {},
pages = {317 - 327},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.11.004},
url = {http://www.sciencedirect.com/science/article/pii/S0925231213011478},
author = {Bineng Zhong and Xiaotong Yuan and Rongrong Ji and Yan Yan and Zhen Cui and Xiaopeng Hong and Yan Chen and Tian Wang and Duansheng Chen and Jiaxin Yu},abstract = {Abstract Segmentation-based tracking methods are a class of powerful tracking methods that have been highly successful in alleviating model drift during online-learning of the trackers. These methods typically include a detection component and a segmentation component, in which the tracked objects are first located by detection; then the results from detection are used to guide the process of segmentation to reduce the noises in the training data. However, one of the limitations is that the processes of detection and segmentation are treated entirely separately. The drift from detection may affect the results of segmentation. This also aggravates the tracker's drift. In this paper, we propose a novel method to address this limitation by incorporating structured labeling information in the partial least square analysis algorithms for simultaneous object tracking and segmentation. This allows for novel structured labeling constraints to be placed directly on the tracked objects to provide useful contour constraint to alleviate the drifting problem. We show through both visual results and quantitative measurements on the challenging sequences that our method produces more robust tracking results while obtaining accurate object segmentation results. }}
@article{ZamoraMartínez20141642,
title = {Neural network language models for off-line handwriting recognition },
journal = {Pattern Recognition },
volume = {47},
number = {4},
pages = {1642 - 1652},
year = {2014},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2013.10.020},
url = {http://www.sciencedirect.com/science/article/pii/S0031320313004494},
author = {F. Zamora-Martínez and V. Frinken and S. España-Boquera and M.J. Castro-Bleda and A. Fischer and H. Bunke},


abstract = {Abstract Unconstrained off-line continuous handwritten text recognition is a very challenging task which has been recently addressed by different promising techniques. This work presents our latest contribution to this task, integrating neural network language models in the decoding process of three state-of-the-art systems: one based on bidirectional recurrent neural networks, another based on hybrid hidden Markov models and, finally, a combination of both. Experimental results obtained on the IAM off-line database demonstrate that consistent word error rate reductions can be achieved with neural network language models when compared with statistical N-gram language models on the three tested systems. The best word error rate, 16.1%, reported with ROVER combination of systems using neural network language models significantly outperforms current benchmark results for the IAM database. }}
@article{Doya2016xiii,
title = {State of Neural Networks Is Strong },
journal = {Neural Networks },
volume = {73},
number = {},
pages = {xiii - },
year = {2016},
note = {},
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/S0893-6080(15)00248-8},
url = {http://www.sciencedirect.com/science/article/pii/S0893608015002488},
author = {Kenji Doya and DeLiang Wang}}
@article{Correia2015217,
title = {Special issue on Soft Biometrics },
journal = {Pattern Recognition Letters },
volume = {68, Part 2},
number = {},
pages = {217 - },
year = {2015},
note = {Special Issue on Soft Biometrics },
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.08.005},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515002603},
author = {Paulo Lobato Correia and Abdenour Hadid and Thomas B. Moeslund}}
@article{Wang201675,
title = {Dynamic label propagation for semi-supervised multi-class multi-label classification },
journal = {Pattern Recognition },
volume = {52},
number = {},
pages = {75 - 84},
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.10.006},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315003738},
author = {Bo Wang and John Tsotsos},



abstract = {Abstract Existing semi-supervised methods often have difficulty in dealing with multi-class/multi-label problems due to insufficient consideration of label correlation, and lack an unified framework for multi-modality data. Also, the classification rate is highly dependent on the size of the available labeled data, as well as the accuracy of the similarity measures. To overcome these disadvantages, we propose a semi-supervised multi-class/multi-label classification scheme, dynamic label propagation (DLP), which performs transductive learning through propagation in a dynamic process. Our algorithm emphasizes dynamic metric fusion with label information. A multi-modality extension of the proposed method has been demonstrated to be capable to deal with multiple data types. Significant improvement over the state-of-the-art methods is observed on benchmark datasets for both multi-class and multi-label tasks. The proposed method is proved to be particularly advantageous with very few labeled data. }}
@article{Nijhuis2008121,
title = {The extent of variability in learning strategies and students' perceptions of the learning environment },
journal = {Learning and Instruction },
volume = {18},
number = {2},
pages = {121 - 134},
year = {2008},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2007.01.009},
url = {http://www.sciencedirect.com/science/article/pii/S0959475207000138},
author = {Jan Nijhuis and Mien Segers and Wim Gijselaers},abstract = {The variability in deep and surface learning has been discussed as part of the trait vs. state debate. However, the question is to what extent students change strategies as a function of course demands. This study focused on discerning subgroups of learners with respect to variability in learning strategies and the role of students' learning environment perceptions in it. Data from 124 second-year university students in three consecutive courses were collected. Cluster analysis on the variability of learning strategies revealed two groups of students: a restricted one and a variable one. Differences in variability of learning between the restricted and variable clusters can be explained by the impact of learning environment perceptions on learning strategies and by the variation in the perceptions of the learning environment factors. }}
@article{Xie201694,
title = {A novel supervised approach to learning efficient kernel descriptors for high accuracy object recognition },
journal = {Neurocomputing },
volume = {182},
number = {},
pages = {94 - 101},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.12.007},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215019177},
author = {Bojun Xie and Yi Liu and Hui Zhang and Jian Yu},



abstract = {Abstract Discriminative patch-level features are essential for achieving good performance in many computer vision tasks. Recently, unsupervised learning approaches have been employed to design such features based on the similarities of image patches. These approaches, such as kernel descriptors (KD) and efficient kernel descriptors (EKD), have shown superior performance than pre-defined image features (e.g., SIFT or HoG) in object recognition. They gave a kernel generalization of orientation histograms and suggested a promising way to ‘grow-up’ features based on available information. A major limitation of these approaches is patch similarities are not directly linked to object categories. Therefore, a supervised approach to learning patch-level features that takes into account image class labels is in urgent need. In this paper, we achieve this goal by proposing supervised efficient kernel descriptors (SEKD), in which incomplete Cholesky decomposition is performed jointly with image class label in feature learning. Experimental results on several well-known image classification benchmarks suggest that SEKDs are more compact and have superior discriminative power than previous unsupervised feature descriptors. }}
@article{Li2014388,
title = {Continuous attractors of higher-order recurrent neural networks with infinite neurons },
journal = {Neurocomputing },
volume = {131},
number = {},
pages = {388 - 396},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.10.004},
url = {http://www.sciencedirect.com/science/article/pii/S0925231213009338},
author = {Jun Li and Jian Yang and Xiaotong Yuan and Zhaohua Hu},

abstract = {Abstract This paper investigates continuous attractors of higher-order recurrent neural networks (RNN) with infinite neurons (HRNNwIN). By employing the linearization technique, we present some new criteria on stable, semi-stable, positive semi-global stable and unstable continuous attractors. We also study the continuous attractors of this network under Lognormal distribution except Gaussian distribution. Finally, some simulations are finally carried out to further illustrate the developed theory. }}
@article{Cabana20161099,
title = {A neural model that implements probabilistic topics },
journal = {Neurocomputing },
volume = {171},
number = {},
pages = {1099 - 1107},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.061},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215010681},
author = {Álvaro Cabana and Eduardo Mizraji and Juan C. Valle-Lisboa},abstract = {Abstract We present a neural network model that can execute some of the procedures used in the information sciences literature. In particular we offer a simplified notion of topic and how to implement it using neural networks that use the Kronecker tensor product. We show that the topic detecting mechanism is related to Naive Bayes statistical classifiers, and that it is able to disambiguate the meaning of polysemous words. We evaluate our network in a text categorization task, resulting in performance levels comparable to Naive Bayes classifiers, as expected. Hence, we propose a simple scalable neural model capable of dealing with machine learning tasks, while retaining biological plausibility and probabilistic transparency. }}
@article{Turcsany2016229,
title = {Local receptive field constrained deep networks },
journal = {Information Sciences },
volume = {349–350},
number = {},
pages = {229 - 247},
year = {2016},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2016.02.034},
url = {http://www.sciencedirect.com/science/article/pii/S0020025516300998},
author = {Diana Turcsany and Andrzej Bargiela and Tomas Maul},

abstract = {Abstract Automatic extraction of distinctive features from a visual information stream is challenging due to the large amount of information contained in most image data. In recent years deep neural networks (DNNs) have gained outstanding popularity for solving visual information processing tasks. This study reports novel contributions, including a new DNN architecture and training method, which increase the fidelity of DNN-based representations to encodings extracted by visual processing neurons. Our local receptive field constrained DNNs (LRF-DNNs) are pre-trained with a modified restricted Boltzmann machine, the LRF-RBM, which utilizes biologically inspired Gaussian receptive field constraints to encourage the emergence of local features. Moreover, we propose a method for concurrently finding advantageous receptive field centers, while training the LRF-RBM. By utilizing LRF-RBMs with gradually increasing receptive field sizes on each layer, our LRF-DNN learns features of increasing complexity and demonstrates hierarchical part-based compositionality. We show superior face completion and reconstruction results on the challenging LFW face dataset. }}
@article{Dagli20149,
title = {Conquering Complexity: Challenges and Opportunities Preface },
journal = {Procedia Computer Science },
volume = {36},
number = {},
pages = {9 - 10},
year = {2014},
note = {Complex Adaptive Systems Philadelphia, PA November 3-5, 2014 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2014.09.001},
url = {http://www.sciencedirect.com/science/article/pii/S1877050914012502},
author = {Cihan H. Dagli}}
@article{Liu20151162,
title = {Computing k shortest paths using modified pulse-coupled neural network },
journal = {Neurocomputing },
volume = {149, Part C},
number = {},
pages = {1162 - 1176},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.09.012},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214011680},
author = {Guisong Liu and Zhao Qiu and Hong Qu and Luping Ji},abstract = {Abstract The K Shortest Paths (KSPs) problem with non-numerable applications has been researched widely, which aims to compute KSPs between two nodes in a non-decreasing order. However, less effort has been devoted to single-source KSP problem than to single-pair KSP computation, especially by using parallel methods. This paper proposes a Modified Continued Pulse Coupled Neural Network (MCPCNN) model to solve the two kinds of KSP problems. Theoretical analysis of MCPCNN and two algorithms for KSPs computation are presented. By using the parallel pulse transmission characteristic of pulse coupled neural networks, the method is able to find k shortest paths quickly. The computational complexity is only related to the length of the longest shortest path. Simulative results for route planning show that the proposed MCPCNN method for KSPs computation outperforms many other current efficient algorithms. }}
@article{Paragios2016,
title = {State of the Journal },
journal = {Computer Vision and Image Understanding },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2016.01.014},
url = {http://www.sciencedirect.com/science/article/pii/S107731421600045X},
author = {Nikos Paragios}}
@article{Marée201617,
title = {Towards generic image classification using tree-based learning: An extensive empirical study },
journal = {Pattern Recognition Letters },
volume = {74},
number = {},
pages = {17 - 23},
year = {2016},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2016.01.006},
url = {http://www.sciencedirect.com/science/article/pii/S0167865516000179},
author = {Raphaël Marée and Pierre Geurts and Louis Wehenkel},
abstract = {Abstract This paper considers the general problem of image classification without using any prior knowledge about image classes. We study variants of a method based on supervised learning whose common steps are the extraction of random subwindows described by raw pixel intensity values and the use of ensemble of extremely randomized trees to directly classify images or to learn image features. The influence of method parameters and variants is thoroughly evaluated so as to provide baselines and guidelines for future studies. Detailed results are provided on 80 publicly available datasets that depict very diverse types of images (more than 3800 image classes and over 1.5 million images). }}
@article{Tanisik201644,
title = {Facial descriptors for human interaction recognition in still images },
journal = {Pattern Recognition Letters },
volume = {73},
number = {},
pages = {44 - 51},
year = {2016},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2016.01.002},
url = {http://www.sciencedirect.com/science/article/pii/S0167865516000064},
author = {Gokhan Tanisik and Cemil Zalluhoglu and Nazli Ikizler-Cinbis},



abstract = {Abstract This paper presents a novel approach in a rarely studied area of computer vision: Human interaction recognition in still images. We explore whether the facial regions and their spatial configurations contribute to the recognition of interactions. In this respect, our method involves extraction of several visual features from the facial regions, as well as incorporation of scene characteristics and deep features to the recognition. Extracted multiple features are utilized within a discriminative learning framework for recognizing interactions between people. Our designed facial descriptors are based on the observation that relative positions, size and locations of the faces are likely to be important for characterizing human interactions. Since there is no available dataset in this relatively new domain, a comprehensive new dataset which includes several images of human interactions is collected. Our experimental results show that faces and scene characteristics contain important information to recognize interactions between people. }}
@article{Chen20161,
title = {RoLoD: Robust local descriptors for computer vision },
journal = {Neurocomputing },
volume = {184},
number = {},
pages = {1 - 2},
year = {2016},
note = {RoLoD: Robust Local Descriptors for Computer Vision 2014 },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.11.043},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017749},
author = {Jie Chen and Zhen Lei and Li Liu and Guoying Zhao and Matti Pietikäinen}}
@article{Kok2016342,
title = {Crowd behavior analysis: A review where physics meets biology },
journal = {Neurocomputing },
volume = {177},
number = {},
pages = {342 - 362},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.11.021},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017403},
author = {Ven Jyn Kok and Mei Kuan Lim and Chee Seng Chan},
abstract = {Abstract Although the traits emerged in a mass gathering are often non-deliberative, the act of mass impulse may lead to irrevocable crowd disasters. The two-fold increase of carnage in crowd since the past two decades has spurred significant advances in the field of computer vision, towards effective and proactive crowd surveillance. Computer vision studies related to crowd are observed to resonate with the understanding of the emergent behavior in physics (complex systems) and biology (animal swarm). These studies, which are inspired by biology and physics, share surprisingly common insights, and interesting contradictions. However, this aspect of discussion has not been fully explored. Therefore, this survey provides the readers with a review of the state-of-the-art methods in crowd behavior analysis from the physics and biologically inspired perspectives. We provide insights and comprehensive discussions for a broader understanding of the underlying prospect of blending physics and biology studies in computer vision. }}
@article{Doya2015xv,
title = {Exciting Time for Neural Networks },
journal = {Neural Networks },
volume = {61},
number = {},
pages = {xv - xvi},
year = {2015},
note = {},
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/S0893-6080(14)00260-3},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002603},
author = {Kenji Doya and DeLiang Wang}}
@article{Li2015437,
title = {Editorial for the special issue of Information Sciences Journal (ISJ) on Nature-inspired algorithms for large scale global optimization },
journal = {Information Sciences },
volume = {316},
number = {},
pages = {437 - 439},
year = {2015},
note = {Nature-Inspired Algorithms for Large Scale Global Optimization },
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2015.05.001},
url = {http://www.sciencedirect.com/science/article/pii/S0020025515003527},
author = {Xiaodong Li and Ke Tang and P.N. Suganthan and Zhenyu Yang}}
@article{Li201523,
title = {Feature learning from incomplete EEG with denoising autoencoder },
journal = {Neurocomputing },
volume = {165},
number = {},
pages = {23 - 31},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.08.092},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215004282},
author = {Junhua Li and Zbigniew Struzik and Liqing Zhang and Andrzej Cichocki},
abstract = {Abstract An alternative pathway for the human brain to communicate with the outside world is by means of a brain computer interface (BCI). A BCI can decode electroencephalogram (EEG) signals of brain activities, and then send a command or an intent to an external interactive device, such as a wheelchair. The effectiveness of the BCI depends on the performance in decoding the EEG. Usually, the EEG is contaminated by different kinds of artefacts (e.g., electromyogram (EMG), background activity), which leads to a low decoding performance. A number of filtering methods can be utilized to remove or weaken the effects of artefacts, but they generally fail when the EEG contains extreme artefacts. In such cases, the most common approach is to discard the whole data segment containing extreme artefacts. This causes the fatal drawback that the BCI cannot output decoding results during that time. In order to solve this problem, we employ the Lomb–Scargle periodogram to estimate the spectral power from incomplete EEG (after removing only parts contaminated by artefacts), and Denoising Autoencoder (DAE) for learning. The proposed method is evaluated with motor imagery EEG data. The results show that our method can successfully decode incomplete EEG to good effect. }}
@article{Tang20141,
title = {Guest editorial: Special issue on brain inspired models of cognitive memory },
journal = {Neurocomputing },
volume = {138},
number = {},
pages = {1 - 2},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.02.010},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214003622},
author = {Huajin Tang and Kiruthika Ramanathan and Ning Ning}}
@article{Liu2016,
title = {Advances in intelligent control and information processing },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2016.01.085},
url = {http://www.sciencedirect.com/science/article/pii/S092523121600254X},
author = {Qingshan Liu and Jun Wang and Zhigang Zeng}}
@article{Song201563,
title = {Hierarchical feature extraction by multi-layer non-negative matrix factorization network for classification task },
journal = {Neurocomputing },
volume = {165},
number = {},
pages = {63 - 74},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.08.095},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215004580},
author = {Hyun Ah Song and Bo-Kyeong Kim and Thanh Luong Xuan and Soo-Young Lee},abstract = {Abstract In this paper, we propose multi-layer non-negative matrix factorization (NMF) network for classification task, which provides intuitively understandable hierarchical feature learning process. The layer-by-layer learning strategy was adopted through stacked NMF layers, which enforced non-negativity of both features and their coefficients. With the non-negativity constraint, the learning process revealed latent feature hierarchies in the complex data in intuitively understandable manner. The multi-layer NMF networks was investigated for classification task by studying various network architectures and nonlinear functions. The proposed multilayer NMF network was applied to document classification task, and demonstrated that our proposed multi-layer NMF network resulted in much better classification performance compared to single-layered network, even with the small number of features. Also, through intuitive learning process, the underlying structure of feature hierarchies was revealed for the complex document data. }}
@article{Cheng2015149,
title = {Semi-supervised learning and feature evaluation for RGB-D object recognition },
journal = {Computer Vision and Image Understanding },
volume = {139},
number = {},
pages = {149 - 160},
year = {2015},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2015.05.007},
url = {http://www.sciencedirect.com/science/article/pii/S1077314215001083},
author = {Yanhua Cheng and Xin Zhao and Kaiqi Huang and Tieniu Tan},
abstract = {Abstract With new depth sensing technology such as Kinect providing high quality synchronized RGB and depth images (RGB-D data), combining the two distinct views for object recognition has attracted great interest in computer vision and robotics community. Recent methods mostly employ supervised learning methods for this new RGB-D modality based on the two feature sets. However, supervised learning methods always depend on large amount of manually labeled data for training models. To address the problem, this paper proposes a semi-supervised learning method to reduce the dependence on large annotated training sets. The method can effectively learn from relatively plentiful unlabeled data, if powerful feature representations for both the RGB and depth view can be extracted. Thus, a novel and effective feature termed CNN-SPM-RNN is proposed in this paper, and four representative features (KDES [1], CKM [2], HMP [3] and CNN-RNN [4]) are evaluated and compared with ours under the unified semi-supervised learning framework. Finally, we verify our method on three popular and publicly available RGB-D object databases. The experimental results demonstrate that, with only 20% labeled training set, the proposed method can achieve competitive performance compared with the state of the arts on most of the databases. }}
@article{Achler2015356,
title = {A Localist Paradigm for Big Data },
journal = {Procedia Computer Science },
volume = {53},
number = {},
pages = {356 - 364},
year = {2015},
note = {INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.312},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915018153},
author = {Tsvi Achler},

abstract = {Abstract Big data problems involve more than being able to create a network that can recognize based on a big data set. Big data problems also involve being able to incorporate new information as it arrives. Rehearsing big data sets may require an inordinate amount of time. We present a localist neural network recognition method that can perform equivalent recognition to popular distributed neural networks (shown mathematically) but does not require rehearsing for learning or update. It can also be placed in deep network configuration. However, the focus of this work is not the details of deep networks. The focus is on how easy it is to create and update individual layers. This is an important bottleneck because ultimately creating and updating layers are a problem whether networks are in a deep configuration or not. We use a small laptop running matlab as a microenvironment to reveal data limits determined by limited memory and processing speed. Within this microenvironment we show our approach accepts the largest datasets. Ultimately we encountered limits of the matlab routines to generate random numbers before the limit of our algorithm. }}
@article{Deng2016107,
title = {Single image super-resolution by approximated Heaviside functions },
journal = {Information Sciences },
volume = {348},
number = {},
pages = {107 - 123},
year = {2016},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2016.02.015},
url = {http://www.sciencedirect.com/science/article/pii/S002002551630069X},
author = {Liang-Jian Deng and Weihong Guo and Ting-Zhu Huang},



abstract = {Abstract Image super-resolution involves the estimation of a high-resolution image from one or multiple low resolution images. It is widely used in medical imaging, satellite imaging, target recognition, etc. In this paper, we solve the problem of single image super-resolution from an image intensity function estimation perspective. We assume that the unknown image intensity function is defined on a continuous domain and belongs to a space with a redundant basis. The selection of the redundant basis is based on an observation: an image is composed of smooth and non-smooth components, and we use two classes of approximated Heaviside functions (AHFs) to represent them respectively. The coefficients of the redundant basis are computed iteratively from a given low-resolution image. In addition, we apply the proposed iterative scheme to image patches to reduce computation and storage size. Comparisons with some existing competitive methods show the effectiveness of the proposed method. }}
@article{Gao2015531,
title = {Learning for 3D understanding },
journal = {Neurocomputing },
volume = {151, Part 2},
number = {},
pages = {531 - 532},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.10.052},
url = {http://www.sciencedirect.com/science/article/pii/S092523121401412X},
author = {Yue Gao and Rongrong Ji and Wei Liu and Qionghai Dai}}
@article{Cui2016126,
title = {Sentiment analysis via integrating distributed representations of variable-length word sequence },
journal = {Neurocomputing },
volume = {187},
number = {},
pages = {126 - 132},
year = {2016},
note = {Recent Developments on Deep Big Vision },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.129},
url = {http://www.sciencedirect.com/science/article/pii/S092523121501855X},
author = {Zhijian Cui and Xiaodong Shi and Yidong Chen},abstract = {Abstract Sentiment analysis aims to identify the overall emotional polarity of a given text. It is a nontrivial task to perform sentiment analysis as sentiment information is crucial in many natural language processing applications. Previous n-gram features is derived from a bag-of-n-gram model which is insensitive to the order of the n-gram. To address this problem, we integrates distributed semantic features of word sequence, with fixed-size independent of the length of the word sequence. We also learn distributed semantic features of part-of-speech (POS) sequence as additional syntax-related clues to sentiment analysis. Our semantic features are able to capture both local contexts and global contexts automatically without involving comprehensive task-specific feature engineering. We validate the effectiveness of the method on our constructed sentiment dataset. Experiment results show that our method are able to improve the quality of sentiment analysis when comparing with several competitive baselines. }}
@article{Yuan2016,
title = {Congested scene classification via efficient unsupervised feature learning and density estimation },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.03.020},
url = {http://www.sciencedirect.com/science/article/pii/S003132031630005X},
author = {Yuan Yuan and Jia Wan and Qi Wang},

abstract = {Abstract An unsupervised learning algorithm with density information considered is proposed for congested scene classification. Though many works have been proposed to address general scene classification during the past years, congested scene classification is not adequately studied yet. In this paper, an efficient unsupervised feature learning approach with density information encoded is proposed to solve this problem. Based on spherical k-means, a feature selection process is proposed to eliminate the learned noisy features. Then, local density information which better reflects the crowdedness of a scene is encoded by a novel feature pooling strategy. The proposed method is evaluated on the assembled congested scene data set and UIUC-sports data set, and intensive comparative experiments justify the effectiveness of the proposed approach. }}
@article{Goldgof20141,
title = {Special issue on depth image analysis },
journal = {Pattern Recognition Letters },
volume = {50},
number = {},
pages = {1 - 2},
year = {2014},
note = {Depth Image Analysis },
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2014.07.006},
url = {http://www.sciencedirect.com/science/article/pii/S0167865514002220},
author = {Dmitry Goldgof and Xiaoyi Jiang and Olga Bellon}}
@article{Saritha201578,
title = {A Hierarchical Framework for the Classification of Multispectral Imagery },
journal = {Procedia Computer Science },
volume = {46},
number = {},
pages = {78 - 85},
year = {2015},
note = {Proceedings of the International Conference on Information and Communication Technologies, ICICT 2014, 3-5 December 2014 at Bolgatty Palace &amp; Island Resort, Kochi, India },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.01.060},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915000617},
author = {S. Saritha and G. Santhosh Kumar},



abstract = {Abstract Out of the abundant digital image data available, multispectral imagery is one which gives us information about the earth we live in. To gain knowledge from multispectral imagery, it is essential to classify the data present in the image based on spectral information. Classification plays a significant role in understanding the remotely sensed data obtained from the satellites. This paper brings out a new classification scheme based on a hierarchical framework. The hierarchical model proposed in this paper helps to understand the imagery at different levels of abstractness and concreteness to serve different applications like town planning, facility management and so on. The model depicts classification of the multispectral imagery on three abstract levels. The algorithm proposed outputs classification at different levels with an average accuracy of 72.6% in level 1 and 78.3% in level 2. The time sensitivity analysis of the algorithm shows that it outperforms the traditional SVM classifier. A detailed analysis of the algorithm proposed is detailed in this paper with respect to the parameters influencing the classification accuracy. }}
@article{Gosselin201492,
title = {Revisiting the Fisher vector for fine-grained classification },
journal = {Pattern Recognition Letters },
volume = {49},
number = {},
pages = {92 - 98},
year = {2014},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2014.06.011},
url = {http://www.sciencedirect.com/science/article/pii/S0167865514002013},
author = {Philippe-Henri Gosselin and Naila Murray and Hervé Jégou and Florent Perronnin},



abstract = {Abstract This paper describes the joint submission of Inria and Xerox to their joint participation to the FGCOMP’2013 challenge. Although the proposed system follows most of the standard Fisher classification pipeline, we describe a few key features and good practices that significantly improve the accuracy when specifically considering fine-grain classification tasks. In particular, we consider the late fusion of two systems both based on Fisher vectors, but for which we choose drastically design choices that make them very complementary. Moreover, we propose a simple yet effective filtering strategy, which significantly boosts the performance for several class domains. }}
@article{Xie201648,
title = {Incorporating visual adjectives for image classification },
journal = {Neurocomputing },
volume = {182},
number = {},
pages = {48 - 55},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.12.008},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215019219},
author = {Lingxi Xie and Jingdong Wang and Bo Zhang and Qi Tian},abstract = {Abstract Image classification is a fundamental problem in computer vision which implies a wide range of real-world applications. Conventional approaches for image classification often involve image description and training/testing phases. The Bag-of-Features (BoF) model is one of the most popular algorithms for image description, in which local descriptors are extracted, quantized, and summarized into global image representation. In the BoF model, all the visual descriptors are naturally treated as nouns, and plenty of useful contents are ignored. In this paper, we suggest to extract descriptive information, known as adjectives, to help visual recognition. We propose a simple framework to integrate various types of adjectives, i.e., color (or brightness), shape and location, for more powerful image representation. Experimental results on both scene recognition and fine-grained object recognition reveal that our approach achieves superior classification accuracy with reasonable computational overheads. It is also possible to generalize our model to many other multimedia applications such as large-scale image search. }}
@article{Tang20141674,
title = {Hierarchical kernel-based rotation and scale invariant similarity },
journal = {Pattern Recognition },
volume = {47},
number = {4},
pages = {1674 - 1688},
year = {2014},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2013.10.008},
url = {http://www.sciencedirect.com/science/article/pii/S0031320313004184},
author = {Y.Y. Tang and Tian Xia and Yantao Wei and Hong Li and Luoqing Li},
abstract = {Abstract Image similarity measure has been widely used in pattern recognition and computer vision. We usually face challenges in terms of rotation and scale changes. In order to overcome these problems, an effective similarity measure which is invariant to rotation and scale is proposed in this paper. Firstly, the proposed method applies the log-polar transform to eliminate the rotation and scale effect and produces a row and column translated log-polar image. Then the obtained log-polar image is passed to hierarchical kernels to eliminate the row and column translation effects. In this way, the output of the proposed method is invariant to rotation and scale. The theoretical analysis of invariance has also been given. In addition, an effective template sets construction method is presented to reduce computational complexity and to improve the accuracy of the proposed similarity measure. Through the experiments with several image data sets we demonstrate the advantages of the proposed approach: high classification accuracy and fast. }}
@article{An20161,
title = {Label transfer via sparse representation },
journal = {Pattern Recognition Letters },
volume = {70},
number = {},
pages = {1 - 7},
year = {2016},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.11.009},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515003955},
author = {Taeg-Hyun An and Ki-Sang Hong},



abstract = {Abstract In this paper, we present a simple and effective approach to the image parsing (or labeling image regions) problem. Inspired by sparse representation techniques for super-resolution, we convert the image parsing problem into a superpixel-wise sparse representation problem with coupled dictionaries related to features and likelihoods. This algorithm works by image-level classification with global image descriptors, followed by sparse representation based likelihood estimation with local features. Finally, Markov random field (MRF) optimization is applied to incorporate neighborhood context. Experimental results on the SIFTflow dataset support the use of our approach for solving the task of image parsing. The advantage of the proposed algorithm is that it can estimate likelihoods from a small set of bases (dictionary) whereas recent nonparametric scene parsing algorithms need features and labels of whole datasets to compute likelihoods. To our knowledge, this is the first approach that utilizes sparse representation to superpixel-based image parsing. }}
@article{Hao2016,
title = {Evaluation of Ground Distances and Features in EMD-based GMM Matching for Texture Classification },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.03.001},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316000960},
author = {Hua Hao and Qilong Wang and Peihua Li and Lei Zhang},
abstract = {Abstract Recently, the Earth Mover's Distance (EMD) has demonstrated its superiority in Gaussian mixture models (GMMs) based texture classification. The ground distances between Gaussian components of GMMs have great influences on performance of GMM matching, which however, has not been fully studied yet. Meanwhile, image features play a key role in image classification task, and often greatly impact classification performance. In this paper, we present a comprehensive study of ground distances and image features in texture classification task. We divide existing ground distances into statistics based ones and Riemannian manifold based ones. We make a theoretical analysis of the differences and relationships among these ground distances. Inspired by Gaussian embedding distance and product of Lie Groups distance, we propose an improved Gaussian embedding distance to compare Gaussians. We also evaluate for the first time the image features for GMM matching, including the handcrafted features such as Gabor filter, Local Binary Pattern (LBP) descriptor, SIFT, covariance descriptor and high-level features extracted by deep convolution networks. The experiments are conducted on three texture databases, i.e., KTH-TIPS-2b, FMD and UIUC. Based on experimental results, we show that the uses of geometrical structure and balance strategy are critical to ground distances. The experimental results show that GMM with the proposed ground distance can achieve stateof- the-art performance when high-level features are exploited. }}
@article{Mayer2014171,
title = {Incorporating motivation into multimedia learning },
journal = {Learning and Instruction },
volume = {29},
number = {},
pages = {171 - 173},
year = {2014},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2013.04.003},
url = {http://www.sciencedirect.com/science/article/pii/S0959475213000339},
author = {Richard E. Mayer},abstract = {Abstract What is the role of motivation in multimedia learning? Cognitive theories of multimedia learning tend to focus on instructional methods aimed at reducing extraneous processing (such as highlighting the essential material) or managing essential processing (such as breaking a lesson into parts), whereas motivational theories tend to focus on instructional methods aimed at fostering generative processing (such as adding appealing graphics or challenging scenarios). Moreno's (2005) cognitive affective theory of learning from media is intended to better incorporate motivation and metacognition into theories of multimedia learning, helping to extend or clarify Mayer's (2009) cognitive theory of multimedia learning and Sweller's (Sweller, Ayres, &amp; Kaluga, 2011) cognitive load theory. The research presented in this special section examines motivating instructional features intended to promote generative processing—such as adding appealing graphics (Magner, Schwonke, Aleven, Popescu, &amp; Renkl, 2013; Plass, Heidig, Hayward, Homer, &amp; Um, 2013) or challenging scenarios (D'Mello, Lehman, Pekrun, &amp; Graesser, 2013). Overall, motivational features can improve student learning by fostering generative processing as long as the learner is not continually overloaded with extraneous processing or overly distracted from essential processing. }}
@article{Schwenker20141,
title = {Partially supervised learning for pattern recognition },
journal = {Pattern Recognition Letters },
volume = {37},
number = {},
pages = {1 - 3},
year = {2014},
note = {Partially Supervised Learning for Pattern Recognition },
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2013.10.014},
url = {http://www.sciencedirect.com/science/article/pii/S0167865513003875},
author = {Friedhelm Schwenker and Edmondo Trentin}}
@article{Liu201434,
title = {Research on the Neurology-based Internet Architecture },
journal = {Procedia Computer Science },
volume = {30},
number = {},
pages = {34 - 38},
year = {2014},
note = {1st International Conference on Data Science, ICDS 2014 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2014.05.378},
url = {http://www.sciencedirect.com/science/article/pii/S1877050914005559},
author = {Feng Liu and Yong Shi},abstract = {Abstract New achievements to the two fields, cross comparison of Internet and neurology begins to get more and more attention of neuroscientists and computer scientists. Important fruit has been obtained. According to fresh development of Internet, the article makes a neurological analysis, puts forward the concept of Virtual brain of Internet, points out that Internet begins to gain features of central nervous system, sensory nervous system and Motor nervous system, probes into the structure of Virtual brain of Internet and its operation mode, draws out the structure map. On the basis, the article explores the relations of Networking, Cloud Computation, Big Data and Internet. }}
@article{Tung2016191,
title = {Scene parsing by nonparametric label transfer of content-adaptive windows },
journal = {Computer Vision and Image Understanding },
volume = {143},
number = {},
pages = {191 - 200},
year = {2016},
note = {Inference and Learning of Graphical Models\: Theory and Applications in Computer Vision and Image Analysis },
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2015.08.009},
url = {http://www.sciencedirect.com/science/article/pii/S1077314215001848},
author = {Frederick Tung and James J. Little},abstract = {Abstract Scene parsing is the task of labeling every pixel in an image with its semantic category. We present CollageParsing, a nonparametric scene parsing algorithm that performs label transfer by matching content-adaptive windows. Content-adaptive windows provide a higher level of perceptual organization than superpixels, and unlike superpixels are designed to preserve entire objects instead of fragmenting them. Performing label transfer using content-adaptive windows enables the construction of a more effective Markov random field unary potential than previous approaches. On a standard benchmark consisting of outdoor scenes from the LabelMe database, CollageParsing obtains state-of-the-art performance with 15–19% higher average per-class accuracy than recent nonparametric scene parsing algorithms. }}
@article{DeLeeuw20112011,
title = {Cognitive consequences of making computer-based learning activities more game-like },
journal = {Computers in Human Behavior },
volume = {27},
number = {5},
pages = {2011 - 2016},
year = {2011},
note = {2009 Fifth International Conference on Intelligent ComputingICIC 20092009 Fifth International Conference on Intelligent Computing },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2011.05.008},
url = {http://www.sciencedirect.com/science/article/pii/S0747563211001038},
author = {Krista E. DeLeeuw and Richard E. Mayer},
abstract = {Some students (base group) played the Circuit Game, a 10-level computer-based learning activity intended to help students learn how electrical circuits work. Other students (competition group) played the same game but with competition features added – including a score bar showing performance on each level, the opportunity to earn one ticket per level if a performance criterion is met, and the opportunity to win a prize based on the number of tickets earned. On a retention test given after the game, the competition group remembered significantly more than the base group (d = 0.47). On an embedded transfer test constituting the final level of the game, the groups did not differ significantly. However, on the transfer test there was a significant gender by group interaction in which men performed worse in the competition group than the base group (d = −0.54) and women performed better in the competition group than the base group (d = 0.24). Overall, adding game-like features to a computer-based learning activity caused students to pay attention to game details but did not motivate students – particularly men – to learn more deeply. }}
@article{Yang2016431,
title = {Learning methodologies for wireless big data networks: A Markovian game-theoretic perspective },
journal = {Neurocomputing },
volume = {174, Part A},
number = {},
pages = {431 - 438},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.04.111},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215012412},
author = {Chungang Yang},
abstract = {Abstract Wireless big data significantly challenges the current network management and control architecture, mathematical modeling techniques, and distributed algorithm design, in particular, in the promising cognitive, distributed, and ultra-dense networks. Motivated by the idea of divide-and-conquer, in this article, we first present a multiple cognitive agent-based divide-and-conquer network management and control architecture. Furthermore, a Markovian game-theoretic modeling framework is proposed to model the state big data-based decision-making problem. Then, we investigate various learning methodologies with respect to different kinds of the state information, in particular, we concentrate on the construction of state space, the state transition computation, and the convergence of parallel Q-learning technique. This work provides a suitable network management architecture, an effective modeling tool, and various learning techniques for wireless big data networks. }}
@article{Fredricks2016,
title = {Student engagement, context, and adjustment: Addressing definitional, measurement, and methodological issues },
journal = {Learning and Instruction },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2016.02.002},
url = {http://www.sciencedirect.com/science/article/pii/S0959475216300159},
author = {Jennifer A. Fredricks and Michael Filsecker and Michael A. Lawson},abstract = {Abstract The goal of this special issue is to examine relationships among context, student engagement, and adjustment. We begin by describing the reasons for the increased popularity of student engagement in research, policy, and practice, and then describe how researchers in the field define and study this construct. Next, we outline some of the issues and challenges around the definitions, measurement, and analytic techniques that have been used in prior research. Finally, we provide a short overview of the papers in this special issue highlighting their theoretical frameworks, methodologies, and analytical techniques by which many of the challenges outlined in this introduction are addressed. The overall findings of these papers come from samples in Finland, Korea, and the United States. }}
@article{Xu2016,
title = {A Deep Convolutional Neural Network for segmenting and classifying epithelial and stromal regions in histopathological images },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2016.01.034},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216001004},
author = {Jun Xu and Xiaofei Luo and Guanhao Wang and Hannah Gilmore and Anant Madabhushi},
abstract = {Abstract Epithelial (EP) and stromal (ST) are two types of tissues in histological images. Automated segmentation or classification of EP and ST tissues is important when developing computerized system for analyzing the tumor microenvironment. In this paper, a Deep Convolutional Neural Networks (DCNN) based feature learning is presented to automatically segment or classify EP and ST regions from digitized tumor tissue microarrays (TMAs). Current approaches are based on handcraft feature representation, such as color, texture, and Local Binary Patterns (LBP) in classifying two regions. Compared to handcrafted feature based approaches, which involve task dependent representation, DCNN is an end-to-end feature extractor that may be directly learned from the raw pixel intensity value of EP and ST tissues in a data driven fashion. These high-level features contribute to the construction of a supervised classifier for discriminating the two types of tissues. In this work we compare DCNN based models with three handcraft feature extraction based approaches on two different datasets which consist of 157 Hematoxylin and Eosin (H&amp;E) stained images of breast cancer and 1376 immunohistological (IHC) stained images of colorectal cancer, respectively. The DCNN based feature learning approach was shown to have a F1 classification score of 85%, 89%, and 100%, accuracy (ACC) of 84%, 88%, and 100%, and Matthews Correlation Coefficient (MCC) of 86%, 77%, and 100% on two H&amp;E stained (NKI and VGH) and IHC stained data, respectively. Our DNN based approach was shown to outperform three handcraft feature extraction based approaches in terms of the classification of EP and ST regions. }}
@article{Perlin2015250,
title = {Extracting human attributes using a convolutional neural network approach },
journal = {Pattern Recognition Letters },
volume = {68, Part 2},
number = {},
pages = {250 - 259},
year = {2015},
note = {Special Issue on Soft Biometrics },
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.07.012},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515002159},
author = {Hugo Alberto Perlin and Heitor Silvério Lopes},

abstract = {Abstract Extracting high level information from digital images and videos is a hard problem frequently faced by the computer vision and machine learning communities. Modern surveillance systems can monitor people, cars or objects by using computer vision methods. The objective of this work is to propose a method for identifying soft-biometrics, in the form of clothing and gender, from images containing people, as a previous step for further identifying people themselves. We propose a solution to this classification problem using a Convolutional Neural Network, working as an all-in-one feature extractor and classifier. This method allows the development of a high-level end-to-end clothing/gender classifier. Experiments were done comparing the CNN with hand-designed classifiers. Also, two different operating modes of CNN are proposed and compared each other. The results obtained were very promising, showing that is possible to extract soft-biometrics attributes using an end-to-end CNN classifier. The proposed method achieved a good generalization capability, classifying the three different attributes with good accuracy. This suggests the possibility to search images using soft biometrics as search terms. }}
@article{Lendasse2015158,
title = {Advances in Extreme Learning Machines (ELM2013) },
journal = {Neurocomputing },
volume = {149, Part A},
number = {},
pages = {158 - 159},
year = {2015},
note = {Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.08.059},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214011163},
author = {Amaury Lendasse and Qing He and Yoan Miche and Guang-Bin Huang}}
@article{Vinay2015623,
title = {Cloud Based Big Data Analytics Framework for Face Recognition in Social Networks Using Machine Learning },
journal = {Procedia Computer Science },
volume = {50},
number = {},
pages = {623 - 630},
year = {2015},
note = {Big Data, Cloud and Computing Challenges },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.04.095},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915005967},
author = {A. Vinay and Vinay S. Shekhar and J. Rituparna and Tushar Aggrawal and K.N. Balasubramanya Murthy and S. Natarajan},

abstract = {Abstract Face recognition (FR) has been at the crux of several novel breakthroughs over the past two decades and has steadily proffered several cross-domain applications that range from mainstream commercial software to critical law enforcement applications. Recent groundbreaking developments in Big Data analysis,Cloud Computing,Social Networks and Machine learning have vastly transformed the conventional view of how several formidable problems in Computer Vision can be tackled. Hence in this paper, we will provide a thorough survey of the concepts of Cloud Computing, Big Data, Social networks and Machine Learning from a contemporary perspective of FR,and proffer a framework for a novel FR approachbased on the Extreme Learning Machines technique to perform the task of Face Tagging for Social Networks operating on Big Data. In the proposed approach, the desirable properties of the aforementioned concepts are amalgamated to form an effective coalition that can augment the performance of FR, in addition to serving immeasurably in a plethora of other disciplines. }}
@article{Yang20151386,
title = {An Improved Computer Interface Comprising a Recurrent Neural Network and a Natural User Interface },
journal = {Procedia Computer Science },
volume = {60},
number = {},
pages = {1386 - 1395},
year = {2015},
note = {Knowledge-Based and Intelligent Information &amp; Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.08.213},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915023406},
author = {Jiachen Yang and Ryota Horie},
abstract = {Abstract We developed an interface system by which a user can operate a computer with hand and finger movements. To implement the interface, we used a gesture sensor to acquire the movement-based data. A recurrent neural network (RNN) was included to discriminate types of gestures. Using the proposed interface, high recognition rates were obtained for simple gestures, while the recognition rates of complicated gestures were low. To improve the rate of accuracy in recognizing complicated gestures, we investigated the dependency of factors on the rate of recognition in the RNN learning process and identified settings to refine these factors. }}
@article{tagkey2015542,
title = {Subject Index },
journal = {Procedia Computer Science },
volume = {61},
number = {},
pages = {542 - 547},
year = {2015},
note = {Complex Adaptive Systems San Jose, CA November 2-4, 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.09.214},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915030446},
key = {tagkey2015542}}
@article{Sboev2015277,
title = {Syntactic Analysis of the Sentences of the Russian Language Based on Neural Networks },
journal = {Procedia Computer Science },
volume = {66},
number = {},
pages = {277 - 286},
year = {2015},
note = {4th International Young Scientist Conference on Computational Science },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.11.033},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915033827},
author = {A.G. Sboev and R. Rybka and I. Moloshnikov and D. Gudovskih},abstract = {Abstract The model of Russian language parser based on a combination of neural networks along with extraction of set of parameters which allows to establish relations with the minimal syntactic ambiguity is presented. The parse tree of sentence is constructed in the format of Russian National Corpus (RNC). RNC texts containing morphological and syntactic markup are used for training neural network models as part of procedure. Estimates of accuracy of the developed parser procedure in comparison with the other Russian language parser systems have been performed. }}
@article{Kim2002761,
title = {Web-based problem solving learning: third-year medical students' participation in end-of-life care Virtual Clinic },
journal = {Computers in Human Behavior },
volume = {18},
number = {6},
pages = {761 - 772},
year = {2002},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/S0747-5632(02)00029-8},
url = {http://www.sciencedirect.com/science/article/pii/S0747563202000298},
author = {Sara Kim and Beth E Kolko and Thomas H Greer},



abstract = {This exploratory study examined problem-solving in an on-line problem-based learning environment. Participants included two moderators and 30 medical students in the end-of-life care Virtual Clinic. Using content analysis of transcripts, we analyzed interaction patterns in two groups of students and moderators and students' problem-solving skills as measured by the critical thinking ratio. Moderator in Group 1 posted more connected comments, feedback, and questions than the moderator in Group 2. Students in Group 1 posted more connected comments compared to students in Group 2. However, the disparate interaction patterns yielded little differences in students' critical thinking skills in both groups. We propose the use of critical thinking ratio as an effective outcome measure in assessing problem-solving skills. }}
@article{Lou2016290,
title = {Graph Regularized Sparsity Discriminant Analysis for face recognition },
journal = {Neurocomputing },
volume = {173, Part 2},
number = {},
pages = {290 - 297},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.04.116},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215012862},
author = {Songjiang Lou and Xiaoming Zhao and Yuelong Chuang and Haitao Yu and Shiqing Zhang},
abstract = {Abstract Manifold learning and Sparse Representation Classifier are two popular techniques for face recognition. Because manifold learning can find low-dimensional representations for high-dimensional data, it is widely applied in computer vision and pattern recognition. Most of the manifold learning algorithms can be unified in the graph embedding framework, where the first step is to determine the adjacent graphs. Traditional methods use k nearest neighbor or the ε -ball schemes. However, they are parametric and sensitive to noises. Moreover, it is hard to determine the size of appropriate neighborhoods. To deal with these problems, in this paper, Graph Regularized Sparsity Discriminant Analysis, GRSDA, for short, is proposed. Based on graph embedding and sparsity preserving projection, the weight matrices for intrinsic and penalty graphs are obtained through sparse representation. GRSDA seeks a subspace in which samples in intra-classes are as compact as possible while samples in inter-classes are as separable as possible. Specifically, samples in the low-dimensional space can preserve the sparse locality relationship in the same class, while enhancing the separability for samples in different classes. Hence, GRSDA can achieve better performance. Extensive experiments were carried out on ORL, YALE-B and AR face databases, and the results confirmed that the proposed algorithm outperformed LPP, UDP, SPP and DSNPE. }}
@article{Shen201666,
title = {Learning discriminative shape statistics distribution features for pedestrian detection },
journal = {Neurocomputing },
volume = {184},
number = {},
pages = {66 - 77},
year = {2016},
note = {RoLoD: Robust Local Descriptors for Computer Vision 2014 },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.08.107},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215018470},
author = {Jifeng Shen and Xin Zuo and Wankou Yang and Hualong Yu and Guohai Liu},



abstract = {Abstract Discriminative feature plays an important role in object detection system and traditional tactics heavily depends on the hand-designed feature. Recent study shows that feature can be learned from data, and this idea opens a new way to deal with many computer vision problems. In this paper, we propose a novel feature which learns discriminative information based on data distribution and shape statistics for pedestrian detection. It makes use of data distribution which is rich of discriminative information from positive and negative samples, and also utilizes shape statistics which comes from average human template. The proposed method exploits the distribution in multiple channel image spaces, and learns an optimal hyper plane to separate pedestrians from background patches in specific area with shape statistics. It maintains the merit of simplicity in computation and also obtains powerful discriminative ability. Two versions of Shape Statistic Distribution features are proposed which are derived from Informed Haar-like feature, but more discriminative than the original one. Experimental results based on INRIA, ETH and Caltech-USA datasets show that our proposed methods can achieve state-of-art performance. Furthermore the running speed of our detector can reach at 22 fps for 480×640 images. }}
@article{Liu201655,
title = {Multi-sparse descriptor: A scale invariant feature for pedestrian detection },
journal = {Neurocomputing },
volume = {184},
number = {},
pages = {55 - 65},
year = {2016},
note = {RoLoD: Robust Local Descriptors for Computer Vision 2014 },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.143},
url = {http://www.sciencedirect.com/science/article/pii/S092523121501958X},
author = {Yazhou Liu and Pongsak Lasang and Mel Siegel and Quansen Sun},
abstract = {Abstract This paper presents a new descriptor, multi-sparse descriptor (MSD), for pedestrian detection in static images. Specifically, the proposed descriptor is based on multi-dictionary sparse coding which contains unsupervised dictionary learning and sparse coding. During unsupervised learning phase, a family of dictionaries with different representation abilities is learnt from the pedestrian data. Then the data are encoded by these dictionaries and the histogram of the sparse coefficients is calculated as the descriptor. The benefit of this multi-dictionary sparse encoding is three-fold: firstly, the dictionaries are learnt from the pedestrian data, they are more efficient for encoding local structures of the pedestrian; secondly, multiple dictionaries can enrich the representation by providing different levels of abstractions; thirdly, since the dictionaries based representation is mainly focused on the low frequency, better generalization ability along the scale range is obtained. Comparisons with the state-of-the-art methods reveal the superiority of the proposed method. }}
@article{Zhen2014295,
title = {Action recognition by spatio-temporal oriented energies },
journal = {Information Sciences },
volume = {281},
number = {},
pages = {295 - 309},
year = {2014},
note = {Multimedia Modeling },
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2014.05.021},
url = {http://www.sciencedirect.com/science/article/pii/S002002551400560X},
author = {Xiantong Zhen and Ling Shao and Xuelong Li},abstract = {Abstract In this paper, we present a unified representation based on the spatio-temporal steerable pyramid (STSP) for the holistic representation of human actions. A video sequence is viewed as a spatio-temporal volume preserving all the appearance and motion information of an action in it. By decomposing the spatio-temporal volumes into band-passed sub-volumes, the spatio-temporal Laplacian pyramid provides an effective technique for multi-scale analysis of video sequences, and spatio-temporal patterns with different scales could be well localized and captured. To efficiently explore the underlying local spatio-temporal orientation structures at multiple scales, a bank of three-dimensional separable steerable filters are conducted on each of the sub-volume from the Laplacian pyramid. The outputs of the quadrature pair of steerable filters are squared and summed to yield a more robust oriented energy representation. To be further invariant and compact, a spatio-temporal max pooling operation is performed between responses of the filtering at adjacent scales and over spatio-temporal neighbourhoods. In order to capture the appearance, local geometric structure and motion of an action, we apply the STSP on the intensity, 3D gradients and optical flow of video sequences, yielding a unified holistic representation of human actions. Taking advantage of multi-scale, multi-orientation analysis and feature pooling, STSP produces a compact but informative and invariant representation of human actions. We conduct extensive experiments on the KTH, UCF Sports and HMDB51 datasets, which shows the unified STSP achieves comparable results with the state-of-the-art methods. }}
@article{Sharan2016,
title = {An Overview of Applications and Advancements in Automatic Sound Recognition },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2016.03.020},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216300406},
author = {Roneel V. Sharan and Tom J. Moir},

abstract = {Abstract Automatic sound recognition (ASR) has seen an increased and wide ranging interests in recent years. In this paper, we carry out a review of some important contributions in ASR techniques, mainly over the last one and a half decades. Similar to speech recognition systems, the robustness of an ASR system largely depends on the choice of feature(s) and classifier(s). We take a wider perspective in providing an overview of the features and classifiers used in ASR systems starting from early works in content-based audio classification to more recent developments in applications such as sound event recognition, audio surveillance, and environmental sound recognition. We also review techniques that have been utilized in noise robust sound recognition systems and feature optimization methods. Finally, some of the less commonly known applications of ASR are discussed. }}
@article{Zhou2016,
title = {Multi-scale context for scene labeling via flexible segmentation graph },
journal = {Pattern Recognition },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2016.03.023},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316300085},
author = {Quan Zhou and Baoyu Zheng and Weiping Zhu and Longin Jan Latecki},

abstract = {Abstract Using contextual information for scene labeling has gained substantial attention in the fields of image processing and computer vision. In this paper, a fusion model using flexible segmentation graph (FSG) is presented to explore multi-scale context for scene labeling problem. Given a family of segmentations, the representation of FSG is established based on the spatial relationship of these segmentations. In the scenario of FSG, the labeling inference process is formulated as a contextual fusion model, trained from the discriminative classifiers. Compared to previous approaches, which usually employ Conditional Random Fields (CRFs) or hierarchical models to explore contextual information, our FSG representation is flexible and efficient without hierarchical constraint, allowing us to capture a wide variety of visual context for the task of image labeling. Our approach yields state-of-the-art results on the MSRC dataset (21 classes) and the LHI dataset (15 classes), and near-record results on the SIFT Flow dataset (33 classes) and PASCAL VOC segmentation dataset (20 classes), while producing a 320×240 scene labeling in less than a second. A remarkable fact is that our approach also outperforms recent CNN-based methods. }}
@article{Clarebout2009793,
title = {The use of support devices in electronic learning environments },
journal = {Computers in Human Behavior },
volume = {25},
number = {4},
pages = {793 - 794},
year = {2009},
note = {Including the Special Issue: The Use of Support Devices in Electronic Learning Environments },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2008.07.004},
url = {http://www.sciencedirect.com/science/article/pii/S0747563208001386},
author = {Geraldine Clarebout and Holger Horz and Jan Elen},
abstract = {This special issue addresses the use of support devices in electronic learning environments. Five articles each discus a study or several studies where the use of support devices is not evident. Factors influencing the use of support devices are addressed: elements of the learning environment, characteristics of the learner, etc. The discussion of this special issue reflects in general on support in computer-based learning environments. }}
@article{Zhang20151857,
title = {Chinese comments sentiment classification based on word2vec and SVMperf },
journal = {Expert Systems with Applications },
volume = {42},
number = {4},
pages = {1857 - 1863},
year = {2015},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2014.09.011},
url = {http://www.sciencedirect.com/science/article/pii/S0957417414005508},
author = {Dongwen Zhang and Hua Xu and Zengcai Su and Yunfeng Xu},abstract = {Abstract Since the booming development of e-commerce in the last decade, the researchers have begun to pay more attention to extract the valuable information from consumers comments. Sentiment classification, which focuses on classify the comments into positive class and negative class according to the polarity of sentiment, is one of the studies. Machine learning-based method for sentiment classification becomes mainstream due to its outstanding performance. Most of the existing researches are centered on the extraction of lexical features and syntactic features, while the semantic relationships between words are ignored. In this paper, in order to get the semantic features, we propose a method for sentiment classification based on word2vec and SVMperf. Our research consists of two parts of work. First of all, we use word2vec to cluster the similar features for purpose of showing the capability of word2vec to capture the semantic features in selected domain and Chinese language. And then, we train and classify the comment texts using word2vec again and SVMperf. In the process, the lexicon-based and part-of-speech-based feature selection methods are respectively adopted to generate the training file. We conduct the experiments on the data set of Chinese comments on clothing products. The experimental results show the superior performance of our method in sentiment classification. }}
@article{Ciarelli2015139,
title = {Achieving a compromise between performance and complexity of structure: An incremental approach },
journal = {Information Sciences },
volume = {294},
number = {},
pages = {139 - 151},
year = {2015},
note = {Innovative Applications of Artificial Neural Networks in Engineering },
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2014.09.013},
url = {http://www.sciencedirect.com/science/article/pii/S0020025514009190},
author = {Patrick Marques Ciarelli and Elias Oliveira},



abstract = {Abstract In incremental learning techniques, learning occurs continuously over time and does not cease once available data have been exhausted. Such techniques are useful in cases where problem data may be acquired in small quantities over time. This paper presents an incremental neural network called the evolving Probabilistic Neural Network. The main advantage of this technique lies in its adaptive architecture, which adjusts to data distributions. This method requires that each training sample be used only once throughout the training phase without being reprocessed. The technique is flexible and offers a simplified structure while maintaining performance levels comparable to those of other techniques. Experiments were conducted using publicly available benchmark data sets. These experiments show that overall, the proposed model achieves a quality of response that is comparable to those of the best techniques evaluated, and its structure size and classification time were as low as those of less complex techniques. These results indicate that the proposed model achieves a satisfactory balance between efficiency and efficacy. }}
@article{Takahashi201531,
title = {A Generic Software Platform for Brain-inspired Cognitive Computing },
journal = {Procedia Computer Science },
volume = {71},
number = {},
pages = {31 - 37},
year = {2015},
note = {6th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2015, 6-8 November Lyon, France },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.12.185},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915036467},
author = {Koichi Takahashi and Kotone Itaya and Masayoshi Nakamura and Moriyoshi Koizumi and Naoya Arakawa and Masaru Tomita and Hiroshi Yamakawa},
abstract = {Abstract We have been developing BriCA (Brain-inspired Computing Architecture), the generic software platform that can combine an arbitrary number of machine learning modules to construct higher structures such as cognitive architectures inspired by the brain. We discuss requirements analysis and design principles of this cognitive computing platform, report its implementation, and describe plans for further development. }}
@article{Guo2015418,
title = {Human action recognition via multi-task learning base on spatial–temporal feature },
journal = {Information Sciences },
volume = {320},
number = {},
pages = {418 - 428},
year = {2015},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2015.04.034},
url = {http://www.sciencedirect.com/science/article/pii/S0020025515003163},
author = {Wenzhong Guo and Guolong Chen},

abstract = {Abstract This study proposes a novel human action recognition method using regularized multi-task learning. First, we propose the part Bag-of-Words (PBoW) representation that completely represents the local visual characteristics of the human body structure. Each part can be viewed as a single task in a multi-task learning formulation. Further, we formulate the task of multi-view human action recognition as a learning problem penalized by a graph structure that is built according to the human body structure. Our experiments show that this method has significantly better performance in human action recognition than the standard Bag-of-Words + Support Vector Machine (BoW + SVM) method and other state-of-the-art methods. Further, the performance of the proposed method with simple global representation is as good as that of state-of-the-art methods for human action recognition on the TJU dataset (a new multi-view action dataset with RGB, depth, and skeleton data, which has been created by our group). }}
@article{Shao2015157,
title = {3D dynamic facial expression recognition using low-resolution videos },
journal = {Pattern Recognition Letters },
volume = {65},
number = {},
pages = {157 - 162},
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.07.039},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515002482},
author = {Jie Shao and Ilaria Gori and Shaohua Wan and J.K. Aggarwal},
abstract = {Abstract In this paper, we focus on the problem of 3D dynamic (4D) facial expression recognition. While traditional methods rely on building deformation models on high-resolution 3D meshes, our approach works directly on low-resolution RGB-D sequences; this feature allows us to apply our algorithm to videos retrieved by widespread and standard low-resolution RGB-D sensors, such as Kinect. After preprocessing both RGB and depth image sequences, sparse features are learned from spatio-temporal local cuboids. Conditional Random Fields classifier is then employed for training and classification. The proposed system is fully-automatic and achieves superior results on three low-resolution datasets built from the 4D facial expression recognition dataset – BU-4DFE. Extensive evaluations of our approach and comparisons with state-of-the-art methods are presented. }}
@article{Xu201613,
title = {Detecting rare events using Kullback–Leibler divergence: A weakly supervised approach },
journal = {Expert Systems with Applications },
volume = {54},
number = {},
pages = {13 - 28},
year = {2016},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2016.01.035},
url = {http://www.sciencedirect.com/science/article/pii/S0957417416000580},
author = {Jingxin Xu and Simon Denman and Clinton Fookes and Sridha Sridharan},abstract = {Abstract Video surveillance infrastructure has been widely installed in public places for security purposes. However, live video feeds are typically monitored by human staff, making the detection of important events as they occur difficult. As such, an expert system that can automatically detect events of interest in surveillance footage is highly desirable. Although a number of approaches have been proposed, they have significant limitations: supervised approaches, which can detect a specific event, ideally require a large number of samples with the event spatially and temporally localised; while unsupervised approaches, which do not require this demanding annotation, can only detect whether an event is abnormal and not specific event types. To overcome these problems, we formulate a weakly-supervised approach using Kullback–Leibler (KL) divergence to detect rare events. The proposed approach leverages the sparse nature of the target events to its advantage, and we show that this data imbalance guarantees the existence of a decision boundary to separate samples that contain the target event from those that do not. This trait, combined with the coarse annotation used by weakly supervised learning (that only indicates approximately when an event occurs), greatly reduces the annotation burden while retaining the ability to detect specific events. Furthermore, the proposed classifier requires only a decision threshold, simplifying its use compared to other weakly supervised approaches. We show that the proposed approach outperforms state-of-the-art methods on a popular real-world traffic surveillance dataset, while preserving real time performance. }}
@article{tagkey1998III,
title = {Contents },
journal = {Computers & Education },
volume = {30},
number = {3–4},
pages = {III - IV},
year = {1998},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/S0360-1315(98)80006-7},
url = {http://www.sciencedirect.com/science/article/pii/S0360131598800067},
key = {tagkey1998III}}
@article{Chang2014124,
title = {The effect of reflective learning e-journals on reading comprehension and communication in language learning },
journal = {Computers & Education },
volume = {71},
number = {},
pages = {124 - 132},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.09.023},
url = {http://www.sciencedirect.com/science/article/pii/S036013151300287X},
author = {Mei-Mei Chang and Mei-Chen Lin},
abstract = {Abstract This study focused on the use of reflective learning e-journals in a university web-based English as a foreign language (EFL) course. In the study, a multimedia-based English programme comprising fifteen different units was delivered online as a one-semester instructional course. Ninety-eight undergraduate students participated, and they were divided into two groups: the treatment group used reflective learning e-journals, while the control group completed content-related exercises. The study investigated the effects of reflective learning e-journals and how students used them to aid learning. Results show that when learning from web-based instruction, students who used reflective learning e-journals outperformed students who did not do so in terms of reading comprehension. Using reflective e-journals improved the academic performance of learners in the online course. In addition, journal writing students claimed that they also improved their organisational skills and writing abilities through their reflective learning e-journal writing and found the journal writing to be a very helpful tool in reviewing the course and preparing for the exam. }}
@article{tagkey2014xiv,
title = {Faster Turnaround },
journal = {Neural Networks },
volume = {49},
number = {},
pages = {xiv - xv},
year = {2014},
note = {},
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/S0893-6080(13)00289-X},
url = {http://www.sciencedirect.com/science/article/pii/S089360801300289X},
key = {tagkey2014xiv}}
@article{Zhen20131899,
title = {A local descriptor based on Laplacian pyramid coding for action recognition },
journal = {Pattern Recognition Letters },
volume = {34},
number = {15},
pages = {1899 - 1905},
year = {2013},
note = {Smart Approaches for Human Action Recognition },
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2012.10.021},
url = {http://www.sciencedirect.com/science/article/pii/S0167865512003510},
author = {Xiantong Zhen and Ling Shao},abstract = {Abstract We present a new descriptor for local representation of human actions. In contrast to state-of-the-art descriptors, which use spatio-temporal features to describe cuboids detected from video sequences, we propose to employ a 2D descriptor based on the Laplacian pyramid for efficiently encoding spatio-temporal regions of interest. Image templates including structural planes and motion templates, are firstly extracted from a cuboid to encode the structural and motion features. A 2D Laplacian pyramid is then performed to decompose each of those images into a series of sub-band feature maps, which is followed by a two-stage feature extraction, i.e., Gabor filtering and max pooling. Motion-related edge and orientation information is enhanced after the filtering. To capture more discriminative and invariant features, max pooling is applied to the outputs of Gabor filtering, between scales within filter banks and over spatial neighbors. The obtained local features associated with cuboids are fed to the localized soft-assignment coding with max pooling on the Bag-of-Words (BoWs) model to represent an action. The image templates, i.e., MHI and TOP, explicitly encode the motion and structure information in the video sequences and the proposed Laplacian pyramid coding descriptor provides an informative representation of them due to the multi-scale analysis. The employment of localized soft-assignment coding and max pooling gives a robust representation of actions. Experimental results on the benchmark KTH dataset and the newly released and challenging HMDB51 dataset demonstrate the effectiveness of the proposed method for human action recognition. }}
@article{Limbu2015393,
title = {How do learners experience joint writing: University students' conceptions of online collaborative writing tasks and environments },
journal = {Computers & Education },
volume = {82},
number = {},
pages = {393 - 408},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.11.024},
url = {http://www.sciencedirect.com/science/article/pii/S0360131514002772},
author = {Lekha Limbu and Lina Markauskaite},
abstract = {Abstract This paper presents a phenomenographic study investigating university students' conceptions of Online Collaborative Writing (OCW) and of an effective learning environment for OCW tasks. To date, there has been little investigation of the expectations that students bring to OCW tasks and of how they interpret the OCW affordances offered to them. Knowledge about students' experiences of the OCW phenomenon and of what they conceive to be an effective OCW environment can provide important insights into the improved design and scaffolding of these collaborative learning experiences. Fifteen university students with varying levels of OCW experience were interviewed in this study. The findings showed that these students conceived of OCW in four qualitatively distinct ways, namely: a) as a way to divide work between participants in order to complete writing tasks efficiently; b) as a means to combine expertise to produce a good end product; c) as an activity involving the fusion of ideas and insights to enable a deeper understanding of content; and d) as a means to develop new skills and attitudes for collaborative work and interaction. The students saw an effective OCW environment in three distinct ways, namely: a) as a directed space prearranged by teachers; b) as a scaffolded and interactively guided space; and c) as an open space co-created by learners. University students' perceptions of OCW tasks and of effective OCW environments were broadly connected, although some students considered scaffolding and active teacher support to be essential irrespective of their conceptions of OCW. }}
@article{Kazemian20151166,
title = {Comparisons of machine learning techniques for detecting malicious webpages },
journal = {Expert Systems with Applications },
volume = {42},
number = {3},
pages = {1166 - 1177},
year = {2015},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2014.08.046},
url = {http://www.sciencedirect.com/science/article/pii/S0957417414005284},
author = {H.B. Kazemian and S. Ahmed},

abstract = {Abstract This paper compares machine learning techniques for detecting malicious webpages. The conventional method of detecting malicious webpages is going through the black list and checking whether the webpages are listed. Black list is a list of webpages which are classified as malicious from a user’s point of view. These black lists are created by trusted organizations and volunteers. They are then used by modern web browsers such as Chrome, Firefox, Internet Explorer, etc. However, black list is ineffective because of the frequent-changing nature of webpages, growing numbers of webpages that pose scalability issues and the crawlers’ inability to visit intranet webpages that require computer operators to log in as authenticated users. In this paper therefore alternative and novel approaches are used by applying machine learning algorithms to detect malicious webpages. In this paper three supervised machine learning techniques such as K-Nearest Neighbor, Support Vector Machine and Naive Bayes Classifier, and two unsupervised machine learning techniques such as K-Means and Affinity Propagation are employed. Please note that K-Means and Affinity Propagation have not been applied to detection of malicious webpages by other researchers. All these machine learning techniques have been used to build predictive models to analyze large number of malicious and safe webpages. These webpages were downloaded by a concurrent crawler taking advantage of gevent. The webpages were parsed and various features such as content, URL and screenshot of webpages were extracted to feed into the machine learning models. Computer simulation results have produced an accuracy of up to 98% for the supervised techniques and silhouette coefficient of close to 0.96 for the unsupervised techniques. These predictive models have been applied in a practical context whereby Google Chrome can harness the predictive capabilities of the classifiers that have the advantages of both the lightweight and the heavyweight classifiers. }}
@article{Bhattacharyya20151,
title = {Finding quasi core with simulated stacked neural networks },
journal = {Information Sciences },
volume = {294},
number = {},
pages = {1 - 14},
year = {2015},
note = {Innovative Applications of Artificial Neural Networks in Engineering },
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2014.09.032},
url = {http://www.sciencedirect.com/science/article/pii/S002002551400944X},
author = {Malay Bhattacharyya and Sanghamitra Bandyopadhyay},

abstract = {Abstract Studying networks is promising for diverse applications. We are often interested in exploring significant substructures in different types of real-life networks. Finding cliques, which denote a complete subgraph of a graph, is one such important problem in network analysis. Interestingly, many real-life networks often contain a significant number of almost (quasi) complete subgraphs, which are not entirely complete due to the presence of noise. Considering these networks as weighted adds further challenges to the problem. Finding quasi-complete subgraphs in weighted graphs has never been formally addressed. In this paper, we propose a stacked neural network model for finding out the largest quasi-complete module (core) in weighted graphs. We show the effectiveness of the proposed approach on DIMACS graphs. We also highlight its utility in analyzing scientific collaboration networks, social networks and biological networks. }}
@article{Jang2016,
title = {Why students become more engaged or more disengaged during the semester: A self-determination theory dual-process model },
journal = {Learning and Instruction },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2016.01.002},
url = {http://www.sciencedirect.com/science/article/pii/S0959475216300020},
author = {Hyungshim Jang and Eun Joo Kim and Johnmarshall Reeve},

abstract = {Abstract We adopted a dual-process model within a self-determination theory framework to investigate why students sometimes veer toward a longitudinal trajectory of rising classroom engagement during the semester and why they other times tend toward a trajectory of rising disengagement. Measures of perceived autonomy support, perceived teacher control, need satisfaction, need frustration, engagement, and disengagement were collected from 366 (174 females, 192 males) Korean high-school students using a three-wave longitudinal research design. Multi-level structural equation modeling analyses found that perceived autonomy support predicted longitudinal changes need satisfaction which predicted changes in engagement and also that perceived teacher control predicted longitudinal changes need frustration which predicted changes disengagement. Reciprocal effects also emerged in that extent of disengagement predicted both longitudinal increases in students' perceptions of teacher control and decreases in perceptions of teacher autonomy support. We conclude that students tend toward a semester-long trajectory of rising engagement when they perceive their teachers to be autonomy supportive and need satisfying while they tend toward a trajectory of rising disengagement when they perceive their teachers to be controlling and need frustrating. }}
@article{Huang20161475,
title = {Adapted competitive learning on continuous semantic space for word sense induction },
journal = {Neurocomputing },
volume = {171},
number = {},
pages = {1475 - 1485},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.090},
url = {http://www.sciencedirect.com/science/article/pii/S092523121501098X},
author = {Yanzhou Huang and Deyi Xiong and Xiaodong Shi and Yidong Chen and ChangXing Wu and Guimin Huang},abstract = {Abstract Word sense induction (WSI) is important to many natural language processing tasks because word sense ambiguity is pervasive in linguistic expressions. The majority of existing WSI algorithms are not applicable to capture both lexical semantics and syntactic relations without involving excessive task-specific feature engineering. Moreover, it remains a challenge to explore a sense clustering method which is capable of determining the number of word senses for the polysemous words automatically and properly. In this paper, we learn continuous semantic space representations for the ambiguous instances via recursive context composition, allowing us to capture lexical semantics and syntactic relations simultaneously. Using the learned representations of ambiguous instances, we further adapt rival penalization competitive learning to conduct instances based word sense clustering, allowing us to determine the number of word senses automatically. We validate the effectiveness of our method on the SEMEVAL-2010 WSI dataset. Experiment results show that our method is able to improve the quality of word sense clustering over several competitive baselines. }}
@article{Sharma201613,
title = {Local Higher-Order Statistics (LHS) describing images with statistics of local non-binarized pixel patterns },
journal = {Computer Vision and Image Understanding },
volume = {142},
number = {},
pages = {13 - 22},
year = {2016},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2015.09.007},
url = {http://www.sciencedirect.com/science/article/pii/S1077314215002027},
author = {Gaurav Sharma and Frédéric Jurie},abstract = {Abstract We propose a new image representation for texture categorization and facial analysis, relying on the use of higher-order local differential statistics as features. It has been recently shown that small local pixel pattern distributions can be highly discriminative while being extremely efficient to compute, which is in contrast to the models based on the global structure of images. Motivated by such works, we propose to use higher-order statistics of local non-binarized pixel patterns for the image description. The proposed model does not require either (i) user specified quantization of the space (of pixel patterns) or (ii) any heuristics for discarding low occupancy volumes of the space. We propose to use a data driven soft quantization of the space, with parametric mixture models, combined with higher-order statistics, based on Fisher scores. We demonstrate that this leads to a more expressive representation which, when combined with discriminatively learned classifiers and metrics, achieves state-of-the-art performance on challenging texture and facial analysis datasets, in low complexity setup. Further, it is complementary to higher complexity features and when combined with them improves performance. }}
@article{Liang2014511,
title = {Sentiment Classification Based on AS-LDA Model },
journal = {Procedia Computer Science },
volume = {31},
number = {},
pages = {511 - 516},
year = {2014},
note = {2nd International Conference on Information Technology and Quantitative Management, ITQM 2014 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2014.05.296},
url = {http://www.sciencedirect.com/science/article/pii/S1877050914004736},
author = {Jiguang Liang and Ping Liu and Jianlong Tan and Shuo Bai},abstract = {Abstract We address the task of sentiment classification - identification of the polarity of the subjective document in this paper. We introduces a sentiment classification method called AS LDA. In this model, we assume that words in subjective documents consists of two parts: sentiment element words and auxiliary words which are sampled accordingly from sentiment topics and auxiliary topics. Sentiment element words include targets of the opinions, polarity words and modifiers of polarity words. Experimental results demonstrate that our approach outperforms Latent Dirichlet Allocation (LDA). }}
@article{Zadeh2016,
title = {Stratification, target set reachability and incremental enlargement principle },
journal = {Information Sciences },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2016.02.047},
url = {http://www.sciencedirect.com/science/article/pii/S0020025516301293},
author = {Lotfi A. Zadeh},abstract = {Abstract This paper presents a brief exposition of a version of the concept of stratification, call it CST for short. In our approach to stratification, CST is a computational system in which the objects of computation are strata of data. Usually, the strata are nested or stacked with nested strata centering on a target set, T. CST has a potential for significant applications in planning, robotics, optimal control, pursuit, multiobjective optimization, exploration, search and other fields. Very simple, familiar examples of stratification are dictionaries, directories and catalogues. A multi-layer perceptron may be viewed as a system with a stratified structure. In spirit, CST has similarity to dynamic programing (DP), but it is much easier to understand and much easier to implement. An interesting question which relates to neuroscience is: Does the human brain employ stratification to store information? It would be natural to represent a concept such as chair, as a collection of strata with one or more strata representing a type of chair. Underlining our approach is a model, call it FSM. FSM is a discrete-time, discrete-state dynamical system which has a finite number of states. The importance of FSM as a model derives from the fact that through the use of granulation and/or quantization almost any kind of system can be approximated to by a finite state system. A concept which plays an important role in our approach is that of target set reachability. Reachability involves moving (transitioning) FSM from a state w to a state in target state, T, in a minimum number of steps. To this end, the state space, W, is stratified through the use of what is refer as the incremental enlargement principle. It should also be noted that the concept reachability is related to the concept of accessibility in modal logic. }}
@article{Wang20161073,
title = {PR-ELM: Parallel regularized extreme learning machine based on cluster },
journal = {Neurocomputing },
volume = {173, Part 3},
number = {},
pages = {1073 - 1081},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.08.066},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215012461},
author = {Yueqing Wang and Yong Dou and Xinwang Liu and Yuanwu Lei},
abstract = {Abstract Extreme learning machine (ELM) has been intensively studied during the last decade due to its high efficiency, effectiveness and easy-to-implementation. Recently, many variants, such as parallel ELM (P-ELM) incremental ELM and online sequential ELM(OS-ELM), have been proposed to improve its timing performance and enable its ability of incremental learning. In this paper, we propose two parallel variants, termed as data parallel regularized ELM (DPR-ELM) and model parallel regularized ELM (MPR-ELM), to further improve the computational efficiency of ELM in handling large scale learning tasks. Collectively, these two variants are called as parallel regularized ELM (PR-ELM). Specifically, our proposed algorithms are implemented on cluster with Message Passing Interface (MPI) environment. In summary, the advantages of the proposed PR-ELM algorithms over existing variants are highlighted as follows: (1) They have better parallelism since they train each data block or each sub-model independently. (2) They dramatically reduce the requirement of huge runtime memory since the whole datasets or the whole model are split into small chunks or sub-models. (3) Both DPR-ELM and MPR-ELM have better scalability since they are able to be configured on clusters with many more computing nodes. Extensive experiments have been conducted to validate the effectiveness of the proposed algorithms. As shown, DPR-ELM and MPR-ELM achieve 5.15× and 3.5× speedup on cluster with six nodes, respectively. Moreover, the speedup of DPR-ELM increases to 5.85× with the increase of the size of dataset, and this quantity is increased to 4× for MPR-ELM with the increase of the number of hidden nodes. }}
@article{tagkey2015iii,
title = {Contents },
journal = {Procedia Computer Science },
volume = {58},
number = {},
pages = {iii - vi},
year = {2015},
note = {Second International Symposium on Computer Vision and the Internet (VisionNet’15) },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/S1877-0509(15)02213-9},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915022139},
key = {tagkey2015iii}}
@article{tagkey2015iii,
title = {Contents },
journal = {Procedia Computer Science },
volume = {72},
number = {},
pages = {iii - v},
year = {2015},
note = {The Third Information Systems International Conference 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/S1877-0509(15)03746-1},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915037461},
key = {tagkey2015iii}}
@article{Tan2015190,
title = {Grassmann manifold for nearest points image set classification },
journal = {Pattern Recognition Letters },
volume = {68, Part 1},
number = {},
pages = {190 - 196},
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.09.008},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515003189},
author = {Hengliang Tan and Zhengming Ma and Sumin Zhang and Zengrong Zhan and Beibei Zhang and Chenggong Zhang},
abstract = {Abstract Image set classification has attracted increasing attention in recent years. How to effectively represent image sets is one key issue of set based classification. Subspaces form non-Euclidean Riemannian manifolds known as Grassmann manifolds, which allows an image set to be conveniently represented as a point on a Grassmann manifold is widely used in many visual classification tasks. Another issue is how to measure the distance/similarity between sets. Modeling image sets as hulls, and then finding distance of nearest points between sets as the set-to-set distance is a popular solution recently. In this paper, we propose a novel approach by exploiting the Projection kernel that explicitly maps the subspaces from the Grassmann manifold to a Reproducing Kernel Hilbert Space (RKHS) where the Euclidean geometry applies. And then, by modeling the points on RKHS as affine hulls, the Euclidean distance between the nearest points of two hulls can be used for classification. In order to obtain enough points for building the Grassmann affine hulls, we also develop a subspaces constructing method extended by K-means. Experiments are conducted on six datasets. Our proposed method achieves the best classification results on two multi-view object categorization datasets and one extreme illumination variation face recognition dataset. }}
@article{Hao2016,
title = {Cross domain mitotic cell recognition },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.06.106},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216000977},
author = {Tong Hao and Ai-Ling Yu and Wei Peng and Bin Wang and Jin-Sheng Sun},
abstract = {Abstract Accurate and automated identification of mitosis is essential and challenging to many biomedical applications. To handle this challenge, we propose a novel mitotic cell recognition method by integrating heterogenous data in the framework of cross domain learning. First, we extract the discriminative feature to represent the local structure and textural saliency of individual cell sample. Second, the cell type-dependent classifiers are respectively trained on the target domain and the auxiliary domain and then fused in the framework of adaptive support vector machine for cross-domain learning. The achieved classifier can be implemented for mitotic cell recognition in the cross domain manner. The extensive experiments on two kinds of phase contrast microscopy image sequences (C3H10T1/2&amp; C2C12) show that the proposed method can leverage the datasets from multiple domains to boost the performance by effectively transferring the knowledge from the auxiliary domain to the target domain. Therefore, it can overcome the inconsistence of feature distributions in different domains. }}
@article{Highland2015314,
title = {Adaptation of Spike-Timing-Dependent Plasticity to Unsupervised Learning for Polychronous Wavefront Computing },
journal = {Procedia Computer Science },
volume = {61},
number = {},
pages = {314 - 321},
year = {2015},
note = {Complex Adaptive Systems San Jose, CA November 2-4, 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.09.146},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915029762},
author = {Fred Highland and Corey B. Hart},
abstract = {Abstract Non-Von Neumann computational architectures have lately aroused significant interest as substrates for complex computation. One recent development in this domain is the Polychronous Wavefront Computing (PWC) computational model based on multiple wavefront dynamics. This model is an abstraction and simplification of the artificial neural network paradigm based on temporal and spatial patterns of activity in a pulse propagating media and their interaction with transponders. While this framework is capable of computing basic logical functions and exhibiting interesting dynamic behaviors, methods for unsupervised training of the framework have not been identified. The lack of input weights and the spatio-temporal nature of the PWC framework make direct application of weight adjusting learning methods (e.g., backpropagation) impractical. The paper will describe research into unsupervised learning for PWCs inspired by Spike-Timing-Dependent Plasticity (STDP) methods used with other types of polychronous models. The method is based on adding Leaky Integrate-and-Fire semantics to the PWC framework allowing analysis of activating wavefronts and determination of the optimal location for future stimulation. The transponder's location is then incrementally adjusted to improve its future response. The paper will discuss the learning approach and examine the results of applying the method over a series of stimulations to sample configurations. }}
@article{Homer2014365,
title = {Level of interactivity and executive functions as predictors of learning in computer-based chemistry simulations },
journal = {Computers in Human Behavior },
volume = {36},
number = {},
pages = {365 - 375},
year = {2014},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2014.03.041},
url = {http://www.sciencedirect.com/science/article/pii/S0747563214001630},
author = {Bruce D. Homer and Jan L. Plass},

abstract = {Abstract High school students’ learning outcomes was examined comparing exploratory vs. worked simulations. The effects of added icons and students’ executive functions were also examined. In Study 1, urban high school students (N = 84) were randomly assigned to one of four versions of a web-based simulation of kinetic molecular theory that varied in instructional format (exploratory vs. worked simulation) and representation (added icons vs. no added icons). Learning was assessed at two levels: comprehension and transfer. For transfer, a main effect was found for instructional format: the exploratory condition yielded greater levels of transfer than the worked simulation. Study 2 used the same conditions and a more complex simulation, the ideal gas law, with a similar sample of students (N = 67). For transfer, an interaction between instructional format and executive functions was found: Whereas students with higher levels of executive functions had better transfer with the exploratory condition, students with lower levels of executive functions had better transfer with the guided simulations. Results are discussed in relation to current theories of instructional design and learning. }}
@article{Çevik201554,
title = {Predicting college students’ online information searching strategies based on epistemological, motivational, decision-related, and demographic variables },
journal = {Computers & Education },
volume = {90},
number = {},
pages = {54 - 63},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.09.002},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515300403},
author = {Yasemin Demiraslan Çevik},
abstract = {Abstract This study examines the extent to which epistemological, motivational, decision-related, and demographic variables predict college students' use of online information searching strategies (behavioural, procedural, and metacognitive strategies). The participants included preservice teachers (N = 538) from 13 universities in different parts of Turkey. Stepwise multiple regression analyses were conducted to identify the variables predicting each online information searching strategy. The results revealed that online information searching strategies were best predicted by epistemological beliefs and then decision-making styles, web search experience, and goal orientations. Students who had advanced epistemological beliefs in speed of learning tended to have better behavioural, procedural, and metacognitive strategies, while students having naive epistemological beliefs in ability to learn had lower level online searching strategies. Students having more web search experience had better online searching strategies. Additionally, as the level of students’ mastery-approach goals increases, the use of procedural and metacognitive domain strategies increase as well, while the increase in the level of mastery-avoidance goals were related to the use of less behavioural domain strategies. Finally, students having rational decision styles were more likely to use higher levels of online information searching strategies, while students with avoidant styles tended to use less behavioural and procedural domain strategies. }}
@article{Yang201570,
title = {Joint representation and pattern learning for robust face recognition },
journal = {Neurocomputing },
volume = {168},
number = {},
pages = {70 - 80},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.06.013},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215008334},
author = {Meng Yang and Pengfei Zhu and Feng Liu and Linlin Shen},



abstract = {Abstract Image feature is a significant factor for the success of robust face recognition. Recently sparse representation based classifier (SRC) has been widely applied to robust face recognition by using sparse representation residuals to tolerate disturbed image features (e.g., occluded pixels). In order to deal with more complicated image variations, robust representation based classifier, which estimates feature weights (e.g., low weight values are given to the pixels with big representation residuals), has attracted much attention in recent work. Although these methods have achieved improved performance by estimating feature weights independently, structured information and prior knowledge of image features are ignored in these works, resulting in unsatisfactory performance in some challenging cases. Thus how to better learn image feature weight to fully exploit structure information and prior knowledge is still an open question in robust face recognition. In this paper, we proposed a novel joint representation and pattern learning (JRPL) model, in which the feature pattern weight is simultaneously learned with the representation of query image. Especially a feature pattern dictionary, which captures structured information and prior knowledge of image features, are constructed to represent the unknown feature pattern weight of a query image. An efficient algorithm to solve JRPL was also presented in this paper. The experiments of face recognition with various variations and occlusions on several benchmark datasets clearly show the advantage of the proposed JRPL in accuracy and efficiency. }}
@article{Price20082486,
title = {Unreal PowerPoint™: Immersing PowerPoint presentations in a virtual computer game engine world },
journal = {Computers in Human Behavior },
volume = {24},
number = {6},
pages = {2486 - 2495},
year = {2008},
note = {Including the Special Issue: Electronic Games and Personalized eLearning Processes },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2008.03.009},
url = {http://www.sciencedirect.com/science/article/pii/S0747563208000563},
author = {Colin B. Price},
abstract = {At a recent conference on games in education, we made a radical decision to transform our standard presentation of PowerPoint slides and computer game demonstrations into a unified whole, inserting the PowerPoint presentation to the computer game. This opened up various questions relating to learning and teaching theories, which were debated by the conference delegates. In this paper, we reflect on these discussions, we present our initial experiment, and relate this to various theories of learning and teaching. In particular, we consider the applicability of concept maps to inform the construction of educational materials, especially their topological, geometrical and pedagogical significance. We supplement this spatial dimension with a theory of the dynamic, temporal dimension, grounded in a context of learning processes, such as Kolb’s learning cycle. Finally, we address the multi-player aspects of computer games, and relate this to the theories of social and collaborative learning. This paper attempts to explore various theoretical bases, and so support the development of a new learning and teaching virtual reality approach. }}
@article{KaplanBerkaya201667,
title = {On circular traffic sign detection and recognition },
journal = {Expert Systems with Applications },
volume = {48},
number = {},
pages = {67 - 75},
year = {2016},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2015.11.018},
url = {http://www.sciencedirect.com/science/article/pii/S0957417415007848},
author = {Selcan Kaplan Berkaya and Huseyin Gunduz and Ozgur Ozsen and Cuneyt Akinlar and Serkan Gunal},

abstract = {Abstract Automatic traffic sign detection and recognition play crucial roles in several expert systems such as driver assistance and autonomous driving systems. In this work, novel approaches for circular traffic sign detection and recognition on color images are proposed. In traffic sign detection, a new approach, which utilizes a recently developed circle detection algorithm and an RGB-based color thresholding technique, is proposed. In traffic sign recognition, an ensemble of features including histogram of oriented gradients, local binary patterns and Gabor features are employed within a support vector machine classification framework. Performances of the proposed detection and recognition approaches are evaluated on German Traffic Sign Detection and Recognition Benchmark datasets, respectively. The results of the experimental work reveal that both approaches offer comparable or even better performances with respect to the best ones reported in the literature and are compatible to real-time operation as well. }}
@article{Zhu2014321,
title = {Multi-granularity distance metric learning via neighborhood granule margin maximization },
journal = {Information Sciences },
volume = {282},
number = {},
pages = {321 - 331},
year = {2014},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2014.06.017},
url = {http://www.sciencedirect.com/science/article/pii/S0020025514006458},
author = {Pengfei Zhu and Qinghua Hu and Wangmeng Zuo and Meng Yang},abstract = {Abstract Learning a distance metric from training samples is often a crucial step in machine learning and pattern recognition. Locality, compactness and consistency are considered as the key principles in distance metric learning. However, the existing metric learning methods just consider one or two of them. In this paper, we develop a multi-granularity distance learning technique. First, a new index, neighborhood granule margin, which simultaneously considers locality, compactness and consistency of neighborhood, is introduced to evaluate a distance metric. By maximizing neighborhood granule margin, we formulate the distance metric learning problem as a sample pair classification problem, which can be solved by standard support vector machine solvers. Then a set of distance metrics are learned in different granular spaces. The weights of the granular spaces are learned through optimizing the margin distribution. Finally, the decisions from different granular spaces are combined with weighted voting. Experiments on UCI datasets, gender classification and object categorization tasks show that the proposed method is superior to the state-of-the-art distance metric learning algorithms. }}
@article{Kester20071047,
title = {Designing support to facilitate learning in powerful electronic learning environments },
journal = {Computers in Human Behavior },
volume = {23},
number = {3},
pages = {1047 - 1054},
year = {2007},
note = {Including the Special Issue: Avoiding Simplicity, Confronting Complexity: Advances in Designing Powerful Electronic Learning Environments },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2006.10.001},
url = {http://www.sciencedirect.com/science/article/pii/S0747563206001245},
author = {Liesbeth Kester and Paul Kirschner and Gemma Corbalan},abstract = {This special issue reflects current developments in instructional design for powerful electronic learning environments. It presents a compilation of contributions to a combined special interest group (SIG) meeting (2006) of Instructional Design and Learning and Instruction with Computers. Both SIGs are part of the European Association for Research on Learning and Instruction (EARLI). The SIG-meeting focused on the design of powerful electronic learning environments for complex learning. The articles in this issue describe how to design support to help learners during complex individual or collaborative learning. This introduction provides the context for the issue and a short overview of the contributions. }}
@article{tagkey2016v,
title = {Neural Networks },
journal = {Neural Networks },
volume = {73},
number = {},
pages = {v - ix},
year = {2016},
note = {},
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/S0893-6080(15)00246-4},
url = {http://www.sciencedirect.com/science/article/pii/S0893608015002464},
key = {tagkey2016v}}
@article{Denman20159449,
title = {Automatic surveillance in transportation hubs: No longer just about catching the bad guy },
journal = {Expert Systems with Applications },
volume = {42},
number = {24},
pages = {9449 - 9467},
year = {2015},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2015.08.001},
url = {http://www.sciencedirect.com/science/article/pii/S0957417415005370},
author = {Simon Denman and Tristan Kleinschmidt and David Ryan and Paul Barnes and Sridha Sridharan and Clinton Fookes},

abstract = {Abstract As critical infrastructure such as transportation hubs continue to grow in complexity, greater importance is placed on monitoring these facilities to ensure their secure and efficient operation. In order to achieve these goals, technology continues to evolve in response to the needs of various infrastructure. To date, however, the focus of technology for surveillance has been primarily concerned with security, and little attention has been placed on assisting operations and monitoring performance in real-time. Consequently, solutions have emerged to provide real-time measurements of queues and crowding in spaces, but have been installed as system add-ons (rather than making better use of existing infrastructure), resulting in expensive infrastructure outlay for the owner/operator, and an overload of surveillance systems which in itself creates further complexity. Given many critical infrastructure already have camera networks installed, it is much more desirable to better utilise these networks to address operational monitoring as well as security needs. Recently, a growing number of approaches have been proposed to monitor operational aspects such as pedestrian throughput, crowd size and dwell times. In this paper, we explore how these techniques relate to and complement the more commonly seen security analytics, and demonstrate the value that can be added by operational analytics by demonstrating their performance on airport surveillance data. We explore how multiple analytics and systems can be combined to better leverage the large amount of data that is available, and we discuss the applicability and resulting benefits of the proposed framework for the ongoing operation of airports and airport networks. }}
@article{Hanbay2016,
title = {Principal curvatures based rotation invariant algorithms for efficient texture classification },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2016.03.032},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216300522},
author = {Kazım Hanbay and Nuh Alpaslan and Muhammed Fatih Talu and Davut Hanbay},abstract = {Abstract The histograms of oriented gradients (HOG) and co-occurrence HOG (CoHOG) algorithms are simple and intuitive descriptors. However, the HOG and CoHOG algorithms based on gradient computation still have some shortcomings: they ignore meaningful textural properties and are unstable to noise. In this paper, two new efficient HOG and CoHOG methods are proposed. The proposed algorithms are based on the Gaussian derivative filters, and the feature vectors are obtained by means of principal curvatures. The feature vectors are rotation invariant by means of the rotation invariance characteristic of principal curvatures (i.e. eigenvalues). The experimental results on the CUReT, KTH-TIPS, KTH-TIPS2-a, UIUC, Brodatz album, Kylberg and Xu datasets confirm that the developed algorithms have higher classification rates than state-of-the-art texture classification methods. The classification results also demonstrate that the developed algorithms are more stable to noise and rotation than the original HOG and CoHOG algorithms. }}
@article{Kohl2009326,
title = {Evolving neural networks for strategic decision-making problems },
journal = {Neural Networks },
volume = {22},
number = {3},
pages = {326 - 337},
year = {2009},
note = {Goal-Directed Neural Systems },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2009.03.001},
url = {http://www.sciencedirect.com/science/article/pii/S0893608009000379},
author = {Nate Kohl and Risto Miikkulainen},
abstract = {Evolution of neural networks, or neuroevolution, has been a successful approach to many low-level control problems such as pole balancing, vehicle control, and collision warning. However, certain types of problems–such as those involving strategic decision-making–have remained difficult for neuroevolution to solve. This paper evaluates the hypothesis that such problems are difficult because they are fractured: The correct action varies discontinuously as the agent moves from state to state. A method for measuring fracture using the concept of function variation is proposed and, based on this concept, two methods for dealing with fracture are examined: neurons with local receptive fields, and refinement based on a cascaded network architecture. Experiments in several benchmark domains are performed to evaluate how different levels of fracture affect the performance of neuroevolution methods, demonstrating that these two modifications improve performance significantly. These results form a promising starting point for expanding neuroevolution to strategic tasks. }}
@article{An2016247,
title = {Person re-identification via hypergraph-based matching },
journal = {Neurocomputing },
volume = {182},
number = {},
pages = {247 - 254},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.12.029},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215019669},
author = {Le An and Xiaojing Chen and Songfan Yang},abstract = {Abstract Person re-identification which aims to match people across non-overlapping cameras has become an important research topic due to the increasing demand in many important applications such as video surveillance and security monitoring. Matching people in different cameras is a challenging task since the appearance of the same subject may change dramatically in different views due to variations in pose, lighting condition, etc. In order to reduce the feature discrepancy caused by view change, most of the existing methods focus either on robust feature extraction or view-invariant feature transformation. During matching, a subject to be identified, i.e., a probe, is compared with each subject in the gallery with known identities. The returned ranked list is generated based on the similarity scores. However, such a matching process only considers pairwise similarity between the probe and a gallery subject while higher order relationships between the probe and the gallery or even among the gallery subjects are ignored. To address this issue, we propose a hypergraph-based matching scheme in which both pairwise and higher order relationships for the probe and gallery subjects are discovered through hypergraph learning. In this way, improved similarity scores are obtained as compared to the conventional pairwise similarity measure. We conduct experiments on two widely used person re-identification datasets and the results demonstrate that matching through hypergraph learning leads to superior performance compared with state-of-the-arts. Furthermore, the proposed approach can be easily incorporated into any existing approach where similarities between probe and gallery are to be computed. }}
@article{Moos20101640,
title = {Nonlinear technology: Changing the conception of extrinsic motivation? },
journal = {Computers & Education },
volume = {55},
number = {4},
pages = {1640 - 1650},
year = {2010},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.07.006},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510001892},
author = {Daniel C. Moos},
abstract = {Think-aloud and self-report data from 84 undergraduates were used to examine the relationship between intrinsic motivation, extrinsic motivation, and use of self-regulated learning (SRL) processes. Participants individually learned about the circulatory system with a hypermedia environment for 30 min. During this experimental session, three measures were used to examine the research questions guiding the study. Participants completed a self-report questionnaire that measured their extrinsic and intrinsic motivation. They also completed a pretest and posttest, which assessed learning outcomes. Lastly, think-aloud data were collected to determine the frequency in which participants used SRL process related to planning, monitoring, and strategy use. Results indicate that participants who had high extrinsic and high intrinsic motivation used significantly more planning and monitoring processes when compared to participants who had lower motivation scores for either the extrinsic or intrinsic category. Additionally, participants who had high extrinsic and high intrinsic motivation significantly outperformed those who had low extrinsic and low intrinsic motivation. }}
@article{Le2010313,
title = {Online lecture accessibility and its influence on performance in skills-based courses },
journal = {Computers & Education },
volume = {55},
number = {1},
pages = {313 - 319},
year = {2010},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.01.017},
url = {http://www.sciencedirect.com/science/article/pii/S036013151000031X},
author = {Ada Le and Steve Joordens and Sophie Chrysostomou and Raymond Grinnell},abstract = {At the University of Toronto at Scarborough, we provide enhanced flexibility to our students using a blended-learning approach (i.e., the webOption) whereby students can attend lectures live, watch them online at their convenience, or both. The current research examines the use of pause and seeks features afforded by the webOption interface and how these features are related to students’ learning approaches and their performance in calculus courses. These courses emphasize the teaching of mathematical proofs; cognitive skills that are enhanced with practice (Schneider &amp; Shiffrin, 1977). Access to online lectures allows students to re-experience the professor as they teach these skills. Given this, it was predicted that use of the webOption might be especially potent in these learning contexts. The results we report here do not confirm that prediction. Students do use and appreciate the features of the webOption, however, those students who augmented their class attendance with online viewing, and those who used the lecture-control features the most, were actually the students who performed most poorly. We interpreted the results to be due to different learning strategies and the manner in which these strategies interact with course content. Our results suggest that using the pause feature is related to a surface strategy of learning, which is in turn related to poorer performance in the course. }}
@article{tagkey2014664,
title = {Subject Index },
journal = {Procedia Computer Science },
volume = {36},
number = {},
pages = {664 - 669},
year = {2014},
note = {Complex Adaptive Systems Philadelphia, PA November 3-5, 2014 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2014.09.072},
url = {http://www.sciencedirect.com/science/article/pii/S1877050914013210},
key = {tagkey2014664}}
@article{Gomez20149,
title = {Special issue on computer vision applying pattern recognition techniques },
journal = {Pattern Recognition },
volume = {47},
number = {1},
pages = {9 - 11},
year = {2014},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2013.08.015},
url = {http://www.sciencedirect.com/science/article/pii/S0031320313003361},
author = {Luis Gomez and Luis Alvarez and Julio Jacobo-Berlles and Marta Mejail}}
@article{Lillywhite20133300,
title = {A feature construction method for general object recognition },
journal = {Pattern Recognition },
volume = {46},
number = {12},
pages = {3300 - 3314},
year = {2013},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2013.06.002},
url = {http://www.sciencedirect.com/science/article/pii/S0031320313002549},
author = {Kirt Lillywhite and Dah-Jye Lee and Beau Tippetts and James Archibald},
abstract = {Abstract This paper presents a novel approach for object detection using a feature construction method called Evolution-COnstructed (ECO) features. Most other object recognition approaches rely on human experts to construct features. ECO features are automatically constructed by uniquely employing a standard genetic algorithm to discover series of transforms that are highly discriminative. Using ECO features provides several advantages over other object detection algorithms including: no need for a human expert to build feature sets or tune their parameters, ability to generate specialized feature sets for different objects, and no limitations to certain types of image sources. We show in our experiments that ECO features perform better or comparable with hand-crafted state-of-the-art object recognition algorithms. An analysis is given of ECO features which includes a visualization of ECO features and improvements made to the algorithm. }}
@article{Yusoff2012652,
title = {Investigating cognitive task difficulties and expert skills in e-Learning storyboards using a cognitive task analysis technique },
journal = {Computers & Education },
volume = {58},
number = {1},
pages = {652 - 665},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.09.009},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511002260},
author = {Nor’ain Mohd Yusoff and Siti Salwah Salim},abstract = {E-learning storyboards have been a useful approach in distance learning development to support interaction between instructional designers and subject-matter experts. Current works show that researchers are focusing on different approaches for use in storyboards, and there is less emphasis on the effect of design and process difficulties faced by instructional designers and subject-matter experts. This study explores problem aspects of the cognitive task and the skills required of subject-matter experts by applying a cognitive task analysis approach from the expert point of view. The result shows that subject-matter experts face difficulties in making decisions on three elements during e-learning course development. The three elements are storyboard templates, prescriptive interactive components, and review process. It is found that the representation skills and decision making of the three elements allows subject-matter experts to decide on alternatives of the task process. The result also indicates that it is important to leverage the design and process skills of subject-matter experts as it affects their interaction with instructional designers. Three recommendations are made: training development, prescriptive interactive components development, and interaction design document development. A new framework can be recommended to train subject-matter experts as e-learning storyboard users, and in turn provide for effective interaction between them and instructional designers. }}
@article{Wäschle2014103,
title = {Procrastination and self-efficacy: Tracing vicious and virtuous circles in self-regulated learning },
journal = {Learning and Instruction },
volume = {29},
number = {},
pages = {103 - 114},
year = {2014},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2013.09.005},
url = {http://www.sciencedirect.com/science/article/pii/S0959475213000662},
author = {Kristin Wäschle and Anne Allgaier and Andreas Lachner and Siegfried Fink and Matthias Nückles},
abstract = {Abstract In the present study, we investigated how students react to self-assessed low goal achievement in self-regulated learning. Over a university term (19 weeks), 150 university students recorded self-efficacy, procrastination and perceived goal achievement in weekly web-based self-monitoring protocols. Using multilevel analyses for growth curve models, we investigated the reciprocal amplifying between procrastination and perceived goal achievement and self-efficacy and perceived goal achievement. Results indicated a vicious circle of procrastination and a virtuous circle of self-efficacy. Students who recorded high levels of procrastination assessed their goal achievement as being low. As a consequence of low goal achievement, they reinforced procrastination. Students who recorded high levels of self-efficacy assessed their goal achievement as being high. As a consequence of high goal achievement, self-efficacy increased. Self-efficacy mediated the effect of perceived goal achievement on procrastination. Thus, students with low perceived self-efficacy are vulnerable for finding themselves in a vicious circle of procrastination. }}
@article{Ke201343,
title = {Online learning across ethnicity and age: A study on learning interaction participation, perception, and learning satisfaction },
journal = {Computers & Education },
volume = {61},
number = {},
pages = {43 - 51},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.09.003},
url = {http://www.sciencedirect.com/science/article/pii/S0360131512002072},
author = {Fengfeng Ke and Dean Kwak},abstract = {This mixed-method study examined whether online learning interaction participation, perception, and learning satisfaction would be consistent across varied age and ethnicity groups. Data were collected from students enrolled in 28 online courses via content analysis with online interaction transcripts, structural equation modeling with the learning-experience survey responses, and interviewing. The interaction-transcript analysis did not indicate a significant advantage or disadvantage in terms of the quality and quantity of online interaction participation for students of non-traditional age or minority status. However, the structural equation modeling of the survey results indicated that students' minority status was associated with more favorable perception of the learner-to-instructor interaction but lower satisfaction with the web-based distance education. }}
@article{Cao2016,
title = {Vehicle detection from highway satellite images via transfer learning },
journal = {Information Sciences },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2016.01.004},
url = {http://www.sciencedirect.com/science/article/pii/S0020025516000062},
author = {Liujuan Cao and Cheng Wang and Jonathan Li},abstract = {Abstract Coming with the era of highway satellites, nowadays there is a massive amount of remote sensing images captured. Therefore, it is now feasible to detect vehicles directly from these satellite images, which has attracted extensive research attentions for both academic and industrial applications. However, it is not an easy task at all, mainly due to the difficulty to obtain training data to train vehicle detectors. On the contrary, there has been sufficient amount of labeled information regarding vehicle regions in the domain of aerial images. In this paper, we study the problem of detecting vehicles on highway satellite images, without the time-consuming step of collecting sufficient training data in this domain. Our key idea is to adopt a novel transfer learning technology that transfers vehicle detectors trained in the aerial image domain to the satellite image domain. In doing so, several cutting-edge vehicle detection algorithms can be directly applied. More specifically, our transfer learning scheme is based on a supervised super-resolution algorithm, which learns mutually correlative sparse coefficients between high and low resolution image patches. Then, a linear SVM based detector is trained, the loss function of which is integrated into the sparse coding operation above. Experimental results have shown that the proposed framework can achieve significant improvement over several alternative and state-of-the-art schemes, with high precision and low false alarms. }}
@article{Naz2016228,
title = {Offline cursive Urdu-Nastaliq script recognition using multidimensional recurrent neural networks },
journal = {Neurocomputing },
volume = {177},
number = {},
pages = {228 - 241},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.11.030},
url = {http://www.sciencedirect.com/science/article/pii/S092523121501749X},
author = {Saeeda Naz and Arif I. Umar and Riaz Ahmad and Saad B. Ahmed and Syed H. Shirazi and Imran Siddiqi and Muhammad I. Razzak},
abstract = {Abstract Optical Character Recognition of cursive scripts remains a challenging task due to a large number of character shapes, inter- and intra-word overlaps, context sensitivity and diagonality of text. This paper presents an implicit segmentation based recognition system for Urdu text lines in Nastaliq script. The proposed technique relies on sliding overlapped windows on lines of text and extracting a set of statistical features. The extracted features are fed to a multi-dimensional long short term memory recurrent neural network (MDLSTM RNN) with a connectionist temporal classification (CTC) output layer that labels the character sequences. Experimental study of the proposed technique is carried out on the standard Urdu Printed Text-line Images (UPTI) database which comprises 10,000 text lines in Nastaliq font. Evaluations under different experimental settings realize promising recognition rates with a highest character recognition rate of 96.40%. }}
@article{Junco20122236,
title = {In-class multitasking and academic performance },
journal = {Computers in Human Behavior },
volume = {28},
number = {6},
pages = {2236 - 2243},
year = {2012},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2012.06.031},
url = {http://www.sciencedirect.com/science/article/pii/S0747563212001926},
author = {Reynol Junco},

abstract = {The omnipresence of student-owned information and communication technologies (ICTs) in today’s college classrooms presents educational opportunities but can also create learning problems. Specifically, multitasking with these technologies can interfere with the learning process. Indeed, research in cognitive science shows that there are clear performance decrements when trying to attend to two tasks at the same time. This study examines the frequency with which students multitask during class using a large sample (N = 1,839) and examines the relationship between multitasking and academic performance as measured by actual overall semester grade point average (GPA). Students reported frequently text messaging during class but reported multitasking with other ICTs to a lesser extent. Furthermore, only social technologies (Facebook and text messaging) were negatively related to GPA. }}
@article{Wang2016,
title = {The Math and Science Engagement Scales: Scale development, validation, and psychometric properties },
journal = {Learning and Instruction },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2016.01.008},
url = {http://www.sciencedirect.com/science/article/pii/S0959475216300081},
author = {Ming-Te Wang and Jennifer A. Fredricks and Feifei Ye and Tara L. Hofkens and Jacqueline Schall Linn},
abstract = {Abstract There is an urgent need to develop appropriate instruments to measure student engagement in math and science for the fields of research and practice. The present study developed and validated student- and teacher-report survey measures of student engagement in math and science. The measures are built around a multidimensional perspective of engagement by using a bifactor modeling approach. The sample was recruited from an ethnically and socioeconomically diverse middle and high school student population in the United States. The findings confirmed that student engagement is comprised of multiple related yet distinct dimensions, with evidence to support a bifactor structural model. There was also empirical evidence supporting measurement invariance and predictive validity. The results demonstrate the soundness of the psychometric properties of the Math and Science Engagement Scales. }}
@article{Wang2016199,
title = {Semantic Boosting Cross-Modal Hashing for efficient multimedia retrieval },
journal = {Information Sciences },
volume = {330},
number = {},
pages = {199 - 210},
year = {2016},
note = {SI\:Visual Info Communication },
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2015.10.028},
url = {http://www.sciencedirect.com/science/article/pii/S0020025515007562},
author = {Ke Wang and Jun Tang and Nian Wang and Ling Shao},



abstract = {Abstract Cross-modal hashing aims to embed data from different modalities into a common low-dimensional Hamming space, which serves as an important part in cross-modal retrieval. Although many linear projection methods were proposed to map cross-modal data into a common abstract space, the semantic similarity between cross-modal data was often ignored. To address this issue, we put forward a novel cross-modal hashing method named Semantic Boosting Cross-Modal Hashing (SBCMH). To preserve the semantic similarity, we first apply multi-class logistic regression to project heterogeneous data into a semantic space, respectively. To further narrow the semantic gap between different modalities, we then use a joint boosting framework to learn hash functions, and finally transform the mapped data representations into a measurable binary subspace. Comparative experiments on two public datasets demonstrate the effectiveness of the proposed SBCMH. }}
@article{Leng2015593,
title = {A 3D model recognition mechanism based on deep Boltzmann machines },
journal = {Neurocomputing },
volume = {151, Part 2},
number = {},
pages = {593 - 602},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.06.084},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214013770},
author = {Biao Leng and Xiangyang Zhang and Ming Yao and Zhang Xiong},



abstract = {Abstract The effectiveness of 3D model recognition generally depends on the feature representations and classification methods. Previous algorithms have not shown good capacities to detect 3D model׳s feature, thus, they seem not to be competent to recognize 3D model. Meanwhile, recent efforts have illustrated that Deep Boltzmann Machines (DBM) have great power to approximate the distributions of input data, and can archive state-of-the-arts results. In this paper, we propose a novel 3D model recognition mechanism based on DBM, which can be divided into two parts: one is feature detecting based on DBM, and the other is classification based on semi-supervised learning method. During the first part, the high-level abstraction representation can be obtained from a well-trained DBM, and the feature is used in semi-supervised classification method in the second part. The experiments are conducted on publicly available 3D model data sets: Princeton Shape Benchmark (PSB), SHREC׳09 and National Taiwan University (NTU). The proposed method is compared with several state-of-the-art methods in terms of several popular evaluation criteria, and the experimental results show better performance of the proposed model. }}
@article{Fredricks2016,
title = {Using qualitative methods to develop a survey measure of math and science engagement },
journal = {Learning and Instruction },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2016.01.009},
url = {http://www.sciencedirect.com/science/article/pii/S0959475216300093},
author = {Jennifer A. Fredricks and Ming-Te Wang and Jacqueline Schall Linn and Tara L. Hofkens and Hannah Sung and Alyssa Parr and Julia Allerton},
abstract = {Abstract Student engagement in math and science is vital to students' academic achievement and long-term participation in science, technology, engineering, and mathematic (STEM) courses and careers. In this study, we conducted in-depth interviews with 106 students from sixth to twelfth grade and 34 middle and high school teachers about how they conceptualized math and science engagement and disengagement. Our qualitative analysis of student and teacher interviews supported the multidimensional construct of engagement outlined in the academic literature. Our analysis also revealed additional indicators that have been included in prior measures of engagement less frequently. We then described how we used this qualitative information from students and teachers to develop and validate a new student self-report measure of math and science engagement. }}
@article{Hong2016214,
title = {Internet cognitive failure relevant to self-efficacy, learning interest, and satisfaction with social media learning },
journal = {Computers in Human Behavior },
volume = {55, Part A},
number = {},
pages = {214 - 222},
year = {2016},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2015.09.010},
url = {http://www.sciencedirect.com/science/article/pii/S0747563215301412},
author = {Jon-Chao Hong and Ming-Yueh Hwang and Elson Szeto and Chi-Ruei Tsai and Yen-Chun Kuo and Wei-Yeh Hsu},
abstract = {Abstract Social media has been postulated as a convenient online resource tool for learning. To understand the usefulness of social media, the present study focused on Guitar Class of Uncle Ma, one of YouTube's most popular guitar learning channels in Taiwan, as a self-directed learning tool. Drawing upon a cognitive-affective theory of learning with media (CATLM), learners have the ability to control the pace of learning through YouTube by repeating playback, rewinding or fast forwarding the video. This study used expectation confirmation theory and structural equation modeling to explore the relationship between affective and cognitive factors in learning with social media. Using convenience sampling, data from 117 users were collected and the results showed Internet cognitive failure (ICF) was negatively correlated to self-efficacy and learning interest in using Guitar Class of Uncle Ma for learning guitar skills. However, self-efficacy and learning interest was positively correlated to learning satisfaction. The results suggest that Guitar Class of Uncle Ma is a beneficial self-directed learning tool for learners with low levels of Internet cognitive failure and high levels of self-efficacy and learning interest when learning how to play guitar using YouTube. }}
@article{Lin20161213,
title = {Effects of mental process integrated nursing training using mobile device on students’ cognitive load, learning attitudes, acceptance, and achievements },
journal = {Computers in Human Behavior },
volume = {55, Part B},
number = {},
pages = {1213 - 1221},
year = {2016},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2015.03.076},
url = {http://www.sciencedirect.com/science/article/pii/S0747563215002770},
author = {Yen-Ting Lin and Yi-Chun Lin},abstract = {Abstract Clinical nursing training is important to nursing educators and student nurses in nursing education since safe and competent care depends on good clinical problem solving skills. Therefore, developing better cognitive problem-solving strategies or tools are essential for clinical nursing practices. Moreover, learning diagnosis is also a critical determinant in the acquisition, processing, and application of clinical skills in nursing practices. Bearing this in mind, this study aims to develop a mobile interactive learning and diagnosis (MILD) system to support problem-based learning (PBL) in a clinical nursing course based on the testing-based approach. Using mobile devices as a learning tool to integrate both real-world and digital-world resources for students and adopting PBL as a learning strategy to facilitate the development of the clinical problem solving skills. To show the effectiveness of the proposed approach, an experiment was conducted in a foundations of nursing course at a nursing college in Taiwan. The experimental results show that the proposed approach is helpful to students in improving learning performance and reducing cognitive loads. Moreover, it was also found that most students showed positive perceptions toward the usage of the proposed system. }}
@article{Wu20161179,
title = {Integration of RPG use and ELC foundation to examine students’ learning for practice },
journal = {Computers in Human Behavior },
volume = {55, Part B},
number = {},
pages = {1179 - 1184},
year = {2016},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2014.10.023},
url = {http://www.sciencedirect.com/science/article/pii/S0747563214005469},
author = {Wen-Hsiung Wu and Wen-Cheng Yan and Hao-Yun Kao and Wei-Yang Wang and Yen-Chun Jim Wu},
abstract = {Abstract Regarding the issue of role-playing games (RPG) and the experiential learning cycle (ELC), the integration of RPG use as a pedagogical and simulation tool for practice and ELC as a learning theoretical foundation is essential for promoting students’ effective learning. However, few studies have applied RPG to simulate the practice with the ELC stages, namely, concrete experience (CE), reflective observation (RO), abstract conceptualization, (AC) and active experimentation (AE), to examine the learning process and further enhance the effective learning outcomes for learners. This study integrates the RPG development and use for practice derived from the ELC’s four stages based on practising the project assessment of software development in a software engineering course. The results show a significant improvement in students’ learning outcomes after RPG use. More importantly, this study provides the major activities and findings of each ELC stage via RPG use and the mapping of RPG activities with ELC stages. The insightful implications and suggestions of this study are discussed. }}
@article{Yu2016652,
title = {Scene text localization using edge analysis and feature pool },
journal = {Neurocomputing },
volume = {175, Part A},
number = {},
pages = {652 - 661},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.10.105},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215015817},
author = {Chong Yu and Yonghong Song and Yuanlin Zhang},



abstract = {Abstract Due to the rapid development of machine learning and data mining in nowadays, how to acquire information from images becomes more and more important. The direct information of an image is the texts inside. However, detecting such texts in images is always a challenging problem in computer vision area. Edge is one of the most important clues in scene character detection task. However, many edge based text detection methods usually had trouble with sticky edges and did not fully utilize characteristic of texts. In this paper, we proposed a method for detecting and localizing texts in natural scene images, by edge recombining, edge filtering and multi-channel processing. In order to segment texts from backgrounds, edges are firstly over-segmented into edge segments during edge analysis. These edge segments are then recombined to candidate characters and an edge filter is used to filter out most of background edges. The left candidate character edges are linked up to candidate text lines. We use two different classifiers to filter out non-text lines. To classify more accurately, extracted edge-based and region-based features are firstly stored in feature pools. Then we use liner SVM to select the most effective features from the feature pool to train classifiers. Finally, multi-channel is used to ensure the recall and a modified non-maximal suppress is applied to eliminate duplicate results. Experimental results on the ICDAR 2011 competition dataset and SVT database demonstrate the effectiveness of our method. }}
@article{Tissera201642,
title = {Deep extreme learning machines: supervised autoencoding architecture for classification },
journal = {Neurocomputing },
volume = {174, Part A},
number = {},
pages = {42 - 49},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.03.110},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215011327},
author = {Migel D. Tissera and Mark D. McDonnell},

abstract = {Abstract We present a method for synthesising deep neural networks using Extreme Learning Machines (ELMs) as a stack of supervised autoencoders. We test the method using standard benchmark datasets for multi-class image classification (MNIST, CIFAR-10 and Google Streetview House Numbers (SVHN)), and show that the classification error rate can progressively improve with the inclusion of additional autoencoding ELM modules in a stack. Moreover, we found that the method can correctly classify up to 99.19% of MNIST test images, which surpasses the best error rates reported for standard 3-layer ELMs or previous deep ELM approaches when applied to MNIST. The approach simultaneously offers a significantly faster training algorithm to achieve its best performance (in the order of 5 min on a four-core CPU for MNIST) relative to a single ELM with the same total number of hidden units as the deep ELM, hence offering the best of both worlds: lower error rates and fast implementation. }}
@article{Dabek2015265,
title = {Leveraging Big Data to Model the Likelihood of Developing Psychological Conditions After a Concussion },
journal = {Procedia Computer Science },
volume = {53},
number = {},
pages = {265 - 273},
year = {2015},
note = {INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.303},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915018062},
author = {Filip Dabek and Jesus J. Caban},abstract = {Abstract A concussion is an invisible and poorly understood mild traumatic brain injury (mTBI) that can alter the way the brain functions. Patients who have screened positive for mTBI are at an increased risk of depression, post-traumatic stress disorder (PTSD), headaches, sleep disorders, and other neurological and psychological problems. Early detection of psychological conditions such as PTSD following a concussion might improve the overall outcome of a patient and could potentially reduce the cost associated with intense interventions often required when conditions go untreated for a long time. Statistical and predictive models that leverage large-scale clinical repositories and use pre-existing conditions to determine the probability of a patient developing psychological conditions following a concussion have not been widely studied. This paper presents an SVM-based model that has been trained with a longitudinal dataset of over 5.3 million clinical encounters of 89,840 service members that have sustained a concussion. The model has been tested and validated with over 16,045 patients that developed PTSD and it has shown an accuracy of over 85% (AUC of 86.52%) at predicting the condition within the first year following the injury. }}
@article{Ding20151462,
title = {Auto-Categorization of HS Code Using Background Net Approach },
journal = {Procedia Computer Science },
volume = {60},
number = {},
pages = {1462 - 1471},
year = {2015},
note = {Knowledge-Based and Intelligent Information &amp; Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.08.224},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915023510},
author = {Liya Ding and ZhenZhen Fan and DongLiang Chen},



abstract = {Abstract The Harmonized System of tariff nomenclature created by the Brussels-based World Customs Organization is widely applied to standardize traded products with Code, Description, Unit of Quantity, and Duty for Classification, to cope with the rapidly increasing international merchandise trade. As part of the function desired by trading system for Singapore Customs, an auto-categorization system is expected to accurately classify products into HS codes based on the text description of the goods declaration so to increase the overall usability of the trading system. Background Nets approach has been adopted as the key technique for the development of classification engine in the system. Experimental results indicate the potential of this approach in text categorization with ill-defined vocabularies and complex semantics. }}
@article{Yuan20161768,
title = {SubMIL: Discriminative subspaces for multi-instance learning },
journal = {Neurocomputing },
volume = {173, Part 3},
number = {},
pages = {1768 - 1774},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.08.089},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215013600},
author = {Jiazheng Yuan and Xiankai Huang and Hongzhe Liu and Bing Li and Weihua Xiong},



abstract = {Abstract As an important learning scheme for Multi-Instance Learning (MIL), the Instance Prototype (IP) selection-based MIL algorithms transform bags into a new instance feature space and achieve impressed classification performance. However, the number of IPs in the existing algorithms linearly increases with the scale of the training data. The performance and efficiencies of these algorithms are easily limited by the high dimension and noise when facing a large scale of training data. This paper proposes a discriminative subspaces-based instance prototype selection method that is suitable for reducing the computation complexity for large scale training data. In the proposed algorithm, we introduce the low-rank matrix recovery technique to find two discriminative and clean subspaces with less noise; then present a ℓ 2 , 1 norm-based self-expressive sparse coding model to select the most representative instances in each subspace. Experimental results on several data sets show that our algorithm achieves superior and stable performance but with lower dimension compared with other IP selection strategies. }}
@article{Antipov201659,
title = {Minimalistic CNN-based ensemble model for gender prediction from face images },
journal = {Pattern Recognition Letters },
volume = {70},
number = {},
pages = {59 - 65},
year = {2016},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.11.011},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515003979},
author = {Grigory Antipov and Sid-Ahmed Berrani and Jean-Luc Dugelay},



abstract = {Abstract Despite being extensively studied in the literature, the problem of gender recognition from face images remains difficult when dealing with unconstrained images in a cross-dataset protocol. In this work, we propose a convolutional neural network ensemble model to improve the state-of-the-art accuracy of gender recognition from face images on one of the most challenging face image datasets today, LFW (Labeled Faces in the Wild). We find that convolutional neural networks need significantly less training data to obtain the state-of-the-art performance than previously proposed methods. Furthermore, our ensemble model is deliberately designed in a way that both its memory requirements and running time are minimized. This allows us to envision a potential usage of the constructed model in embedded devices or in a cloud platform for an intensive use on massive image databases. }}
@article{Braghirolli2016315,
title = {Benefits of educational games as an introductory activity in industrial engineering education },
journal = {Computers in Human Behavior },
volume = {58},
number = {},
pages = {315 - 324},
year = {2016},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2015.12.063},
url = {http://www.sciencedirect.com/science/article/pii/S0747563215303344},
author = {Lynceo Falavigna Braghirolli and José Luis Duarte Ribeiro and Andreas Dittmar Weise and Morgana Pizzolato},
abstract = {Abstract This study evaluates the use of educational games as an introductory activity in the first year of undergraduate degree programs in industrial engineering. This proposal exploit the potential use of games to present complex situations without discouraging players, allowing new students to examine important elements of the professional field. Therefore, an educational game designed for use during the first year of classes was developed. The contribution of this game proposed for student learning and motivation was evaluated using a questionnaire, as was the receptivity to the use of educational games. The results show that this activity motivated students to participate and to better understand the course content. They also indicate that educational games are well accepted by the first-year students. The following benefits of educational games as an introductory activity in higher education contribute to these results: the opportunity to present different concepts in an integrated manner, the possibility of offering a comprehensive and dynamic example that can be shared by students and professors, the greater freedom afforded to the professor for individual interaction with students and the ability to simultaneously satisfy the demand for knowledge and motivation. }}
@article{Shi2016448,
title = {Script identification in the wild via discriminative convolutional neural network },
journal = {Pattern Recognition },
volume = {52},
number = {},
pages = {448 - 458},
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.11.005},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315004252},
author = {Baoguang Shi and Xiang Bai and Cong Yao},
abstract = {Abstract Script identification facilitates many important applications in document/video analysis. This paper investigates a relatively new problem: identifying scripts in natural images. The basic idea is combining deep features and mid-level representations into a globally trainable deep model. Specifically, a set of deep feature maps is firstly extracted by a pre-trained CNN model from the input images, where the local deep features are densely collected. Then, discriminative clustering is performed to learn a set of discriminative patterns based on such local features. A mid-level representation is obtained by encoding the local features based on the learned discriminative patterns (codebook). Finally, the mid-level representations and the deep features are jointly optimized in a deep network. Benefiting from such a fine-grained classification strategy, the optimized deep model, termed Discriminative Convolutional Neural Network (DisCNN), is capable of effectively revealing the subtle differences among the scripts difficult to be distinguished, e.g. Chinese and Japanese. In addition, a large scale dataset containing 16,291 in-the-wild text images in 13 scripts, namely SIW-13, is created for evaluation. Our method is not limited to identifying text images, and performs effectively on video and document scripts as well, not requiring any preprocess like binarization, segmentation or hand-crafted features. The experimental comparisons on the datasets including SIW-13, CVSI-2015 and Multi-Script consistently demonstrate DisCNN a state-of-the-art approach for script identification. }}
@article{Escalante201691,
title = {A naïve Bayes baseline for early gesture recognition },
journal = {Pattern Recognition Letters },
volume = {73},
number = {},
pages = {91 - 99},
year = {2016},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2016.01.013},
url = {http://www.sciencedirect.com/science/article/pii/S0167865516000258},
author = {Hugo Jair Escalante and Eduardo F. Morales and L. Enrique Sucar},



abstract = {Abstract Early gesture/action recognition is the task of determining the identity of a gesture/action with as few information as possible. Although the topic is relatively new, there are some methods that address this problem. However, existing methods rely on complex modeling procedures, that do not necessarily paid off the computational effort. Thus, simple yet effective and efficient techniques are required for this task. This paper describes a new methodology for early gesture recognition based on the well known naïve Bayes classifier. The method is extremely simple and very fast, yet it compares favorably with more elaborated state of the art methodologies. The naïve baseline is based on three main observations: (1) the effectiveness of the naïve Bayes classifier in text mining problems; (2) the link between natural language processing and computer vision via the bag-of-words representation; and (3) the cumulative-evidence nature of the inference process of naïve Bayes. We evaluated the proposed method in several collections that included segmented and continuous video. Experimental results show that the proposed methodology compares favorably with state of the art methodologies that are more elaborated or were specifically designed for this purpose. }}
@article{Cecotti201676,
title = {Active graph based semi-supervised learning using image matching: Application to handwritten digit recognition },
journal = {Pattern Recognition Letters },
volume = {73},
number = {},
pages = {76 - 82},
year = {2016},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2016.01.016},
url = {http://www.sciencedirect.com/science/article/pii/S0167865516000283},
author = {Hubert Cecotti},abstract = {Abstract With the availability of large amounts of documents and multimedia content to be classified, the creation of new databases with labeled examples is an expensive task. Efficient supervised classifiers often require large training databases that are not always immediately available. Active learning approaches solve this issue by querying an expert to set a label to particular instances. In this paper, we present a novel active learning strategy for the classification of handwritten digits. The proposed method is based on a k-nearest neighbor graph obtained with an image deformation model, which takes into account local deformations. During the active learning procedure, the user is first asked to label the vertices with the highest number of neighbors. Thus, the expert sets the label to the examples that are more likely to propagate their labels to a high number of close neighbors. Then, a label propagation function is performed to automatically label the examples. The procedure is repeated until all the images are labeled. We evaluate the performance of the method on four databases corresponding to different scripts (Latin, Bangla, Devnagari, and Oriya). We show that it is possible to label only 332 images in the MNIST training database to obtain an accuracy of 98.54% on this same database (60000 images). The robustness of the method is highlighted by the performance of handwritten digit recognition in different scripts. }}
@article{Lai201621,
title = {Training nursing students' communication skills with online video peer assessment },
journal = {Computers & Education },
volume = {97},
number = {},
pages = {21 - 30},
year = {2016},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2016.02.017},
url = {http://www.sciencedirect.com/science/article/pii/S0360131516300513},
author = {Chin-Yuan Lai},abstract = {Abstract Communication is an important skill which nursing students must master in order to be effective in their career. One of the purposes of this study was to implement an online video peer assessment system to scaffold their communication skills. The other purpose was to examine the effects and validity of the peer assessment. Fifty nursing students enrolled in a psychiatric nursing course in Taiwan participated in the study. The experiment contained two rounds of peer assessments. In each round, the students had a therapeutic consultation with a simulated patient. It was recorded and uploaded on a YouTube platform which we designed to keep a log of viewing, rating and feedback from their peers. The peer assessment process was synchronized with the viewing of peers' communication videos so that feedback could be marked to the relevant point on the video. Expert evaluation scores showed that students' communication performance, when involved in peer assessments, significantly improved. In the first round, the scores determined by the peers were not correlated with those marked by the experts. However, in the second round, both scores were significantly correlated, indicating that the online peer assessment could be perceived as a valid assessment method for nursing communication skills training. Moreover, the analysis of peer feedback also revealed that their communication became more patient-centered gradually due to the peer assessments. On the whole, the students were satisfied with the peer assessment activities and appreciated the contribution to their communication skills. }}
@article{McAndrew2002201,
title = {Handbook on Information Technologies for Education and Training: Edited by H.H. Adelsberger, B. Collis, and J.M. Pawloski. Springer-Verlag, 2002. 715pp. £91.50 (€124) hardback. },
journal = {Computers & Education },
volume = {39},
number = {2},
pages = {201 - 203},
year = {2002},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/S0360-1315(02)00033-7},
url = {http://www.sciencedirect.com/science/article/pii/S0360131502000337},
author = {Patrick McAndrew}}
@article{Ding2016664,
title = {Locality sensitive batch feature extraction for high-dimensional data },
journal = {Neurocomputing },
volume = {171},
number = {},
pages = {664 - 672},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.076},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215010838},
author = {Jie Ding and Changyun Wen and Guoqi Li and Chin Seng Chua},
abstract = {Abstract For feature extraction, the dimensionality of the feature space is usually much larger than the size of training set. This is known as under sample problem. At this time, local structure is more important than global structure. In this paper, locality sensitive batch feature extraction (LSBFE) is derived based on a new gradient optimization model by exploiting both local and global discriminant structure of data manifold. With the proposed LSBFE, a set of features can be extracted simultaneously. Recognition rate is improved compared with batch feature extraction (BFE), which only considers global information. It is shown that the proposed method achieves good performance for face databases, handwritten digit database, object database and DBWorld data set. }}
@article{Qi2015,
title = {HEp-2 cell classification: The role of Gaussian Scale Space Theory as a pre-processing approach },
journal = {Pattern Recognition Letters },
volume = {},
number = {},
pages = { - },
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.12.011},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515004341},
author = {Xianbiao Qi and Guoying Zhao and Jie Chen and Matti Pietikäinen},



abstract = {Abstract Indirect Immunofluorescence Imaging of Human Epithelial Type 2 (HEp-2) cells is an effective way to identify the presence of Anti-Nuclear Antibody (ANA). Most existing works on HEp-2 cell classification mainly focus on feature extraction, feature encoding and classifier design. Very few efforts have been devoted to study the importance of the pre-processing techniques. In this paper, we analyze the importance of the pre-processing, and investigate the role of Gaussian Scale Space (GSS) theory as a pre-processing approach for the HEp-2 cell classification task. We validate the GSS pre-processing under the Local Binary Pattern (LBP) and the Bag-of-Words (BoW) frameworks. Under the BoW framework, the introduced pre-processing approach, using only one Local Orientation Adaptive Descriptor (LOAD), achieved superior performance on the Executable Thematic on Pattern Recognition Techniques for Indirect Immunofluorescence (ET-PRT-IIF) image analysis. Our system, using only one feature, outperformed the winner of the ICPR 2014 contest that combined four types of features. Meanwhile, the proposed pre-processing method is not restricted to this work; it can be generalized to many existing works. }}
@article{Tan2015,
title = {Computational aesthetics of photos quality assessment based on improved artificial neural network combined with an autoencoder technique },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.04.124},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215019013},
author = {Yunlan Tan and Yimin Zhou and Guangyao Li and Anmin Huang},

abstract = {Abstract Photograph aesthetical evaluation has been widely investigated in these decades. For fine-granularity aesthetic quality prediction, a novel aesthetics classifier based on improved artificial neural network combined with an Autoencoder technique is presented. First, we download large consumer photographic images from a well-known online photograph portal. Then, we extract 56 features normalized to 0–1 and train the networks with photographs of high and low ratings to test the quality of photos. Experimental results show that the accuracy of classification is above 86.67%, which is better than all state-of-the-art methods. Meanwhile, it is observed from experiments that the extracted features are consistent with the humans׳ visual perception systems. }}
@article{Mayer201412,
title = {Benefits of emotional design in multimedia instruction },
journal = {Learning and Instruction },
volume = {33},
number = {},
pages = {12 - 18},
year = {2014},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2014.02.004},
url = {http://www.sciencedirect.com/science/article/pii/S0959475214000231},
author = {Richard E. Mayer and Gabriel Estrella},



abstract = {Abstract Emotional design of multimedia instruction involves making the essential elements in the lesson's graphics more appealing, such as by rendering them with human-like features and with distinct, appealing colors (Um, Plass, Hayward, &amp; Homer, 2012). College students received an 8-slide multimedia lesson on how a virus causes a cold for 5 min (Experiment 1) or for as long as they wanted (Experiment 2). For the control group, the graphics consisted of simple black-and-white drawings in which the host cell was represented as a large circle, and the virus was represented as a small circle with small spikes on the outside and a rectangle on the inside. For the enhanced group, the graphics were redrawn to render the host cell as a red face with expressive eyes (registering surprise, fear, and sickness at various stages in the process), and the virus as a blue face with fierce eyes and with a green dot at the end of each of the blue tentacles surrounding the virus face. The enhanced group performed better than the control group on a subsequent learning test (d = 0.69 in Experiment 1, d = 0.65 in Experiment 2) and gave higher effort ratings in Experiment 1 (d = 0.65) but not in Experiment 2 (d = −0.10). The findings are generally consistent with the cognitive affective theory of learning with media, and point to the importance of incorporating motivation into cognitive theories of multimedia learning. }}
@article{Lin2012378,
title = {Promoting and scaffolding argumentation through reflective asynchronous discussions },
journal = {Computers & Education },
volume = {59},
number = {2},
pages = {378 - 384},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.01.019},
url = {http://www.sciencedirect.com/science/article/pii/S0360131512000425},
author = {Huann-shyang Lin and Zuway-R. Hong and Frances Lawrenz},
abstract = {The purpose of this quasi-experimental study was to explore the impact of asynchronous discussion on the quality and complexity of college students’ arguments. Three different cohorts of students registered in a physical science course in 2009 Fall, 2010 Spring, and 2010 Fall semesters were briefly supported with scaffolding in class and then involved in argumentation about socio-scientific issues as take-home assignments. Each cohort was divided into an asynchronous online communication group and a paper–pencil group. The findings showed that very few students’ arguments from either group were rated low in quality levels of 1 or 2 on a five-scale level. Additional comparisons revealed that the asynchronous online communication group students slightly outperformed their counterparts in terms of mean quality level of arguments (effect sizes ranged from 0.25 to 0.35) and the frequency of rebuttals. The major finding is that after only one hour of scaffolding followed by the opportunity to practice argumentation at home, students’ argumentation skills were slightly better developed through reflective asynchronous online discussions about socio-scientific issues than through paper-pencil practice. }}
@article{Dong2015308,
title = {Multi-level photo quality assessment with multi-view features },
journal = {Neurocomputing },
volume = {168},
number = {},
pages = {308 - 319},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.05.095},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215007936},
author = {Zhe Dong and Xinmei Tian},abstract = {Abstract Photo quality assessment using the principles of visual aesthetics has been a hot research topic in recent years. Due to the complexity of human aesthetic activities, this task is very challenging. Most existing works apply binary labels (good or bad) to represent the photo quality, and focus on constructing rule-based features under the guidance of photography knowledge. However, those features strictly imitate photography rules and suffer from low effectiveness and high computational cost. Besides, the binary quality representation is oversimplified and fails to distinguish varying quality degrees. To tackle these problems, we construct new effective and efficient features from different views and further fuse them to predict multi-level, instead of binary, photo quality. More specifically, we design a set of compact rule-based features through careful analyses on photographic rules and aesthetic attributes. We propose using Deep Convolutional Neural Network (DCNN) descriptor, which encodes the photo content thoroughly, to implicitly describe the photo quality. Experiments conducted on two large scale benchmark datasets verify the effectiveness of these two different kinds of features. Furthermore, we propose a method to combine these features for multi-level photo quality prediction. This feature fusion method has proven to be effective on a dataset that is carefully organized to support research on this new multi-level photo quality assessment problem. }}
@article{Klatter2001485,
title = {Learning conceptions of young students in the final year of primary education },
journal = {Learning and Instruction },
volume = {11},
number = {6},
pages = {485 - 516},
year = {2001},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/S0959-4752(01)00002-0},
url = {http://www.sciencedirect.com/science/article/pii/S0959475201000020},
author = {Ellen B Klatter and Hans G.L.C Lodewijks and Cor A.J Aarnoutse},abstract = {The purpose of this research was to describe young pupils' learning conceptions. In this study, a learning conception was defined as a cluster of interrelated beliefs about different aspects of learning. Firstly, 27 pupils, all in the final year of primary school, were interviewed to elicit learning-related issues as being relevant for six-graders. Secondly, a questionnaire, developed on the basis of the outcomes of the interviews, was used to determine the interrelatedness of pupils' beliefs about the selected aspects. The results showed the young pupils to have different beliefs about five aspects of learning: purpose of school; learning orientation; regulation; learning demands; and mental activities. In exploring group differences, three different learning conceptions could be distinguished: a restricted learning conception; a functional learning conception; and a developmental learning conception. The characteristics of these different learning conceptions may be indicative of how young pupils conceive learning-related aspects. }}
@article{Delen2014312,
title = {Effects of interactivity and instructional scaffolding on learning: Self-regulation in online video-based environments },
journal = {Computers & Education },
volume = {78},
number = {},
pages = {312 - 320},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.06.018},
url = {http://www.sciencedirect.com/science/article/pii/S0360131514001511},
author = {Erhan Delen and Jeffrey Liew and Victor Willson},
abstract = {Abstract Online learning often requires learners to be self-directed and engaged. The present study examined students' self-regulatory behaviors in online video-based learning environments. Using an experimental design, this study investigated the effects of a newly designed enhanced video learning environment, which was designed to support or scaffold students' self-regulated or self-directed learning on students' learning behaviors and outcomes. In addition, correspondence between students' self-regulation strategies in traditional learning environments and observed self-regulated learning behaviors in the enhanced video environment were examined. A cross-sectional experimental research design with systematic random assignment of participants to either the control condition (common video) or the experimental condition (enhanced video) was utilized. Undergraduate and graduate students participated in the study (N = 80). Study results indicate that the newly designed enhanced video learning environment was a superior instructional tool than the common video learning environment in terms students' learning performance. In addition, there was correspondence between graduate students' self-reported self-regulation and observed self-regulation, with those high on seeking/learning information and managing their environment/behavior more likely to engage more in interactive note-taking. }}
@article{Mayer2003125,
title = {The promise of multimedia learning: using the same instructional design methods across different media },
journal = {Learning and Instruction },
volume = {13},
number = {2},
pages = {125 - 139},
year = {2003},
note = {External and Internal Representations in Multimedia Learning },
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/S0959-4752(02)00016-6},
url = {http://www.sciencedirect.com/science/article/pii/S0959475202000166},
author = {Richard E. Mayer},abstract = {Multimedia learning occurs when students build mental representations from words and pictures that are presented to them (e.g., printed text and illustrations or narration and animation). The promise of multimedia learning is that students can learn more deeply from well-designed multimedia messages consisting of words and pictures than from more traditional modes of communication involving words alone. This article explores a program of research aimed at determining (a) research-based principles for the design of multimedia explanations—which can be called methods, and (b) the extent to which methods are effective across different learning environments—which can be called media. A review of research on the design of multimedia explanations conducted in our lab at Santa Barbara shows (a) a multimedia effect—in which students learn more deeply from words and pictures than from words alone—in both book-based and computer-based environments, (b) a coherence effect—in which students learn more deeply when extraneous material is excluded rather than included—in both book-based and computer-based environments, (c) a spatial contiguity effect—in which students learn more deeply when printed words are placed near rather than far from corresponding pictures—in both book-based and computer-based environments, and (d) a personalization effect—in which students learn more deeply when words are presented in conversational rather than formal style—both in computer-based environments containing spoken words and those using printed words. Overall, our results provide four examples in which the same instructional design methods are effective across different media. }}
@article{Yang2015216,
title = {Media multitasking and psychological wellbeing in Chinese adolescents: Time management as a moderator },
journal = {Computers in Human Behavior },
volume = {53},
number = {},
pages = {216 - 222},
year = {2015},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2015.06.034},
url = {http://www.sciencedirect.com/science/article/pii/S0747563215300017},
author = {Xiaohui Yang and Xiaohui Xu and Liqi Zhu},abstract = {Abstract The present study examined the relationships among media multitasking, time management, and psychological wellbeing in Chinese adolescents. A total of 320 adolescents aged 11 to 18 years old were recruited and asked to complete the Media Use Questionnaire, Chinese Adolescent Mental Health Inventory, and Adolescent Time Management Disposition scale. A structural equation model was used to assess possible relationships among media multitasking, time management, and psychological wellbeing. The results showed that the media multitasking index of the sample was 2.5, indicating that adolescents also had access to other 2.5 media tasks when performing the primary media task. Media multitasking was significantly negatively correlated with psychological wellbeing. Time management disposition was negatively correlated with Media multitasking and positively correlated with psychological wellbeing. Our findings indicate that time management disposition can moderate the relationship between Media multitasking and psychological wellbeing. The theoretical and practical implications of adolescent media use are discussed. }}
@article{Liu20151132,
title = {Universal consistency of extreme learning machine for RBFNs case },
journal = {Neurocomputing },
volume = {168},
number = {},
pages = {1132 - 1137},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.05.010},
url = {http://www.sciencedirect.com/science/article/pii/S092523121500627X},
author = {Xia Liu and Anhua Wan},



abstract = {Abstract This paper concerns the universal consistency of extreme learning machine (ELM) for radial basis function networks (RBFNs). That is, the estimator constructed by ELM for RBFNs learning system can approximate an arbitrary regression function to any accuracy, as long as the number of the training samples is sufficiently large. Furthermore, we also give the conditions for the kernel functions, with which the corresponding ELM-RBFNs estimator is strongly universal consistency. These results not only underlie the feasibility of ELM for RBFNs case, but also provide guidance of practical selection for kernel functions in ELM application. }}
@article{Montalto2015159,
title = {Neural networks with non-uniform embedding and explicit validation phase to assess Granger causality },
journal = {Neural Networks },
volume = {71},
number = {},
pages = {159 - 171},
year = {2015},
note = {},
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2015.08.003},
url = {http://www.sciencedirect.com/science/article/pii/S0893608015001574},
author = {Alessandro Montalto and Sebastiano Stramaglia and Luca Faes and Giovanni Tessitore and Roberto Prevete and Daniele Marinazzo},



abstract = {Abstract A challenging problem when studying a dynamical system is to find the interdependencies among its individual components. Several algorithms have been proposed to detect directed dynamical influences between time series. Two of the most used approaches are a model-free one (transfer entropy) and a model-based one (Granger causality). Several pitfalls are related to the presence or absence of assumptions in modeling the relevant features of the data. We tried to overcome those pitfalls using a neural network approach in which a model is built without any a priori assumptions. In this sense this method can be seen as a bridge between model-free and model-based approaches. The experiments performed will show that the method presented in this work can detect the correct dynamical information flows occurring in a system of time series. Additionally we adopt a non-uniform embedding framework according to which only the past states that actually help the prediction are entered into the model, improving the prediction and avoiding the risk of overfitting. This method also leads to a further improvement with respect to traditional Granger causality approaches when redundant variables (i.e. variables sharing the same information about the future of the system) are involved. Neural networks are also able to recognize dynamics in data sets completely different from the ones used during the training phase. }}
@article{tagkey2015v,
title = {Neural Networks },
journal = {Neural Networks },
volume = {61},
number = {},
pages = {v - ix},
year = {2015},
note = {},
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/S0893-6080(14)00258-5},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002585},
key = {tagkey2015v}}
@article{Mao20151285,
title = {A Framework for Food Traceability Information Extraction Based on a Video Surveillance System },
journal = {Procedia Computer Science },
volume = {55},
number = {},
pages = {1285 - 1292},
year = {2015},
note = {3rd International Conference on Information Technology and Quantitative Management, ITQM 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.139},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915016142},
author = {Bo Mao and Jing He and Jie Cao and Stephen W. Bigger and Todor Vasiljevic},



abstract = {Abstract Food security is currently one of the most concerning problems in China. A traceability system is an effective method to improve the quality of food production. This system has been widely applied in several countries such as the US, Japan and the EU. However, in China, the creditability of traceability systems is not strong and many producers try to deceive the public by forging the data in such systems. In this paper, a video surveillance system-based traceability system is proposed which will significantly increase the forgery cost. In this system, subjects, such as vehicles or people, are firstly defined using a novel dynamic background model, then their trajectories are generated and connected using different cameras with a camera relation graph. The experimental results indicate that the proposed method can efficiently extract the object information from the video surveillance system and generate image-based traceability information to be used for further analysis. }}
@article{tagkey2006I,
title = {Volume contents 46 &amp; 47 &amp; Author Index (2006) },
journal = {Computers & Education },
volume = {47},
number = {4},
pages = {I - VII},
year = {2006},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/S0360-1315(06)00097-2},
url = {http://www.sciencedirect.com/science/article/pii/S0360131506000972},
key = {tagkey2006I}}
@article{Wang20142116,
title = {Bag of contour fragments for robust shape classification },
journal = {Pattern Recognition },
volume = {47},
number = {6},
pages = {2116 - 2125},
year = {2014},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2013.12.008},
url = {http://www.sciencedirect.com/science/article/pii/S0031320313005426},
author = {Xinggang Wang and Bin Feng and Xiang Bai and Wenyu Liu and Longin Jan Latecki},



abstract = {Abstract Shape representation is a fundamental problem in computer vision. Current approaches to shape representation mainly focus on designing low-level shape descriptors which are robust to rotation, scaling and deformation of shapes. In this paper, we focus on mid-level modeling of shape representation. We develop a new shape representation called Bag of Contour Fragments (BCF) inspired by classical Bag of Words (BoW) model. In BCF, a shape is decomposed into contour fragments each of which is then individually described using a shape descriptor, e.g., the Shape Context descriptor, and encoded into a shape code. Finally, a compact shape representation is built by pooling shape codes in the shape. Shape classification with BCF only requires an efficient linear SVM classifier. In our experiments, we fully study the characteristics of BCF, show that BCF achieves the state-of-the-art performance on several well-known shape benchmarks, and can be applied to real image classification problem. }}
@article{Bohnsack2016,
title = {Learning Matrix Quantization and Relevance Learning Based on Schatten-p-norms },
journal = {Neurocomputing },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.12.109},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216002642},
author = {A. Bohnsack and K. Domaschke and M. Kaden and M. Lange and T. Villmann},



abstract = {Abstract In this paper, we propose an extension of the learning vector quantization approach to classify matrix data. Examples for those data are functional data depending on time and frequency. The resulting learning matrix quantization algorithm is similar to the vectorial approach but now based on matrix norms. We favor Schatten-p-norms as the generalization of lp-norms for vectors. Furthermore, relevance learning for those matrix data allows a greater structural flexibility compared to the vectorial counterpart. We identify different kinds of algebraic relevance weighting and discuss the respective mathematical properties according to the relevance learning paradigm. Exemplary applications accompany the theoretical investigations to demonstrate basic properties. }}
@article{Tan2016,
title = {A Detection-driven and Sparsity-constrained Deformable Model for Fascia Lata Labeling and Thigh Inter-muscular Adipose Quantification },
journal = {Computer Vision and Image Understanding },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2016.03.008},
url = {http://www.sciencedirect.com/science/article/pii/S1077314216300029},
author = {Chaowei Tan and Kang Li and Zhennan Yan and Dong Yang and Shaoting Zhang and Hui Jing Yu and Klaus Engelke and Colin Miller and Dimitris Metaxas},
abstract = {Abstract Quantification of the thigh inter-muscular adipose tissue (IMAT) plays a critical role in various medical data analysis tasks, e.g., the analysis of physical performance or the diagnosis of knee osteoarthritis. Several techniques have been proposed to perform automated thigh tissues quantification. However, none of them has provided an effective method to track fascia lata, which is an important anatomic trail to distinguish between subcutaneous adipose tissue (SAT) and IMAT in the thigh. As a result, the estimates of IMAT may not be accurate due to the unclear appearance cues, complicated anatomic, or pathological characteristics of the fascia lata. Thus, prior tissue information, e.g., intensity, orientation and scale, becomes critical to infer the fascia lata location from magnetic resonance (MR) images. In this paper, we propose a novel detection-driven and sparsity-constrained deformable model to obtain accurate fascia lata labeling. The model’s deformation is driven by the detected control points on fascia lata through a discriminative detector in a narrow-band fashion. By using a sparsity-constrained optimization, the deformation is solved from errors and outliers suppression. The proposed approach has been evaluated on a set of 3D MR thigh volumes. In a comparison with the state-of-the-art framework, our approach produces superior performance. }}
@article{Tran201575,
title = {A robust framework for tracking simultaneously rigid and non-rigid face using synthesized data },
journal = {Pattern Recognition Letters },
volume = {65},
number = {},
pages = {75 - 80},
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.06.028},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515002007},
author = {Ngoc-Trung Tran and Fakhreddine Ababsa and Maurice Charbit},

abstract = {Abstract This paper presents a robust framework for simultaneously tracking rigid pose and non-rigid animation of a single face with a monocular camera. Our proposed method consists of two phases: training and tracking. In the training phase, using automatically detected landmarks and the three-dimensional face model Candide-3, we built a cohort of synthetic face examples with a large range of the three axial rotations. The representation of a face’s appearance is a set of local patches of landmarks that are characterized by Scale Invariant Feature Transform (SIFT) descriptors. In the tracking phase, we propose an original approach combining geometric and appearance models. The purpose of the geometric model is to provide a SIFT baseline matching between the current frame and an adaptive set of keyframes for rigid parameter estimation. The appearance model uses nearest synthetic examples of the training set to re-estimate rigid and non-rigid parameters. We found a tracking capability up to 90° of vertical axial rotation, and our method is robust even in the presence of fast movements, illumination changes and tracking losses. Numerical results on the rigid and non-rigid parameter sets are reported using several annotated public databases. Compared to other published algorithms, our method provides an excellent compromise between rigid and non-rigid parameter accuracies. The approach has some potential, providing good pose estimation (average error less than 4° on the Boston University Face Tracking dataset) and landmark tracking precision (6.3 pixel error compared to 6.8 of one of state-of-the-art methods on Talking Face video). }}
@article{vanderVelde201544,
title = {Computation and dissipative dynamical systems in neural networks for classification },
journal = {Pattern Recognition Letters },
volume = {64},
number = {},
pages = {44 - 52},
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.02.008},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515000562},
author = {Frank van der Velde},

abstract = {Abstract Foundational issues related to learning, processing and representation underlying pattern recognition have been discussed in history and in recent times. The scientific approach to pattern recognition could provide new tools to investigate these foundational issues, which in turn could inform the scientific approach to pattern recognition as well. One such tool could be the analysis of learning, processing and representation in connectionist (or neural) networks, which have been extensively used for pattern recognition. Based on a mathematical analysis of the classification behavior of feedforward networks an analysis is given of the empiricist vs. rationalist debate on the possibility or impossibility of induction. The analysis aims to show that forms of induction are possible but not without certain given forms of structure and representation. The analysis is then extended to cover the role of representation in pattern recognition, and the nature of the underlying forms of processing, aiming to show that models of cognition derive from a specific relation between dynamics and computation. These examples illustrate that an interaction between modeling and the discussion on foundational issues could be beneficial for both and could open new avenues in the philosophical and foundational debate not available in previous times. }}
@article{Mrazova2012194,
title = {Can Deep Neural Networks Discover Meaningful Pattern Features? },
journal = {Procedia Computer Science },
volume = {12},
number = {},
pages = {194 - 199},
year = {2012},
note = {Complex Adaptive Systems 2012 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2012.09.053},
url = {http://www.sciencedirect.com/science/article/pii/S1877050912006448},
author = {Iveta Mrazova and Marek Kukacka},

abstract = {Recent advances in the area of deep neural networks brought a lot of attention to some of the key issues important for their design. In particular for 2D-shapes, their accuracy has been shown to outperform all other classifiers - e.g., in the German Traffic Sign competition run by IJCNN 2011. On the other hand, their training may be quite cumber- some and the structure of the network has to be chosen beforehand. This paper introduces a new sensitivity-based approach capable of picking the right image features from a pre-trained SOM-like feature detector. Experimental results obtained so far for hand-written digit recognition show that pruned network architectures impact a transparent representation of the features actually present in the data while improving network robustness. }}
@article{Schwenker20144,
title = {Pattern classification and clustering: A review of partially supervised learning approaches },
journal = {Pattern Recognition Letters },
volume = {37},
number = {},
pages = {4 - 14},
year = {2014},
note = {Partially Supervised Learning for Pattern Recognition },
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2013.10.017},
url = {http://www.sciencedirect.com/science/article/pii/S0167865513004091},
author = {Friedhelm Schwenker and Edmondo Trentin},

abstract = {Abstract The paper categorizes and reviews the state-of-the-art approaches to the partially supervised learning (PSL) task. Special emphasis is put on the fields of pattern recognition and clustering involving partially (or, weakly) labeled data sets. The major instances of PSL techniques are categorized into the following taxonomy: (i) active learning for training set design, where the learning algorithm has control over the training data; (ii) learning from fuzzy labels, whenever multiple and discordant human experts are involved in the (complex) data labeling process; (iii) semi-supervised learning (SSL) in pattern classification (further sorted out into: self-training, SSL with generative models, semi-supervised support vector machines; SSL with graphs); (iv) SSL in data clustering, using additional constraints to incorporate expert knowledge into the clustering process; (v) PSL in ensembles and learning by disagreement; (vi) PSL in artificial neural networks. In addition to providing the reader with the general background and categorization of the area, the paper aims at pointing out the main issues which are still open, motivating the on-going investigations in PSL research. }}
@article{Heo20101383,
title = {Exploratory study on the patterns of online interaction and knowledge co-construction in project-based learning },
journal = {Computers & Education },
volume = {55},
number = {3},
pages = {1383 - 1392},
year = {2010},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.06.012},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510001727},
author = {Heeok Heo and Kyu Yon Lim and Youngsoo Kim},
abstract = {This study aims to investigate the patterns and the quality of online interaction during project-based learning (PjBL) on both micro and macro levels. To achieve this purpose, PjBL was implemented with online group activities in an undergraduate course. Social network analysis (SNA) and content analysis were employed to analyze online interaction during project work. According to the SNA results generated from the online discussion boards, the group cohesiveness of seven teams, indicated by density indices, varied considerably, from as low as 9.81 to as high as 30.00. Regarding the content analysis of two teams with high project scores (Teams F and G), team members not only shared information (Phase I), but also identified the areas of disagreement and clarified the goals and strategies (Phase II). They also conducted some negotiations (Phase III). However, team members with low project scores (Teams C and E) shared information and stated their opinions in most cases (Phase I), with not much social construction in the higher level. Although both Team C and G showed high level of group cohesiveness among the seven teams, it is notable that the high-performing Team G dedicated nearly 39.3 percent of online discussion to negotiating and co-constructing knowledge, contrary to the 5.9 percent of low-performing Team C. Based upon the findings, some implications were proposed for further research. }}
@article{Wanner2015354,
title = {Personalising learning: Exploring student and teacher perceptions about flexible learning and assessment in a flipped university course },
journal = {Computers & Education },
volume = {88},
number = {},
pages = {354 - 369},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.07.008},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515300130},
author = {Thomas Wanner and Edward Palmer},
abstract = {Abstract Flexible teaching and learning and the ‘flipped classroom’ are current buzzwords in higher education in Australia and elsewhere in the world. They are reflections of the progressive change in higher education over the last few decades towards more student-and learning centred pedagogies and practices, which are made possible through new technologies and more delivery of online and blended (combination of face-to-face and online components) courses. The increasing personalising and flexibility of learning in higher education requires equal attention spent to assessment practices to ensure a cohesive learning experience. This paper provides the findings and conclusions of a study about a flipped classroom, which also included flexible assessment components. The study showed that students enjoy and are more engaged in a flipped classroom, prefer a blended learning to a fully online learning approach, want and require clear structure and guidelines, and strongly value flexible assessment through more choices and control. The main concern of higher education teachers is the time commitment and lack of institutional support for flipping classrooms and providing flexible assessment. It is argued that personalising learning requires more personalising of assessment, and that it is mainly the responsibility of teachers and institutions to develop ‘flexible students’. }}
@article{Mohamad2013356,
title = {Pattern of reflection in learning Authoring System through blogging },
journal = {Computers & Education },
volume = {69},
number = {},
pages = {356 - 368},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.07.031},
url = {http://www.sciencedirect.com/science/article/pii/S036013151300208X},
author = {Siti Khadijah Mohamad and Zaidatun Tasir and Jamalludin Harun and Nurbiha A. Shukor},
abstract = {Abstract This research study aims to identify student's perceptions regarding the use of blogging, the pattern of reflection involved in learning Authoring System through blogging and student's performance in tests based on the reflection's pattern. Sixteen students who registered for the Authoring System subject participated in this study. It was conducted using quantitative approaches, through survey and pre-experimental design of one group post-test type. The instruments used were questionnaire, performance test and blog contents, where tutors and students posted messages and comments on the blog during the course. The results showed that the students' overall perception regarding the educational benefits of writing a blog and reading other students' blogs and comments was positive. Students also moderately agreed that they had difficulties in engaging in the reflection through blogging. It was also found that blogging indirectly improved the students' performance in the test. Through blog content analysis, the dominant type of reflection was monologue. However, the results from the data mining analysis showed that the students used reflective conversation and monologue type of reflection to achieve Grade A in learning Authoring System. It shows that students require deep and critical reflection to perform better in the subject. }}
@article{Canal2016,
title = {A real-time Human-Robot Interaction system based on gestures for assistive scenarios },
journal = {Computer Vision and Image Understanding },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2016.03.004},
url = {http://www.sciencedirect.com/science/article/pii/S107731421600076X},
author = {Gerard Canal and Sergio Escalera and Cecilio Angulo},abstract = {Abstract Natural and intuitive human interaction with robotic systems is a key point to develop robots assisting people in an easy and effective way. In this paper, a Human Robot Interaction (HRI) system able to recognize gestures usually employed in human non-verbal communication is introduced, and an in-depth study of its usability is performed. The system deals with dynamic gestures such as waving or nodding which are recognized using a Dynamic Time Warping approach based on gesture specific features computed from depth maps. A static gesture consisting in pointing at an object is also recognized. The pointed location is then estimated in order to detect candidate objects the user may refer to. When the pointed object is unclear for the robot, a disambiguation procedure by means of either a verbal or gestural dialogue is performed. This skill would lead to the robot picking an object in behalf of the user, which could present difficulties to do it by itself. The overall system — which is composed by a NAO and Wifibot robots, a KinectTM v2 sensor and two laptops — is firstly evaluated in a structured lab setup. Then, a broad set of user tests has been completed, which allows to assess correct performance in terms of recognition rates, easiness of use and response times. }}
@article{Muis2015168,
title = {The curious case of climate change: Testing a theoretical model of epistemic beliefs, epistemic emotions, and complex learning },
journal = {Learning and Instruction },
volume = {39},
number = {},
pages = {168 - 183},
year = {2015},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2015.06.003},
url = {http://www.sciencedirect.com/science/article/pii/S0959475215300141},
author = {Krista R. Muis and Reinhard Pekrun and Gale M. Sinatra and Roger Azevedo and Gregory Trevors and Elisabeth Meier and Benjamin C. Heddy},
abstract = {Abstract We propose a theoretical model linking students' epistemic beliefs, epistemic emotions, learning strategies, and learning outcomes. The model was tested across two studies with 439 post-secondary students from Canada, the United States, and Germany for Study 1, and 56 students from Canada for Study 2. For Study 1, students self-reported their epistemic beliefs about climate change, read four conflicting documents about the causes and consequences of climate change, self-reported their epistemic emotions and learning strategies used to learn the content, and were given an inference verification test to measure learning. Study 2 used the same procedure but added a think aloud protocol to capture self-regulatory processes and emotions as they occurred. Path analyses revealed that epistemic beliefs served as important antecedents to the epistemic emotions students experienced during learning. Students who believed that the justification of knowledge about climate change requires critical evaluation of multiple sources experienced higher levels of enjoyment and curiosity, and lower levels of boredom when confronted with conflicting information. A belief in the complexity of this knowledge was related to lower levels of confusion, anxiety, and boredom. A belief in the uncertainty of this knowledge predicted lower levels of anxiety and frustration, and a belief in the active construction of knowledge predicted lower levels of confusion. Epistemic emotions predicted the types of learning strategies students used to learn the content and mediated relations between epistemic beliefs and learning strategies. Learning strategies predicted learning outcomes and mediated relations between epistemic emotions and learning outcomes. Implications for research on epistemic beliefs, epistemic emotions, and students' self-regulated learning are discussed. }}
@article{Tung201586,
title = {Improving scene attribute recognition using web-scale object detectors },
journal = {Computer Vision and Image Understanding },
volume = {138},
number = {},
pages = {86 - 91},
year = {2015},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2015.05.012},
url = {http://www.sciencedirect.com/science/article/pii/S1077314215001265},
author = {Frederick Tung and James J. Little},abstract = {Abstract Semantic attributes enable a richer description of scenes than basic category labels. While traditionally scenes have been analyzed using global image features such as Gist, recent studies suggest that humans often describe scenes in ways that are naturally characterized by local image evidence. For example, humans often describe scenes by their functions or affordances, which are largely suggested by the objects in the scene. In this paper, we leverage a large collection of modern object detectors trained at the web scale to derive effective high-level features for scene attribute recognition. We conduct experiments using two modern object detection frameworks: a semi-supervised learner that continuously learns object models from web images, and a state-of-the-art deep network. The detector response features improve the state of the art on the standard scene attribute benchmark by 5% average precision, and also capture intuitive object-scene relationships, such as the positive correlation of castles with vacationing/touring scenes. }}
@article{deOliveira201627,
title = {A hybrid evolutionary decomposition system for time series forecasting },
journal = {Neurocomputing },
volume = {180},
number = {},
pages = {27 - 34},
year = {2016},
note = {Progress in Intelligent Systems DesignSelected papers from the 4th Brazilian Conference on Intelligent Systems (BRACIS 2014) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.113},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215016057},
author = {João F.L. de Oliveira and Teresa B. Ludermir},


abstract = {Abstract In the field of time series forecasting, the combination of linear and nonlinear models has been explored to improve the accuracy of predictions when compared with the performance of individual models. Traditional forecasting methods such as the autoregressive integrated moving average (ARIMA) and exponential smoothing (ETS) are employed to map linear patterns in a time series while neural networks (ANNs) and support vector machines (SVMs) map nonlinear patterns. A traditional hybrid ARIMA–ANN system works by performing linear relationships in the data, considering the residual error a nonlinear component which is mapped by the ANN. The nature of a time series can be taken into consideration before applying a model. This work employs both linear and nonlinear patterns of a time series based on its volatility. This is explored using a hybrid evolutionary system composed by a simple exponential smoothing filter, ARIMA and autoregressive (AR) linear models and a SVR model. Particle swarm optimization is employed to optimize the order of the AR model, SVR parameters and number of lags of the time series. Experimental results show that the evolutionary hybrid system presented promising results in the forecasting domain. }}
@article{ZolfaghariMashhadi20111178,
title = {Influences of digital classrooms on education },
journal = {Procedia Computer Science },
volume = {3},
number = {},
pages = {1178 - 1183},
year = {2011},
note = {World Conference on Information Technology },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2010.12.190},
url = {http://www.sciencedirect.com/science/article/pii/S187705091000565X},
author = {Vahideh Zolfaghari Mashhadi and Mohammad Reza Kargozari},



abstract = {Information technology affects in all aspects of human activity, and education is not exception, so its impact on education and training is inevitable. A digitally literate citizen will be able to learn and take responsibility for their learning so this results in a higher demand for education and feel of the needs for more equipment and tools. By spreading the use of World Wide Web, internet and intranet, integrating technology that support the education became a prevalent subject in the 1990s. So today you can achieve information wherever in the world you are. By using information technology, students can decide about their study, its time, its place and their resources. In digital environment students can share their ideas and experiences and using help from other students and teachers. Digital classroom comprises all forms of electronically supported learning and teaching. The Information and communication systems, whether networked or not, serve as specific media to implement the learning process. It is essentially the computer and network-enabled transfer of skills and knowledge. Digital classroom applications and processes include Web-based learning, computer-based learning, virtual classroom opportunities and digital collaboration. Content is delivered via the Internet, intranet/extranet, audio or video tape, satellite TV, and CD-ROM. It can be self-paced or instructor-led and includes media in the form of text, image, animation, streaming video and audio. Acronyms like CBT (Computer-Based Training), IBT (Internet-Based Training) or WBT (WebBased Training) are different forms of digital classroom. For utilizing digital class, some features must be met. Students, and teachers must be trained and qualified to fulfill their roles; Schools and organizations must be developed and prepared for the new context. This paper displays how digital classroom affects education and how it proliferate learning process. This study also demonstrates the benefits and defects of digital classroom. }}
@article{tagkey1997v,
title = {Subject index },
journal = {Learning and Instruction },
volume = {7, Supplement 1},
number = {},
pages = {v - vii},
year = {1997},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/S0959-4752(97)88760-9},
url = {http://www.sciencedirect.com/science/article/pii/S0959475297887609},
key = {tagkey1997v}}
@article{Brom2015682,
title = {Playing educational micro-games at high schools: Individually or collectively? },
journal = {Computers in Human Behavior },
volume = {48},
number = {},
pages = {682 - 694},
year = {2015},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2015.02.025},
url = {http://www.sciencedirect.com/science/article/pii/S0747563215001235},
author = {Cyril Brom and David Levčík and Michaela Buchtová and Daniel Klement},
abstract = {Abstract The effectivity of learning by playing serious games is increasingly subject to research, but information about how these games should actually be used in classes is limited. In this explorative study with between-subject design (N = 166; high school students), we investigated the effectivity of playing two different micro-games in two different ways. After an expository lecture, either students played a game individually at computers (individual play), or the teacher played it, while showing it to the class on a projector and prompting the students on how to proceed with the game (collective play). Results indicated that the two modes of play were nearly comparable as concerns immediate and one month delayed learning gains, as well as subjective evaluation of educational experience. There were only two notable differences. First, immediate test scores for factual questions, but not transfer questions, for one of the games were higher for the individual play (medium effect size). Second, this difference was accompanied by a higher enjoyment in the better performing group (small to medium effect size). The results support the idea that collective play, which is easier to implement in schools, is a method that should be considered in educational design and future research. }}
@article{Rey20132022,
title = {The personalization effect in multimedia learning: The influence of dialect },
journal = {Computers in Human Behavior },
volume = {29},
number = {5},
pages = {2022 - 2028},
year = {2013},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2013.04.003},
url = {http://www.sciencedirect.com/science/article/pii/S0747563213001064},
author = {Günter Daniel Rey and Nadine Steib},
abstract = {Abstract The personalization effect states that through addressing a learner personally or formulating multimedia instruction in a personal way the learning outcome is improved. This effect can be explained either with higher social presence, with stronger self-reference or with more familiarity of personal messages. Based on these explanations, using a regional dialect instead of standard language should also improve the learning outcome. Two hundred and ten Austrian pupils at a lower secondary school viewed a narrated animation concerning computer networks. The students were randomly assigned to one cell of a 2 (formal or personalized) × 2 (standard German or Austrian dialect) between-subjects factorial design. Results confirmed the personalization effect for retention and transfer performance, showing a stronger effect for transfer. This result is discussed as well as the partly significant findings for the factor speech and the significant interaction effect between personalization and speech on learners’ interest. }}
@article{Peng201636,
title = {Deep Boosting: Joint feature selection and analysis dictionary learning in hierarchy },
journal = {Neurocomputing },
volume = {178},
number = {},
pages = {36 - 45},
year = {2016},
note = {Smart Computing for Large Scale Visual Data Sensing and ProcessingSelected papers from the 2014 International Conference on Smart Computing (SMARTCOMP 2014) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.116},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215016161},
author = {Zhanglin Peng and Ya Li and Zhaoquan Cai and Liang Lin},abstract = {Abstract This work investigates how the traditional image classification pipelines can be extended into a deep architecture, inspired by recent successes of deep neural networks. We propose a deep boosting framework based on layer-by-layer joint feature boosting and dictionary learning. In each layer, we construct a dictionary of filters by combining the filters from the lower layer, and iteratively optimize the image representation with a joint discriminative-generative formulation, i.e. minimization of empirical classification error plus regularization of analysis image generation over training images. For optimization, we perform two iterating steps: (i) to minimize the classification error, select the most discriminative features using the gentle adaboost algorithm; (ii) according to the feature selection, update the filters to minimize the regularization on analysis image representation using the gradient descent method. Once the optimization is converged, we learn the higher layer representation in the same way. Our model delivers several distinct advantages. First, our layer-wise optimization provides the potential to build very deep architectures. Second, the generated image representation is compact and meaningful by jointly considering image classification and generation. In several visual recognition tasks, our framework outperforms existing state-of-the-art approaches. }}
@article{Zhou2015298,
title = {Cross-domain sentiment classification via topical correspondence transfer },
journal = {Neurocomputing },
volume = {159},
number = {},
pages = {298 - 305},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.12.006},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214016701},
author = {Guangyou Zhou and Yin Zhou and Xiyue Guo and Xinhui Tu and Tingting He},



abstract = {Abstract Sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of user generated sentiment data (e.g., reviews, blogs). In real applications, these users generated sentiment data can span so many different domains that it is difficult to manually label training data for all of them. In this article, we develop a general solution to cross-domain sentiment classification when we do not have any labeled data in a target domain but have some labeled data in a source domain. To bridge the gap between domains, we propose a novel algorithm, called topical correspondence transfer (TCT). This is achieved by learning the domain-specific information from different domains into unified topics, with the help of shared topics across all domains. In this way, the topical correspondences behind the shared topics can be used as a bridge to reduce the gap between domains. We conduct experiments on a benchmark composed of reviews of 4 types of Amazon products. Experimental results show that our proposed TCT significantly outperforms the baseline method, and achieves an accuracy which is competitive with the state-of-the-art methods for cross-domain sentiment classification. }}
@article{Zheng201527,
title = {Detecting spammers on social networks },
journal = {Neurocomputing },
volume = {159},
number = {},
pages = {27 - 34},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.02.047},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215002106},
author = {Xianghan Zheng and Zhipeng Zeng and Zheyi Chen and Yuanlong Yu and Chunming Rong},abstract = {Abstract Social network has become a very popular way for internet users to communicate and interact online. Users spend plenty of time on famous social networks (e.g., Facebook, Twitter, Sina Weibo, etc.), reading news, discussing events and posting messages. Unfortunately, this popularity also attracts a significant amount of spammers who continuously expose malicious behavior (e.g., post messages containing commercial URLs, following a larger amount of users, etc.), leading to great misunderstanding and inconvenience on users׳ social activities. In this paper, a supervised machine learning based solution is proposed for an effective spammer detection. The main procedure of the work is: first, collect a dataset from Sina Weibo including 30,116 users and more than 16 million messages. Then, construct a labeled dataset of users and manually classify users into spammers and non-spammers. Afterwards, extract a set of feature from message content and users׳ social behavior, and apply into SVM (Support Vector Machines) based spammer detection algorithm. The experiment shows that the proposed solution is capable to provide excellent performance with true positive rate of spammers and non-spammers reaching 99.1% and 99.9% respectively. }}
@article{Tempelaar2015157,
title = {In search for the most informative data for feedback generation: Learning analytics in a data-rich context },
journal = {Computers in Human Behavior },
volume = {47},
number = {},
pages = {157 - 167},
year = {2015},
note = {Learning Analytics, Educational Data Mining and data-driven Educational Decision Making },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2014.05.038},
url = {http://www.sciencedirect.com/science/article/pii/S0747563214003240},
author = {Dirk T. Tempelaar and Bart Rienties and Bas Giesbers},
abstract = {Abstract Learning analytics seek to enhance the learning processes through systematic measurements of learning related data and to provide informative feedback to learners and teachers. Track data from learning management systems (LMS) constitute a main data source for learning analytics. This empirical contribution provides an application of Buckingham Shum and Deakin Crick’s theoretical framework of dispositional learning analytics: an infrastructure that combines learning dispositions data with data extracted from computer-assisted, formative assessments and LMSs. In a large introductory quantitative methods module, 922 students were enrolled in a module based on the principles of blended learning, combining face-to-face problem-based learning sessions with e-tutorials. We investigated the predictive power of learning dispositions, outcomes of continuous formative assessments and other system generated data in modelling student performance of and their potential to generate informative feedback. Using a dynamic, longitudinal perspective, computer-assisted formative assessments seem to be the best predictor for detecting underperforming students and academic performance, while basic LMS data did not substantially predict learning. If timely feedback is crucial, both use-intensity related track data from e-tutorial systems, and learning dispositions, are valuable sources for feedback generation. }}
@article{Ma201583,
title = {Two dimensional hashing for visual tracking },
journal = {Computer Vision and Image Understanding },
volume = {135},
number = {},
pages = {83 - 94},
year = {2015},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2015.01.003},
url = {http://www.sciencedirect.com/science/article/pii/S107731421500017X},
author = {Chao Ma and Chuancai Liu},abstract = {Abstract Appearance model is a key part of tracking algorithms. To attain robustness, many complex appearance models are proposed to capture discriminative information of object. However, such models are difficult to maintain accurately and efficiently. In this paper, we observe that hashing techniques can be used to represent object by compact binary code which is efficient for processing. However, during tracking, online updating hash functions is still inefficient with large number of samples. To deal with this bottleneck, a novel hashing method called two dimensional hashing is proposed. In our tracker, samples and templates are hashed to binary matrices, and the hamming distance is used to measure confidence of candidate samples. In addition, the designed incremental learning model is applied to update hash functions for both adapting situation change and saving training time. Experiments on our tracker and other eight state-of-the-art trackers demonstrate that the proposed algorithm is more robust in dealing with various types of scenarios. }}
@article{Vajda201523,
title = {Semi-automatic ground truth generation using unsupervised clustering and limited manual labeling: Application to handwritten character recognition },
journal = {Pattern Recognition Letters },
volume = {58},
number = {},
pages = {23 - 28},
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.02.001},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515000380},
author = {Szilárd Vajda and Yves Rangoni and Hubert Cecotti},abstract = {Abstract For training supervised classifiers to recognize different patterns, large data collections with accurate labels are necessary. In this paper, we propose a generic, semi-automatic labeling technique for large handwritten character collections. In order to speed up the creation of a large scale ground truth, the method combines unsupervised clustering and minimal expert knowledge. To exploit the potential discriminant complementarities across features, each character is projected into five different feature spaces. After clustering the images in each feature space, the human expert labels the cluster centers. Each data point inherits the label of its cluster’s center. A majority (or unanimity) vote decides the label of each character image. The amount of human involvement (labeling) is strictly controlled by the number of clusters – produced by the chosen clustering approach. To test the efficiency of the proposed approach, we have compared, and evaluated three state-of-the art clustering methods (k-means, self-organizing maps, and growing neural gas) on the MNIST digit data set, and a Lampung Indonesian character data set, respectively. Considering a k-nn classifier, we show that labeling manually only 1.3% (MNIST), and 3.2% (Lampung) of the training data, provides the same range of performance than a completely labeled data set would. }}
@article{Gough19971117,
title = {Associative List Memory },
journal = {Neural Networks },
volume = {10},
number = {6},
pages = {1117 - 1131},
year = {1997},
note = {},
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/S0893-6080(97)00029-4},
url = {http://www.sciencedirect.com/science/article/pii/S0893608097000294},
author = {M.Paul Gough},


abstract = {This paper introduces an Associative List Memory (ALM) that has high recall fidelity with low memory and low processing requirements. This permits a simple implementation in software on a personal computer or space instrument microprocessor. Associative List Memory has a performance comparable with Sparse Distributed Memory (SDM) but differs from SDM in that convergence occurs during learning, rather than on recall, and in that the memory is in the form of a dynamic list rather than static randomly distributed locations. Associative List Memory is suitable for unsupervised finding of classes of phenomena in large databases. In particular, all of the class exemplars deduced can be easily accessed at any time to provide a summary of current database knowledge, being essentially the contents of the list. Examples are given where patterns of 1000 bits length with &gt; 30% noise can be learned unsupervised to deduce the original pattern's noise free. A second pass through the data in recall mode can be used to assign to each input the appropriate original pattern, effectively removing all noise from the input data. At large input bit sizes the recall fidelity approaches closely to the maximum possible value. Associative List Memory compares well in recall fidelity with SDM and other associative memories. Its processing times on a personal computer are found to be practical for database applications. Implemented within a space instrument processor, ALM would greatly reduce downlink data transmission rates. © 1997 Elsevier Science Ltd. }}
@article{Fu2016336,
title = {Robust manifold-preserving diffusion-based saliency detection by adaptive weight construction },
journal = {Neurocomputing },
volume = {175, Part A},
number = {},
pages = {336 - 347},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.10.066},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215015258},
author = {Keren Fu and Irene Y.H. Gu and Chen Gong and Jie Yang},abstract = {Abstract Graph-based diffusion techniques have drawn much interest lately for salient object detection. The diffusion performance is heavily dependent on the edge weights in graph representing the similarity between nodes, and are usually set through manually tuning. To improve the diffusion performance, this paper proposes a robust diffusion scheme, referred to as manifold-preserving diffusion (MPD), that is built jointly on two assumptions for preserving the manifold used in saliency detection. The smoothness assumption reflects the conditional random field (CRF) property and the related penalty term enforces similar saliency on similar graph neighbors. The penalty term related to the local reconstruction assumption enforces a local linear mapping from the feature space to saliency values. Graph edge weights in the above two penalties in the proposed MPD method are determined adaptively by minimizing local reconstruction errors in feature space. This enables a better adaption of diffusion on different images. The final diffusion process is then formulated as a regularized optimization problem, taking into account of initial seeds, manifold smoothness and local reconstruction. Consequently, when applied to saliency diffusion, MPD provides a higher performance upper bound than some existing diffusion methods such as manifold ranking. By utilizing MPD, we further introduce a two-stage saliency detection scheme, referred to as manifold-preserving diffusion-based saliency (MPDS), where boundary prior, Harris convex hull, and foci convex hull are employed for deriving initial seeds and a coarse map for MPD. Experiments were conducted on five benchmark datasets and compared with eight existing methods. Our results show that the proposed method is robust in terms of consistently achieving the highest weighted F-measure and lowest mean absolute error, meanwhile maintaining comparable precision–recall curves. Salient objects in different background can be uniformly highlighted in the output final saliency maps. }}
@article{Goodfellow199453,
title = {Design principles for computer-aided vocabulary learning },
journal = {Computers & Education },
volume = {23},
number = {1–2},
pages = {53 - 62},
year = {1994},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/0360-1315(94)90032-9},
url = {http://www.sciencedirect.com/science/article/pii/0360131594900329},
author = {Robin Goodfellow}}
@article{Peng2016265,
title = {Discriminative manifold extreme learning machine and applications to image and EEG signal classification },
journal = {Neurocomputing },
volume = {174, Part A},
number = {},
pages = {265 - 277},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.03.118},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215011704},
author = {Yong Peng and Bao-Liang Lu},

abstract = {Abstract Extreme learning machine (ELM) uses a non-iterative method to train single-hidden-layer feed-forward networks (SLFNs), which has been proven to be an efficient and effective learning model for both classification and regression. The main advantage of ELM lies in that the input weights as well as the hidden layer biases can be randomly generated, which contributes to the analytical solution of output weights. In this paper, we propose a discriminative manifold ELM (DMELM) by simultaneously considering the discriminative information and geometric structure of data; specifically, we exploit the discriminative information in the local neighborhood around each data point. To this end, a graph regularizer based on a newly designed graph Laplacian to characterize both properties is formulated and incorporated into the ELM objective. In DMELM, the output weights can also be obtained in analytical form. Extensive experiments are conducted on image and EEG signal classification to evaluate the effectiveness of DMELM. The results show that DMELM consistently achieves better performance than original ELM and yields promising results in comparison with several state-of-the-art algorithms, which suggests that both the discriminative as well as manifold information are beneficial to classification. }}
@article{Liu2016355,
title = {Describing and learning of related parts based on latent structural model in big data },
journal = {Neurocomputing },
volume = {173, Part 2},
number = {},
pages = {355 - 363},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.12.120},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215012655},
author = {Lei Liu and Xiao Bai and Huigang Zhang and Jun Zhou and Wenzhong Tang},abstract = {Abstract In this paper, we propose a novel latent structural model for big data image recognition. It addresses the problem that large amount of labeled training samples are needed in traditional structural models. This method first builds an initial structural model by using only one labeled image. After pooling unlabeled samples into the initial model, an incremental learning process is used to find more candidate parts and to update the model. The appearance features of the parts are described by multiple kernel learning method that assembles more information of the parts, such as color, edge, and texture. Therefore, the proposed model considers not only independent components but also their inherent spatial and appearance relationships. Finally, the updated model is applied to recognition tasks. Experiments show that this method is effective in handling big data problems and has achieved better performance than several state-of-the-art methods. }}
@article{Ponti2016385,
title = {Image quantization as a dimensionality reduction procedure in color and texture feature extraction },
journal = {Neurocomputing },
volume = {173, Part 2},
number = {},
pages = {385 - 396},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.04.114},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215012771},
author = {Moacir Ponti and Tiago S. Nazaré and Gabriela S. Thumé},



abstract = {Abstract The image-based visual recognition pipeline includes a step that converts color images into images with a single channel, obtaining a color-quantized image that can be processed by feature extraction methods. In this paper we explore this step in order to produce compact features that can be used in retrieval and classification systems. We show that different quantization methods produce very different results in terms of accuracy. While compared with more complex methods, this procedure allows the feature extraction in order to achieve a significant dimensionality reduction, while preserving or improving system accuracy. The results indicate that quantization simplify images before feature extraction and dimensionality reduction, producing more compact vectors and reducing system complexity. }}
@article{Yang20161310,
title = {Dynamic texture recognition by aggregating spatial and temporal features via ensemble SVMs },
journal = {Neurocomputing },
volume = {173, Part 3},
number = {},
pages = {1310 - 1321},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.09.004},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215013119},
author = {Feng Yang and Gui-Song Xia and Gang Liu and Liangpei Zhang and Xin Huang},

abstract = {Abstract A dynamic texture (DT) refers to a sequence of images that exhibit spatial and temporal regularities. The modeling of DTs plays an important role in many video-related vision tasks, where the main difficulty lies in fact how to simultaneously depict the spatial and temporal aspects of DTs. While unlike the modeling of DTs, tremendous achievements have been recently reported on static texture modeling. This paper addresses the problem of dynamic texture recognition by aggregating spatial and temporal texture features via an ensemble SVM scheme, and bypassing the difficulties of simultaneously spatio-temporal description of DTs. More precisely, firstly, by considering a 3-dimensional DT video as a stack 2-dimensional static textures, we exploit the spatial texture features of single frame to combine different aspects of spatial structures, followed by randomly selecting several frames of the DT video in the time augmentation process. Secondly, in order to incorporate temporal information, the naive linear dynamic system (LDS) model is used to extract dynamics of DTs in temporal domain. Finally, we aggregate these spatial and temporal cues via an ensemble SVM architecture. We have experimented not only on several common dynamic texture datasets, but also on two challenging dynamic scene datasets. The results show that the proposed scheme achieves the state-of-the-art performances on the recognition of dynamic textures and dynamic scenes. Moreover, our approach offers a simple and general way to aggregate any spatial and temporal features into the task of dynamic texture recognition. }}
@article{Robertson2012385,
title = {Making games in the classroom: Benefits and gender concerns },
journal = {Computers & Education },
volume = {59},
number = {2},
pages = {385 - 398},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.12.020},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511003368},
author = {Judy Robertson},abstract = {This paper argues that making computer games as part of a classroom project can develop a range of new media storytelling, visual design and audience awareness skills. This claim is supported by data from the evaluation of a six week game making project in a state funded primary school in which 11–12 year old learners made their own computer games using software called Adventure Author. The paper reports on analysis of the games produced by the children and documents the range of new media storytelling skills used as well as examining how the pupils responded to peer reviews of their games. In light of concerns raised in the literature that girls may be disadvantaged by classroom games projects, it investigates whether there are gender differences in the game making skills displayed by the learners. The results of the study indicate that girls' games score more highly than boys', particularly on skills relating to storytelling. }}
@article{Chan201596,
title = {An exploration of students' lived experiences of using smartphones in diverse learning contexts using a hermeneutic phenomenological approach },
journal = {Computers & Education },
volume = {82},
number = {},
pages = {96 - 106},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.11.001},
url = {http://www.sciencedirect.com/science/article/pii/S0360131514002486},
author = {Nee Nee Chan and Caroline Walker and Alan Gleaves},
abstract = {Abstract This study describes young people's experiences of using smartphones, by exploring what it means to acquire, possess, and create a purpose for these personal mobile devices within the complex and fluid contexts of formal and informal learning. Applying the principles and practices of hermeneutic phenomenology, this study's methods comprised the use of interviews and written reflective exercises. 12 youths ranging from 16 to 19 years old participated in 3 rounds of semi-structured interviews over a period of 6 months. The findings reveal that participants' smartphone appropriation is associated with self-identity and management of their image as it is perceived by salient others, including peers and teachers. Furthermore, the participants' smartphone use is dependant upon their perception of learning-value and subject to influences concerning the status of knowledge, from their peers, parents and the community at large. The findings would suggest that the significance that young people attach to this form of mobile device use and the transferability of such behaviours and uses across spaces, time and dimensions in learning contexts is critically a function of particular smartphone adoption at a cultural rather than pedagogic level. Further research including rich qualitative studies is suggested to better theorize the phenomenon of smartphone use in learning contexts through engaging with cultural and social perspectives. }}
@article{Amin201384,
title = {One-shot Classification of 2-D Leaf Shapes Using Distributed Hierarchical Graph Neuron (DHGN) Scheme with k-NN Classifier },
journal = {Procedia Computer Science },
volume = {24},
number = {},
pages = {84 - 96},
year = {2013},
note = {17th Asia Pacific Symposium on Intelligent and Evolutionary Systems, IES2013 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2013.10.030},
url = {http://www.sciencedirect.com/science/article/pii/S1877050913011721},
author = {Anang Hudaya Muhamad Amin and Asad I. Khan},
abstract = {Abstract This article presents a scalable approach for classifying plant leaves using the 2-dimensional shape feature. The proposed approach integrates a distributed recognition scheme called Distributed Hierarchical Graph Neuron (DHGN) for pattern recognition and k-nearest neighbor (k-NN) for pattern classification. With increasing amount of leaves data that can be captured using existing image gathering and processing technology, the ability for any particular classification scheme to produce high recall accuracy while adapting to large-scale dataset and data features is very important. The approach presented in this paper implements a one-shot learning mechanism within a distributed processing infrastructure, enabling large-scale data to be classified efficiently. The experimental results obtained through a series of classification tests indicate that the proposed scheme is able to produce high recall accuracy and large number of perfect recalls for a given plant leaves dataset. Furthermore, the results also indicate that the recognition procedure within the DHGN distributed scheme incurs low computational complexity and minimum processing time. }}
@article{Manap2015141,
title = {Non-distortion-specific no-reference image quality assessment: A survey },
journal = {Information Sciences },
volume = {301},
number = {},
pages = {141 - 160},
year = {2015},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2014.12.055},
url = {http://www.sciencedirect.com/science/article/pii/S0020025515000079},
author = {Redzuan Abdul Manap and Ling Shao},

abstract = {Abstract Over the last two decades, there has been a surge of interest in the research of image quality assessment due to its wide applicability to many domains. In general, the aim of image quality assessment algorithms is to evaluate the perceptual quality of an image using an objective index which should be highly consistent with the human subjective index. The objective image quality assessment algorithms can be classified into three main classes: full-reference, reduced-reference, and no-reference. While full-reference and reduced-reference algorithms require full information or partial information of the reference image respectively, no reference information is required for no-reference algorithms. Consequently, a no-reference (or blind) image quality assessment algorithm is highly preferred in cases where the availability of any reference information is implausible. In this paper, a survey of the recent no-reference image quality algorithms, specifically for non-distortion-specific cases, is provided in the first half of this paper. Two major approaches in designing the non-distortion-specific no-reference algorithms, namely natural scene statistics-based and learning-based, are studied. In the second half of this paper, their performance and limitations are discussed before current research trends addressing the limitations are presented. Finally, possible future research directions are proposed towards the end of this paper. }}
@article{ScottGrabinger2009836,
title = {Discussion },
journal = {Computers in Human Behavior },
volume = {25},
number = {4},
pages = {836 - 840},
year = {2009},
note = {Including the Special Issue: The Use of Support Devices in Electronic Learning Environments },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2008.07.003},
url = {http://www.sciencedirect.com/science/article/pii/S0747563208001404},
author = {R. Scott Grabinger}}
@article{Bruce20161085,
title = {Sparse coding in early visual representation: From specific properties to general principles },
journal = {Neurocomputing },
volume = {171},
number = {},
pages = {1085 - 1098},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.070},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215010772},
author = {Neil D.B. Bruce and Shafin Rahman and Diana Carrier},abstract = {Abstract In this paper, we examine the problem of learning sparse representations of visual patterns in the context of artificial and biological vision systems. There are a myriad of strategies for sparse coding that often result in similar feature properties for the learned feature set. Typically this results in a bank of Gabor-like or edge filters that are sensitive to a range of distinct angular and radial frequencies. The theory and experimentation that is presented in this paper serves to provide a better understanding of a number of specific properties related to low-level feature learning. This includes close examination of the role of phase pairing in complex cells, the role of depth information and its relationship to variation of intensity and chroma, and deriving hybrid features that borrow from both analytic forms and statistical methods. Together, these specific examples provide context for more general discussion of effective strategies for feature learning. In particular, we make the case that imposing additional constraints on mechanisms for feature learning inspired by biological vision systems can be useful in guiding constrained optimization towards convergence, or specific desirable computational properties for representation of visual input in artificial vision systems. }}
@article{Yang2015281,
title = {Virtual CEOs: A blended approach to digital gaming for enhancing higher order thinking and academic achievement among vocational high school students },
journal = {Computers & Education },
volume = {81},
number = {},
pages = {281 - 295},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.10.004},
url = {http://www.sciencedirect.com/science/article/pii/S0360131514002243},
author = {Ya-Ting Carolyn Yang},
abstract = {Abstract The requirements of a contemporary workplace include the ability to think critically and creatively in order to solve problems and respond to changes in economic and social conditions. Unfortunately, vocational education often fails to prepare graduates for this environment due to limited resources, low student motivation, or the reliance upon outdated instructional strategies. The use of digital game-based learning (DGBL) for vocational education has been proposed, but has yet to be effectively implemented, particularly in terms of the promotion of higher order thinking skills (HOTS). Data from 68 eleventh grade vocational high school students were evaluated after a quasi-experimental, 27 week intervention. Pretest and posttest results were evaluated by MANCOVA and demonstrated that the experimental group (blended DGBL incorporating integrative HOTS activities) outperformed the comparison group (technology enhanced learning) in terms of creative thinking, critical thinking, problem solving, and academic achievement, with significant improvements on all four measures. While technology-enhanced learning was effective in promoting academic achievement and creative thinking, the DGBL condition was deemed most effective in providing an authentic context for developing employment-related skills and knowledge. Based on these results, a blended approach for DGBL, which incorporates instructor orchestration and scaffolding, provision of learning aids, and the use of collaborative learning, is recommended, particularly for vocational learners. This paper provides examples of a concrete model of DGBL instruction that was verified empirically as successful in significantly improving all three higher order thinking skills, including creative thinking, critical thinking, and problem solving. }}
@article{He201559,
title = {Implementing flexible hybrid instruction in an electrical engineering course: The best of three worlds? },
journal = {Computers & Education },
volume = {81},
number = {},
pages = {59 - 68},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.09.005},
url = {http://www.sciencedirect.com/science/article/pii/S036013151400205X},
author = {Wenliang He and Daniel Gajski and George Farkas and Mark Warschauer},
abstract = {Abstract This study explored a modified version of hybrid instruction, referred to as the flexible hybrid format, in a lower division electrical engineering course offered at a large public university. The objective of the study is to use longitudinal data to investigate the impact of class attendance, out-of-class study time, and motivation on student exam performance. Generalized least squares and fixed effects models were used in the analyses. It was found that class attendance was indispensable; it was associated with exam performance even when all essential course material was made available online and students generally rated the online instruction component to be of higher quality. The benefit of class attendance was then explained by the ICAP hypothesis and spaced learning practice and it was suggested that online education might be more effective in teaching relatively simpler contents. Out-of-class effort significantly predicated performance in previous weeks, but not in the final period. The harmful effect of cramming was cited to explain this phenomenon. Hence, by implication, time management might be an issue in a flexible hybrid environment. Finally, motivation was found to be a robust predicator of performance and its effect was the strongest when the course was at its most challenging stage. Besides, the relationship between motivation and exam performance was likely to be bidirectional, as higher motivation resulted in better performance, which in turn further boosted motivation. Based on current findings, directions for future research were also suggested to verify our claims and improve our implementation. }}
@article{Harskamp2007465,
title = {Does the modality principle for multimedia learning apply to science classrooms? },
journal = {Learning and Instruction },
volume = {17},
number = {5},
pages = {465 - 477},
year = {2007},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2007.09.010},
url = {http://www.sciencedirect.com/science/article/pii/S0959475207000916},
author = {Egbert G. Harskamp and Richard E. Mayer and Cor Suhre},abstract = {This study demonstrated that the modality principle applies to multimedia learning of regular science lessons in school settings. In the first field experiment, 27 Dutch secondary school students (age 16–17) received a self-paced, web-based multimedia lesson in biology. Students who received lessons containing illustrations and narration performed better on subsequent transfer tests than did students who received lessons containing illustrations and on-screen text. In the second field experiment, 55 Dutch secondary school students (age 16–17) received similar multimedia programs that allowed more self-pacing and required students to record the time to learn. The illustrations-and-narration group outperformed the illustrations-and-text group on subsequent transfer tests for students who required less time to learn but not for students who required more time to learn. The interaction of learning time spent with modality of presentation on post-test scores was studied. Implications for testing of the robustness of cognitive theory of multimedia learning are discussed. }}
@article{Saadé20121608,
title = {Critical thinking in E-learning environments },
journal = {Computers in Human Behavior },
volume = {28},
number = {5},
pages = {1608 - 1617},
year = {2012},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2012.03.025},
url = {http://www.sciencedirect.com/science/article/pii/S074756321200091X},
author = {Raafat George Saadé and Danielle Morin and Jennifer D.E. Thomas},abstract = {One of the primary aims of higher education in today’s information technology enabled classroom is to make students more active in the learning process. The intended outcome of this increased IT-facilitated student engagement is to foster important skills such as critical thinking used in both academia and workplace environments. Critical thinking (CT) skills entails the ability(ies) of mental processes of discernment, analysis and evaluation to achieve a logical understanding. Critical thinking in the classroom as well as in the workplace is a central theme; however, with the dramatic increase of IT usage the mechanisms by which critical thinking is fostered and used has changed. This article presents the work and results of critical thinking in a virtual learning environment. We therefore present a web-based course and we assess in which parts of the course, and to what extent, critical thinking was perceived to occur. The course contained two categories of learning modules namely resources and interactive components. Critical thinking was measured subjectively using the ART scale. Results indicate the significance of interactivity in what students perceived to be critical-thinking-oriented versus online material as a resource. Results and opportunities that virtual environments present to foster critical thinking are discussed. }}
@article{Chakraborty20161,
title = {A dense subgraph based algorithm for compact salient image region detection },
journal = {Computer Vision and Image Understanding },
volume = {145},
number = {},
pages = {1 - 14},
year = {2016},
note = {Light Field for Computer Vision },
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2015.12.005},
url = {http://www.sciencedirect.com/science/article/pii/S1077314215002696},
author = {Souradeep Chakraborty and Pabitra Mitra},

abstract = {Abstract We present an algorithm for graph based saliency computation that utilizes the underlying dense subgraphs in finding visually salient regions in an image. To compute the salient regions, the model first obtains a saliency map using random walks on a Markov chain. Next, k-dense subgraphs are detected to further enhance the salient regions in the image. Dense subgraphs convey more information about local graph structure than simple centrality measures. To generate the Markov chain, intensity and color features of an image in addition to region compactness is used. For evaluating the proposed model, we do extensive experiments on benchmark image data sets. The proposed method performs comparable to well-known algorithms in salient region detection. }}
@article{Bianco201615,
title = {CURL: Image Classification using co-training and Unsupervised Representation Learning },
journal = {Computer Vision and Image Understanding },
volume = {145},
number = {},
pages = {15 - 29},
year = {2016},
note = {Light Field for Computer Vision },
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2016.01.003},
url = {http://www.sciencedirect.com/science/article/pii/S1077314216000151},
author = {Simone Bianco and Gianluigi Ciocca and Claudio Cusano},abstract = {Abstract In this paper we propose a strategy for semi-supervised image classification that leverages unsupervised representation learning and co-training. The strategy, that is called CURL from co-training and unsupervised representation learning, iteratively builds two classifiers on two different views of the data. The two views correspond to different representations learned from both labeled and unlabeled data and differ in the fusion scheme used to combine the image features. To assess the performance of our proposal, we conducted several experiments on widely used data sets for scene and object recognition. We considered three scenarios (inductive, transductive and self-taught learning) that differ in the strategy followed to exploit the unlabeled data. As image features we considered a combination of GIST, PHOG, and LBP as well as features extracted from a Convolutional Neural Network. Moreover, two embodiments of CURL are investigated: one using Ensemble Projection as unsupervised representation learning coupled with Logistic Regression, and one based on LapSVM. The results show that CURL clearly outperforms other supervised and semi-supervised learning methods in the state of the art. }}
@article{Hudson20161,
title = {The effects of winning and losing on social presence in team-based digital games },
journal = {Computers in Human Behavior },
volume = {60},
number = {},
pages = {1 - 12},
year = {2016},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2016.02.001},
url = {http://www.sciencedirect.com/science/article/pii/S074756321630053X},
author = {Matthew Hudson and Paul Cairns},abstract = {Abstract Social play is an increasingly important constituent of the digital game experience. Though there is a growing understanding of how the social context influences the experience of playing, there is little known about how the experience of play influences the social experience. Specifically, it is not even known whether winning or losing affects a player's sense of social presence with their co-players. This paper provides the results of two studies aiming to explore this interaction. The first study is a lab-based study that looked at whether social presence varied in collocated teams playing team-based games depending on whether they won or lost. The second study is a user experience survey which measured how variables in the context of gameplay affected social presence across a number of team-based online games. The results of both studies show that when teams lose, the negative impact on social presence is greater within teams than between the competing teams. This has implications for how studies in this area should be analysed and also, through consideration of individual games, suggests that mechanisms in the games may lead to the reduced social presence. }}
@article{Mandal2016107,
title = {Performance evaluation of local descriptors and distance measures on benchmarks and first-person-view videos for face identification },
journal = {Neurocomputing },
volume = {184},
number = {},
pages = {107 - 116},
year = {2016},
note = {RoLoD: Robust Local Descriptors for Computer Vision 2014 },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.121},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215017713},
author = {Bappaditya Mandal and Zhikai Wang and Liyuan Li and Ashraf A. Kassim},abstract = {Abstract Face identification (FI) has made significant amount of progress in the last three decades. Its application is now moving towards wearable devices (like Google Glass and mobile devices) leading to the problem of FI on first-person-views (FPV) or ego-centric videos for scenarios like business networking, memory assistance, etc. In the existing literature, performance analysis of various image descriptors on FPV data is little known. In this paper, we evaluate six popular image descriptors: local binary patterns (LBP), scale invariant feature transform (SIFT), local phase quantization (LPQ), local intensity order pattern (LIOP), histogram of oriented gradients (HOG) and binarized statistical image features (BSIF) and ten different distance measures: Euclidean, Cosine, Chi square, Spearman, Cityblock, Minkowski, Correlation, Hamming, Jaccard and Chebychev with first nearest neighbor (1-NN) and support vector machines (SVM) as classifiers for FI task on both benchmark databases: FERET, AR, GT and FPV database collected using wearable devices like Google Glass (GG). Comparative analysis on these databases using various descriptors shows the superiority of BSIF with Cosine, Chi square and Cityblock distance measures using 1-NN as classifier over other descriptors and distance measures and even some of the current state-of-art benchmark database results. }}
@article{Maier201685,
title = {Effects of a computer-assisted formative assessment intervention based on multiple-tier diagnostic items and different feedback types },
journal = {Computers & Education },
volume = {95},
number = {},
pages = {85 - 98},
year = {2016},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.12.002},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515300919},
author = {Uwe Maier and Nicole Wolf and Christoph Randler},
abstract = {Abstract Computer-assisted formative assessments with multiple-tier items are a valid instrument for diagnosing students' conceptual understanding in learning domains with well-structured declarative knowledge (e.g. science education). However, it is unknown how feedback on multiple-tier items can improve learning success. Therefore, we assessed (1) predictors of students' perception and use of elaborated feedback, and (2) if feedback content (elaborated, verification, control) matters in explaining students' achievement in post- and retention tests. We developed computer-assisted formative tests for a teaching unit on evolutionary adaptations. Three treatment groups were employed with varying feedback content: Treatment 1 (T1) was an elaborated instruction-based feedback, T2 was a dichotomous verification feedback, and T3 (control) consisted of reading appropriate texts (no formative assessment and no feedback). Afterwards, T1 was separated into one subgroup with pupils who used the feedback thoroughly (T1A) and a subgroup that did not use the feedback (T1B). Ten secondary classrooms were used and 261 pupils participated in this study. Each student in each classroom was randomly assigned to one treatment group. Correlation and univariate regression analysis showed that perception and use of elaborated feedback were related to intrinsic motivation and self-reported grades. Multivariate analysis of covariance was applied to check treatment effects on post-tests and retention tests as dependent variables. Results revealed that verification feedback (T2) and elaborated feedback when students did use it (T1A) was superior to no feedback (T3) and elaborated feedback when students did not use it (T1B). Implications for the design of multiple-tier diagnostic assessments are discussed. }}
@article{Orús2016254,
title = {The effects of learner-generated videos for YouTube on learning outcomes and satisfaction },
journal = {Computers & Education },
volume = {95},
number = {},
pages = {254 - 269},
year = {2016},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2016.01.007},
url = {http://www.sciencedirect.com/science/article/pii/S0360131516300070},
author = {Carlos Orús and María José Barlés and Daniel Belanche and Luis Casaló and Elena Fraj and Raquel Gurrea},abstract = {Abstract This paper presents the results of an educational innovation project based on learner-generated videos. The videos were created for a YouTube channel specifically developed for a marketing course. Despite the potential of YouTube as a learning tool in education, its use as a learning instrument for learner-generated content is scarce. In this project, students could voluntarily participate in the creation of videos, which were then uploaded to the channel by the professors. At the end of the course, students completed a questionnaire assessing learning outcomes and satisfaction. The findings showed that active participation had a direct influence on the perceived acquisition of cross-curricular competencies and on academic performance. While participation did not directly increase subjective learning or satisfaction with the course, it had an indirect influence through cross-curricular competencies. This research contributes to previous literature by showing how learner-generated content and the use of YouTube as a teaching vehicle has a positive impact on students' learning outcomes and satisfaction. }}
@article{Hao201682,
title = {Exploring undergraduates' perspectives and flipped learning readiness in their flipped classrooms },
journal = {Computers in Human Behavior },
volume = {59},
number = {},
pages = {82 - 92},
year = {2016},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2016.01.032},
url = {http://www.sciencedirect.com/science/article/pii/S0747563216300401},
author = {Yungwei Hao},abstract = {Abstract This study surveyed 84 undergraduate students, majoring in education, in order to gather their perspectives regarding flipped classrooms and investigate their readiness levels for flipped learning. After the implementation of flipped learning for an entire semester, surveys were distributed in two flipped classrooms that were taught by the same instructor. Students showed particular preferences for the Bring Your Own Device and the Instant Response System features of the flipped classroom. Approximately 60% agreed with the idea of flipped classrooms, but only 39% agreed that the flipped classrooms met their learning needs. Their readiness levels for flipped learning were moderately above the average levels, and males or juniors (compared with freshmen), felt more prepared for flipped learning. In general, course grades, self-directed learning readiness, and group work preference can predict the different readiness dimensions. The findings may enhance educators' understanding in how to apply the flipped learning model in ways that are most beneficial for their own students. }}
@article{Dornaika2016,
title = {Building Detection from Orthophotos using a Machine Learning Approach: An Empirical Study on Image Segmentation and Descriptors },
journal = {Expert Systems with Applications },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2016.03.024},
url = {http://www.sciencedirect.com/science/article/pii/S0957417416301154},
author = {Fadi Dornaika and Abdelmalik Moujahid and Youssef El Merabet and Yassine Ruichek},

abstract = {Abstract Building detection from aerial images has many applications in fields like urban planning, real-estate management, and disaster relief. In the last two decades, a large variety of methods on automatic building detection have been proposed in the remote sensing literature. Many of these approaches make use of local features to classify each pixel or segment to an object label, therefore involving an extra step to fuse pixelwise decisions. This paper presents a generic framework that exploits recent advances in image segmentation and region descriptors extraction for the automatic and accurate detection of buildings on aerial orthophotos. The proposed solution is supervised in the sense that appearances of buildings are learnt from examples. For the first time in the context of building detection, we use the matrix covariance descriptor, which proves to be very informative and compact. Moreover, we introduce a principled evaluation that allows selecting the best pair segmentation algorithm-region descriptor for the task of building detection. Finally, we provide a performance evaluation at pixel level using different classifiers. This evaluation is conducted over 200 buildings using different segmentation algorithms and descriptors. The performance analysis quantifies the quality of both the image segmentation and the descriptor used. The proposed approach presents several advantages in terms of scalability, suitability and simplicity with respect to the existing methods. Furthermore, the proposed scheme (detection chain and evaluation) can be deployed for detecting multiple object categories that are present in images and can be used by intelligent systems requiring scene perception and parsing such as intelligent unmanned aerial vehicle navigation and automatic 3D city modeling. }}
@article{Hrasko2015990,
title = {Time Series Prediction Using Restricted Boltzmann Machines and Backpropagation },
journal = {Procedia Computer Science },
volume = {55},
number = {},
pages = {990 - 999},
year = {2015},
note = {3rd International Conference on Information Technology and Quantitative Management, ITQM 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.104},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915015793},
author = {Rafael Hrasko and André G.C. Pacheco and Renato A. Krohling},abstract = {Abstract Time series prediction appear in many real-world problems, e.g., financial market, signal processing, weather forecasting among others. The underlying models and time series data of those problems are generally complex in a way that reasonable accurate estimation cannot be easily achieved, thus requiring more advanced techniques. Statistical models are the classical approaches for tackling this problem. Many works extended different architectures of Artificial neural networks to work with time series prediction, such as Feedforward, Boltzmann Machines and Deep Belief Network. A Deep Belief Network based on hybridization between Gaussian-Bernoulli Restricted Boltzmann Machine and the Backpropagation algorithm is presented. The hybrid algorithm is tested on three time series databases showing promising results. }}
@article{Vineyard2015298,
title = {MapReduce SVM Game },
journal = {Procedia Computer Science },
volume = {53},
number = {},
pages = {298 - 307},
year = {2015},
note = {INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.307},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915018104},
author = {Craig M. Vineyard and Stephen J. Verzi and Conrad D. James and James B. Aimone and Gregory L. Heileman},abstract = {Abstract Despite technological advances making computing devices faster, smaller, and more prevalent in today's age, data generation and collection has outpaced data processing capabilities. Simply having more compute platforms does not provide a means of addressing challenging problems in the big data era. Rather, alternative processing approaches are needed and the application of machine learning to big data is hugely important. The MapReduce programming paradigm is an alternative to conventional supercomputing approaches, and requires less stringent data passing constrained problem decompositions. Rather, MapReduce relies upon defining a means of partitioning the desired problem so that subsets may be computed independently and recom- bined to yield the net desired result. However, not all machine learning algorithms are amenable to such an approach. Game-theoretic algorithms are often innately distributed, consisting of local interactions between players without requiring a central authority and are iterative by nature rather than requiring extensive retraining. Effectively, a game-theoretic approach to machine learning is well suited for the MapReduce paradigm and provides a novel, alternative new perspective to addressing the big data problem. In this paper we present a variant of our Support Vector Machine (SVM) Game classifier which may be used in a distributed manner, and show an illustrative example of applying this algorithm. }}
@article{Bai2015391,
title = {Generic Object Recognition with Local Receptive Fields Based Extreme Learning Machine },
journal = {Procedia Computer Science },
volume = {53},
number = {},
pages = {391 - 399},
year = {2015},
note = {INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.316},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915018190},
author = {Zuo Bai and Liyanaarachchi Lekamalage Chamara Kasun and Guang-Bin Huang},



abstract = {Abstract Generic object recognition is to classify the object to a generic category. Intra-class variabilities cause big troubles for this task. Traditional methods involve plenty of pre-processing steps, like model construction, feature extraction, etc. Moreover, these methods are only effective for some specific dataset. In this paper, we propose to use local receptive fields based extreme learning machine (ELM-LRF) as a general framework for object recognition. It is operated directly on the raw images and thus suitable for all different datasets. Additionally, the architecture is simple and only requires few computations, as most connection weights are randomly generated. Comparing to state-of-the-art results on NORB, ETH-80 and COIL datasets, it is on par with the best one on ETH-80 and sets the new records for NORB and COIL. }}
@article{Gunawan201564,
title = {Visual Tracking for Abrupt Motions of Human Sperm Using Smoothing Stochastic Approximate Monte Carlo },
journal = {Procedia Computer Science },
volume = {59},
number = {},
pages = {64 - 72},
year = {2015},
note = {International Conference on Computer Science and Computational Intelligence (ICCSCI 2015) },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.338},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915018670},
author = {Alexander A.S. Gunawan and Aniati Murni Arymurthy},

abstract = {Abstract Characteristic of sperm movement or sperm motility is one of important quality of sperm. Computer-aided Sperm Analysis (CASA) systems have attempted to give more accurate information about sperm motility. For collecting a single good sperm in Intracytoplasmic Sperm Injection (ICSI) procedures, achieving correct sperm trajectory is necessary. On the other hand, visual tracking of a sperm is a challenging issue because: (i) sperms have similar size and shape, (ii) a good sperm moves fast and has unpredictable motions. Furthermore, our sperm videos were taken by regular cameras which have low frame rate (about 20 fps), which cause the sperm-motion more abrupt. To address this problem, we propose searching driven stochastic sampling framework for visual tracking of abrupt motions. In here, searching algorithm will give promising regions of the target, and thus can replace the role of transition model in tracking system. For searching, we employ Coherency Sensitive Hashing (CSH) in a window to constrain search space in each frame, called as Search Window. And then for stochastic sampling framework, we adopt Smoothing Stochastic Approximate Monte Carlo (SSAMC) to specifically finding the target. The experimental results on human-sperm sequences show that: (i) comparing to our previous tracker which use geometric transition dynamic model, the proposed tracker can handle abrupt motions robustly, (ii) by using appropriate Search Window, the tracker can localize the sperm target and restrict observation of other similar sperms. }}
@article{Cunha2015425,
title = {Health Twitter Big Bata Management with Hadoop Framework },
journal = {Procedia Computer Science },
volume = {64},
number = {},
pages = {425 - 431},
year = {2015},
note = {Conference on ENTERprise Information Systems/International Conference on Project MANagement/Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN / HCist 2015 October 7-9, 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.08.536},
url = {http://www.sciencedirect.com/science/article/pii/S187705091502671X},
author = {João Cunha and Catarina Silva and Mário Antunes},
abstract = {Abstract Social media advancements and the rapid increase in volume and complexity of data generated by Internet services are becoming challenging not only technologically, but also in terms of application areas. Performance and availability of data processing are critical factors that need to be evaluated since conventional data processing mechanisms may not provide adequate support. Apache Hadoop with Mahout is a framework to storage and process data at large-scale, including different tools to distribute processing. It has been considered an effective tool currently used by both small and large businesses and corporations, like Google and Facebook, but also public and private healthcare institutions. Given its recent emergence and the increasing complexity of the associated technological issues, a variety of holistic framework solutions have been put forward for each specific application. In this work, we propose a generic functional architecture with Apache Hadoop framework and Mahout for handling, storing and analyzing big data that can be used in different scenarios. To demonstrate its value, we will show its features, advantages and applications on health Twitter data. We show that big health social data can generate important information, valuable both for common users and practitioners. Preliminary results of data analysis on Twitter health data using Apache Hadoop demonstrate the potential of the combination of these technologies. }}
@article{tagkey2015iii,
title = {Contents },
journal = {Procedia Computer Science },
volume = {60},
number = {},
pages = {iii - ix},
year = {2015},
note = {Knowledge-Based and Intelligent Information &amp; Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/S1877-0509(15)02460-6},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915024606},
key = {tagkey2015iii}}
@article{Buessler2014258,
title = {Image receptive fields for artificial neural networks },
journal = {Neurocomputing },
volume = {144},
number = {},
pages = {258 - 270},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.04.045},
url = {http://www.sciencedirect.com/science/article/pii/S092523121400650X},
author = {Jean-Luc Buessler and Philippe Smagghe and Jean-Philippe Urban},

abstract = {Abstract This paper describes the structure of the Image Receptive Fields Neural Network (IRF-NN) introduced recently by our team. This structure extends simplified learning introduced by Extreme Learning Machine and Reservoir Computing techniques to the field of images. Neurons are organized in a single hidden layer feedforward network architecture with an original organization of the network׳s input weights. To represent color images efficiently, without prior feature extraction, the weight values linked to a neuron are determined by a 2-D Gaussian function. The activation of a neuron by an image presents the properties of a nonlinear localized receptive field, parameterized with a small number of degrees of freedom. A network composed of a large number of neurons, each associated with a randomly initialized and constant receptive field, induces a remarkable representation of the images. Supervised training determines only the output weights of the network. It is therefore extremely fast, without retropropagation or iterations, adapted to large sets of images. The network is easy to implement, presents excellent generalization performances for classification applications, and allows the detection of unknown inputs. The efficiency of this technique is illustrated with several benchmarks, photo and video datasets. }}
@article{Tang2015124,
title = {An efficient concept detection system via sparse ensemble learning },
journal = {Neurocomputing },
volume = {169},
number = {},
pages = {124 - 133},
year = {2015},
note = {Learning for Visual Semantic Understanding in Big DataESANN 2014Industrial Data Processing and AnalysisSelected papers from the 22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2014)Selected papers from the 11th World Congress on Intelligent Control and Automation (WCICA2014) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.09.100},
url = {http://www.sciencedirect.com/science/article/pii/S092523121500675X},
author = {Sheng Tang and Yong-Dong Zhang and Zuo-Xin Xu and Hao-Jie Li and Yan-Tao Zheng and Jin-Tao Li},
abstract = {Abstract In this paper, we present an efficient concept detection system based on a novel bag of words extraction method and sparse ensemble learning. The presented system can efficiently build the concept detectors upon large scale image dataset, and achieve real-time concept detection on unseen images with the state-of-the-arts accuracy. To do so, we first develop an efficient bag of visual words (BoW) construction method based on sparse non-negative matrix factorization (NMF) and GPU enabled SIFT feature extraction. We then develop a sparse ensemble learning method to build the detection model, which drastically reduces learning time in order of magnitude over traditional methods like Support Vector Machine. To overcome the difficulty of manual annotation of training dataset, we construct a large training set with both pseudo relevance feedback of negative samples and interactive feedback of positive samples. Experiments on TRECVID 2012 dataset and MIRFlickr-1M dataset show both efficiency and effectiveness of our system. }}
@article{Shi2015550,
title = {Person re-identification with multi-level adaptive correspondence models },
journal = {Neurocomputing },
volume = {168},
number = {},
pages = {550 - 559},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.05.072},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215007705},
author = {Shi-Chang Shi and Chun-Chao Guo and Jian-Huang Lai and Shi-Zhe Chen and Xiao-Jun Hu},
abstract = {Abstract In this work, we present a multi-level adaptive correspondence model for person re-identification. Coarse segmentation and single level representation carry poorly discriminative information for generating a signature of a target, whilst fine segmentation with a fixed matching fashion is hindered severely by misalignment of corresponding body parts. We address such a dilemma through a multi-level adaptive correspondence scheme. Our approach encodes a pedestrian based on horizontal stripes in multi-level to capture rich visual cues as well as implicit spatial structure. Then dynamic correspondence of stripes within an image pair is conducted. Considering that manually selected weights in the final fusion stage is not advisable, we employ RankSVM to seek a data-driven fusion solution. We demonstrate the effectiveness of our method on two public datasets and another new dataset built for single shot re-identification. Comparisons with state-of-the-art re-identification methods show the superior performance of our approach. }}
@article{Xu2015566,
title = {Adaptive weighted fusion: A novel fusion approach for image classification },
journal = {Neurocomputing },
volume = {168},
number = {},
pages = {566 - 574},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.05.070},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215007687},
author = {Yong Xu and Yuwu Lu},



abstract = {Abstract Score fusion is a very competent fusion approach and weighted score fusion is the most preferable score fusion approach. To automatically set proper weights is the most important key of weighted score fusion and it seems that there are no truly adaptive weighted fusion approaches at present. In this paper we design a perfect adaptive weighted fusion approach, which automatically determines optimal weights and no any manual setting is needed. Though the proposed approach is very simple and quite easy to implement, it can obtain better performance than previous state-of-the-art approaches. }}
@article{Kouskouridas20158123,
title = {What, Where and How? Introducing pose manifolds for industrial object manipulation },
journal = {Expert Systems with Applications },
volume = {42},
number = {21},
pages = {8123 - 8133},
year = {2015},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2015.06.039},
url = {http://www.sciencedirect.com/science/article/pii/S0957417415004418},
author = {R. Kouskouridas and A. Amanatiadis and S.A. Chatzichristofis and A. Gasteratos},abstract = {Abstract In this paper we propose a novel method for object grasping that aims to unify robot vision techniques for efficiently accomplishing the demanding task of autonomous object manipulation. Through ontological concepts, we establish three mutually complementary processes that lead to an integrated grasping system able to answer conjunctive queries such as What, Where and How? For each query, the appropriate module provides the necessary output based on ontological formalities. The What is handled by a state of the art object recognition framework. A novel 6 DoF object pose estimation technique, which entails a bunch-based architecture and a manifold modeling method, answers the Where. Last, How is addressed by an ontology-based semantic categorization enabling the sufficient mapping between visual stimuli and motor commands. }}
@article{Postareff2008109,
title = {Variation in teachers' descriptions of teaching: Broadening the understanding of teaching in higher education },
journal = {Learning and Instruction },
volume = {18},
number = {2},
pages = {109 - 120},
year = {2008},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2007.01.008},
url = {http://www.sciencedirect.com/science/article/pii/S0959475207000126},
author = {Liisa Postareff and Sari Lindblom-Ylänne},abstract = {In the present study 71 university teachers from several disciplines were interviewed in order to capture the variation in descriptions of teaching. Two broad categories of description were identified: the learning-focused and the content-focused approaches to teaching. The results showed that the relationship between the two approaches was complex and variation could be captured in detail only after considering the purpose of teaching. Within both of these categories 10 aspects of teaching were identified, which were further grouped into four broader ones, namely teaching process, learning environment, conception of learning, and pedagogical development. }}
@article{Gao2015170,
title = {Cross-pose face recognition based on multiple virtual views and alignment error },
journal = {Pattern Recognition Letters },
volume = {65},
number = {},
pages = {170 - 176},
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.07.018},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515002275},
author = {Yongbin Gao and Hyo Jong Lee},



abstract = {Abstract Although studied for decades, effective face recognition remains difficult to accomplish on account of occlusions and pose and illumination variations. Pose variance is a particular challenge in face recognition. Effective local descriptors have been proposed for frontal face recognition. When these descriptors are directly applied to cross-pose face recognition, the performance significantly decreases. To improve the descriptor performance for cross-pose face recognition, we propose a face recognition algorithm based on multiple virtual views and alignment error. First, warps between poses are learned using the Lucas–Kanade algorithm. Based on these warps, multiple virtual profile views are generated from a single frontal face, which enables non-frontal faces to be matched using the scale-invariant feature transform (SIFT) algorithm. Furthermore, warps indicate the correspondence between patches of two faces. A two-phase alignment error is proposed to obtain accurate warps, which contain pose alignment and individual alignment. Correlations between patches are considered to calculate the alignment error of two faces. Finally, a hybrid similarity between two faces is calculated; it combines the number of matched keypoints from SIFT and the alignment error. Experimental results show that our proposed method achieves better recognition accuracy than existing algorithms, even when the pose difference angle was greater than 30°. }}
@article{Pelillo20153,
title = {Pattern recognition between science and engineering: A red herring? },
journal = {Pattern Recognition Letters },
volume = {64},
number = {},
pages = {3 - 10},
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.06.030},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515002068},
author = {Marcello Pelillo and Teresa Scantamburlo and Viola Schiaffonati},abstract = {Abstract Pattern recognition has been plagued since its beginnings by the elusiveness of its very nature, permeated as it is by a scientific as well as an engineering outlook, and over the years a debate has taken place among scholars aimed at clarifying its role and function. In this paper, we would like to reopen the discussion around the nature of pattern recognition research in the light of some recent developments both in the philosophy of technology and in the philosophy of science. These suggest that we have to rethink the classical dichotomy between science and engineering as, at the conceptual level, the boundary between the two camps turns out to be more blurred than is commonly thought, and that they stand to each other in a kind of circular, symbiotic relationship. Our analysis will be complemented by some historical examples and by further reflections concerning the notion of progress in our field. }}
@article{Strauß2016,
title = {Regular expressions for decoding of neural network outputs },
journal = {Neural Networks },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2016.03.003},
url = {http://www.sciencedirect.com/science/article/pii/S0893608016000447},
author = {Tobias Strauß and Gundram Leifert and Tobias Grüning and Roger Labahn},abstract = {Abstract This article proposes a convenient tool for decoding the output of neural networks trained by Connectionist Temporal Classification (CTC) for handwritten text recognition. We use regular expressions to describe the complex structures expected in the writing. The corresponding finite automata are employed to build a decoder. We analyze theoretically which calculations are relevant and which can be avoided. A great speed-up results from an approximation. We conclude that the approximation most likely fails if the regular expression does not match the ground truth which is not harmful for many applications since the low probability will be even underestimated. The proposed decoder is very efficient compared to other decoding methods. The variety of applications reaches from information retrieval to full text recognition. We refer to applications where we integrated the proposed decoder successfully. }}
@article{Adams2014401,
title = {Using erroneous examples to improve mathematics learning with a web-based tutoring system },
journal = {Computers in Human Behavior },
volume = {36},
number = {},
pages = {401 - 411},
year = {2014},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2014.03.053},
url = {http://www.sciencedirect.com/science/article/pii/S0747563214001757},
author = {Deanne M. Adams and Bruce M. McLaren and Kelley Durkin and Richard E. Mayer and Bethany Rittle-Johnson and Seiji Isotani and Martin van Velsen},
abstract = {Abstract This study examines whether asking students to critique incorrect solutions to decimal problems based on common misconceptions can help them learn about decimals better than asking them to solve the same problems and receive feedback. In a web-based tutoring system, 208 middle school students either had to identify, explain, and correct errors made by a fictional student (erroneous examples group) or solve isomorphic versions of the problems with feedback (problem-solving group). Although the two groups did not differ significantly on an immediate posttest, students in the erroneous examples group performed significantly better on a delayed posttest administered one week later (d = .62). Students in the erroneous examples group also were more accurate at judging whether their posttest answers were correct (d = .49). Students in the problem-solving group reported higher satisfaction with the materials than those in the erroneous examples group, indicating that liking instructional materials does not equate to learning from them. Overall, practice in identifying, explaining, and correcting errors may help students process decimal problems at a deeper level, and thereby help them overcome misconceptions and build a lasting understanding of decimals. }}
@article{Wang201461,
title = {Image tag refinement by regularized latent Dirichlet allocation },
journal = {Computer Vision and Image Understanding },
volume = {124},
number = {},
pages = {61 - 70},
year = {2014},
note = {Large Scale Multimedia Semantic Indexing },
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2014.02.011},
url = {http://www.sciencedirect.com/science/article/pii/S107731421400037X},
author = {Jingdong Wang and Jiazhen Zhou and Hao Xu and Tao Mei and Xian-Sheng Hua and Shipeng Li},



abstract = {Abstract Tagging is nowadays the most prevalent and practical way to make images searchable. However, in reality many manually-assigned tags are irrelevant to image content and hence are not reliable for applications. A lot of recent efforts have been conducted to refine image tags. In this paper, we propose to do tag refinement from the angle of topic modeling and present a novel graphical model, regularized latent Dirichlet allocation (rLDA). In the proposed approach, tag similarity and tag relevance are jointly estimated in an iterative manner, so that they can benefit from each other, and the multi-wise relationships among tags are explored. Moreover, both the statistics of tags and visual affinities of images in the corpus are explored to help topic modeling. We also analyze the superiority of our approach from the deep structure perspective. The experiments on tag ranking and image retrieval demonstrate the advantages of the proposed method. }}
@article{Favier2014225,
title = {The effects of geography lessons with geospatial technologies on the development of high school students' relational thinking },
journal = {Computers & Education },
volume = {76},
number = {},
pages = {225 - 236},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.04.004},
url = {http://www.sciencedirect.com/science/article/pii/S036013151400089X},
author = {Tim T. Favier and Joop A. van der Schee},
abstract = {Abstract Geospatial technologies offer access to geospatial information via digital representations, such as digital maps, and tools for interaction with those representations. The question is whether geography lessons with geospatial technologies really contribute to the development of students' geospatial thinking, in particular geospatial relational thinking, as is suggested in the literature about geospatial technologies in secondary education. This paper reports about the outcomes of a quasi-experimental research project, in which a geography lesson series with geospatial technologies was compared with a conventional geography lesson series that had the same content. Although the lesson series covered only three lessons, the data showed that the lesson series with geospatial technologies contributed significantly more to the development of students' geospatial relational thinking than the conventional lesson series. The effect size was ‘medium large’. }}
@article{AramoImmonen20151154,
title = {Exploring co-learning behavior of conference participants with visual network analysis of Twitter data },
journal = {Computers in Human Behavior },
volume = {51, Part B},
number = {},
pages = {1154 - 1162},
year = {2015},
note = {Computing for Human Learning, Behaviour and Collaboration in the Social and Mobile Networks Era },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2015.02.033},
url = {http://www.sciencedirect.com/science/article/pii/S0747563215001375},
author = {Heli Aramo-Immonen and Jari Jussila and Jukka Huhtamäki},

abstract = {Abstract Knowledge management has acknowledged organizational learning as a key factor for creating competitive advantage for companies already from early 1990. However, the studies of co-learning in this connection are in their infancy. This article contributes to an emerging field of ‘smart data’ research on Twitter by presenting a case study of how community managers in Finland used this social media platform to construct a co-learning environment around an annually organized conference. In this empirical study we explore the co-learning behavior in project contexts especially by analyzing and visualizing co-learning behavior from conference participants Twitter data. }}
@article{Fernando201521,
title = {Location recognition over large time lags },
journal = {Computer Vision and Image Understanding },
volume = {139},
number = {},
pages = {21 - 28},
year = {2015},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2015.05.016},
url = {http://www.sciencedirect.com/science/article/pii/S107731421500137X},
author = {Basura Fernando and Tatiana Tommasi and Tinne Tuytelaars},



abstract = {Abstract Would it be possible to automatically associate ancient pictures to modern ones and create fancy cultural heritage city maps? We introduce here the task of recognizing the location depicted in an old photo given modern annotated images collected from the Internet. We present an extensive analysis on different features, looking for the most discriminative and most robust to the image variability induced by large time lags. Moreover, we show that the described task benefits from domain adaptation. }}
@article{Kabilan20121007,
title = {Assessing pre-service English language teachers’ learning using e-portfolios: Benefits, challenges and competencies gained },
journal = {Computers & Education },
volume = {58},
number = {4},
pages = {1007 - 1020},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.11.011},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511002922},
author = {Muhammad Kamarul Kabilan and Mahbub Ahsan Khan},
abstract = {Assessment in learning is always of interest to practitioners, academics and researchers, and is always evolving with new implications. Alternative forms of assessment such as e-portfolios have gained recognition in documenting students’ learning, as it is synchronous with both product and process. Vast amount of literature narrates the relative advantages of e-portfolios across disciplines, institutions, and applications. In Malaysia, such alternative assessment practices are less explored so far in teacher education. In this study, 55 pre-service TESOL teachers from Universiti Sains Malaysia (USM) are required to create and maintain a personal e-portfolio. The aim of the study is to ascertain the future teachers’ practices with e-portfolios in their learning and to determine if these practices lead to teaching competencies. In addition, the study also aims to identify the benefits and challenges of using an e-portfolio as a tool for learning and self-assessment. Findings indicate that participants are appreciative of e-portfolios, as their performance and achievements are traced over time. It is also found that e-portfolios function as a monitoring tool, which helps the teachers recognize their learning and identify their strengths and weaknesses. Challenges are also noted, which include validity and reliability, interrupted Internet connection, negative attitudes participants, time constraints, workload and ethical issues. In terms of teacher competencies, it is found that six competencies emerge from the teachers’ practices of e-portfolios – (1) developing understanding of an effective teacher’s role; (2) developing teaching approaches/activities; (3) improving linguistic abilities; (4) comprehending content knowledge; (5) gaining ICT skills and; (6) the realization of the need to change mindsets. }}
@article{Chen201153,
title = {Effects of matching teaching strategy to thinking style on learner’s quality of reflection in an online learning environment },
journal = {Computers & Education },
volume = {56},
number = {1},
pages = {53 - 64},
year = {2011},
note = {Serious Games },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.08.021},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510002496},
author = {Nian-Shing Chen and Kinshuk and Chun-Wang Wei and Chia-Chi Liu},
abstract = {Reflection plays an important role in improving learning performance. This study, therefore, attempted to explore whether learners’ reflection levels can be improved if teaching strategies are adapted to fit with learners’ thinking styles in an online learning environment. Three teaching strategies, namely constructive, guiding, and inductive, were designed to match with three thinking styles, namely legislative, executive, and judicial respectively. An online reflection learning system was subsequently developed to reflect this scenario. An experiment was then conducted where the learners were classified into fit or non-fit group in order to analyze whether there was a good fit between the teaching strategies designed by the teacher and the thinking styles of learners. A total of 223 graduate and undergraduate students participated in the experiment. The results revealed that the reflection levels of the fit group had outperformed the non-fit group. }}
@article{Lei20152567,
title = {Saliency-driven image classification method based on histogram mining and image score },
journal = {Pattern Recognition },
volume = {48},
number = {8},
pages = {2567 - 2580},
year = {2015},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.02.004},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315000527},
author = {Baiying Lei and Ee-Leng Tan and Siping Chen and Dong Ni and Tianfu Wang},
abstract = {Abstract Since most image classification tasks involve discriminative information (i.e., saliency), this paper proposes a new bag-of-phrase (BoP) approach to incorporate this information. Specifically, saliency map and local features are first extracted from edge-based dense descriptors. These features are represented by histogram and mined with discriminative learning technique. Image score calculated from the saliency map is also investigated to optimize a support vector machine (SVM) classifier. Both feature map and kernel trick methods are explored to enhance the accuracy of the SVM classifier. In addition, novel inter- and intra-class histogram normalization methods are investigated to further boost the performance of the proposed method. Experiments using several publicly available benchmark datasets demonstrate that the proposed method achieves promising classification accuracy and superior performance over state-of-the-art methods. }}
@article{tagkey1997iii,
title = {Content },
journal = {Learning and Instruction },
volume = {7},
number = {},
pages = {iii - vii},
year = {1997},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/S0959-4752(97)90000-1},
url = {http://www.sciencedirect.com/science/article/pii/S0959475297900001},
key = {tagkey1997iii}}
@article{Song2014198,
title = {The cognitive impact of interactive design features for learning complex materials in medical education },
journal = {Computers & Education },
volume = {71},
number = {},
pages = {198 - 205},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.09.017},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513002807},
author = {Hyuksoon S. Song and Martin Pusic and Michael W. Nick and Umut Sarpel and Jan L. Plass and Adina L. Kalet},
abstract = {Abstract To identify the most effective way for medical students to interact with a browser-based learning module on the symptoms and neurological underpinnings of stroke syndromes, this study manipulated the way in which subjects interacted with a graphical model of the brain and examined the impact of functional changes on learning outcomes. It was hypothesized that behavioral interactions that were behaviorally more engaging and which required deeper consideration of the model would result in heightened cognitive interaction and better learning than those whose manipulation required less deliberate behavioral and cognitive processing. One hundred forty four students were randomly assigned to four conditions whose model controls incorporated features that required different levels of behavioral and cognitive interaction: Movie (low behavioral/low cognitive, n = 40), Slider (high behavioral/low cognitive, n = 36), Click (low behavioral/high cognitive, n = 30), and Drag (high behavioral/high cognitive, n = 38). Analysis of Covariates (ANCOVA) showed that students who received the treatments associated with lower cognitive interactivity (Movie and Slider) performed better on a transfer task than those receiving the module associated with high cognitive interactivity (Click and Drag, partial eta squared = .03). In addition, the students in the high cognitive interactivity conditions spent significantly more time on the stroke locator activity than other conditions (partial eta squared = .36). The results suggest that interaction with controls that were tightly coupled with the model and whose manipulation required deliberate consideration of the model's features may have overtaxed subjects' cognitive resources. Cognitive effort that facilitated manipulation of content, though directed at the model, may have resulted in extraneous cognitive load, impeding subjects in recognizing the deeper, global relationships in the materials. Instructional designers must, therefore, keep in mind that the way in which functional affordances are integrated with the content can shape both behavioral and cognitive processing, and has significant cognitive load implications. }}
@article{So2010479,
title = {Designing collaborative knowledge building environments accessible to all learners: Impacts and design challenges },
journal = {Computers & Education },
volume = {54},
number = {2},
pages = {479 - 490},
year = {2010},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2009.08.031},
url = {http://www.sciencedirect.com/science/article/pii/S0360131509002395},
author = {Hyo-Jeong So and Lay Hoon Seah and Hwee Leng Toh-Heng},
abstract = {The present study attempted to investigate whether young learners who were new to knowledge building approaches could work towards advancing both individual and collective knowledge, and whether knowledge building could be beneficial to both high-achieving and low-achieving students. Findings reported in this paper are from one and a half-year design research for science learning in one primary school in Singapore. In this study, we closely examined the design and enactment of the Knowledge Building Community model in one class with high-achieving students and two classes with mixed-ability students. The research consists of two phases: Phase I Cultivating a collaborative knowledge building culture and Phase II Progressive Knowledge Building using Knowledge Forum. Data were collected from multiple sources, including knowledge assessment, conceptual understanding tasks, and the content analysis of Knowledge Forum postings. The results in Phase I show that while it is critical for students to monitor and build knowledge for their own understanding, they had difficulties developing such skills. In both phases, we found positive impacts on academic achievements showing improvement of student understanding in the course of reflective thinking and progressive inquiry. Overall, quantitative data suggest that the collaborative knowledge building environment was beneficial for both high-achieving and low-achieving students. We conclude by discussing some of challenges and issues in designing collaborative knowledge building environments for young learners with diverse abilities. }}
@article{Wang2015174,
title = {Adaptive road detection via context-aware label transfer },
journal = {Neurocomputing },
volume = {158},
number = {},
pages = {174 - 183},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.01.054},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215001010},
author = {Qi Wang and Jianwu Fang and Yuan Yuan},

abstract = {Abstract The vision ability is fundamentally important for a mobile robot. Many aspects have been investigated during the past few years, but there still remain questions to be answered. This work mainly focuses on the task of road detection, which is considered as the first step for a robot to become moveable. The proposed method combines the depth clue with traditional RGB information and is divided into three steps: depth recovery and superpixel generation, weakly supervised SVM classification and context-aware label transfer. The main contributions made in this paper are (1) Design a novel superpixel based context-aware descriptor by utilizing depth map. (2) Conduct label transfer in an efficient nearest neighbor search and a temporal MRF model. (3) Update the learned model adaptively with the changing scene. Experimental results on a publicly available dataset justify the effectiveness of the proposed method. }}
@article{O’Neil201423,
title = {Adding self-explanation prompts to an educational computer game },
journal = {Computers in Human Behavior },
volume = {30},
number = {},
pages = {23 - 28},
year = {2014},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2013.07.025},
url = {http://www.sciencedirect.com/science/article/pii/S074756321300263X},
author = {Harold F. O’Neil and Gregory K.W.K. Chung and Deirdre Kerr and Terry P. Vendlinski and Rebecca E. Buschang and Richard E. Mayer},abstract = {Abstract Proponents envision a role for computer games in improving student learning of academic material, including mathematics and science. Asking learners to engage in self-explanations during learning has been found to be an effective instructional method. In the present experiment, we examined the effects of adding a self-explanation prompt—asking players to answer one of three questions after completing each level of the game—within a children’s math game on addition of fractions. Middle-school participants played either a base version of the game (n = 57) or the base version with a self-explanation instructional feature (n = 57). Participants’ learning was measured by a fractions posttest and their learning processes measured via in-game measures of game progress and errors. When we separated the self-explanation condition into participants who used a focused self-explanation strategy versus those who did not, the focused participants had significantly fewer game level deaths, game level resets, and progressed significantly farther in the game, compared to the control group, than participants not using a focused self-explanation strategy. The major new contribution of this study is that self-explanation can help the process of playing educational games in some situations and hurt in others. In particular, the most effective self-explanation prompts were aimed at helping learners make connections between game terminology and mathematics terminology, whereas the least effective self-explanation prompts asked very simple or very abstract questions. }}
@article{Liu20141066,
title = {The Search Engine IQ Test based on the Internet IQ Evaluation Algorithm },
journal = {Procedia Computer Science },
volume = {31},
number = {},
pages = {1066 - 1073},
year = {2014},
note = {2nd International Conference on Information Technology and Quantitative Management, ITQM 2014 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2014.05.361},
url = {http://www.sciencedirect.com/science/article/pii/S1877050914005389},
author = {Feng Liu and Yong Shi},



abstract = {Abstract This paper initiates an innovative concept and basic measurements on testing the IQ (Intelligence Quotient) on Internet search engines. It first proposes the stipulation of 2014 Internet intelligence scale and designs an IQ test question bank to aim at the search engine. To show its applicability, the paper then carries out the IQ test on seven classic search engines, such as Google, Baidu, Sogou, Bing, Zhongsou, panguso, so, etc., compared with the results of the same IQ test on three groups of Children whose ages are 6, 12, 18. Based on the absolute IQ and relative IQ of ten testing objects, this paper finds that the IQ search engine of Internet is behind far away that of human being in the field of creative testing. }}
@article{Kim2016131,
title = {Weighted joint-based human behavior recognition algorithm using only depth information for low-cost intelligent video-surveillance system },
journal = {Expert Systems with Applications },
volume = {45},
number = {},
pages = {131 - 141},
year = {2016},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2015.09.035},
url = {http://www.sciencedirect.com/science/article/pii/S0957417415006648},
author = {Hanguen Kim and Sangwon Lee and Youngjae Kim and Serin Lee and Dongsung Lee and Jinsun Ju and Hyun Myung},abstract = {Abstract Recent advances in 3D depth sensors have created many opportunities for security, surveillance, and entertainment. The 3D depth sensors provide more powerful monitoring systems for dangerous situations irrespective of lighting conditions in buildings or production facilities. To robustly recognize emergency actions or hazardous situations of workers at a production facility, we present human joint estimation and behavior recognition algorithms that solely use depth information in this paper. To estimate human joints on a low cost computing platform, we propose a human joint estimation algorithm that integrates a geodesic graph and a support vector machine (SVM). The human feature points are extracted within a range of geodesic distance from a geodesic graph. The geodesic graph is used for optimizing the estimation result. The SVM-based human joint estimator uses randomly selected human features to reduce computation. Body parts that typically involve many motions are then estimated by the geodesic distance value. The proposed algorithm can work for any human without calibration, and thus the system can be used with any subject immediately even with a low cost computing platform. In the case of the behavior recognition algorithm, the algorithm should have a simple behavior registration process, and it also should be robust to environmental changes. To meet these goals, we propose a template matching-based behavior recognition algorithm. Our method creates a behavior template set that consists of weighted human joint data with scale and rotation invariant properties. A single behavior template consists of the joint information that is estimated per frame. Additionally, we propose adaptive template rejection and a sliding window filter to prevent misrecognition between similar behaviors. The human joint estimation and behavior recognition algorithms are evaluated individually through several experiments and the performance is proven through a comparison with other algorithms. The experimental results show that our method performs well and is applicable in real environments. }}
@article{Manivannan201612,
title = {An automated pattern recognition system for classifying indirect immunofluorescence images of HEp-2 cells and specimens },
journal = {Pattern Recognition },
volume = {51},
number = {},
pages = {12 - 26},
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.09.015},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315003465},
author = {Siyamalan Manivannan and Wenqi Li and Shazia Akbar and Ruixuan Wang and Jianguo Zhang and Stephen J. McKenna},

abstract = {Abstract Immunofluorescence antinuclear antibody tests are important for diagnosis and management of autoimmune conditions; a key step that would benefit from reliable automation is the recognition of subcellular patterns suggestive of different diseases. We present a system to recognize such patterns, at cellular and specimen levels, in images of HEp-2 cells. Ensembles of SVMs were trained to classify cells into six classes based on sparse encoding of texture features with cell pyramids, capturing spatial, multi-scale structure. A similar approach was used to classify specimens into seven classes. Software implementations were submitted to an international contest hosted by ICPR 2014 (Performance Evaluation of Indirect Immunofluorescence Image Analysis Systems). Mean class accuracies obtained on heldout test data sets were 87.1% and 88.5% for cell and specimen classification respectively. These were the highest achieved in the competition, suggesting that our methods are state-of-the-art. We provide detailed descriptions and extensive experiments with various features and encoding methods. }}
@article{Boyle2016178,
title = {An update to the systematic literature review of empirical evidence of the impacts and outcomes of computer games and serious games },
journal = {Computers & Education },
volume = {94},
number = {},
pages = {178 - 192},
year = {2016},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.11.003},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515300750},
author = {Elizabeth A. Boyle and Thomas Hainey and Thomas M. Connolly and Grant Gray and Jeffrey Earp and Michela Ott and Theodore Lim and Manuel Ninaus and Claudia Ribeiro and João Pereira},

abstract = {Abstract Continuing interest in digital games indicated that it would be useful to update Connolly et al.'s (2012) systematic literature review of empirical evidence about the positive impacts and outcomes of games. Since a large number of papers was identified in the period from 2009 to 2014, the current review focused on 143 papers that provided higher quality evidence about the positive outcomes of games. Connolly et al.'s multidimensional analysis of games and their outcomes provided a useful framework for organising the varied research in this area. The most frequently occurring outcome reported for games for learning was knowledge acquisition, while entertainment games addressed a broader range of affective, behaviour change, perceptual and cognitive and physiological outcomes. Games for learning were found across varied topics with STEM subjects and health the most popular. Future research on digital games would benefit from a systematic programme of experimental work, examining in detail which game features are most effective in promoting engagement and supporting learning. }}
@article{Guido2016264,
title = {A tutorial on signal energy and its applications },
journal = {Neurocomputing },
volume = {179},
number = {},
pages = {264 - 282},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.12.012},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215019281},
author = {Rodrigo Capobianco Guido},

abstract = {Abstract This tutorial, dedicated both to young professionals and students working with digital signal processing and pattern recognition, introduces three feature extraction approaches based on signal energy, characterising alternative and innovative ways for its use. The proposed theory, smoothly presented, is complemented with numerical examples, source-codes in C/C++ programming language, and applications in a diversity of computational problems, namely, neurophysiological signal processing, speech processing, and image processing. The lack of novelty in current energy-based approaches and the feasibility of a balance among creativity, simplicity, and accuracy constitutes the motivation for this text, which reveals how relevant the concept of signal energy may be, if properly employed. }}
@article{Navarrete2013320,
title = {Creative thinking in digital game design and development: A case study },
journal = {Computers & Education },
volume = {69},
number = {},
pages = {320 - 331},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.07.025},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513001929},
author = {Cesar C. Navarrete},
abstract = {Abstract In a case study on middle-school student educational game creation course in south central US state, the students' creative thinking process is investigated in order to understand perceptions of the digital design and programming involved in the game creation learning approach. Interviewing 12 students at with three different levels of game design experience, students in grade 6, 7 and 8, with 1, 2, and 3 years of game design experience respectively, findings suggest that students enjoyed the learning approach as satisfying and engaging, yet technologically challenging. The students experienced positive opportunities for engaging the creative thinking process in synthesizing social issue information for constructing their understanding through the creation of interactive, educational digital games. Findings suggest that the creative thinking process in student-centered game creation learning approach may provide learners a rich and enjoyable learning experience with the authentic technology use as well as provide for deep, insightful learning. }}
@article{Lawlor2010962,
title = {Using podcasts to support communication skills development: A case study for content format preferences among postgraduate research students },
journal = {Computers & Education },
volume = {54},
number = {4},
pages = {962 - 971},
year = {2010},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2009.09.031},
url = {http://www.sciencedirect.com/science/article/pii/S0360131509002747},
author = {Bob Lawlor and Roisin Donnelly},abstract = {The need for the integration of generic skills training into structured PhD programmes is widely accepted. However, effective integration of such training requires flexible delivery mechanisms which facilitate self-paced and independent learning. A video recording was made of an eminent speaker delivering a 1-h live presentation to a group of 15 first-year science and engineering PhD research students. The topic of the presentation was inter-disciplinary professional communication skills. Following the presentation, the video recording was post-processed into seven alternative podcast formats. These podcast formats included a typed transcription, a full audio recording, a full video recording, presentation slides with embedded speech etc. The choice of podcast formats was based on ease-of-production by a typical computer-literate academic and ease-of-use by a typical computer-literate student. At a subsequent session, the seven podcast formats were shown to the 15 students and a survey to assess their reactions to the various formats was carried out. The survey results (quantitative and qualitative) were analysed to provide useful insight into the student preferences in relation to podcast formats. The students expressed a clear preference for summary key-point slides with explanatory voice-over by the original speaker. }}
@article{Foroughi20153038,
title = {Robust people counting using sparse representation and random projection },
journal = {Pattern Recognition },
volume = {48},
number = {10},
pages = {3038 - 3052},
year = {2015},
note = {Discriminative Feature Learning from Big Data for Visual Recognition },
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.02.009},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315000692},
author = {Homa Foroughi and Nilanjan Ray and Hong Zhang},

abstract = {Abstract Estimating the number of people present in an image has many practical applications including visual surveillance and public resource management. Recently, regression-based methods for people counting have gained considerable importance, principally due to the capability of these methods to handle crowded scenes. However, the principal drawback of regression-based methods is to find an optimal set of features and a model, which is usually dependent on the crowd density. Encouraged by the recent success of sparse representation, here, we develop a robust and scalable people counting method. Sparse representation allows us to capture the hidden structure and semantic information in visual data and leads to faster processing algorithms. In order to reduce the complexity of solving l 1 - minimization problem, which resides at the heart of the sparse representation, a dimensionality reduction method based on random projection is employed. The sparse representation framework provides new insight that if sparsity in the classification problem is properly harnessed, feature extraction is no longer critical. So, in addition to several hand-crafted features, we exploit the features obtained from pre-trained deep Convolutional neural network and show these features perform competitively. Further, to render the proposed method user friendly, we employ a semi-supervised elastic net to automatically annotate unlabelled data with only a handful of user-labelled image frames. Our semi-supervised method exploits temporal continuity in videos. We use extensive evaluations on the crowd analysis benchmark datasets to demonstrate the effectiveness of our approach as well as its superiority over the state-of-the-art regression-based people counting methods, in terms of accuracy and time. }}
@article{Mazzolini2003237,
title = {Sage, guide or ghost? The effect of instructor intervention on student participation in online discussion forums },
journal = {Computers & Education },
volume = {40},
number = {3},
pages = {237 - 253},
year = {2003},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/S0360-1315(02)00129-X},
url = {http://www.sciencedirect.com/science/article/pii/S036013150200129X},
author = {Margaret Mazzolini and Sarah Maddison},abstract = {When facilitating asynchronous discussion forums, should online instructors be encouraged to take a prominent ‘sage on the stage' role, a more constructivist ‘guide on the side' role, or an ultra low profile as ‘the ghost in the wings'? There is no shortage of anecdotal advice on how to conduct discussion forums in online education, but there appears to be very little research available so far to back that advice up. In this study of an online astronomy program with approximately 200 participants, we investigated the way that the rate at which instructors post and how often those instructors initiate discussions correlate with several variables—student posting rates, lengths of discussion threads, and student survey responses concerning their educational experience. We found that the ways in which instructors post to forums can influence students' forum discussions and perceptions, but not always in expected ways. On average, frequent posting by instructors did not lead to more student postings, and the more the instructors posted, the shorter were the lengths of the discussions overall. On the other hand, while most students rated their educational experience highly, instructors who posted frequently were judged on average to be more enthusiastic and expert than those who did not. Clearly the number of student postings and the rate at which instructors participate are not simple indicators of the quality of forum discussions. We need to find more subtle measures of the effectiveness of asynchronous discussion forums for learning and teaching. }}
@article{Lee2013345,
title = {Investigating students' learning approaches, perceptions of online discussions, and students' online and academic performance },
journal = {Computers & Education },
volume = {68},
number = {},
pages = {345 - 352},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.05.019},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513001474},
author = {Silvia Wen-Yu Lee},abstract = {Abstract The main purpose of this study was to understand the relationships between students' approaches to learning, their perceptions of online discussions, students' contributions in asynchronous discussions, and their academic performance. Two sets of questionnaires were used for understanding students' approaches of learning and perceptions of online discussions. The online postings from seven weeks of discussions were coded into three major categories: Initiation, Elaborated Response (ER), and Response with Resources (RWR). The results showed, first, some aspects of students' perceptions influenced the numbers of ERs and RWRs. Secondly, students' contributions to Initiation messages and RWR significantly related to deep motivation and deep strategies; however, the numbers of these two types of messages were negatively correlated to surface strategies. Finally, cluster analysis revealed three distinct groups who scored significantly different in almost all aspects of approaches to learning and perceptions of online discussions. Students in the cluster who adopted deep approaches and scored highest in the perception scales outperformed students in the other two clusters, both in terms of the number of ER messages and academic performance. Pedagogical implications for teaching with online discussions are discussed in this study. }}
@article{Choi20131980,
title = {Development of a scale for fantasy state in digital games },
journal = {Computers in Human Behavior },
volume = {29},
number = {5},
pages = {1980 - 1986},
year = {2013},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2013.04.007},
url = {http://www.sciencedirect.com/science/article/pii/S0747563213001106},
author = {Beomkyu Choi and Jie Huang and Annie Jeffrey and Youngkyun Baek},
abstract = {Abstract Digital games appear to motivate players intrinsically. Of various game features, fantasy in particularly plays a crucial role in enhancing motivation and is a key factor in immersion in gameplay. As with its inherent value, fantasy also plays a vital role in distinguishing digital games itself from other media. Despite its significance, fantasy has received little attention, and this concept is still ambiguous to define with any certainty. This study thus aims to create a framework to explore a dimension of fantasy and to develop a scale to measure a state of fantasy in digital games. As a result, four factors were extracted, which were ‘identification’, ‘imagination’, ‘analogy’, and ‘satisfaction’, to account for fantasy state in digital gameplay. Based on these factors, a fantasy scale in digital games (FSDGs) included 16 items was developed. }}
@article{Ozcelik201312,
title = {The effect of uncertainty on learning in game-like environments },
journal = {Computers & Education },
volume = {67},
number = {},
pages = {12 - 20},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.02.009},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513000481},
author = {Erol Ozcelik and Nergiz Ercil Cagiltay and Nese Sahin Ozcelik},


abstract = {Considering the role of games for educational purposes, there has an increase in interest among educators in applying strategies used in popular games to create more engaging learning environments. Learning is more fun and appealing in digital educational games and, as a result, it may become more effective. However, few research studies have been conducted to establish principles based on empirical research for designing engaging and entertaining games so as to improve learning. One of the essential characteristics of games that has been unexplored in the literature is the concept of uncertainty. This study examines the effect of uncertainty on learning outcomes. In order to better understand this effect on learning, a game-like learning tool was developed to teach a database concept in higher education programs of software engineering. The tool is designed in two versions: one including uncertainty and the other including no uncertainty. The experimental results of this study reveal that uncertainty enhances learning. Uncertainty is found to be positively associated with motivation. As motivation increases, participants tend to spend more time on answering the questions and to have higher accuracy in these questions. }}
@article{Kihl20151174,
title = {A unified framework for local visual descriptors evaluation },
journal = {Pattern Recognition },
volume = {48},
number = {4},
pages = {1174 - 1184},
year = {2015},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2014.11.013},
url = {http://www.sciencedirect.com/science/article/pii/S003132031400483X},
author = {Olivier Kihl and David Picard and Philippe-Henri Gosselin},

abstract = {Abstract Local descriptors are the ground layer of recognition feature based systems for still images and video. We propose a new framework for the design of local descriptors and their evaluation. This framework is based on the descriptors decomposition in three levels: primitive extraction, primitive coding and code aggregation. With this framework, we are able to explain most of the popular descriptors in the literature such as HOG, HOF or SURF. This framework provides an efficient and rigorous approach for the evaluation of local descriptors, and allows us to uncover the best parameters for each descriptor family. Moreover, we are able to extend usual descriptors by changing the code aggregation or adding new primitive coding method. The experiments are carried out on images (VOC 2007) and videos datasets (KTH, Hollywood2, UCF11 and UCF101), and achieve equal or better performances than the literature. }}
@article{Teimoornia2011617,
title = {The implementation of information and communication technology (ICT) in extracurricular activities of education system in Iran },
journal = {Procedia Computer Science },
volume = {3},
number = {},
pages = {617 - 622},
year = {2011},
note = {World Conference on Information Technology },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2010.12.103},
url = {http://www.sciencedirect.com/science/article/pii/S1877050910004783},
author = {Mahin Teimoornia and Farideh Hamidi and Seyed Mohammad Reza Imam Jomeh and Somayeh Foroozesh-nia},abstract = {Extracurricular activities are those activities designed for preservation of motivation and creation of challenges in the learner in order to obtain experience out of school settings and in relation to curriculum subjects. The range of extracurricular activities includes school atmosphere as well as out of school environments. Extracurricular activities are not necessarily designed by the teacher but they are considered as a pivotal and basic figure in planning extracurricular activities. The implementation of information and communication technologies in curriculum has many advantages. For instance, it can provide the possibility of benefitting an eclectic curriculum both for teachers and students. This type of curriculum program, rather than indoctrinating a finite and limited knowledge to the students, creates a basis through which the individual potentials of students as well as their independence and individual experiences are enhanced and blossomed. In this study, the focus has been on the extracurricular activities that can be implemented in the form of information and communication technologies in Iranian educational system. Also, some strategic recommendations for enriching the quality of extracurricular activities through information and communication technology are provided. }}
@article{Amadieu201136,
title = {The attention-guiding effect and cognitive load in the comprehension of animations },
journal = {Computers in Human Behavior },
volume = {27},
number = {1},
pages = {36 - 40},
year = {2011},
note = {Current Research Topics in Cognitive Load TheoryThird International Cognitive Load Theory Conference },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2010.05.009},
url = {http://www.sciencedirect.com/science/article/pii/S0747563210001469},
author = {Franck Amadieu and Claudette Mariné and Carole Laimay},

abstract = {To be effective, instructional animations should avoid causing high extraneous cognitive load imposed by the high attentional requirements of selecting and processing relevant elements. In accordance with the attention-guiding principle (Bétrancourt, 2005), a study was carried out concerning the impact of cueing on cognitive load and comprehension of animations which depicted a dynamic process in a neurobiology domain. Cueing consisted of zooming in important information at each step of the process. Thirty-six undergraduate psychology students were exposed to an animation three times. Half of the participants received an animation without cueing while the other half received the same animation with cueing. Measures of cognitive load and comprehension performance (questions on isolated elements and on high-element interactivity material) were administered twice, after one and three exposures to the animation. The analyses revealed two main results. First, extraneous cognitive load was reduced by cueing after three exposures. Second, retention of the isolated elements was improved in both animation groups, whereas comprehension of high-element interactive material (i.e., the causal relations between elements) increased only in the cueing condition. Furthermore, a problem solving task showed that cueing supported the development of a more elaborate mental model. }}
@article{Schwamborn201189,
title = {Cognitive load and instructionally supported learning with provided and learner-generated visualizations },
journal = {Computers in Human Behavior },
volume = {27},
number = {1},
pages = {89 - 93},
year = {2011},
note = {Current Research Topics in Cognitive Load TheoryThird International Cognitive Load Theory Conference },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2010.05.028},
url = {http://www.sciencedirect.com/science/article/pii/S0747563210001688},
author = {Annett Schwamborn and Hubertina Thillmann and Maria Opfermann and Detlev Leutner},abstract = {This study investigated, whether learning from science texts can be enhanced by providing learners with different forms of visualizations (pictures) in addition to text. One-hundred-two 9th and 10th graders read a computer-based text on chemical processes of washing and answered questions on cognitive load (mental effort, perceived difficulty) and comprehension (retention, transfer, drawing). Instruction varied according to a 2 × 2-factorial design with ‘learner-generated pictures’ (yes, no) and ‘provided pictures’ (yes, no) as factors. Results indicate positive main effects of provided pictures on all three comprehension measures and negative main effects on both cognitive load measures. Additional analyses revealed a mediation effect of perceived difficulty on retention and transfer, that is learning with provided pictures decreased cognitive load and enhanced comprehension. Furthermore, results show a positive main effect of learner-generated pictures on drawing and mental effort, but no mediation effect. Taken together, computer-based learning with provided pictures enhances comprehension as it seems to promote active processing while reducing extraneous cognitive processing. Learners, generating pictures, however, seem to have less cognitive resources available for essential and generative processing, resulting in reduced comprehension. These results are in line with cognitive load theory, cognitive theories of multimedia learning, and generative theories of learning. }}
@article{Czarnecki20155591,
title = {Multithreshold Entropy Linear Classifier: Theory and applications },
journal = {Expert Systems with Applications },
volume = {42},
number = {13},
pages = {5591 - 5606},
year = {2015},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2015.03.007},
url = {http://www.sciencedirect.com/science/article/pii/S0957417415001839},
author = {Wojciech Marian Czarnecki and Jacek Tabor},abstract = {Abstract This paper proposes a new multithreshold linear classifier (MELC) based on the Renyi’s quadratic entropy and Cauchy–Schwarz divergence, combined with the adaptive kernel density estimation in the one dimensional projections space. Due to its nature MELC is especially well adapted to deal with unbalanced data. As the consequence of both used model and the applied density regularization technique, it shows strong regularization properties and therefore is almost unable to overfit. Moreover, contrary to SVM, in its basic form it has no free parameters, however, at the cost of being a non-convex optimization problem which results in the existence of local optima and the possible need for multiple initializations. In practice, MELC obtained similar or higher scores than the ones given by SVM on both synthetic and real data from the UCI repository. We also perform experimental evaluation of proposed method as a part of expert system designed for drug discovery problem. It appears that not only MELC achieves better results than SVM but also gives some additional insights into data structure, resulting in more complex decision support system. }}
@article{Ding2016118,
title = {Simultaneous body part and motion identification for human-following robots },
journal = {Pattern Recognition },
volume = {50},
number = {},
pages = {118 - 130},
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.08.020},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315003088},
author = {Sihao Ding and Qiang Zhai and Ying Li and Junda Zhu and Yuan F. Zheng and Dong Xuan},



abstract = {Abstract Human-following robots are important for home, industrial and battlefield applications. To effectively interact with human, a robot needs to locate a person's position and understand his/her motion. Vision based techniques are widely used. However, due to the close distance between human and robot, and the limitation in a camera's field of view, only part of a human body can be observed most of the time. As such, the human motion observed by a robot is inherently ambiguous. Simultaneously identifying the body part being observed and the motion the person undergoing is a challenging problem, and has not been well studied in the past. In this paper, we propose a novel method solving the body part and motion identification problem in a unified framework. The relative position of an observed part with respect to the whole body and the motion type are treated as continuous and discrete labels, respectively, and the most probable labeling is inferred by structured learning. A fast part-distribution estimation is introduced to reduce the computational cost. The proposed approach is able to identify different body parts without explicitly building models for each single part, and to recognize the motion with only partial body observations. The proposed approach is evaluated using actual videos captured by a human-following robot as well as the synthesized videos from the public UCF50 dataset, originally developed for action recognition. The result demonstrates the effectiveness of the approach. }}
@article{Jeon2016220,
title = {Spoiler detection in TV program tweets },
journal = {Information Sciences },
volume = {329},
number = {},
pages = {220 - 235},
year = {2016},
note = {Special issue on Discovery Science },
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2015.09.005},
url = {http://www.sciencedirect.com/science/article/pii/S0020025515006593},
author = {Sungho Jeon and Sungchul Kim and Hwanjo Yu},



abstract = {Abstract Watching TV programs at the scheduled airtime is difficult due to time differences between countries or personal circumstances. Not to be a victim of spoilers, people sometimes choose a self imposed isolation from civilization until they have seen their favorite program, such as to stay away from the Internet. However, smartphones allow people to habitually check the SNS messages posted by their friends to maintain their relationships. It leads to the problem of exposing spoilers about their favorite TV programs. To prevent a self imposed isolation from their friends, we need automatic method for detecting spoilers from TV program tweets. To the best of our knowledge, there have been two works that have addressed the spoiler detection task: (1) a keyword matching method and (2) a machine-learning method based on Latent Dirichlet Allocation (LDA). However, they were not designed for short texts as well as the real-world system. The keyword matching method incorrectly predicts most tweets as spoilers. Although the LDA-based method works well on large bodies of text, it fails to accurately detect spoilers from short texts such as Twitter. In this work, we introduce a simple and powerful method of spoiler detection based on four representative features, which are significant indicators of spoilers. To identify and utilize four features, we conduct a precise analysis on real-world tweet data, and we build an SVM-based prediction model based on the result. Using tweets about Dancing with the Stars, and the final of the 2014 World-Cup, we evaluate the effectiveness of the proposed methods on spoiler detection tasks. According to the result, our method achieves greater precision than the competitors while maintaining a comparable recall performance. At the same time, our method outperforms the competitors in terms of processing time, showing that our method is sufficiently lightweight for application to the web-browser. Furthermore, to reduce the labeling cost, we introduce a semi-supervised approach that automatically re-trains the prediction model based on a small amount of labeled data. The experimental results show that the semi-supervised approach delivers performance comparable to that of the previous model. }}
@article{Goertzel201030,
title = {A world survey of artificial brain projects, Part II: Biologically inspired cognitive architectures },
journal = {Neurocomputing },
volume = {74},
number = {1–3},
pages = {30 - 49},
year = {2010},
note = {Artificial Brains },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2010.08.012},
url = {http://www.sciencedirect.com/science/article/pii/S0925231210003498},
author = {Ben Goertzel and Ruiting Lian and Itamar Arel and Hugo de Garis and Shuo Chen},


abstract = {A number of leading cognitive architectures that are inspired by the human brain, at various levels of granularity, are reviewed and compared, with special attention paid to the way their internal structures and dynamics map onto neural processes. Four categories of Biologically Inspired Cognitive Architectures (BICAs) are considered, with multiple examples of each category briefly reviewed, and selected examples discussed in more depth: primarily symbolic architectures (e.g. ACT-R), emergentist architectures (e.g. DeSTIN), developmental robotics architectures (e.g. IM-CLEVER), and our central focus, hybrid architectures (e.g. LIDA, CLARION, 4D/RCS, DUAL, MicroPsi, and OpenCog). Given the state of the art in BICA, it is not yet possible to tell whether emulating the brain on the architectural level is going to be enough to allow rough emulation of brain function; and given the state of the art in neuroscience, it is not yet possible to connect BICAs with large-scale brain simulations in a thoroughgoing way. However, it is nonetheless possible to draw reasonably close function connections between various components of various BICAs and various brain regions and dynamics, and as both BICAs and brain simulations mature, these connections should become richer and may extend further into the domain of internal dynamics as well as overall behavior. }}
@article{Bisio2016154,
title = {Inductive bias for semi-supervised extreme learning machine },
journal = {Neurocomputing },
volume = {174, Part A},
number = {},
pages = {154 - 167},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.04.104},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215011479},
author = {Federica Bisio and Sergio Decherchi and Paolo Gastaldo and Rodolfo Zunino},



abstract = {Abstract This research shows that inductive bias provides a valuable method to effectively tackle semi-supervised classification problems. In the learning theory framework, inductive bias provides a powerful tool, and allows one to shape the generalization properties of a learning machine. The paper formalizes semi-supervised learning as a supervised learning problem biased by an unsupervised reference solution. The resulting semi-supervised classification framework can apply any clustering algorithm to derive the reference function, thus ensuring maximum flexibility. In this context, the paper derives the biased version of Extreme Learning Machine (br-ELM). The experimental session involves several real world problems and proves the reliability of the semi-supervised classification scheme. }}
@article{Gleaves2013249,
title = {Richness, redundancy or relational salience? A comparison of the effect of textual and aural feedback modes on knowledge elaboration in higher education students' work },
journal = {Computers & Education },
volume = {62},
number = {},
pages = {249 - 261},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.11.004},
url = {http://www.sciencedirect.com/science/article/pii/S0360131512002606},
author = {Alan Gleaves and Caroline Walker},
abstract = {This study examines the effects of formative assessment feedback commentaries utilizing textual and aural media on the quality of knowledge elaboration within the written work of a sample of 104 higher education students. A randomized, mixed methodological approach was adopted that examined changes within the students' work over a period of one academic year as a function of the feedback medium. The research outcomes indicated that whilst there were some improvements in very specific elements of the students' contextual knowledge elaboration that appeared to be related to qualities within the audio feedback, these were not significant and thus further research is required to explore the effects of audio media on elements of elaboration. However, analysis of students' qualitative comments suggests that feedback may serve simultaneously to reinforce and undermine tutor–student relationships as well as influencing the students' attitudes towards academic progress in general. This research assists not only in the furtherance of understanding the place of media in progressing students' knowledge elaboration within their studies, but also in comprehending the relationship between perception and actualization of learning development and progress. }}
@article{vanHeeswijk2015187,
title = {Binary/ternary extreme learning machines },
journal = {Neurocomputing },
volume = {149, Part A},
number = {},
pages = {187 - 197},
year = {2015},
note = {Advances in neural networksAdvances in Extreme Learning MachinesSelected papers from the Tenth International Symposium on Neural Networks (ISNN 2013)Selected articles from the International Symposium on Extreme Learning Machines (ELM 2013) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.01.072},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214011515},
author = {Mark van Heeswijk and Yoan Miche},

abstract = {Abstract In this paper, a new hidden layer construction method for Extreme Learning Machines (ELMs) is investigated, aimed at generating a diverse set of weights. The paper proposes two new ELM variants: Binary ELM, with a weight initialization scheme based on { 0 , 1 } –weights; and Ternary ELM, with a weight initialization scheme based on { − 1 , 0 , 1 } –weights. The motivation behind this approach is that these features will be from very different subspaces and therefore each neuron extracts more diverse information from the inputs than neurons with completely random features traditionally used in ELM. Therefore, ideally it should lead to better ELMs. Experiments show that indeed ELMs with ternary weights generally achieve lower test error. Furthermore, the experiments show that the Binary and Ternary ELMs are more robust to irrelevant and noisy variables and are in fact performing implicit variable selection. Finally, since only the weight generation scheme is adapted, the computational time of the ELM is unaffected, and the improved accuracy, added robustness and the implicit variable selection of Binary ELM and Ternary ELM come for free. }}
@article{Kalyuga2009332,
title = {Instructional designs for the development of transferable knowledge and skills: A cognitive load perspective },
journal = {Computers in Human Behavior },
volume = {25},
number = {2},
pages = {332 - 338},
year = {2009},
note = {Including the Special Issue: State of the Art Research into Cognitive Load Theory },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2008.12.019},
url = {http://www.sciencedirect.com/science/article/pii/S074756320800232X},
author = {Slava Kalyuga},


abstract = {This paper analyzes the main points and results of a set of the previous papers in this Special Issue from the point of view of developing characteristics of flexible—transferable—expertise. It focuses on cognitive load issues related to the acquisition of deep transferable knowledge structures and developing metacognitive and self-regulation skills. The contributions to this Special Issue demonstrate that appropriate instructional support and optimal levels of control over the learning processes, enhanced by self-explanation and self-visualization techniques, may enhance learners’ abilities to transfer their knowledge and skills. Better understanding of the role of germane cognitive load, as well as our abilities to measure different types of load and high-level cognitive processes are essential for further progress in this area. }}
@article{Bennett2015211,
title = {Technology tools to support learning design: Implications derived from an investigation of university teachers' design practices },
journal = {Computers & Education },
volume = {81},
number = {},
pages = {211 - 220},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.10.016},
url = {http://www.sciencedirect.com/science/article/pii/S036013151400236X},
author = {Sue Bennett and Shirley Agostinho and Lori Lockyer},
abstract = {Abstract The need to improve the quality of higher education has fostered an interest in technology tools to support effective design for teaching and learning. Over the past decade this interest has led to the development of tools to support the creation of online learning experiences, specifications to underpin design systems, and repositories to share examples. Despite this significant activity, there remain unanswered questions about what shapes university teachers' design decisions and how tools can best support their design processes. This paper presents findings from a study of university teachers' design practices that identified teachers' perceptions of student characteristics, their own beliefs and experiences, and contextual factors as key influences on design decisions. The findings extend our understanding of activities fundamental to higher education teaching and inform thinking about design support tools. }}
@article{Nguyen201660,
title = {Graph-induced restricted Boltzmann machines for document modeling },
journal = {Information Sciences },
volume = {328},
number = {},
pages = {60 - 75},
year = {2016},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2015.08.023},
url = {http://www.sciencedirect.com/science/article/pii/S002002551500609X},
author = {Tu Dinh Nguyen and Truyen Tran and Dinh Phung and Svetha Venkatesh},
abstract = {Abstract Discovering knowledge from unstructured texts is a central theme in data mining and machine learning. We focus on fast discovery of thematic structures from a corpus. Our approach is based on a versatile probabilistic formulation – the restricted Boltzmann machine (RBM) – where the underlying graphical model is an undirected bipartite graph. Inference is efficient – document representation can be computed with a single matrix projection, making RBMs suitable for massive text corpora available today. Standard RBMs, however, operate on bag-of-words assumption, ignoring the inherent underlying relational structures among words. This results in less coherent word thematic grouping. We introduce graph-based regularization schemes that exploit the linguistic structures, which in turn can be constructed from either corpus statistics or domain knowledge. We demonstrate that the proposed technique improves the group coherence, facilitates visualization, provides means for estimation of intrinsic dimensionality, reduces overfitting, and possibly leads to better classification accuracy. }}
@article{Nguyen20161565,
title = {Statistical binary patterns for rotational invariant texture classification },
journal = {Neurocomputing },
volume = {173, Part 3},
number = {},
pages = {1565 - 1577},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.09.029},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215013375},
author = {Thanh Phuong Nguyen and Ngoc-Son Vu and Antoine Manzanera},



abstract = {Abstract A new texture representation framework called statistical binary patterns (SBPs) is presented. It consists in applying rotation invariant local binary pattern operators ( LBP riu 2 ) to a series of moment images, defined by local statistics uniformly computed using a given spatial support. It can be seen as a generalisation of the commonly used complementation approach (CLBP), since it extends the local description not only to local contrast information, but also to higher order local variations. In short, SBPs aim at expanding LBP self-similarity operator from the local grey level to the regional distribution level. Thanks to a richer local description, the SBPs have better discrimination power than other LBP variants. Furthermore, thanks to the regularisation effect of the statistical moments, the SBP descriptors show better noise robustness than classical CLBPs. The interest of the approach is validated through a large experimental study performed on five texture databases: KTH-TIPS, KTH-TIPS 2b, CUReT, UIUC and DTD. The results show that, for the four first datasets, the SBPs are comparable or outperform the recent state-of-the-art methods, even using small support for the LBP operator, and using limited size spatial support for the computation of the local statistics. }}
@article{He201390,
title = {Examining students’ online interaction in a live video streaming environment using data mining and text mining },
journal = {Computers in Human Behavior },
volume = {29},
number = {1},
pages = {90 - 102},
year = {2013},
note = {Including Special Section Youth, Internet, and Wellbeing },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2012.07.020},
url = {http://www.sciencedirect.com/science/article/pii/S0747563212002233},
author = {Wu He},

abstract = {This study analyses the online questions and chat messages automatically recorded by a live video streaming (LVS) system using data mining and text mining techniques. We apply data mining and text mining techniques to analyze two different datasets and then conducted an in-depth correlation analysis for two educational courses with the most online questions and chat messages respectively. The study found the discrepancies as well as similarities in the students’ patterns and themes of participation between online questions (student–instructor interaction) and online chat messages (student–students interaction or peer interaction). The results also identify disciplinary differences in students’ online participation. A correlation is found between the number of online questions students asked and students’ final grades. The data suggests that a combination of using data mining and text mining techniques for a large amount of online learning data can yield considerable insights and reveal valuable patterns in students’ learning behaviors. Limitations with data and text mining were also revealed and discussed in the paper. }}
@article{Huijse201529,
title = {Discriminating Variable Star Candidates in Large Image Databases from the HiTS Survey Using NMF },
journal = {Procedia Computer Science },
volume = {53},
number = {},
pages = {29 - 38},
year = {2015},
note = {INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.276},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915017792},
author = {Pablo Huijse and Pablo A. Estévez and Francisco Förster and Emanuel Berrocal},
abstract = {Abstract New instruments and technologies are allowing the acquisition of large amounts of data from astronomical surveys. Nowadays there is a pressing need for autonomous methods to discriminate the interesting astronomical objects in the vast sky. The High Cadence Transient Survey (HiTS) project is an astronomical survey that is trying to find a rare transient event that occurs during the first instants of a supernova. In this paper we propose an autonomous method to discriminate stellar variability from the HiTS database, that uses a feature extraction scheme based on Non-negative matrix factorization (NMF). Using NMF, dictionaries of image prototypes that represent the data in a compact way are obtained. The projections of the dataset into these dictionaries are fed into a random forest classifier. NMF is compared with other feature extraction schemes, on a subset of 500,000 transient candidates from the HiTS survey. With NMF a better class separability at feature level is obtained which enhances the classification accuracy significantly. Using the NMF features less than 4% of the true stellar transients are lost, at a manageable false positive rate of 0.1%. }}
@article{Solgi2015316,
title = {WWN-8: Incremental Online Stereo with Shape-from-X Using Life-Long Big Data from Multiple Modalities },
journal = {Procedia Computer Science },
volume = {53},
number = {},
pages = {316 - 326},
year = {2015},
note = {INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.309},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915018128},
author = {Mojtaba Solgi and Juyang Weng},


abstract = {Abstract When a child lives in the real world, from infancy to adulthood, his retinae receive a flood of stereo sensory stream. His muscles produce another action stream. How does the child's brain deal with such big data from multiple sensory modalities (left- and right-eye modalities) and multiple effector modalities (location, disparity map, and shape type)? This capability incrementally learns to produce simple-to-complex sensorimotor behaviors — autonomous development. We present a model that incrementally fuses such an open-ended life-long stream and updates the brain online so the perceived world is 3D. Traditional methods for shape- from-X use a particular type of cue X (e.g., stereo disparity, shading, etc.) to compute depths or local shapes based on a handcrafted physical model. Such a model likely results in a brit- tle system because of the fluctuation of the availability of the cue. An embodiment of the Developmental Network (DN), called Stereo Where-What Network (WWN-8), learns to per- form simultaneous attention and recognition, while developing invariances in location, disparity, shape, and surface type, so that multiple cues can automatically fill in if a particular type of cue (e.g., texture) is missing locally from the real world. We report some experiments: 1) dynamic synapse retraction and growth as a method of developing receptive fields. 2) training for recognizing 3D objects directly in cluttered natural backgrounds. 3) integration of depth perception with location and type information. The experiments used stereo images and motor actions on the order of 105 frames. Potential applications include driver assistance for road safety, mobile robots, autonomous navigation, and autonomous vision-guided manipulators. }}
@article{Chiou2015211,
title = {Effects on learning of multimedia animation combined with multidimensional concept maps },
journal = {Computers & Education },
volume = {80},
number = {},
pages = {211 - 223},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.09.002},
url = {http://www.sciencedirect.com/science/article/pii/S0360131514002024},
author = {Chei-Chang Chiou and Li-Chu Tien and Li-Tze Lee},abstract = {Abstract This study investigates whether teaching materials combining multimedia animation and multidimensional concept maps (MAMCMs) improve learning achievement, retention, and satisfaction more than multidimensional concept maps (MCMs), as suggested by Huang et al. (2012) in Computers &amp; Education. Learning retention, learning achievement, and learning satisfaction associated with two sets of course materials were compared in this quasi-experimental study. In total, 114 students from two classes at one private university in Taiwan participated in this 6-week teaching experiment. Analytical results indicate that learning achievement, learning satisfaction, and learning retention of the MAMCM group were better than those of the MCM group. Pedagogical implications and suggestions are given. }}
@article{Jiang2015503,
title = {Modeling Temporal Dynamics of User Interests in Online Social Networks },
journal = {Procedia Computer Science },
volume = {51},
number = {},
pages = {503 - 512},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015Computational Science at the Gates of Nature },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.05.275},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915010832},
author = {Bo Jiang and Ying Sha},abstract = {Abstract Recent years have witnessed an explosive growth of Online Social Networks (OSNs), which serve as a fertile ground for research such as, characterizing individual and group behaviors, identifying information diffusion patterns, and building new recommendation system. This paper explores user interests in social network. While user interests has been extensively studied as the fundamental solution, it neglects the point that a user may change her interests due to social status shift over time. In this paper, we explore two main problems: how user interests change over time and whether user interests have hierarchy. To this end, we first formulate the user interests problem, then adopt semantic enrichment method to determine user interests, and finally employ the topic hierarchy tree model to capture user interests change over time and identify interest hierarchy. Experimental results demonstrate user interests can be divided into primary interest and secondary interest. the primary interest of user hold stability in a long-term period; the secondary interest, however, is more likely to keep up with hot topics or events in the moment. Meanwhile, We also test and compare our model with two existing systems - Who likes what? and TUMS, the result shows that our model can be profiled a more fine-grained user interests. }}
@article{Hämäläinen2015283,
title = {Multilingual Speech Recognition for the Elderly: The AALFred Personal Life Assistant },
journal = {Procedia Computer Science },
volume = {67},
number = {},
pages = {283 - 292},
year = {2015},
note = {Proceedings of the 6th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.09.272},
url = {http://www.sciencedirect.com/science/article/pii/S187705091503118X},
author = {Annika Hämäläinen and António Teixeira and Nuno Almeida and Hugo Meinedo and Tibor Fegyó and Miguel Sales Dias},


abstract = {Abstract The PaeLife project is a European industry-academia collaboration in the framework of the Ambient Assisted Living Joint Programme (AAL JP), with a goal of developing a multimodal, multilingual virtual personal life assistant to help senior citizens remain active and socially integrated. Speech is one of the key interaction modalities of AALFred, the Windows application developed in the project; the application can be controlled using speech input in four European languages: French, Hungarian, Polish and Portuguese. This paper briefly presents the personal life assistant and then focuses on the speech-related achievements of the project. These include the collection, transcription and annotation of large corpora of elderly speech, the development of automatic speech recognisers optimised for elderly speakers, a speech modality component that can easily be reused in other applications, and an automatic grammar translation service that allows for fast expansion of the automatic speech recognition functionality to new languages. }}
@article{Bach2015322,
title = {Leveraging User Ratings for Resource-poor Sentiment Classification },
journal = {Procedia Computer Science },
volume = {60},
number = {},
pages = {322 - 331},
year = {2015},
note = {Knowledge-Based and Intelligent Information &amp; Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.08.134},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915022619},
author = {Ngo Xuan Bach and Tu Minh Phuong},
abstract = {Abstract This paper presents a general, simple, yet effective method for weakly supervised sentiment classification in resource-poor lan- guages. Given as input weak training signals in forms of textual reviews and associated ratings, which are available in many e-commerce websites, our method computes class distributions for sentences using the statistical information of n-grams in the reviews. These distributions can then be used directly to build sentiment classifiers in unsupervised settings, or they can be used as extra features to boost the classification accuracy in semi-supervised settings. We empirically verified the effectiveness of the proposed method on two datasets in Japanese and Vietnamese languages. The results are promising, showing that the method is able to make relatively accurate predictions even when no labeled data are given. In the semi-supervised settings, the method achieved from 1.8% to 4.7% relative improvement over the pure supervised baseline method, depending on the amount of labeled data. }}
@article{Orvis2002783,
title = {Communication patterns during synchronous Web-based military training in problem solving },
journal = {Computers in Human Behavior },
volume = {18},
number = {6},
pages = {783 - 795},
year = {2002},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/S0747-5632(02)00018-3},
url = {http://www.sciencedirect.com/science/article/pii/S0747563202000183},
author = {Kara L Orvis and Robert A Wisher and Curtis J Bonk and Tatana M Olson},

abstract = {The nature of communication among geographically dispersed groups of learners using text messaging in a military training environment was assessed. A total of 6601 acts of chat were coded into one of three interaction content categories (social, task, or technology-related) and analyzed for frequency and relative change over time. Results indicated shifting patterns of interaction over the 6-month course; while technology concerns gradually diminished, on task discussion peaked in the middle months and social interactions were higher at the start and end of the training. Overall, student chats were categorized as on-task 55%, social 30%, or technology-related 15%. Examples of chats and focus group data indicated that there was an emphasis on fostering student problem solving within the online course. }}
@article{Ma20161387,
title = {Two dimensional ensemble hashing for visual tracking },
journal = {Neurocomputing },
volume = {171},
number = {},
pages = {1387 - 1400},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.091},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215010991},
author = {Chao Ma and Chuancai Liu and Furong Peng},



abstract = {Abstract Appearance model in visual tracking is a key component to attain robustness and efficiency. In the last decades, many complex appearance models have been proposed to improve performance of tracking algorithm. However, these models are difficult to maintain accuracy and efficiency simultaneously. In this paper, we observe that data-dependent hashing method could improve processing speed by generating compact representation for the visual object. But applying the method to visual tracking is still a challenging task. To reinforce the performance of hashing technique, a novel hashing method called two dimensional ensemble hashing is proposed. In our tracker, image samples are hashed to binary matrices, and the Hamming distance is used to measure their confidences. Moreover, for adapting situation change, the hash functions are updated by the learning model at each frame. Experimental results not only demonstrate the accuracy and effectiveness of our tracker, but also show that the tracking algorithm outperforms other state-of-the-art trackers. }}
@article{Hayat2016889,
title = {An RGB–D based image set classification for robust face recognition from Kinect data },
journal = {Neurocomputing },
volume = {171},
number = {},
pages = {889 - 900},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.07.027},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215010048},
author = {Munawar Hayat and Mohammed Bennamoun and Amar A. El-Sallam},



abstract = {Abstract The paper proposes a method for robust face recognition from low quality Kinect acquired images which have a wide range of variations in head pose, illumination, facial expressions, sunglass disguise and occlusions by hand. Multiple Kinect images of a person are considered as an image set and face recognition from these images is formulated as an RGB–D image set classification problem. The Kinect acquired raw depth data is used for pose estimation and an automatic cropping of the face region. Based upon the estimated poses, the face images of a set are divided into multiple image subsets. An efficient block based covariance matrix representation is proposed to model images in an image subset on Riemannian manifold (Lie group). For classification, SVM models are separately learnt for each image subset on the Lie group of Riemannian manifold and a fusion strategy is introduced to combine results from all image subsets. The proposed technique has been evaluated on a combination of three large data sets containing over 35,000 RGB–D images under challenging conditions. The proposed RGB–D based image set classification incurs low computational cost and achieves an identification rate as high as 99.5%. }}
@article{Jain2016,
title = {50 years of biometric research: Accomplishments, challenges, and opportunities },
journal = {Pattern Recognition Letters },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.12.013},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515004365},
author = {Anil K. Jain and Karthik Nandakumar and Arun Ross},


abstract = {Abstract Biometric recognition refers to the automated recognition of individuals based on their biological and behavioral characteristics such as fingerprint, face, iris, and voice. The first scientific paper on automated fingerprint matching was published by Mitchell Trauring in the journal Nature in 1963. The first objective of this paper is to document the significant progress that has been achieved in the field of biometric recognition in the past 50 years since Trauring’s landmark paper. This progress has enabled current state-of-the-art biometric systems to accurately recognize individuals based on biometric trait(s) acquired under controlled environmental conditions from cooperative users. Despite this progress, a number of challenging issues continue to inhibit the full potential of biometrics to automatically recognize humans. The second objective of this paper is to enlist such challenges, analyze the solutions proposed to overcome them, and highlight the research opportunities in this field. One of the foremost challenges is the design of robust algorithms for representing and matching biometric samples obtained from uncooperative subjects under unconstrained environmental conditions (e.g., recognizing faces in a crowd). In addition, fundamental questions such as the distinctiveness and persistence of biometric traits need greater attention. Problems related to the security of biometric data and robustness of the biometric system against spoofing and obfuscation attacks, also remain unsolved. Finally, larger system-level issues like usability, user privacy concerns, integration with the end application, and return on investment have not been adequately addressed. Unlocking the full potential of biometrics through inter-disciplinary research in the above areas will not only lead to widespread adoption of this promising technology, but will also result in wider user acceptance and societal impact. }}
@article{Liu20143819,
title = {Realistic action recognition via sparsely-constructed Gaussian processes },
journal = {Pattern Recognition },
volume = {47},
number = {12},
pages = {3819 - 3827},
year = {2014},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2014.07.006},
url = {http://www.sciencedirect.com/science/article/pii/S0031320314002659},
author = {Li Liu and Ling Shao and Feng Zheng and Xuelong Li},abstract = {Abstract Realistic action recognition has been one of the most challenging research topics in computer vision. The existing methods are commonly based on non-probabilistic classification, predicting category labels but not providing an estimation of uncertainty. In this paper, we propose a probabilistic framework using Gaussian processes (GPs), which can tackle regression problems with explicit uncertain models, for action recognition. A major challenge for GPs when applied to large-scale realistic data is that a large covariance matrix needs to be inverted during inference. Additionally, from the manifold perspective, the intrinsic structure of the data space is only constrained by a local neighborhood and data relationships with far-distance usually can be ignored. Thus, we design our GPs covariance matrix via the proposed ℓ1 construction and a local approximation (LA) covariance weight updating method, which are demonstrated to be robust to data noise, automatically sparse and adaptive to the neighborhood. Extensive experiments on four realistic datasets, i.e., UCF YouTube, UCF Sports, Hollywood2 and HMDB51, show the competitive results of ℓ1-GPs compared with state-of-the-art methods on action recognition tasks. }}
@article{Li2014198,
title = {Sparse-based neural response for image classification },
journal = {Neurocomputing },
volume = {144},
number = {},
pages = {198 - 207},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.04.053},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214006778},
author = {Hong Li and Hongfeng Li and Yantao Wei and Yuanyan Tang and Qiong Wang},
abstract = {Abstract Image classification is a popular and challenging topic in the computer vision field. On the basis of advances in neuroscience, this paper proposes a sparse-based neural response feature extraction method for image classification. The approach extracts discriminative and invariant representations of images by alternating between non-negative sparse coding and maximum pooling operation with effectiveness. Additionally, effective template selection methods are proposed to further enhance the performance of the algorithm. In comparison with traditional hierarchical methods, our proposed model accounts for the neural processing of visual cortex in human brain, which appears to gain more beneficial discriminative and robust properties for image classification tasks. A variety of benchmarks are used to evaluate the algorithm. The experiment results demonstrate that our proposed algorithm achieves quite excellent or state-of-the-art performance compared with other popular methods. }}
@article{ChamosoSánchez2002303,
title = {Designing hypermedia tools for solving problems in mathematics },
journal = {Computers & Education },
volume = {38},
number = {4},
pages = {303 - 317},
year = {2002},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/S0360-1315(01)00062-8},
url = {http://www.sciencedirect.com/science/article/pii/S0360131501000628},
author = {José Chamoso Sánchez and Luis Hernández Encinas and Ricardo López Fernández and Mercedes Rodrı́guez Sánchez},
abstract = {This article presents the design and preparation using hypermedia tools of an interactive CD-ROM for the active teaching and learning of diverse problem-solving strategies in Mathematics for secondary school students. The use of the CD-ROM allows the students to learn, interactively, the heuristic style of solving problems. A range of problems has been used, each of which requires different solving strategies. A complementary section for consulting the theoretical foundations for the process of solving problems and other related information is also included on the CD-ROM. This section provides both theoretical and curriculum support for teachers. }}
@article{Wood20091048,
title = {Comments on Learning with ICT: New perspectives on help seeking and information searching },
journal = {Computers & Education },
volume = {53},
number = {4},
pages = {1048 - 1051},
year = {2009},
note = {Learning with ICT: New perspectives on help seeking and information searching },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2009.07.002},
url = {http://www.sciencedirect.com/science/article/pii/S0360131509001663},
author = {David Wood}}
@article{Wen2014499,
title = {Multiple perceptual neighborhoods-based feature construction for pattern classification },
journal = {Neurocomputing },
volume = {142},
number = {},
pages = {499 - 507},
year = {2014},
note = {SI Computational Intelligence Techniques for New Product Development },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.04.007},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214005578},
author = {Guihua Wen and Lijun Jiang and Jun Wen},abstract = {Abstract Feature construction is much critical to support classification tasks when a combination of the original features carries more discriminative information. However, the construction of features usually implies searching a very large space of possibilities and is often computationally demanding. Besides, some approaches require domain knowledge and the underlying principles of some approaches are hard to interpret. This paper presents a simple and efficient feature construction approach, which is independent of concrete classifiers and data domains. It begins with generating the features by calculating the distances between the sample and its neighborhoods in each class as features, as they have abilities to distinguish the sample. These features are then applied to combine with the original features of the sample to form the new feature vector for the sample. The novel work of this method lies in that a new general framework to create features for the given sample and a simple rule to combine the generated features with the original features are presented. This approach has been validated by applying it to a local classifier in experiments. The results suggest that the proposed method can be applied to nicely deal with the sparse and the noisy data. }}
@article{Michinov20151,
title = {A step further in Peer Instruction: Using the Stepladder technique to improve learning },
journal = {Computers & Education },
volume = {91},
number = {},
pages = {1 - 13},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.09.007},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515300440},
author = {Nicolas Michinov and Julien Morice and Vincent Ferrières},
abstract = {Abstract Peer Instruction (PI) is an instructional strategy for engaging students during class through a structured questioning process that improves the learning of the concepts of fundamental sciences. Although all students are supposedly engaged in discussions with their peers during Peer Instruction, the learning gains generally remain at a medium level, suggesting a lack of participation of certain students who do not benefit from social interactions. The present study examined whether the Stepladder technique might optimize the Peer Instruction method and increase learning gains. With this technique, students enter a group sequentially, forcing every group member to participate in discussions. Eighty-four chemistry students were asked to answer easy and difficult multiple-choice questions before and after being randomly assigned to one of three instructional conditions during a chromatography lesson (Classic PI vs. Stepladder PI vs. Individual Instruction without any discussion with peers). As predicted, results showed that learning gains were greatest in the Stepladder PI group, and that this effect was mainly observed for difficult questions. Results also revealed higher perceived satisfaction when students had to discuss the questions with their peers than when they were not given this possibility. By extending the Stepladder technique to higher education, these findings offer a step forward in the Peer Instruction literature, showing how it can enhance learning gains. }}
@article{Balram2008371,
title = {Collaborative spaces for GIS-based multimedia cartography in blended environments },
journal = {Computers & Education },
volume = {50},
number = {1},
pages = {371 - 385},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2006.07.004},
url = {http://www.sciencedirect.com/science/article/pii/S0360131506001114},
author = {Shivanand Balram and Suzana Dragićević},

abstract = {The interaction spaces between instructors and learners in the traditional face-to-face classroom environment are being changed by the diffusion and adoption of many forms of computer-based pedagogy. An integrated understanding of these evolving interaction spaces together with how they interconnect and leverage learning are needed to develop meaningful strategies for effective teaching and learning. The 18i collaborative interaction spaces model was designed based on constructivist principles, and describes 18 mixed instructor–learner spaces contextualized at a finer operational scale that makes explicit a wider range of interactions. The model was implemented during the life cycle of an undergraduate GIS-based multimedia cartography course. One output was the generation of a repository of rule-based trajectory plans for rapid planning and problem solving. The model provides an integrated workflow to manage course contents, products, interactions, individuality, and learning styles in blended environments. }}
@article{Carlon2012215,
title = {The community of inquiry instrument: Validation and results in online health care disciplines },
journal = {Computers & Education },
volume = {59},
number = {2},
pages = {215 - 221},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.01.004},
url = {http://www.sciencedirect.com/science/article/pii/S036013151200005X},
author = {S. Carlon and D. Bennett-Woods and B. Berg and L. Claywell and K. LeDuc and N. Marcisz and M. Mulhall and T. Noteboom and T. Snedden and K. Whalen and L. Zenoni},

abstract = {This descriptive study using survey design sought to establish the efficacy of the Community of Inquiry instrument utilized in a study published by Shea and Bidjerano in 2009 exploring an online community of business students in a multi-institutional study. The current study sought to validate the instrument with a population of students in three health care disciplines (nursing, physical therapy and health care administration (HCA)) which includes health information management (HIM) at a large private western university. A secondary aim was to identify similarities and differences in the Community of Inquiry model among selected health care disciplines comparing sample student populations in previously described research. Results indicate that the instrument was validated in the health care disciplines on all subscales. Significant differences were found in social presence and cognitive presence among the three groups of students with no significant differences in teaching presence. There was a significant difference in presence by course experience (number of courses completed) for the second versus the fifth course in the social presence construct. The three factor model was validated with this population of students; however, when additional factor analysis was done, results indicated a potential four factor model consistent with recent research by Diaz, Swan, Ice, and Kupczynski (2010), Bangert (2009) and Shea and Bidjerano (2009a). These studies provided evidence of two factors within teaching presence whereas the current study yielded two factors within the construct of social presence (social comfort and social experience). }}
@article{Sidney201529,
title = {How do contrasting cases and self-explanation promote learning? Evidence from fraction division },
journal = {Learning and Instruction },
volume = {40},
number = {},
pages = {29 - 38},
year = {2015},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2015.07.006},
url = {http://www.sciencedirect.com/science/article/pii/S0959475215300207},
author = {Pooja G. Sidney and Shanta Hattikudur and Martha W. Alibali},
abstract = {Abstract Past research has shown that both contrasting cases instruction and prompts to self-explain promote students' learning in mathematics. However, it is not clear whether these instructional approaches enhance learning through similar mechanisms or whether each supports learning in distinct ways. The purpose of this study was to investigate the unique and combined effects of comparison, defined as noticing similarities and differences, and explanation, defined as making sense of problems, on student learning, and to assess whether these processes are more effective when combined than when implemented separately. We also investigated potential mechanisms involved in comparison and explanation. We addressed these issues in the domain of fraction division. Prompts to self-explain promoted conceptual learning, but inviting comparison, without prompts to self-explain, did not. The quality of students' self-explanations was affected by both prompts to self-explain and encouragement to compare. The findings suggest that contrasting cases instruction is effective, at least in part, because it typically involves self-explanation. }}
@article{Mills20159,
title = {The influence of consequence value and text difficulty on affect, attention, and learning while reading instructional texts },
journal = {Learning and Instruction },
volume = {40},
number = {},
pages = {9 - 20},
year = {2015},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2015.07.003},
url = {http://www.sciencedirect.com/science/article/pii/S0959475215300177},
author = {Caitlin Mills and Sidney K. D'Mello and Kristopher Kopp},
abstract = {Abstract The present study investigated how consequence value influences affect, attention, and learning while reading instructional texts, and if text difficulty moderates these effects. Participants studied four instructional texts on research methods in a 2 × 2 consequence value (high vs. low) × text difficulty (easy vs. difficult) within-subjects experiment. Consequence value was manipulated by assigning two of the four texts as having high value and the other two as having low value with respect to a performance goal on a subsequent test, while text difficulty was manipulated via experimenter-created easy and difficult versions of the texts. We hypothesized that consequence value would induce mild anxiety, which would focus attention and facilitate learning, and that text difficulty would moderate the influence of consequence value. Partially consistent with the predictions, high consequence value led to lower valence, higher arousal, longer reading times, and positively predicted knowledge transfer. Arousal mediated the relationship between consequence value and knowledge transfer, but only when the texts were difficult, thereby suggesting moderated mediation. }}
@article{Seyyedsalehi2015669,
title = {A fast and efficient pre-training method based on layer-by-layer maximum discrimination for deep neural networks },
journal = {Neurocomputing },
volume = {168},
number = {},
pages = {669 - 680},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.05.057},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215007389},
author = {Seyyede Zohreh Seyyedsalehi and Seyyed Ali Seyyedsalehi},

abstract = {Abstract In this paper, through extension of the present methods and based on error minimization, two fast and efficient layer-by-layer pre-training methods are proposed for initializing deep neural network (DNN) weights. Due to confrontation with a large number of local minima, DNN training often does not converge. By proper initializing of DNN weights instead of random values at the beginning of the training, it is possible to avoid many local minima. The first version of the proposed method is for pre-training the deep bottleneck neural network (DBNN) in which the DBNN is broken down to some corresponding single-hidden-layer bottleneck neural networks (BNN) which must be trained first. The weight values resulting from their training are then applied in the DBNN. The proposed method was utilized to pre-train a five-hidden-layer DBNN to extract the non-linear principal components of face images in the Bosphorus database. A comparison of the randomly initialized DBNN result with pre-trained DBNN by the layer-by-layer pre-training method shows that this method not only increased the convergence rate of training but also improved its generalizability. Furthermore, it has been shown that this method yields higher efficiency and convergence speed in comparison with some of the previous pre-training methods. This paper also presents the bidirectional version of the layer-by-layer pre-training method for hetero-associative DNN pre-training. This method pre-trains DNN weights in forward and backward manner in parallel. Bidirectional layer-by-layer pre-training was utilized to pre-train the classifier DNN weights, and revealed that both the training speed and the recognition rate were improved in Bosphorus and CK+ databases. }}
@article{Bannert2009829,
title = {Effects of a metacognitive support device in learning environments },
journal = {Computers in Human Behavior },
volume = {25},
number = {4},
pages = {829 - 835},
year = {2009},
note = {Including the Special Issue: The Use of Support Devices in Electronic Learning Environments },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2008.07.002},
url = {http://www.sciencedirect.com/science/article/pii/S0747563208001350},
author = {Maria Bannert and Melanie Hildebrand and Christoph Mengelkamp},abstract = {Successful learning is mainly based on metacognitive activities which have to be performed and constantly monitored during learning. Research reveals that many learners have difficulties in performing such metacognitive activities spontaneously, which most probably results in lower learning outcomes. The aim of this study is to experimentally analyse the effects of a metacognitive support device combined with a paper-based prompting scheme. With this support device, students are instructed to activate their repertoire of metacognitive knowledge and skills which should further enhance learning and transfer. University students of the experimental group (n = 29) were instructed by means of a metacognitive support device why metacognitive activities are useful and how to apply them during learning. In addition, during learning, they were prompted to apply the metacognitive activities they just had learned. Students of the control group (n = 27) were not instructed why and how to use metacognitive activities, and furthermore, they were not prompted during learning to apply these metacognitive activities. Rather, they were instructed by a computer device how to organise a work place for their studies so all groups were treated in a similar way. The students’ learning task was to learn about psychological theories of using pictures in multimedia learning environments within 60 min. Immediately afterwards, learning outcome was measured with a test. Altogether, 56 university students participated, counterbalanced according to their prior knowledge as well as metacognitive knowledge. As expected, students of the experimental group showed better transfer performance compared with the control group. In addition, training did increase metacognitive behavior measured by subjective ratings. }}
@article{Cui201252,
title = {Feature extraction using fuzzy maximum margin criterion },
journal = {Neurocomputing },
volume = {86},
number = {},
pages = {52 - 58},
year = {2012},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2011.12.031},
url = {http://www.sciencedirect.com/science/article/pii/S0925231212000756},
author = {Yan Cui and Liya Fan},abstract = {In pattern recognition, feature extraction techniques are widely employed to reduce the dimensionality of date. In this paper, a novel feature extraction criterion, fuzzy maximum margin criterion (FMMC), is proposed by means of the maximum margin criterion (MMC) and fuzzy set theory. More specifically, the between-class and within-class fuzzy scatter matrices are redefined by incorporating the membership degrees of samples which relates the samples distribution information; then the feature extraction criterion maximized the average margin between classes after dimensionality reduction is applied. Furthermore, we utilize the generalized singular value decomposition (GSVD) to the criterion, which make the algorithm more effective; for nonlinear separated problems, we extend the kernel extension of FMMC with positive definite kernels. The effective of the novel criterion for linear and nonlinear separated problems is illustrated by experiments. }}
@article{Altun201531,
title = {Recognizing affect in human touch of a robot },
journal = {Pattern Recognition Letters },
volume = {66},
number = {},
pages = {31 - 40},
year = {2015},
note = {Pattern Recognition in Human Computer Interaction },
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2014.10.016},
url = {http://www.sciencedirect.com/science/article/pii/S016786551400333X},
author = {Kerem Altun and Karon E. MacLean},
abstract = {Abstract A pet cat or dog’s ability to respond to our emotional state opens an interaction channel with high visceral impact, which social robots may also be able to access. Touch is a key but understudied element; here, we explore its emotional content in the context of a furry robot pet. We asked participants to imagine feeling nine emotions located in a 2-D arousal-valence affect space, then to express them by touching a lap-sized robot prototype equipped with pressure sensors and accelerometer. We found overall correct classification (Random Forests) within the 2-D grid of 36% (all participants combined) and 48% (average of participants classified individually); chance 11%. Rates rose to 56% in the high arousal zone. To better understand classifier performance, we defined and analyzed new metrics that better indicate closeness of the gestural expressions. We also present a method to combine direct affect recognition with affect inferred from gesture recognition. This analysis provides a unique first insight into the nature and quality of affective touch, with implications as a design tool and for incorporating unintrusive affect sensing into deployed interactions. }}
@article{Bernacki201473,
title = {Stability and change in adolescents’ task-specific achievement goals and implications for learning mathematics with intelligent tutors },
journal = {Computers in Human Behavior },
volume = {37},
number = {},
pages = {73 - 80},
year = {2014},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2014.04.009},
url = {http://www.sciencedirect.com/science/article/pii/S0747563214002180},
author = {Matthew L. Bernacki and Vincent Aleven and Timothy J. Nokes-Malach},abstract = {Abstract Individuals’ achievement goals are known to influence learning behaviors and academic achievement. However, prior research also indicates that undergraduates’ achievement goals for psychology coursework vary from assignment to assignment. The effect of stability of achievement goals on learning behaviors and outcomes has yet to be explored. This study examined how adolescents’ achievement goals varied over mathematics units completed in an intelligent tutoring system, and whether strength or variability in achievement goals influenced behavior or achievement. At the group level, achievement goals correlated significantly from unit to unit; mean scores were not significantly different over time. However, individuals’ goal scores changed reliably across units. No relationships were found between the strength of students’ achievement goal scores and learning behaviors or performance. However, students with stable mastery approach goals achieved better grades than those with more variable mastery-approach goals. Students with stable performance-approach goals engaged in fewer help-seeking behaviors than those with variable performance approach goals. }}
@article{Chandler2009389,
title = {Dynamic visualisations and hypermedia: Beyond the Wow factor },
journal = {Computers in Human Behavior },
volume = {25},
number = {2},
pages = {389 - 392},
year = {2009},
note = {Including the Special Issue: State of the Art Research into Cognitive Load Theory },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2008.12.018},
url = {http://www.sciencedirect.com/science/article/pii/S074756320800229X},
author = {Paul Chandler},
abstract = {Dynamic visualisations and hypermedia have the potential to transform how we design instruction and can lead to highly innovative and flexible learning environments. However, their continued success largely depends on the importance placed by designers on the cognitive processes crucial to the learning process. This discussion paper examines the findings of six papers which increase our knowledge of how we can use dynamic visualisations and hypermedia to generate powerful learning solutions. }}
@article{Leopold201216,
title = {Science text comprehension: Drawing, main idea selection, and summarizing as learning strategies },
journal = {Learning and Instruction },
volume = {22},
number = {1},
pages = {16 - 26},
year = {2012},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2011.05.005},
url = {http://www.sciencedirect.com/science/article/pii/S0959475211000429},
author = {Claudia Leopold and Detlev Leutner},
abstract = {The purpose of two experiments was to contrast instructions to generate drawings with two text-focused strategies—main idea selection (Exp. 1) and summarization (Exp. 2)—and to examine whether these strategies could help students learn from a chemistry science text. Both experiments followed a 2 × 2 design, with drawing strategy instructions (yes vs. no) and main idea/summarization strategy instructions (yes vs. no) as experimental factors. The main dependent variable was science text comprehension, measured by a multiple-select test and a transfer test. Participants were 90 (Exp. 1) and 71 (Exp. 2) students (grade 10). The results of both experiments showed positive effects of the drawing strategy instructions and negative effects of the text-focused strategy instructions without interactions. These results are consistent with the mental model approach to comprehension, showing advantages of drawing activity in fostering science text comprehension. }}
@article{Kalelioğlu2015200,
title = {A new way of teaching programming skills to K-12 students: Code.org },
journal = {Computers in Human Behavior },
volume = {52},
number = {},
pages = {200 - 210},
year = {2015},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2015.05.047},
url = {http://www.sciencedirect.com/science/article/pii/S0747563215004288},
author = {Filiz Kalelioğlu},



abstract = {Abstract This study attempts to investigate the effect of teaching code.org site on reflective thinking skills towards problem solving. More specifically, this study attempts to investigate whether there is a gender difference in terms of students’ reflective thinking skills towards problem solving. This triangulation study was conducted with 32 primary school students. The quantitative part of the study was conducted in pre-test/post-test comparison design of quasi-experimental design. The scores of reflective problem solving skills were gathered through the reflective thinking skill scale towards problem solving and the students’ performances in the code-org site were examined. In the qualitative part of the research, after the five-week experimental process, focus group interviews were conducted with ten students and a reflection paper from the IT teacher was analysed. According to the t-test results, teaching programming to primary school students in the code.org site did not cause any differences in reflective thinking skills towards problem solving. However, there is a slight increment in the means of female students’ reflective thinking skills towards problem solving over the males’ reflective thinking skills towards problem solving. On the other hand, qualitative data provided more information about the students’ experiences. Students developed a positive attitude towards programming, and female students showed that they were as successful as their male counterparts, and that programming could be part of their future plans. }}
@article{Kampf2015541,
title = {Do computer games enhance learning about conflicts? A cross-national inquiry into proximate and distant scenarios in Global Conflicts },
journal = {Computers in Human Behavior },
volume = {52},
number = {},
pages = {541 - 549},
year = {2015},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2014.08.008},
url = {http://www.sciencedirect.com/science/article/pii/S0747563214004361},
author = {Ronit Kampf and Esra Cuhadar},

abstract = {Abstract Interactive conflict resolution and peace education have developed as two major lines of practice to tackle intractable inter-group conflicts. Recently, new media technologies such as social media, computer games, and online dialogue are added to the existing set of tools used for peace education. However, a debate is emerging as to how effective they are in motivating learning and teaching skills required for peace building. We take issue with this question and have conducted a study investigating the effect of different conflict contexts on student learning. We have designed a cross-national experimental study with Israeli-Jewish, Palestinian, and Guatemalan undergraduate students using the Israeli–Palestinian and Guatemalan scenarios in the computer game called Global Conflicts. The learning effects of these scenarios were systematically analyzed using pre- and post-test questionnaires. The study indicated that Israeli-Jews and Palestinians acquired more knowledge from the Guatemalan game than Guatemalans acquired from the Israeli–Palestinian game. All participants acquired knowledge about proximate conflicts after playing games about these scenarios, and there were insignificant differences between the three national groups. Israeli-Jews and Palestinians playing the Israeli–Palestinian game changed their attitudes about this conflict, while Guatemalans playing the Guatemalan game did not change their attitudes about this case. All participants changed their attitudes about distant conflicts after playing games about these scenarios. }}
@article{Cheng201412,
title = {Semi-supervised multi-graph hashing for scalable similarity search },
journal = {Computer Vision and Image Understanding },
volume = {124},
number = {},
pages = {12 - 21},
year = {2014},
note = {Large Scale Multimedia Semantic Indexing },
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2014.04.001},
url = {http://www.sciencedirect.com/science/article/pii/S1077314214000794},
author = {Jian Cheng and Cong Leng and Peng Li and Meng Wang and Hanqing Lu},abstract = {Abstract Due to the explosive growth of the multimedia contents in recent years, scalable similarity search has attracted considerable attention in many large-scale multimedia applications. Among the different similarity search approaches, hashing based approximate nearest neighbor (ANN) search has become very popular owing to its computational and storage efficiency. However, most of the existing hashing methods usually adopt a single modality or integrate multiple modalities simply without exploiting the effect of different features. To address the problem of learning compact hashing codes with multiple modality, we propose a semi-supervised Multi-Graph Hashing (MGH) framework in this paper. Different from the traditional methods, our approach can effectively integrate the multiple modalities with optimized weights in a multi-graph learning scheme. In this way, the effects of different modalities can be adaptively modulated. Besides, semi-supervised information is also incorporated into the unified framework and a sequential learning scheme is adopted to learn complementary hash functions. The proposed framework enables direct and fast handling for the query examples. Thus, the binary codes learned by our approach can be more effective for fast similarity search. Extensive experiments are conducted on two large public datasets to evaluate the performance of our approach and the results demonstrate that the proposed approach achieves promising results compared to the state-of-the-art methods. }}
@article{Tran20144113,
title = {An approach to fault diagnosis of reciprocating compressor valves using Teager–Kaiser energy operator and deep belief networks },
journal = {Expert Systems with Applications },
volume = {41},
number = {9},
pages = {4113 - 4122},
year = {2014},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2013.12.026},
url = {http://www.sciencedirect.com/science/article/pii/S0957417413010014},
author = {Van Tung Tran and Faisal AlThobiani and Andrew Ball},abstract = {Abstract This paper presents an approach to implement vibration, pressure, and current signals for fault diagnosis of the valves in reciprocating compressors. Due to the complexity of structure and motion of such compressor, the acquired vibration signal normally involves transient impacts and noise. This causes the useful information to be corrupted and difficulty in accurately diagnosing the faults with traditional methods. To reveal the fault patterns contained in this signal, the Teager–Kaiser energy operation (TKEO) is proposed to estimate the amplitude envelopes. In case of pressure and current, the random noise is removed by using a denoising method based on wavelet transform. Subsequently, statistical measures are extracted from all signals to represent the characteristics of the valve conditions. In order to classify the faults of compressor valves, a new type of learning architecture for deep generative model called deep belief networks (DBNs) is applied. DBN employs a hierarchical structure with multiple stacked restricted Boltzmann machines (RBMs) and works through a greedy layer-by-layer learning algorithm. In pattern recognition research areas, DBN has proved to be very effective and provided with high performance for binary values. However, for implementing DBN to fault diagnosis where most of signals are real-valued, RBM with Bernoulli hidden units and Gaussian visible units is considered in this study. The proposed approach is validated with the signals from a two-stage reciprocating air compressor under different valve conditions. To confirm the superiority of DBN in fault classification, its performance is compared with that of relevant vector machine and back propagation neuron networks. The achieved accuracy indicates that the proposed approach is highly reliable and applicable in fault diagnosis of industrial reciprocating machinery. }}
@article{Inglese200767,
title = {Using audiovisual TV interviews to create visible authors that reduce the learning gap between native and non-native language speakers },
journal = {Learning and Instruction },
volume = {17},
number = {1},
pages = {67 - 77},
year = {2007},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2006.11.006},
url = {http://www.sciencedirect.com/science/article/pii/S0959475206001204},
author = {Terry Inglese and Richard E. Mayer and Francesca Rigotti},
abstract = {Can archives of audiovisual TV interviews be used to make authors more visible to students, and thereby reduce the learning gap between native and non-native language speakers in college classes? We examined students in a college course who learned about one scholar's ideas through watching an audiovisual TV interview (i.e., visible author format) and about another scholar's ideas through reading a formal text description (i.e., invisible author format). For the invisible author, native language speakers scored significantly higher than the non-native language speakers on a corresponding exam question (i.e., a cognitive measure), generated more words on the exam question (i.e., a motivational measure), and mentioned the author's name more often in answering the exam question (i.e., an affective measure). For the visible author, the groups did not differ on any of these measures. These findings provide evidence for the idea that making the author visible through audiovisual TV interviews can eliminate the learning gap between native and non-native language speakers. }}
@article{Puntambekar2006332,
title = {Analyzing collaborative interactions: divergence, shared understanding and construction of knowledge },
journal = {Computers & Education },
volume = {47},
number = {3},
pages = {332 - 351},
year = {2006},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2004.10.012},
url = {http://www.sciencedirect.com/science/article/pii/S0360131504001563},
author = {Sadhana Puntambekar},abstract = {One of the most important facets of collaborative learning is the interaction between individual and collaborative learning activities – between divergent perspectives and shared knowledge building. Individuals bring divergent ideas into a collaborative environment. While individuals bring their own unique knowledge and perspectives, the second important aspect of collaborative learning is how they move from seemingly divergent perspectives to collaborative knowledge building. This is clearly a social process among group members who could adopt various strategies for resolving differences including asserting dominance, acquiescing, or some form of reciprocal sense making. An important aspect of collaborative learning is the move from assimilation to construction, i.e., creating new understandings based on the discussions that they have had. Documenting this change from divergence to collaborative knowledge building to possible construction is therefore important in understanding the nature the collaborative interactions. In this paper we discuss our analysis of the process of collaborative interactions based on three dimensions – divergence of ideas, collaborative knowledge building and construction. Our aim was to document as well as to understand how collaborative interactions develop over time: whether students raise new issues (ideas) more frequently as they become more familiar with the discussion and discussants, and whether shared knowledge building becomes richer over time, and subsequent evidence that students were able to construct their own understanding based on their interactions with others. Our analyses were conducted in the context of an online graduate course conducted using the learning environment that we designed, CoDE, (Constructivist, Distributed learning Environment). In this paper, we will first describe the design of CoDE. We will then describe a study in which CoDE was used to offer an online graduate course in learning theories. We then discuss our analyses of both individual and collaborative learning as it progressed through the duration of the course. }}
@article{Brown201511,
title = {On unifiers, diversifiers, and the nature of pattern recognition },
journal = {Pattern Recognition Letters },
volume = {64},
number = {},
pages = {11 - 20},
year = {2015},
note = {},
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2015.04.014},
url = {http://www.sciencedirect.com/science/article/pii/S0167865515001312},
author = {Gavin Brown},abstract = {Abstract We study a dichotomy of scientific styles, unifying and diversifying, as proposed by Freeman J. Dyson. We discuss the extent to which the dichotomy transfers from the natural sciences (where Dyson proposed it) to the field of Pattern Recognition. To address this we must firstly ask what it means to be a unifier or diversifier in a field, and what are the relative merits of each style of thinking. Secondly, given that Dyson applied this to the sciences, does it also apply in a field known to be a blend of science and engineering? Parallels are drawn to Platonic/Aristotelian views, and to Cartesian/Baconian science, and questions are asked on what drives the Kuhnian paradigm shifts of our field. This article is intended not to marginalise individuals into categories (unifier/diversifier) but instead to demonstrate the utility of philosophical reflection on our field, showing the depth and complexities a seemingly simple idea can unearth. }}
@article{Schrire200649,
title = {Knowledge building in asynchronous discussion groups: Going beyond quantitative analysis },
journal = {Computers & Education },
volume = {46},
number = {1},
pages = {49 - 70},
year = {2006},
note = {Methodological Issues in Researching CSCL },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2005.04.006},
url = {http://www.sciencedirect.com/science/article/pii/S0360131505000539},
author = {Sarah Schrire},abstract = {This contribution examines the methodological challenges involved in defining the collaborative knowledge-building processes occurring in asynchronous discussion and proposes an approach that could advance understanding of these processes. The written protocols that are available to the analyst provide an exact record of the instructional transactions at a given time in the online discussion. On the basis of a study of online discussion forums used in a higher education context, a model for the analysis of collaborative knowledge building in asynchronous discussion is presented. The model allows examination of the communication from the multiple perspectives of interaction, cognition and discourse analysis. The investigation was conducted using a qualitative case study approach and involved an in-depth examination of three cases. Content analysis of the discourse was done at a number of levels, focusing on the discussion forum itself, the discussion threads, the messages, and the exchanges and moves among the messages. As a result of correspondences found among the variables representing the different levels of the analysis, the most important being the relationship between type of interaction, phase of critical inquiry, and move in the exchange structure, it was possible to build a scheme for assessing knowledge building in asynchronous discussion groups. The scheme integrates the interactive, cognitive and discourse dimensions in computer-supported collaborative learning (CSCL). The study represents a merging of quantitative analysis within qualitative methodology and provides both an analytic and a holistic perspective on CSCL. }}
@article{Ghazanfari201661,
title = {Extracting bottlenecks for reinforcement learning agent by holonic concept clustering and attentional functions },
journal = {Expert Systems with Applications },
volume = {54},
number = {},
pages = {61 - 77},
year = {2016},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2016.01.030},
url = {http://www.sciencedirect.com/science/article/pii/S0957417416000403},
author = {Behzad Ghazanfari and Nasser Mozayani},
abstract = {Abstract Reinforcement learning is not well scalable in state spaces with high-dimensions. The hierarchical reinforcement learning resolves this problem by task decomposition. Task decomposition is done by extracting bottlenecks, which is in turn another challenging issue, especially in terms of time and memory complexity and the need to the prior knowledge of the environment. To alleviate these issues, a new approach is proposed toward the problem of extracting bottlenecks. Holonic concept clustering and attentional functions are proposed to extract bottleneck states. To this end, states are organized based on the effects of actions by means of a holonic clustering to extract high-level concepts. High-level concepts are used as cues for controlling attention. The proposed mechanism has a better time complexity and fewer requirements to the designer's help. The experimental results showed a considerable improvement in the precision of bottleneck detection and agent's performance for traditional benchmarks comparing to other similar methods. }}
@article{Lee201652,
title = {Collaborative expression representation using peak expression and intra class variation face images for practical subject-independent emotion recognition in videos },
journal = {Pattern Recognition },
volume = {54},
number = {},
pages = {52 - 67},
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.12.016},
url = {http://www.sciencedirect.com/science/article/pii/S0031320316000108},
author = {Seung Ho Lee and Wissam J. Baddar and Yong Man Ro},
abstract = {Abstract This paper proposes a facial expression recognition (FER) method in videos. The proposed method automatically selects the peak expression face from a video sequence using closeness of the face to the neutral expression. The severely non-frontal faces and poorly aligned faces are discarded in advance to eliminate their negative effects on the peak expression face selection and FER. To reduce the effect of the facial identity in the feature extraction, we compute difference information between the peak expression face and its intra class variation (ICV) face. An ICV face is generated by combining the training faces of an expression class and looks similar to the peak expression face in identity. Because the difference information is defined as the distances of locally pooled texture features between the two faces, the feature extraction is robust to face rotation and mis-alignment. Results show that the proposed method is practical with videos containing spontaneous facial expressions and pose variations. }}
@article{Pontes201634,
title = {A flexible hierarchical approach for facial age estimation based on multiple features },
journal = {Pattern Recognition },
volume = {54},
number = {},
pages = {34 - 51},
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.12.003},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315004458},
author = {Jhony K. Pontes and Alceu S. Britto Jr and Clinton Fookes and Alessandro L. Koerich},

abstract = {Abstract Age estimation from facial images is increasingly receiving attention to solve age-based access control, age-adaptive targeted marketing, amongst other applications. Since even humans can be induced in error due to the complex biological processes involved, finding a robust method remains a research challenge today. In this paper, we propose a new framework for the integration of Active Appearance Models (AAM), Local Binary Patterns (LBP), Gabor wavelets (GW) and Local Phase Quantization (LPQ) in order to obtain a highly discriminative feature representation which is able to model shape, appearance, wrinkles and skin spots. In addition, this paper proposes a novel flexible hierarchical age estimation approach consisting of a multi-class Support Vector Machine (SVM) to classify a subject into an age group followed by a Support Vector Regression (SVR) to estimate a specific age. The errors that may happen in the classification step, caused by the hard boundaries between age classes, are compensated in the specific age estimation by a flexible overlapping of the age ranges. The performance of the proposed approach was evaluated on FG-NET Aging and MORPH Album 2 datasets and a mean absolute error (MAE) of 4.50 and 5.86 years was achieved respectively. The robustness of the proposed approach was also evaluated on a merge of both datasets and a MAE of 5.20 years was achieved. Furthermore, we have also compared the age estimation made by humans with the proposed approach and it has shown that the machine outperforms humans. The proposed approach is competitive with current state-of-the-art and it provides an additional robustness to blur, lighting and expression variance brought about by the local phase features. }}
@article{Magana2016427,
title = {A case study of undergraduate engineering students' computational literacy and self-beliefs about computing in the context of authentic practices },
journal = {Computers in Human Behavior },
volume = {61},
number = {},
pages = {427 - 442},
year = {2016},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2016.03.025},
url = {http://www.sciencedirect.com/science/article/pii/S0747563216301868},
author = {Alejandra J. Magana and Michael L. Falk and Camilo Vieira and Michael J. Reese Jr.},abstract = {Abstract Engineering students, as compared to computing-related majors, are not traditionally introduced to computing in the context of authentic learning experiences, i.e., real-world applications within their discipline. This paper identifies the impact of computation delivered by authentic learning experiences in the form of anchored instruction on students' self-beliefs and their capacity to leverage computation to acquire disciplinary concepts in subsequent computationally-based engineering coursework. This case study included 130 students with different programing preparation (authentic or traditional), who were exposed to computational learning modules. Control-Value Theory of Achievement Emotions is the conceptual framework that guided the evaluation of this investigation. Measures included student self-beliefs such as control and value appraisals, and their relationship with academic performance. Results suggest that programming preparation presented in an authentic engineering context provides an important foundation that goes beyond increasing students' control self-beliefs. This preparation seems to effectively enable students to leverage computational practices for the purpose of acquiring disciplinary concepts. Implications for teaching relate to the integration of computation sooner, more often and within a disciplinary context in the undergraduate engineering curriculum. Implications for learning relate to fostering engineering computational literacy guided by anchored instruction to support disciplinary problem solving. }}
@article{Wäschle2014120,
title = {Effects of visual feedback on medical students’ procrastination within web-based planning and reflection protocols },
journal = {Computers in Human Behavior },
volume = {41},
number = {},
pages = {120 - 136},
year = {2014},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2014.09.022},
url = {http://www.sciencedirect.com/science/article/pii/S0747563214004749},
author = {Kristin Wäschle and Andreas Lachner and Björn Stucke and Sabine Rey and Cornelius Frömmel and Matthias Nückles},
abstract = {Abstract Procrastination is a very common problem among students that results from ineffective selfregulation. In two field-experimental studies (N = 18 and N = 49), we investigated whether visual feedback on students’ previous procrastination was effective in provoking a decrease in students’ future procrastination as well as improvements in self-regulated learning. The visual feedback was implemented as a dynamic line chart in a web-based planning and reflection protocol used once a week by medical students to record their class preparation and homework once a week. In the protocols, the students planned and reflected on their personal learning processes and they estimated retrospectively their inclination to procrastinate. The results of both studies consistently showed that presenting students a line chart that adaptively visualizes the course and extent of their self-reported previous procrastination led to a statistically significant and practically relevant decrease in their future procrastination. Furthermore, the visualization had positive effects on other variables central to self-regulated learning. The studies provide converging evidence that the inclination to procrastinate can successfully be counteracted both by a parsimonious and easy-to-implement method. They are suggestive of ways how Internet technology can be used support students’ self-regulated learning. }}
@article{Shen20153227,
title = {On robust image spam filtering via comprehensive visual modeling },
journal = {Pattern Recognition },
volume = {48},
number = {10},
pages = {3227 - 3238},
year = {2015},
note = {Discriminative Feature Learning from Big Data for Visual Recognition },
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.02.027},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315000874},
author = {Jialie Shen and Robert H. Deng and Zhiyong Cheng and Liqiang Nie and Shuicheng Yan},abstract = {Abstract The Internet has brought about fundamental changes in the way peoples generate and exchange media information. Over the last decade, unsolicited message images (image spams) have become one of the most serious problems for Internet service providers (ISPs), business firms and general end users. In this paper, we report a novel system called RoBoTs (Robust BoosTrap based spam detector) to support accurate and robust image spam filtering. The system is developed based on multiple visual properties extracted from different levels of granularity, aiming to capture more discriminative contents for effective spam image identification. In addition, a resampling based learning framework is developed to effectively integrate random forest and linear discriminative analysis (LDA) to generate comprehensive signature of spam images. It can facilitate more accurate and robust spam classification process with very limited amount of initial training examples. Using three public available test collections, the proposed system is empirically compared with the state-of-the-art techniques. Our results demonstrate its significantly higher performance from different perspectives. }}
@article{Brun2015,
title = {Action Recognition by using kernels on aclets sequences },
journal = {Computer Vision and Image Understanding },
volume = {},
number = {},
pages = { - },
year = {2015},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2015.09.003},
url = {http://www.sciencedirect.com/science/article/pii/S1077314215001988},
author = {Luc Brun and Gennaro Percannella and Alessia Saggese and Mario Vento},abstract = {Abstract In this paper we propose a method for human action recognition based on a string kernel framework. An action is represented as a string, where each symbol composing it is associated to an aclet, that is an atomic unit of the action encoding a feature vector extracted from raw data. In this way, measuring similarities between actions leads to design a similarity measure between strings. We propose to define this string’s similarity using the global alignment kernel framework. In this context, the similarity between two aclets is computed by a novel soft evaluation method based on an enhanced gaussian kernel. The main advantage of the proposed approach lies in its ability to effectively deal with actions of different lengths or different temporal scales as well as with noise introduced during the features extraction step. The proposed method has been tested over three publicly available datasets, namely the MIVIA, the CAD and the MHAD, and the obtained results, compared with several state of the art approaches, confirm the effectiveness and the applicability of our system in real environments, where unexperienced operators can easily configure it. }}
@article{Schoor2011560,
title = {Motivation in a computer-supported collaborative learning scenario and its impact on learning activities and knowledge acquisition },
journal = {Learning and Instruction },
volume = {21},
number = {4},
pages = {560 - 573},
year = {2011},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2010.11.002},
url = {http://www.sciencedirect.com/science/article/pii/S0959475210000976},
author = {Cornelia Schoor and Maria Bannert},
abstract = {Addressing a drawback in current research on computer-supported collaborative learning (CSCL), this study investigated the influence of motivation on learning activities and knowledge acquisition during CSCL. Participants’ (N = 200 university students) task was to develop a handout for which they had first an individual preparing phase followed by a computer-supported collaborative learning phase immediately afterwards. It was hypothesized that in both phases current motivation (in terms of expectancy and value components) influences both learning activities and knowledge acquisition in a positive way. According to main results, only goal orientations (before learning) were associated with knowledge acquisition respectively observed learning activities during the collaborative phase. Expectancy and value components of current motivation related neither to observed learning activities nor to knowledge acquisition during collaborative learning but were in part associated with learning activities and knowledge acquisition during individual learning. The discussion addresses several possible explanations for these unexpected results. }}
@article{Milentijevic20081331,
title = {Version control in project-based learning },
journal = {Computers & Education },
volume = {50},
number = {4},
pages = {1331 - 1338},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2006.12.010},
url = {http://www.sciencedirect.com/science/article/pii/S0360131506001977},
author = {Ivan Milentijevic and Vladimir Ciric and Oliver Vojinovic},
abstract = {This paper deals with the development of a generalized model for version control systems application as a support in a range of project-based learning methods. The model is given as UML sequence diagram and described in detail. The proposed model encompasses a wide range of different project-based learning approaches by assigning a supervisory role either to instructor or students in different project stages. Different strategies for supervisor role assignment are given. Project duration, project milestones, as well as a number of team members are discussed in respect to project-based learning method that the proposed model supports. Possible implementations of different project-based learning approaches on the proposed model are demonstrated by setting the model parameters. Version control server security issues are discussed in the manner of implementation aspects of the proposed model. One of possible model implementations is evaluated in respect of cooperation on the test group of 21 students. Implementation details are presented and compared with other approaches. Mentoring and monitoring students efforts during the development by implementing proposed model with specific model settings introduces controlled cooperation with high clarity in evaluation of individual students work. Using open source version control software on Linux platform, with web interface package, we implemented a low-cost support for project-based learning. }}
@article{BrandGruwel2008615,
title = {Instructional support for enhancing students’ information problem solving ability },
journal = {Computers in Human Behavior },
volume = {24},
number = {3},
pages = {615 - 622},
year = {2008},
note = {Instructional Support for Enhancing Students' Information Problem Solving Ability },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2007.01.020},
url = {http://www.sciencedirect.com/science/article/pii/S0747563207000313},
author = {Saskia Brand-Gruwel and Peter Gerjets},
abstract = {This special issue discusses European research on instructional support to foster students’ ability to solve information-based problems. In this introduction, the concept of information problem solving (IPS) and research in this field of interest will be placed in the broader perspective, which is called information behavior. The focus of this special issue is an educational one and the papers all go into a specific kind of instructional support. The main research questions, findings and conclusions of the six contributions will be outlined. It is concluded that the most important directions for future research deal with how instructional support for different aspect of the process, like for instance how to regulated the process, best can be designed in order to make the instruction adaptive and fit to the learners needs. }}
@article{Liu2015567,
title = {Evolutionary compact embedding for large-scale image classification },
journal = {Information Sciences },
volume = {316},
number = {},
pages = {567 - 581},
year = {2015},
note = {Nature-Inspired Algorithms for Large Scale Global Optimization },
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2014.06.030},
url = {http://www.sciencedirect.com/science/article/pii/S0020025514006586},
author = {Li Liu and Ling Shao and Xuelong Li},
abstract = {Abstract Effective dimensionality reduction is a classical research area for many large-scale analysis tasks in computer vision. Several recent methods attempt to learn either graph embedding or binary hashing for fast and accurate applications. In this paper, we propose a novel framework to automatically learn the task-specific compact coding, called evolutionary compact embedding (ECE), which can be regarded as an optimization algorithm combining genetic programming (GP) and a boosting trick. As an evolutionary computation methodology, GP can solve problems inspired by natural evolution without any prior knowledge of the solutions. In our evolutionary architecture, each bit of ECE is iteratively computed using a binary classification function, which is generated through GP evolving by jointly minimizing its empirical risk with the AdaBoost strategy on a training set. We address this as greedy optimization leading to small Hamming distances for similar samples and large distances for dissimilar samples. We then evaluate ECE on four image datasets: USPS digital hand-writing, CMU PIE face, CIFAR-10 tiny image and SUN397 scene, showing the accurate and robust performance of our method for large-scale image classification. }}
@article{Caspi2008718,
title = {Participation in class and in online discussions: Gender differences },
journal = {Computers & Education },
volume = {50},
number = {3},
pages = {718 - 724},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2006.08.003},
url = {http://www.sciencedirect.com/science/article/pii/S0360131506001229},
author = {Avner Caspi and Eran Chajut and Kelly Saporta},abstract = {Gender differences between participation in face-to-face and web-based classroom discussions were examined, by comparing the men–women actual participation ratio to the men–women attendance (or login) ratio. It was found that men over-proportionally spoke at the face-to-face classroom whereas women over-proportionally posted messages in the web-based conference. Two alternative explanations are discussed. It is suggested that either women prefer written communication more than men do, or that women prefer written communication over spoken communication. Nonetheless, despite some advantages of virtual discussions, especially for women, the online environment is apparently not attractive enough for either gender. }}
@article{Fransen20111103,
title = {Mediating team effectiveness in the context of collaborative learning: The importance of team and task awareness },
journal = {Computers in Human Behavior },
volume = {27},
number = {3},
pages = {1103 - 1113},
year = {2011},
note = {Group Awareness in CSCL Environments },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2010.05.017},
url = {http://www.sciencedirect.com/science/article/pii/S074756321000155X},
author = {Jos Fransen and Paul A. Kirschner and Gijsbert Erkens},
abstract = {Learning teams in higher education executing a collaborative assignment are not always effective. To remedy this, there is a need to determine and understand the variables that influence team effectiveness. This study aimed at developing a conceptual framework, based on research in various contexts on team effectiveness and specifically team and task awareness. Core aspects of the framework were tested to establish its value for future experiments on influencing team effectiveness. Results confirmed the importance of shared mental models, and to some extent mutual performance monitoring for learning teams to become effective, but also of interpersonal trust as being conditional for building adequate shared mental models. Apart from the importance of team and task awareness for team effectiveness it showed that learning teams in higher education tend to be pragmatic by focusing primarily on task aspects of performance and not team aspects. Further steps have to be taken to validate this conceptual framework on team effectiveness. }}
@article{Joksimović2015204,
title = {Learning at distance: Effects of interaction traces on academic achievement },
journal = {Computers & Education },
volume = {87},
number = {},
pages = {204 - 217},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.07.002},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515300075},
author = {Srećko Joksimović and Dragan Gašević and Thomas M. Loughin and Vitomir Kovanović and Marek Hatala},abstract = {Abstract Contemporary literature on online and distance education almost unequivocally argues for the importance of interactions in online learning settings. Nevertheless, the relationship between different types of interactions and learning outcomes is rather complex. Analyzing 204 offerings of 29 courses, over the period of six years, this study aimed at expanding the current understanding of the nature of this relationship. Specifically, with the use of trace data about interactions and utilizing the multilevel linear mixed modeling techniques, the study examined whether frequency and duration of student–student, student–instructor, student–system, and student–content interactions had an effect of learning outcomes, measured as final course grades. The findings show that the time spent on student–system interactions had a consistent and positive effect on the learning outcome, while the quantity of student–content interactions was negatively associated with the final course grades. The study also showed the importance of the educational level and the context of individual courses for the interaction types supported. Our findings further confirmed the potential of the use of trace data and learning analytics for studying learning and teaching in online settings. However, further research should account for various qualitative aspects of the interactions used while learning, different pedagogical/media features, as well as for the course design and delivery conditions in order to better explain the association between interaction types and the learning achievement. Finally, the results might imply the need for the development of the institutional and program-level strategies for learning and teaching that would promote effective pedagogical approaches to designing and guiding interactions in online and distance learning settings. }}
@article{PérezSanagustín201570,
title = {Lessons learned from the design of situated learning environments to support collaborative knowledge construction },
journal = {Computers & Education },
volume = {87},
number = {},
pages = {70 - 82},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.03.019},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515000974},
author = {Mar Pérez-Sanagustín and Pedro J. Muñoz-Merino and Carlos Alario-Hoyos and Xavier Soldani and Carlos Delgado Kloos},
abstract = {Abstract The main characteristics of situated learning environments (SLEs) are: to provide authentic contexts, activities, expert performances and integrated assessment; to support multiple roles and perspectives, collaborative knowledge construction, coaching and scaffolding; and to promote reflection and articulation. However, current SLEs have two limitations: (1) not all of these characteristics are included, particularly lacking collaborative knowledge construction, in most cases; and (2) most SLEs are designed to support learning activities outdoors, but not indoors. This paper presents the implementation of an SLE that overcomes these two limitations. This SLE is based on bidirectional Quick Response (QR) codes, which are enhanced QR codes that not only provide information when scanned but also collect user-generated content. This Bidirectional SLE is evaluated in an experiment in which it is compared with an equivalent Traditional SLE, which is built upon traditional QR codes. The purpose of this comparison is to understand if using bidirectional QR codes as a mechanism to support collaborative knowledge construction in indoor settings has an impact on students' learning outcomes and on their impression of the learning experience. Two hundred fifty-three students participated in this experiment. Data collected from this experiment indicate that the students who worked in the Bidirectional SLE (1) received better scores, providing better and more complete answers, and (2) evaluated their learning experience better than their peers' who worked in the Traditional SLE. Finally, a cross-analysis of these results including teachers' opinions led to a set of lessons learned about the design of SLEs to support collaborative knowledge construction. }}
@article{SerranoCámara2014499,
title = {An evaluation of students’ motivation in computer-supported collaborative learning of programming concepts },
journal = {Computers in Human Behavior },
volume = {31},
number = {},
pages = {499 - 508},
year = {2014},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2013.04.030},
url = {http://www.sciencedirect.com/science/article/pii/S0747563213001428},
author = {Luis Miguel Serrano-Cámara and Maximiliano Paredes-Velasco and Carlos-María Alcover and J. Ángel Velazquez-Iturbide},
abstract = {Abstract Motivation is a very important factor for successful instruction. This factor is especially relevant in collaborative learning contexts, where social interaction plays an important role. In this paper we present an evaluation of motivation in 139 students who were instructed under four pedagogical approaches: traditional lecture, collaborative learning, collaborative learning guided by CIF (an instructional framework for collaborative learning), and collaborative learning guided by CIF and supported by MoCAS (a collaborative learning tool). We considered the four dimensions of motivation according to self-determination theory. The statistical results show that, in global terms, students were more motivated by jointly using the collaborative instructional approach CIF and the MoCAS tool than by using a collaborative approach. Detailed analysis of the different kinds of motivation yields mixed results. Students who were instructed with CIF and especially those students instructed with CIF and MoCAS exhibited higher intrinsic motivation. Furthermore, students instructed with CIF and MoCAS were the most extrinsically motivated via identified regulation. With respect to extrinsic motivation via external regulation, students instructed in a traditional, individual way were more motivated than students instructed collaboratively. Finally, high levels of amotivation were also associated to instruction using CIF and MoCAS. In summary, our results suggest that CIF and MoCAS are associated with high levels of intrinsic and extrinsic motivation, a finding that can aid in improving the learning processes, but they are also, unexpectedly, associated with amotivation, suggesting an overall increase in activation in the students who show mixed motivators. }}
@article{Tobarra2014659,
title = {Analyzing the students’ behavior and relevant topics in virtual learning communities },
journal = {Computers in Human Behavior },
volume = {31},
number = {},
pages = {659 - 669},
year = {2014},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2013.10.001},
url = {http://www.sciencedirect.com/science/article/pii/S0747563213003518},
author = {Llanos Tobarra and Antonio Robles-Gómez and Salvador Ros and Roberto Hernández and Agustín C. Caminero},abstract = {Abstract The constant development of new Internet platforms is shifting the users’ role of such platforms, from viewers to main actors. In the field of education, faculty can take advantage of these new technologies for the design of pedagogical contents. The face-to-face observation of behavioral patterns allows faculty to detect and track new problems, and to apply possible corrections which would improve the learning/teaching process. However, with a distance methodology, these observations are not possible. When forums are created they are intended to discuss particular topics. It is relevant to monitor that the topics discussed are the intended ones in order to achieve course objectives. To tackle this shortcoming, our work studies the dynamics of relevant topics in on-line asynchronous discussion forums, and this is done by analyzing the large amount of students’ interactions generated in the forums of our Learning Management System (LMS). In particular, we analyze the students’ behavior patterns in the forums of a distance subject, and characterize the relevant topics and subtopics from the forums’ messages belonging to two academic years. From the statistical and graphical results obtained, a set of valuable recommendations are also given. }}
@article{Reychav201443,
title = {Exploring mobile tablet training for road safety: A uses and gratifications perspective },
journal = {Computers & Education },
volume = {71},
number = {},
pages = {43 - 55},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.09.005},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513002601},
author = {Iris Reychav and Dezhi Wu},abstract = {Abstract Traffic injuries are predicted to be the fifth leading cause of death and injury by 2030 if no further action is taken. Generation Y, who are growing up with technology and Internet, are among the most vulnerable road users, so it is crucial to provide effective road safety training for them. In the light of the Uses and Gratification Theory (U&amp;G), we propose a conceptual research model to measure how users' different needs and gratifications with mobile technologies impact their learning outcomes. A field study with 182 young drivers who participated in a mobile road safety training program was conducted just before they took their license exam on site. A structural equation modeling (SEM) approach was utilized to test the research model. Perceived information needs, user preference, and innovativeness were found to have significant mediating relationships with user perceived multimedia enjoyment, and effectively promoted higher-order learning outcomes. The discussion focuses on the importance of designing multimedia content with the latest mobile technologies to effectively engage young users. }}
@article{Judd2014194,
title = {Making sense of multitasking: The role of Facebook },
journal = {Computers & Education },
volume = {70},
number = {},
pages = {194 - 202},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.08.013},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513002352},
author = {Terry Judd},
abstract = {Abstract Media multitasking and Facebook use are commonplace among college and university-aged students. While the two are often linked and each has been independently associated with reductions in academic performance, their relationship to each other is not particularly well understood. This relationship was examined by analysing comprehensive time-based logs of students' computer-based tasks, including Facebook, during unsupervised, self-directed learning sessions. A total of 3372 sessions contributed by 1249 students were analysed. Multitasking was extremely common – around 99% of sessions involved some multitasking (at least three instances of a particular task within a 20 min period). Facebook was the second most common task overall (University was first), accounting for 9.2% of all task instances and being present in 44% of sessions. Sessions containing Facebook typically contained more, shorter duration tasks and were significantly more likely to include multitasking behaviour. The introduction of Facebook within a session was associated with an increase in multitasking and a reduction in focused (no more than two tasks in a 20 min period) behaviour. Facebook users (students who contributed at least five sessions and used Facebook in at least one of these sessions) were also more likely to multitask and less likely to engage in focused behaviour. These results confirm that Facebook use is a key contributor to students' task switching and multitasking behaviours. }}
@article{Junco20132328,
title = {Inequalities in Facebook use },
journal = {Computers in Human Behavior },
volume = {29},
number = {6},
pages = {2328 - 2336},
year = {2013},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2013.05.005},
url = {http://www.sciencedirect.com/science/article/pii/S0747563213001568},
author = {Reynol Junco},

abstract = {Abstract While research has examined digital inequalities in general Internet use, little research has examined inequalities in social networking website use. This study extends previous research by examining how Facebook use is related to student background characteristics. Analyses were conducted to assess differences in time spent and activities performed on Facebook using a large sample (N = 2359) of college students. Results showed that women were more likely to use Facebook for communication, African Americans were less likely to use Facebook to check up on their friends, and students from lower socioeconomic levels were less likely to use Facebook for communication and sharing. Implications for education, communication, and student outcomes are presented. }}
@article{Blooma2013109,
title = {Social question answering: Analyzing knowledge, cognitive processes and social dimensions of micro-collaborations },
journal = {Computers & Education },
volume = {69},
number = {},
pages = {109 - 120},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.07.006},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513001735},
author = {Mohan John Blooma and Jayan Chirayath Kurian and Alton Yeow Kuan Chua and Dion Hoe Lian Goh and Nguyen Huong Lien},

abstract = {Abstract Social question answering (SQA) services are social media applications that are dedicated platforms where users ask, answer and rate content interactively, resulting in building a community of users. SQA services are rich in micro-collaborations which are referred to as brief, informal episodes of collaborative information seeking. Micro-collaborations have gathered interest in the educational domain because of new ways of engaging students in collaborative information seeking. Previous studies in the field of computer supported collaborative learning are based on various theoretical and methodological approaches that examined different units of analysis. Yet, amid on-going research efforts, there still persist a lack of an overarching understanding on how micro-collaborations enhance collaborative learning in SQA services. Hence, this study aims to understand the distribution of knowledge, cognitive process and social dimension that learners demonstrate in micro-collaborations in a SQA service. Data was collected from Piazza, a SQA service used for teaching Java programming for bachelor students and analyzed using the integrated framework. Findings suggest that micro-collaborations in SQA services promote all the three dimensions including knowledge, cognitive process and social dimensions. The findings reveal that social dimension in micro-collaborations promote collaborative learning by enhancing community building, developing self-identity, and improving relational dynamics, which in turn support learning in various knowledge levels and improve the cognitive process in learning. This study serves as a foundation for researchers to study social dimension along with knowledge and cognitive process, to understand the dynamics of micro-collaborations involved in collaborative learning. As for practitioners, they can look into creating environments for collaborative learning rich in micro-collaborations in both physical as well as digital space. }}
@article{Johnson20101496,
title = {Individual and team annotation effects on students’ reading comprehension, critical thinking, and meta-cognitive skills },
journal = {Computers in Human Behavior },
volume = {26},
number = {6},
pages = {1496 - 1507},
year = {2010},
note = {Online Interactivity: Role of Technology in Behavior Change },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2010.05.014},
url = {http://www.sciencedirect.com/science/article/pii/S0747563210001524},
author = {Tristan E. Johnson and Thomas N. Archibald and Gershon Tenenbaum},



abstract = {Many students enter college without the needed skills to be successful. Colleges and universities are seeking instructional interventions to address these needs. Various classes are leveraging web-based social media to provide new instructional technologies that will help students learn. This paper reports on two studies related to the potential of online social annotation for improving teaching and learning in second-semester Freshman English classes. The approach, referred to as the Social Annotation Model-Learning System (SAM-LS), combines various instructional strategies, team-based learning, and a social annotation computer-supported collaborative learning tool, HyLighter, to increase student engagement with selected essays and with classmates. SAM-LS stimulates students to actively monitor their thoughts and compare them to both peers and the instructor (or domain experts). Study 1 showed no significant difference between the SAM-LS approach and a control; however, results appear to be related to confounding factors. Study 2 showed that students achieve better outcomes on measures of reading comprehension and meta-cognitive skill, but not critical thinking, when SAM-LS activities include small team collaborations. The two studies suggest future directions for research and development of SAM-LS and the HyLighter tool. }}
@article{Zhou201425,
title = {Discriminative anatomy detection: Classification vs regression },
journal = {Pattern Recognition Letters },
volume = {43},
number = {},
pages = {25 - 38},
year = {2014},
note = {ICPR2012 Awarded Papers },
issn = {0167-8655},
doi = {http://dx.doi.org/10.1016/j.patrec.2013.08.009},
url = {http://www.sciencedirect.com/science/article/pii/S0167865513003127},
author = {S. Kevin Zhou},

abstract = {Abstract Detecting a single anatomy or a plurality of anatomical objects, such as landmarks or organs, in a medical image is important yet challenging. An anatomy detection method has to address offline model learning complexity related to modeling the appearance of a single object or a plurality of objects and online computational complexity related to search or inference strategy. In the paper, we present a survey of discriminative learning methods for appearance modeling as well as their corresponding search strategies and discuss how they leverage the anatomical context embedded in the medical image for more effective and more efficient detection. }}
@article{Cheng201351,
title = {Reconsidering assessment in online/hybrid courses: Knowing versus learning },
journal = {Computers & Education },
volume = {68},
number = {},
pages = {51 - 59},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.04.022},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513001152},
author = {An-Chih Cheng and Michelle E. Jordan and Diane L. Schallert},
abstract = {Abstract This study explores the influence of assessment on students' online written discussions. A two-by-two design was used to understand students' expression of knowledge and of learning in the contexts of regular online discussions versus final test online discussions. Findings suggested that assessment had an impact on how students interacted online and in their use of rhetorical moves; and that knowing and learning are related but distinct constructs, correlated within each writing context, dissociated across contexts, and performing differentially as a function of students' perceptions of academic demands. We discuss the limitations of traditional assessment, offer an alternative approach, and conclude with practical suggestions for online/hybrid course instructors. }}
@article{Domagk20101024,
title = {Interactivity in multimedia learning: An integrated model },
journal = {Computers in Human Behavior },
volume = {26},
number = {5},
pages = {1024 - 1033},
year = {2010},
note = {Advancing Educational Research on Computer-supported Collaborative Learning (CSCL) through the use of gStudy CSCL Tools },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2010.03.003},
url = {http://www.sciencedirect.com/science/article/pii/S0747563210000439},
author = {Steffi Domagk and Ruth N. Schwartz and Jan L. Plass},

abstract = {What does interactivity entail? What factors need to be taken into account in the design of interactive systems? Although interactivity is a widely used term accorded great prominence in discussions of multimedia learning, even a preliminary look at the literature suggests that how interactivity is defined, and what benefits it may offer, are not at all clear. The goal of this article is therefore to clarify the concept of interactivity. We present a unifying model that includes the user, the learning environment, and a system of connections and concepts that together make up interactivity. Such a model can help inform research, discussion, and design decisions on interactive multimedia instruction. }}
@article{Akbari2015126,
title = {Autonomy, competence, and relatedness in foreign language learning through Facebook },
journal = {Computers in Human Behavior },
volume = {48},
number = {},
pages = {126 - 134},
year = {2015},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2015.01.036},
url = {http://www.sciencedirect.com/science/article/pii/S0747563215000503},
author = {Elham Akbari and Albert Pilot and P. Robert-Jan Simons},



abstract = {Abstract This article aims to explain differences between a group learning English on a Facebook page and a face-to-face group in terms of Self-Determination Theory (SDT). SDT focuses on three main variables, which improve self-determination and motivation outside but also inside the classroom: autonomy, competence and relatedness. The main research question was: how can we explain differences between a face-to-face group (FTF) and a Facebook group learning a foreign language in terms of autonomy, competence and relatedness? The results indicate that there was a significant difference between the two groups in terms of learning outcomes as well as in the three SDT variables. Students in the Facebook group felt more autonomous, competent and related. All three SDT variables correlated with learning outcomes. There was, however, almost no relationship among the SDT variables with learning outcomes within the two groups. The strongest predictor of the difference in learning outcomes proved to be relatedness, followed by competence. }}
@article{Burgers201594,
title = {How feedback boosts motivation and play in a brain-training game },
journal = {Computers in Human Behavior },
volume = {48},
number = {},
pages = {94 - 103},
year = {2015},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2015.01.038},
url = {http://www.sciencedirect.com/science/article/pii/S0747563215000527},
author = {Christian Burgers and Allison Eden and Mélisande D. van Engelenburg and Sander Buningh},

abstract = {Abstract Games are important vehicles for learning and behavior change as long as players are motivated to continue playing. We study the impact of verbal feedback in stimulating player motivation and future play in a brain-training game. We conducted a 2 (feedback valence: positive vs. negative) × 3 (feedback type: descriptive, comparative, evaluative) between-subjects experiment (N = 157, 69.4% female, Mage = 32.07). After playing a brain-training game and receiving feedback, we tapped players’ need satisfaction, motivation and intention to play the game again. Results demonstrate that evaluative feedback increases, while comparative feedback decreases future game play. Furthermore, negative feedback decreases players’ feeling of competence, but also increases immediate game play. Positive feedback, in contrast, satisfies competence and autonomy needs, thereby boosting intrinsic motivation. Negative feedback thus motivates players to repair poor short-term performances, while positive feedback is more powerful in fostering long-term motivation and play. }}
@article{Wu20152279,
title = {Multi-label learning with missing labels for image annotation and facial action unit recognition },
journal = {Pattern Recognition },
volume = {48},
number = {7},
pages = {2279 - 2289},
year = {2015},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.01.022},
url = {http://www.sciencedirect.com/science/article/pii/S0031320315000412},
author = {Baoyuan Wu and Siwei Lyu and Bao-Gang Hu and Qiang Ji},abstract = {Abstract Many problems in computer vision, such as image annotation, can be formulated as multi-label learning problems. It is typically assumed that the complete label assignment for each training image is available. However, this is often not the case in practice, as many training images may only be annotated with a partial set of labels, either due to the intensive effort to obtain the fully labeled training set or the intrinsic ambiguities among the classes. In this work, we propose a method for multi-label learning that explicitly handles missing labels. We train classifiers with the multi-label with missing labels (MLML) learning framework by enforcing the consistency between the predicted labels and the provided labels as well as the local smoothness among the label assignments. Experiments on three benchmark data sets in image annotation and one benchmark data set in facial action unit recognition demonstrate the improved performance of our method in comparison of several state-of-the-art methods. }}
@article{Chiu201559,
title = {The effects of augmented virtual science laboratories on middle school students' understanding of gas properties },
journal = {Computers & Education },
volume = {85},
number = {},
pages = {59 - 73},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.02.007},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515000512},
author = {Jennifer L. Chiu and Crystal J. DeJaegher and Jie Chao},abstract = {Abstract The Next Generation Science Standards (NGSS) emphasize authentic scientific practices such as developing models and constructing explanations of phenomena. However, research documents how students struggle to explain observable phenomena with molecular-level behaviors with current classroom experiences. For example, physical laboratory experiences in science enable students to interact with observable scientific phenomena, but students often fail to make connections to underlying molecular-level behaviors. Virtual laboratory experiences and computer-based visualizations enable students to interact with unobservable scientific concepts, but students can have difficulties connecting to actual instantiations of the observed phenomenon. This paper investigates how combining physical and virtual experiences into augmented virtual science laboratories can help students build upon intuitive ideas and develop molecular-level explanations of macroscopic phenomena. Specifically, this study uses the Frame, a sensor-augmented virtual lab that uses sensors as physical inputs to control scientific simulations. Eighth-grade students (N = 45) engaged in a Frame lab focused on the properties of gas. Results demonstrate that students using the Frame lab made progress developing molecular-level explanations of gas behavior and refining alternative and partial ideas into normative ideas about gases. This study offers insights for how augmented virtual labs can be designed to enhance science learning and encourage scientific practices as called for in the NGSS. }}
@article{Peng2016,
title = {Bag of Visual Words and Fusion Methods for Action Recognition: Comprehensive Study and Good Practice },
journal = {Computer Vision and Image Understanding },
volume = {},
number = {},
pages = { - },
year = {2016},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2016.03.013},
url = {http://www.sciencedirect.com/science/article/pii/S1077314216300091},
author = {Xiaojiang Peng and Limin Wang and Xingxing Wang and Yu Qiao},abstract = {Abstract Video based action recognition is one of the important and challenging problems in computer vision research. Bag of Visual Words model (BoVW) with local features has been very popular for a long time and obtained the state-of-the-art performance on several realistic datasets, such as the HMDB51, UCF50, and UCF101. BoVW is a general pipeline to construct a global representation from local features, which is mainly composed of five steps: (i) feature extraction, (ii) feature pre-processing, (iii) codebook generation, (iv) feature encoding, and (v) pooling and normalization. Although many efforts have been made in each step independently in different scenarios, their effects on action recognition are still unknown. Meanwhile, video data exhibits different views of visual patterns , such as static appearance and motion dynamics. Multiple descriptors are usually extracted to represent these different views. Fusing these descriptors is crucial for boosting the final performance of an action recognition system. This paper aims to provide a comprehensive study of all steps in BoVW and different fusion methods, and uncover some good practices to produce a state-of-the-art action recognition system. Specifically, we explore two kinds of local features, ten kinds of encoding methods, eight kinds of pooling and normalization strategies, and three kinds of fusion methods. We conclude that every step is crucial for contributing to the final recognition rate and improper choice in one of the steps may counteract the performance improvement of other steps. Furthermore, based on our comprehensive study, we propose a simple yet effective representation, called hybrid supervector, by exploring the complementarity of different BoVW frameworks with improved dense trajectories. Using this representation, we obtain impressive results on the three challenging datasets: HMDB51 (61.9%), UCF50 (92.3%), and UCF101 (87.9%). }}
@article{Johnson20101246,
title = {Applying the self-explanation principle to multimedia learning in a computer-based game-like environment },
journal = {Computers in Human Behavior },
volume = {26},
number = {6},
pages = {1246 - 1252},
year = {2010},
note = {Online Interactivity: Role of Technology in Behavior Change },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2010.03.025},
url = {http://www.sciencedirect.com/science/article/pii/S0747563210000658},
author = {Cheryl I. Johnson and Richard E. Mayer},



abstract = {What is the most effective way to incorporate self-explanation into an educational game? In Experiment 1, students who played a 10-level computer game about electrical circuits performed better on an embedded transfer test (i.e., level 10) if they were required to select the reason for each move from a list on levels 1–9 (selection self-explanation) than if they were not required to engage in self-explanation (d = 1.20). In Experiment 2, the same pattern of results was replicated (d = 0.71), but students who were required to type in their reason for each move on levels 1–9 (generation self-explanation) did not perform any better than those who were not required to engage in self-explanation (d = −0.06). Overall, asking students to select a reason from a list fosters some degree of reflection while not overly disrupting the flow of the game. }}
@article{Abdous2010733,
title = {Learner outcomes and satisfaction: A comparison of live video-streamed instruction, satellite broadcast instruction, and face-to-face instruction },
journal = {Computers & Education },
volume = {55},
number = {2},
pages = {733 - 741},
year = {2010},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.03.006},
url = {http://www.sciencedirect.com/science/article/pii/S036013151000076X},
author = {M’hammed Abdous and Miki Yoshimura},abstract = {This study examined the final grade and satisfaction level differences among students taking specific courses using three different methods: face-to-face in class, via satellite broadcasting at remote sites, and via live video-streaming at home or at work. In each case, the same course was taught by the same instructor in all three delivery methods, and an attempt was made to survey students taking the course via the three different delivery methods. MANOVA results indicated no grade or satisfaction level differences among the three populations. Self-reported computer literacy skills revealed a slight fit between the chosen delivery mode and the reported computer literacy skills. These results provide additional evidence to support both the no significant difference phenomenon and the use of distance education as a viable, convenient and flexible alternative delivery mode capable of extending learning opportunities to non-traditional students. }}
@article{Richey2013104,
title = {How much is too much? Learning and motivation effects of adding instructional explanations to worked examples },
journal = {Learning and Instruction },
volume = {25},
number = {},
pages = {104 - 124},
year = {2013},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2012.11.006},
url = {http://www.sciencedirect.com/science/article/pii/S0959475212001016},
author = {J. Elizabeth Richey and Timothy J. Nokes-Malach},
abstract = {A central goal of the learning sciences is to discover principles that determine the optimal amount of instructional assistance to support robust learning (Koedinger &amp; Aleven, 2007). We examined learning outcomes from providing and withholding stepwise instructional explanations as students studied worked examples and solved physics problems. We hypothesized that students would acquire more conceptual knowledge from withholding instructional explanations because they would be more likely to engage in constructive cognitive activities to understand the problem-solving steps, whereas providing instructional explanations might suppress such activities. Furthermore, we examined the roles of prior knowledge and student motivation in determining learning outcomes. Across three experiments, students in the withholding conditions showed greater conceptual learning than students in the providing conditions. Additionally, achievement goal orientations were more predictive of learning for the withholding conditions than the providing conditions. We discuss how the interactions between prior knowledge, motivation, and instruction can support learning and transfer. }}
@article{Feng201511,
title = {DLANet: A manifold-learning-based discriminative feature learning network for scene classification },
journal = {Neurocomputing },
volume = {157},
number = {},
pages = {11 - 21},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.01.043},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215000880},
author = {Ziyong Feng and Lianwen Jin and Dapeng Tao and Shuangping Huang},abstract = {Abstract This paper presents Discriminative Locality Alignment Network (DLANet), a novel manifold-learning-based discriminative learnable feature, for wild scene classification. Based on a convolutional structure, DLANet learns the filters of multiple layers by applying DLA and exploits the block-wise histograms of the binary codes of feature maps to generate the local descriptors. A DLA layer maximizes the margin between the inter-class patches and minimizes the distance of the intra-class patches in the local region. In particular, we construct a two-layer DLANet by stacking two DLA layers and a feature layer. It is followed by a popular framework of scene classification, which combines Locality-constrained Linear Coding–Spatial Pyramid Matching (LLC–SPM) and linear Support Vector Machine (SVM). We evaluate DLANet on NYU Depth V1, Scene-15 and MIT Indoor-67. Experiments show that DLANet performs well on depth image. It outperforms the carefully tuned features, including SIFT and is also competitive to the other reported methods. }}
@article{Celotto20151,
title = {Fuzzy linguistic approach to quality assessment model for electricity network infrastructure },
journal = {Information Sciences },
volume = {304},
number = {},
pages = {1 - 15},
year = {2015},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2015.01.001},
url = {http://www.sciencedirect.com/science/article/pii/S0020025515000201},
author = {Antonio Celotto and Vincenzo Loia and Sabrina Senatore},
abstract = {Abstract In the modern service economy, the consumer satisfaction is one of primary objectives that a company aims at achieving. Successful companies offer high quality of products or services in order to meet the consumers’ expectation, and, at the same time, they safeguard their own profits and increase market competitiveness. The consumer satisfaction is an indicator to estimate how likely a customer will make a purchase in the future and it is used as a metric very useful in managing and monitoring the company businesses. To address this issue, we present QuAM (Quality Assessment Model), a model for evaluating the overall quality and value of services supplied by a company, through the analysis of the consumer satisfaction. The quality is measured indeed, by the definition of some subjective criteria that are collected through a question form filled in by the consumers. The consumers’ judgments about the supplied items/services allow evaluating the reputation as well as the success of a company. In this work, QuAM has been applied in the electricity network domain, in order to assess an electricity company. In this domain, the overall evaluation of the organization is based on measuring service quality in terms of response times and cost. The quality of service often comes at a cost, with a concern that the pursuit of profit incentives by utilities may have a negative effect on the quality of service. The role of customers is crucial to estimate a market demand curve for service quality, and maximize the customers satisfaction means increasing profitability, productivity and the corporate image. QuAM has been designed by exploiting a fuzzy linguistic approach along with the Computing with Words (CWW) paradigm: the customers feedbacks are modeled through linguistic labels, which naturally fit to describe human judgments; then a linguistic operator LOWA (Linguistic Ordered Weighted Averaging) allows aggregating all the collected judgments into a synthetic linguistic expression. Finally, heuristic measures enable a comprehensive company evaluation. }}
@article{Francescato2006163,
title = {Evaluation of the efficacy of collaborative learning in face-to-face and computer-supported university contexts },
journal = {Computers in Human Behavior },
volume = {22},
number = {2},
pages = {163 - 176},
year = {2006},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2005.03.001},
url = {http://www.sciencedirect.com/science/article/pii/S0747563205000385},
author = {Donata Francescato and Rita Porcelli and Minou Mebane and Marcella Cuddetta and Jane Klobas and Paolo Renzi},


abstract = {This study aimed to compare the efficacy of collaborative learning in face-to-face and online groups. Fifty psychology majors learnt the same professional skill (a community evaluation methodology) in two seminars taught over a two month period by the same teacher online and face-to-face. Participants in both seminars achieved similar growth in level of professional competence, academic self-efficacy, social self-efficacy and self efficacy for problem solving among members. Post-course evaluation of collaborative experience showed no significant differences between online and face-to-face seminar participants in perceived social presence, cooperation and satisfaction with the learning experience. Our results support the claim of advocates of third generation distance education methodologies that computers can be an effective enabler, not only of independent learning, but also of collaborative learning. Furthermore, computer-supported collaborative learning environments are as efficient as collaborative learning in face-to-face seminars in developing social presence and increasing professional competencies and self-efficacy. }}
@article{Tømte201526,
title = {Educating online student teachers to master professional digital competence: The TPACK-framework goes online },
journal = {Computers & Education },
volume = {84},
number = {},
pages = {26 - 35},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.01.005},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515000305},
author = {Cathrine Tømte and Ann-Britt Enochsson and Ulf Buskqvist and Asbjørn Kårstein},
abstract = {Abstract In this article we study how online teacher education programmes may enhance innovative ways of teaching and learning with Information and Communication Technology (ICT). We explore how online teachers are practising professional digital competence, in general and within subject areas, and to what extent they encourage student teachers to develop their own professional digital competence. Based on online teacher education programmes at two distinct higher education institutions (HEIs), we applied mixed method design including quantitative and qualitative approaches to illuminate the aims and the scope. Our study revealed that even if online teacher education programmes represent good avenues for stimulating teachers and student teachers to develop digital competence for pedagogical purposes, this aspect is poorly integrated within the actual programmes, although some interesting examples were demonstrated. By looking at the origins of the discourses on online education and on digital competence, we found that they derive from different stakeholders: while the discourse on online education originated from the management side at both HEIs, the discourse on digital competence derived from certain teaching staff at the two HEIs. Our study indicated that there is still some way to go to innovative solutions and to develop the potential of professional digital competence in online teacher education programmes. }}
@article{Cheng2015127,
title = {A link-based approach to semantic relation analysis },
journal = {Neurocomputing },
volume = {154},
number = {},
pages = {127 - 138},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.12.011},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214016750},
author = {Xin Cheng and Duoqian Miao and Can Wang},abstract = {Abstract The semantic relation analysis is an interesting issue in natural language processing. To capture the semantic relation between terms (words or phrases), various approaches have been proposed by using the co-occurrence statistics within corpus. However, it is still a challenging task to build a robust relation measure due to the complexity of the natural language. In this paper, we present a novel approach for the semantic relation analysis, which takes account of both the pairwise relation and the link-based relation within terms. The pairwise relation captures the relation between terms from the local view, which conveys the co-occurrence pattern between terms to measure their relation. The link-based relation involves the global information into the relation measure, which derives the relation between terms from the similarity of their context information. The combination of these two relations creates a model for robust and accurate semantic relation analysis. Experimental evaluation indicates that our proposed approach leads to much improved result in document clustering over the existed methods. }}
@article{Judd2013358,
title = {Making sense of multitasking: Key behaviours },
journal = {Computers & Education },
volume = {63},
number = {},
pages = {358 - 367},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.12.017},
url = {http://www.sciencedirect.com/science/article/pii/S0360131512003089},
author = {Terry Judd},abstract = {Traditionally viewed as a positive characteristic, there is mounting evidence that multitasking using digital devices can have a range of negative impacts on task performance and learning. While the cognitive processes that cause these impacts are starting to be understood and the evidence that they occur in real learning contexts is mounting, the mechanics and extent of students' task switching and multitasking during learning activities is neither well documented or understood. This study seeks to redress this gap by defining and describing key task switching and multitasking behaviours adopted by students. It employs computer-based task switching and self-directed learning as the technology and learning frameworks within which these behaviours are explored. A custom monitoring system was used to capture and analyse 3372 computer session logs of students undertaking self-directed study within an open-access computer laboratory. Each session was broken down into a sequence of tasks within a series of time segments. Segments and sessions were then analysed and classified as conforming to one of three core behaviours – little or no task switching (focused), task switching without multitasking (sequential) and multitasking. Multitasking was much more common than focused or sequential behaviours. Multitasking was present in more than 70%, was most frequent in over 50% and occurred exclusively in around 35% of all sessions. By comparison, less than 10% of sessions were exclusively focused and only 7% were exclusively sequential. Once initiated, focused and multitasking behaviours appear to be quite stable. Students were much more likely to continue with them than to switch to an alternate behaviour. Sequential behaviour is far less stable and appears to represent a transitional state between multitasking and focused behaviours. The importance of personal, social and learning contexts in setting and influencing multitasking behaviours are discussed, as are some of the potential effects of these behaviours on learning practises and outcomes. }}
@article{Hatlevik2013240,
title = {Digital competence at the beginning of upper secondary school: Identifying factors explaining digital inclusion },
journal = {Computers & Education },
volume = {63},
number = {},
pages = {240 - 247},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.11.015},
url = {http://www.sciencedirect.com/science/article/pii/S0360131512002801},
author = {Ove Edvard Hatlevik and Knut-Andreas Christophersen},


abstract = {During the last decade, information and communication technology has been given an increasingly large importance in our society. There seems to be a consensus regarding the necessity of supporting and developing school-based digital competence. In order to sustain digital inclusion, schools need to identify digital deficiencies and digital achievements. The concept of digital competence is scrutinized and discussed. This paper presents a research study including 4087 students from 24 upper secondary schools. The aim of the study was to scrutinize factors predicting students' digital competence, here operationalised as Digital judgements, To acquire and process digital information and To produce digital information. Analysis revealed substantial variation in digital competence between schools and within schools. The conditions at home, i.e. language integration and cultural capital, together with mastery orientation and academic aspirations did predict digital competence, and explained a substantial share of the total variation in digital competence. There are differences in what students mastered with ICT, and therefore, the students have various requirements. Further, the students attend heterogenic schools facing different kinds of challenges. Hopefully, the schools and teachers are willing to use the results from the test, and moreover, the test results can contribute to needs-based interventions and follow-ups. }}
@article{Wei201510,
title = {Can more interactivity improve learning achievement in an online course? Effects of college students' perception and actual use of a course-management system on their learning achievement },
journal = {Computers & Education },
volume = {83},
number = {},
pages = {10 - 21},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.12.013},
url = {http://www.sciencedirect.com/science/article/pii/S0360131514002905},
author = {Huei-Chuan Wei and Hsinyi Peng and Chien Chou},abstract = {Abstract This study aims to investigate how interactivity influence learners' use of interactive functions in the course-management system (CMS) and their online learning performance. A two-tier mediation framework is proposed to examine the mediating effects of different actual-use records concerning the CMS's interactive functions. Data are collected from 381 undergraduate students who enrolled in a general-education asynchronous online course from three universities in Taiwan. The results indicate that the relationships among students' self-reported use of interactive functions, students' perceptions of the usefulness of interactive functions, and students' actual-use logs have some direct influences on students' online learning performance (online-discussion scores, exam scores, and group-project scores). In addition, students' actual-use logs (the number of times of log-ins to the online course, the number of times students read learning materials, and the number of postings on the discussion board) have a mediated effect on students' self-reported frequency of logging into the CMS, students' self-reported frequency of using the learner–instructor/learner–learner interactive functions, and online learning performance. The findings and implications could constitute a useful guide for educational practitioners and designers concerned with the effective integration of interactivity into future online courses. }}
@article{Lonn2009686,
title = {Saving time or innovating practice: Investigating perceptions and uses of Learning Management Systems },
journal = {Computers & Education },
volume = {53},
number = {3},
pages = {686 - 694},
year = {2009},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2009.04.008},
url = {http://www.sciencedirect.com/science/article/pii/S0360131509001006},
author = {Steven Lonn and Stephanie D. Teasley},
abstract = {Learning Management Systems (LMS) are web-based systems that allow instructors and/or students to share materials, submit and return assignments, and communicate online. In this study, we explored the uses and perceived benefits of using a LMS to support traditional classroom teaching as reported by instructors and students at a large American Midwestern university. We examined two years of survey data focusing on specific uses of the LMS that emphasized either efficient communication or interactive teaching and learning practices. We matched aggregate user log data with corresponding survey items to see if system use was consistent with patterns seen in the survey results. Findings suggest that instructors and students value tools and activities for efficient communication more than interactive tools for innovating existing practices. However, survey item analysis reveals that instructors and students also highly value the teaching and learning tools within the LMS. }}
@article{Snodin2013209,
title = {The effects of blended learning with a CMS on the development of autonomous learning: A case study of different degrees of autonomy achieved by individual learners },
journal = {Computers & Education },
volume = {61},
number = {},
pages = {209 - 216},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.10.004},
url = {http://www.sciencedirect.com/science/article/pii/S0360131512002266},
author = {Navaporn S. Snodin},abstract = {The findings of this study support the argument made by many learner autonomy scholars that the road to autonomy is a process conditioned by each individual's zone of proximal development (ZPD) and that there are different degrees of autonomy. The description of behavioural patterns found from the experiment supports this notion. The findings show that once the direction was initiated by the teacher with the help of an external structure like a course management system (CMS), the learners could organise the resources in the system autonomously, took on new learning roles that were different from those in a traditional face-to-face classroom, and eventually they could develop autonomous perceptions and behaviours as an outcome of their engagement in this blended learning environment. The data from four research tools: i.e., questionnaire, student learning journals, interviews and classroom observation are triangulated and amalgamated to increase the validity and reliability of the findings. }}
@article{Park2015267,
title = {Cognitive and affective effects of seductive details in multimedia learning },
journal = {Computers in Human Behavior },
volume = {44},
number = {},
pages = {267 - 278},
year = {2015},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2014.10.061},
url = {http://www.sciencedirect.com/science/article/pii/S0747563214006591},
author = {Babette Park and Terri Flowerday and Roland Brünken},


abstract = {Abstract The present study integrates cognitive and affective aspects of media processing in order to make an argument for reexamining the current cold cognition perspective in multimedia research in favor of a more integrative perspective. The Cognitive-Affective-Theory-of-Learning-with-Media (CATLM) assumes that students need to become motivated to make full use of their cognitive resources. Therefore, and even though seductive details (sds) are additional interesting but unnecessary pieces of information that do not conform with the coherence principle, their possible motivational role should not be dismissed. Using a 2 × 3-experimental design, participants (N = 123) were asked to learn about biology with multimedia instruction that manipulated modality (text vs. narration) and presence of seductive details (no-sds vs. textual-sds vs. narrated-sds). Results of variance analyses show a modality effect. In addition, moderated mediation analyses with the moderator modality and mediator situational interest confirm the affective mediation assumption with the following two conditional effects. A direct detrimental effect of seductive details on learning performance under the text-condition and an indirect compensatory effect under the narration-condition were shown. }}
@article{Park2015129,
title = {Boosting learning-by-teaching in virtual tutoring },
journal = {Computers & Education },
volume = {82},
number = {},
pages = {129 - 140},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.11.006},
url = {http://www.sciencedirect.com/science/article/pii/S036013151400253X},
author = {SeungWon Park and ChanMin Kim},
abstract = {Abstract Research has shown that students tend to engage in quality learning when they are asked to teach (i.e., learning-by-teaching). In this study, a web-based tutoring environment has been developed to enhance the learning of college students by their teaching others: the Virtual Tutee System (VTS). In the VTS, students take the role of tutor and teach a virtual character about what they learn from readings. The design of the VTS has been refined through several iterations of formative evaluation. The current study explored whether the recent improvements made in the VTS augmented the learning-by-teaching effects. The VTS was evaluated with regard to its' effects on students' reading engagement and reading performance. Results indicated that students were behaviorally and cognitively engaged in reading with use of the VTS. Also, the study found a significant improvement in students' emotional engagement in reading after using the VTS. Limited support was found for enhancement of reading performance with repeated use of the VTS. Implications of the study findings are discussed, and suggestions for future research are provided. }}
@article{Feng2016225,
title = {A software system for automated identification and retrieval of moth images based on wing attributes },
journal = {Pattern Recognition },
volume = {51},
number = {},
pages = {225 - 241},
year = {2016},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2015.09.012},
url = {http://www.sciencedirect.com/science/article/pii/S003132031500343X},
author = {Linan Feng and Bir Bhanu and John Heraty},



abstract = {Abstract Manually collecting, identifying, archiving and retrieving specimen images is an expensive and time-consuming work for entomologists. There is a clear need to introduce fast systems integrated with modern image processing and analysis algorithms to accelerate the process. In this paper, we describe the development of an automated moth species identification and retrieval system (SPIR) using computer vision and pattern recognition techniques. The core of the system is a probabilistic model that infers Semantically Related Visual (SRV) attributes from low-level visual features of moth images in the training set, where moth wings are segmented into information-rich patches from which the local features are extracted, and the SRV attributes are provided by human experts as ground-truth. For the large amount of unlabeled test images in the database or added into the database later on, an automated identification process is evoked to translate the detected salient regions of low-level visual features on the moth wings into meaningful semantic SRV attributes. We further propose a novel network analysis based approach to explore and utilize the co-occurrence patterns of SRV attributes as contextual cues to improve individual attribute detection accuracy. Working with a small set of labeled training images, the approach constructs a network with nodes representing the SRV attributes and weighted edges denoting the co-occurrence correlation. A fast modularity maximization algorithm is proposed to detect the co-occurrence patterns as communities in the network. A random walk process working on the discovered co-occurrence patterns is applied to refine the individual attribute detection results. The effectiveness of the proposed approach is evaluated in automated moth identification and attribute-based image retrieval. In addition, a novel image descriptor called SRV attribute signature is introduced to record the visual and semantic properties of an image and is used to compare image similarity. Experiments are performed on an existing entomology database to illustrate the capabilities of our proposed system. We observed that the system performance is improved by the SRV attribute representation and their co-occurrence patterns. }}
@article{Hunsu2016102,
title = {A meta-analysis of the effects of audience response systems (clicker-based technologies) on cognition and affect },
journal = {Computers & Education },
volume = {94},
number = {},
pages = {102 - 119},
year = {2016},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.11.013},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515300853},
author = {Nathaniel J. Hunsu and Olusola Adesope and Dan James Bayly},
abstract = {Abstract Audience Response Systems (ARS) are thought to be a good way of using technology to increase engagement in the classroom and have been widely adopted by many instructors seeking to improve academic performance through student engagement. While researchers have examined the degree to which they promote cognitive and non-cognitive learning outcomes in the classroom, most of their findings are largely mixed and inconclusive. This meta-analysis seeks to resolve the conflicting findings. Specifically, the meta-analysis compared classrooms that did, and did not use ARS-based technologies on different cognitive and non-cognitive learning outcomes to examine the potential effects of using ARS. Overall, we found small but significant effects of using ARS-based technologies on a number of desirable cognitive and non-cognitive learning outcomes. Further analysis revealed that knowledge domain, class size, and the use of clicker questions, are among factors that significantly moderated the summary effect sizes observed among the studies in the meta-analysis. These findings hold significant implication for the implementation of clicker-based technologies in the classroom. }}
@article{Xia2016246,
title = {A distributed spatial–temporal weighted model on MapReduce for short-term traffic flow forecasting },
journal = {Neurocomputing },
volume = {179},
number = {},
pages = {246 - 263},
year = {2016},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2015.12.013},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215019293},
author = {Dawen Xia and Binfeng Wang and Huaqing Li and Yantao Li and Zili Zhang},

abstract = {Abstract Accurate and timely traffic flow prediction is crucial to proactive traffic management and control in data-driven intelligent transportation systems (D2ITS), which has attracted great research interest in the last few years. In this paper, we propose a Spatial–Temporal Weighted K-Nearest Neighbor model, named STW-KNN, in a general MapReduce framework of distributed modeling on a Hadoop platform, to enhance the accuracy and efficiency of short-term traffic flow forecasting. More specifically, STW-KNN considers the spatial–temporal correlation and weight of traffic flow with trend adjustment features, to optimize the search mechanisms containing state vector, proximity measure, prediction function, and K selection. Furthermore, STW-KNN is implemented on a widely adopted Hadoop distributed computing platform with the MapReduce parallel processing paradigm, for parallel prediction of traffic flow in real time. Finally, with extensive experiments on real-world big taxi trajectory data, STW-KNN is compared with the state-of-the-art prediction models including conventional K-Nearest Neighbor (KNN), Artificial Neural Networks (ANNs), Naïve Bayes (NB), Random Forest (RF), and C4.5. The results demonstrate that the proposed model is superior to existing models on accuracy by decreasing the mean absolute percentage error (MAPE) value more than 11.59% only in time domain and even achieves 89.71% accuracy improvement with the MAPEs of between 3.34% and 6.00% in both space and time domains, and also significantly improves the efficiency and scalability of short-term traffic flow forecasting over existing approaches. }}
@article{Paul20122117,
title = {Effect of online social networking on student academic performance },
journal = {Computers in Human Behavior },
volume = {28},
number = {6},
pages = {2117 - 2127},
year = {2012},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2012.06.016},
url = {http://www.sciencedirect.com/science/article/pii/S0747563212001665},
author = {Jomon Aliyas Paul and Hope M. Baker and Justin Daniel Cochran},
abstract = {Online social networks (OSNs) have permeated all generations of Internet users, becoming a prominent communications tool, particularly in the student community. Thus, academic institutions and faculty are increasingly using social networking sites, such as Facebook and LinkedIn, to connect with current and potential students and to deliver instructional content. This has led to a rise in questions about the impact of OSN on academic performance and the possibility of using it as an effective teaching tool. To learn more about the impact on academic performance, we conducted a survey of business students at a large state university. Survey results were analyzed using structural equation modeling (SEM). The results revealed a statistically significant negative relationship between time spent by students on OSN and their academic performance. The time spent on OSN was found to be heavily influenced by the attention span of the students. Specifically, we determined that the higher the attention span, the lower is the time spent on OSN. Further, attention span was found to be highly correlated with characteristics that predict or influence student behavior, such as their perceptions about society’s view of social networking, their likes and dislikes of OSN, ease of use of OSN, etc. }}
@article{Park2009649,
title = {Do students benefit equally from interactive computer simulations regardless of prior knowledge levels? },
journal = {Computers & Education },
volume = {52},
number = {3},
pages = {649 - 655},
year = {2009},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2008.11.014},
url = {http://www.sciencedirect.com/science/article/pii/S0360131508001826},
author = {Seong Ik Park and Gyumin Lee and Meekyoung Kim},



abstract = {The purposes of this study were to examine the effects of two types of interactive computer simulations and of prior knowledge levels on concept comprehension, cognitive load, and learning efficiency. Seventy-two 5th grade students were sampled from two elementary schools. They were divided into two groups (high and low) based on prior knowledge levels, and each group was divided into two treatment groups (a low-interactive simulation group and a high-interactive simulation group). The dependent variables were concept comprehension, cognitive load, and learning efficiency. The results showed that, for students with high prior knowledge levels, high-interactive simulations, rather than low-interactive simulations, resulted in significantly increased comprehension scores, decreased cognitive load scores, and higher learning efficiency. On the other hand, among students with low prior knowledge levels, the low-interactive simulation group did not demonstrate significantly increased comprehension scores, but they did show lower cognitive load scores and higher learning efficiency than the high-interactive simulation group. }}
@article{ReyesOrtiz2015121,
title = {Big Data Analytics in the Cloud: Spark on Hadoop vs MPI/OpenMP on Beowulf },
journal = {Procedia Computer Science },
volume = {53},
number = {},
pages = {121 - 130},
year = {2015},
note = {INNS Conference on Big Data 2015 Program San Francisco, CA, USA 8-10 August 2015 },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2015.07.286},
url = {http://www.sciencedirect.com/science/article/pii/S1877050915017895},
author = {Jorge L. Reyes-Ortiz and Luca Oneto and Davide Anguita},abstract = {Abstract One of the biggest challenges of the current big data landscape is our inability to pro- cess vast amounts of information in a reasonable time. In this work, we explore and com- pare two distributed computing frameworks implemented on commodity cluster architectures: MPI/OpenMP on Beowulf that is high-performance oriented and exploits multi-machine/multi- core infrastructures, and Apache Spark on Hadoop which targets iterative algorithms through in-memory computing. We use the Google Cloud Platform service to create virtual machine clusters, run the frameworks, and evaluate two supervised machine learning algorithms: KNN and Pegasos SVM. Results obtained from experiments with a particle physics data set show MPI/OpenMP outperforms Spark by more than one order of magnitude in terms of processing speed and provides more consistent performance. However, Spark shows better data manage- ment infrastructure and the possibility of dealing with other aspects such as node failure and data replication. }}
@article{Li20151,
title = {A comparison of 3D shape retrieval methods based on a large-scale benchmark supporting multimodal queries },
journal = {Computer Vision and Image Understanding },
volume = {131},
number = {},
pages = {1 - 27},
year = {2015},
note = {Special section: Large Scale Data-Driven Evaluation in Computer Vision },
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2014.10.006},
url = {http://www.sciencedirect.com/science/article/pii/S1077314214002100},
author = {Bo Li and Yijuan Lu and Chunyuan Li and Afzal Godil and Tobias Schreck and Masaki Aono and Martin Burtscher and Qiang Chen and Nihad Karim Chowdhury and Bin Fang and Hongbo Fu and Takahiko Furuya and Haisheng Li and Jianzhuang Liu and Henry Johan and Ryuichi Kosaka and Hitoshi Koyanagi and Ryutarou Ohbuchi and Atsushi Tatsuma and Yajuan Wan and Chaoli Zhang and Changqing Zou},



abstract = {Abstract Large-scale 3D shape retrieval has become an important research direction in content-based 3D shape retrieval. To promote this research area, two Shape Retrieval Contest (SHREC) tracks on large scale comprehensive and sketch-based 3D model retrieval have been organized by us in 2014. Both tracks were based on a unified large-scale benchmark that supports multimodal queries (3D models and sketches). This benchmark contains 13680 sketches and 8987 3D models, divided into 171 distinct classes. It was compiled to be a superset of existing benchmarks and presents a new challenge to retrieval methods as it comprises generic models as well as domain-specific model types. Twelve and six distinct 3D shape retrieval methods have competed with each other in these two contests, respectively. To measure and compare the performance of the participating and other promising Query-by-Model or Query-by-Sketch 3D shape retrieval methods and to solicit state-of-the-art approaches, we perform a more comprehensive comparison of twenty-six (eighteen originally participating algorithms and eight additional state-of-the-art or new) retrieval methods by evaluating them on the common benchmark. The benchmark, results, and evaluation tools are publicly available at our websites (http://www.itl.nist.gov/iad/vug/sharp/contest/2014/Generic3D/, 2014, http://www.itl.nist.gov/iad/vug/sharp/contest/2014/SBR/, 2014). }}
@article{Huang2012250,
title = {The effectiveness of using procedural scaffoldings in a paper-plus-smartphone collaborative learning context },
journal = {Computers & Education },
volume = {59},
number = {2},
pages = {250 - 259},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.01.015},
url = {http://www.sciencedirect.com/science/article/pii/S0360131512000310},
author = {Hui-Wen Huang and Chih-Wei Wu and Nian-Shing Chen},



abstract = {The purpose of this study was to evaluate the effectiveness of using procedural scaffoldings in fostering students’ group discourse levels and learning outcomes in a paper-plus-smartphone collaborative learning context. All participants used built-in camera smartphones to learn new knowledge by scanning Quick Response (QR) codes, a type of two-dimensional barcode, embedded in paper-based learning materials in this study. Sixty undergraduate and graduate students enrolled at a four-year university in southern Taiwan participated in this study. Participants were randomly assigned into two different groups, using procedural scaffoldings learning and non-procedural scaffoldings learning. The learning unit about the Long Tail, an important concept used in products sales, was the learning task that participants were expected to complete. During the experiment, pretest–posttest and the completed group worksheets were used to collect data. The researchers applied content analyses, chi-square test, t-test, and ANCOVA to answer research questions. The findings indicated that participants in the experimental group using procedural scaffoldings achieved better learning outcomes than their counterparts in the control group in terms of group discourse levels, group learning, and individual learning. }}
@article{Malmberg2008438,
title = {Student teachers' achievement goal orientations during teacher studies: Antecedents, correlates and outcomes },
journal = {Learning and Instruction },
volume = {18},
number = {5},
pages = {438 - 452},
year = {2008},
note = {Motivation for Teaching },
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2008.06.003},
url = {http://www.sciencedirect.com/science/article/pii/S0959475208000686},
author = {Lars-Erik Malmberg},abstract = {This study aimed to investigate whether student teachers' achievement goal orientations changed during teacher studies, and how motivational trajectories were related to academically- and teaching-relevant antecedents and outcomes. A total of 170 participants were followed up between two and five time points. Using individual growth models, achievement goal orientations were found to increase over time and to peak during the third year of studies. Secondary school grades predicted a higher level of performance-approach goal orientation and graded performance. Reflective thinking, teacher intrinsic motivation and teacher control-expectancy beliefs were related to increase of mastery goal orientation. Task-irrelevant behavior was related to low graded performance as well as to increase in performance-approach and performance-avoidance goals. }}
@article{Pieschl2012281,
title = {Is adaptation to task complexity really beneficial for performance? },
journal = {Learning and Instruction },
volume = {22},
number = {4},
pages = {281 - 289},
year = {2012},
note = {Improving Self-Monitoring and Self-Regulation of Learning: From Cognitive Psychology to the Classroom },
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2011.08.005},
url = {http://www.sciencedirect.com/science/article/pii/S0959475211000818},
author = {Stephanie Pieschl and Elmar Stahl and Tom Murray and Rainer Bromme},
abstract = {Theories of self-regulated learning assume that learners flexibly adapt their learning process to external task demands and that this is positively related to performance. In this study, university students (n = 119) solved three tasks that greatly differed in complexity. Their learning processes were captured in detail by task-specific questionnaires and computer-generated log files. Results indicate that students adapted almost all learning processes significantly to task complexity. For example, students accessed more hypertext pages for complex tasks than for simple tasks. However, this kind of adaptation was not consistently related to performance. For variables capturing learners’ self-regulation, such as the number of accessed hypertext pages, more pronounced adaptation was significantly and positively related to performance even when learners’ general processing depth was statistically controlled. Results were less consistent for variables capturing learners’ self-monitoring, such as their judged task complexity. }}
@article{Kong2008886,
title = {The development of a cognitive tool for teaching and learning fractions in the mathematics classroom: A design-based study },
journal = {Computers & Education },
volume = {51},
number = {2},
pages = {886 - 899},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2007.09.007},
url = {http://www.sciencedirect.com/science/article/pii/S0360131507001042},
author = {Siu Cheung Kong},
abstract = {Two cycles of design-based research of a cognitive tool (CT) for teaching fractions have been completed. Following the success of a quasi-experimental study of the enhanced CT derived from the second cycle of design-based research, this article reports the findings of a pre-test–post-test control group empirical study using the enhanced CT in the classroom. The results indicate that there were no statistically significant differences in learning outcomes between the exploratory learning approach, using the CT, and the traditional direct teaching approach. The CT enabled students to generate a procedural knowledge of adding and subtracting fractions with like and unlike denominators through an exploratory learning process. Teachers asserted that the CT was effective for stimulating reciprocal tutoring among students, and students were enthusiastic about using the CT as an educational tool. Hence, the CT has potential for further development as a tool for promoting collaborative learning in the classroom. }}
@article{Echeverría20121170,
title = {Exploring different technological platforms for supporting co-located collaborative games in the classroom },
journal = {Computers in Human Behavior },
volume = {28},
number = {4},
pages = {1170 - 1177},
year = {2012},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2012.01.027},
url = {http://www.sciencedirect.com/science/article/pii/S0747563212000295},
author = {Alejandro Echeverría and Matías Améstica and Francisca Gil and Miguel Nussbaum and Enrique Barrios and Sandra Leclerc},



abstract = {Computer Supported Collaborative Learning is a pedagogical approach that can be used for deploying educational games in the classroom. However, there is no clear understanding as to which technological platforms are better suited for deploying co-located collaborative games, nor the general affordances that are required. In this work we explore two different technological platforms for developing collaborative games in the classroom: one based on augmented reality technology and the other based on multiple-mice technology. In both cases, the same game was introduced to teach electrostatics and the results were compared experimentally using a real class. The results of our experimental work showed that students significantly increased their conceptual understanding of electrostatics with both platforms. However, there were some important differences between platforms. While in the multiple-mice platform there were no gender differences, in the augmented reality platform boys significantly outperformed girls. In addition, the augmented reality platform was considerably more costly to deploy in a real world setting than the multiple-mice platform. These results suggest that, when co-located collaborative games are designed, careful consideration must be taken when selecting the technology to be used, something which can have effects that go beyond the effects of the games themselves. }}
@article{Yang2014138,
title = {Adaptive multi-view selection for semi-supervised emotion recognition of posts in online student community },
journal = {Neurocomputing },
volume = {144},
number = {},
pages = {138 - 150},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.05.055},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214007206},
author = {Zongkai Yang and Zhi Liu and Sanya Liu and Lei Min and Wenting Meng},

abstract = {Abstract In statistical text emotion recognition, semi-supervised learning that can leverage plenty of unlabeled data has drawn much attention in recent years. However, the quality of the training data is typically influenced by some mislabeled samples. In this paper, we present a novel co-training method, namely adaptive multi-view selection (AMVS), to improve labeling accuracy of unlabeled samples for semi-supervised emotion recognition. In particular, two importance distributions are proposed to construct multiple discriminative feature views. One is the distribution of feature emotional strengths, and the other is the importance distribution of view dimensionality. On the basis of these two distributions, several feature views are iteratively selected from the original feature space in a cascaded way, and corresponding base classifiers are trained on these views to build a dynamic and robust ensemble. The experimental results on the real-life dataset consisting of moods posts demonstrate the proposed AMVS outperforms conventional multi-view semi-supervised emotion recognition methods, and that abundant emotional discriminative features could be fully exploited in view selection process. }}
@article{MorenoGer20082530,
title = {Educational game design for online education },
journal = {Computers in Human Behavior },
volume = {24},
number = {6},
pages = {2530 - 2540},
year = {2008},
note = {Including the Special Issue: Electronic Games and Personalized eLearning Processes },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2008.03.012},
url = {http://www.sciencedirect.com/science/article/pii/S0747563208000617},
author = {Pablo Moreno-Ger and Daniel Burgos and Iván Martínez-Ortiz and José Luis Sierra and Baltasar Fernández-Manjón},

abstract = {The use of educational games in learning environments is an increasingly relevant trend. The motivational and immersive traits of game-based learning have been deeply studied in the literature, but the systematic design and implementation of educational games remain an elusive topic. In this study some relevant requirements for the design of educational games in online education are analyzed, and a general game design method that includes adaptation and assessment features is proposed. Finally, a particular implementation of that design is described in light of its applicability to other implementations and environments. }}
@article{Chao2014288,
title = {A developmental approach to robotic pointing via human–robot interaction },
journal = {Information Sciences },
volume = {283},
number = {},
pages = {288 - 303},
year = {2014},
note = {New Trend of Computational Intelligence in Human-Robot Interaction },
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2014.03.104},
url = {http://www.sciencedirect.com/science/article/pii/S0020025514004010},
author = {Fei Chao and Zhengshuai Wang and Changjing Shang and Qinggang Meng and Min Jiang and Changle Zhou and Qiang Shen},



abstract = {Abstract The ability of pointing is recognised as an essential skill of a robot in its communication and social interaction. This paper introduces a developmental learning approach to robotic pointing, by exploiting the interactions between a human and a robot. The approach is inspired through observing the process of human infant development. It works by first applying a reinforcement learning algorithm to guide the robot to create attempt movements towards a salient object that is out of the robot’s initial reachable space. Through such movements, a human demonstrator is able to understand the robot desires to touch the target and consequently, to assist the robot to eventually reach the object successfully. The human–robot interaction helps establish the understanding of pointing gestures in the perception of both the human and the robot. From this, the robot can collect the successful pointing gestures in an effort to learn how to interact with humans. Developmental constraints are utilised to drive the entire learning procedure. The work is supported by experimental evaluation, demonstrating that the proposed approach can lead the robot to gradually gain the desirable pointing ability. It also allows that the resulting robot system exhibits similar developmental progress and features as with human infants. }}
@article{DiNoia2016354,
title = {Building a relatedness graph from Linked Open Data: A case study in the IT domain },
journal = {Expert Systems with Applications },
volume = {44},
number = {},
pages = {354 - 366},
year = {2016},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2015.08.038},
url = {http://www.sciencedirect.com/science/article/pii/S0957417415005941},
author = {Tommaso Di Noia and Vito Claudio Ostuni and Jessica Rosati and Paolo Tomeo and Eugenio Di Sciascio and Roberto Mirizzi and Claudio Bartolini},



abstract = {Abstract The availability of encyclopedic Linked Open Data (LOD) paves the way to a new generation of knowledge-intensive applications able to exploit the information encoded in the semantically-enriched datasets freely available on the Web. In such applications, the notion of relatedness between entities plays an important role whenever, given a query, we are looking not only for exact answers but we are also interested in a ranked list of related ones. In this paper we present an approach to build a relatedness graph among resources in the DBpedia dataset that refer to the IT domain. Our final aim is to create a useful data structure at the basis of an expert system that, looking for an IT resource, returns a ranked list of related technologies, languages, tools the user might be interested in. The graph we created is a basic building block to allow an expert system to support the user in entity search tasks in the IT domain (e.g. software component search or expert finding) that goes beyond string matching typical of pure keyword-based approaches and is able to exploit the explicit and implicit semantics encoded within LOD datasets. The graph creation relies on different relatedness measures that are combined with each other to compute a ranked list of candidate resources associated to a given query. We validated our tool through experimental evaluation on real data to verify the effectiveness of the proposed approach. }}
@article{Gulikers2008172,
title = {The effect of practical experience on perceptions of assessment authenticity, study approach, and learning outcomes },
journal = {Learning and Instruction },
volume = {18},
number = {2},
pages = {172 - 186},
year = {2008},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2007.02.012},
url = {http://www.sciencedirect.com/science/article/pii/S0959475207000382},
author = {Judith T.M. Gulikers and Liesbeth Kester and Paul A. Kirschner and Theo J. Bastiaens},
abstract = {Does authentic assessment or the perception of it affect how students study and learn? Does practical experience affect how assessment authenticity is perceived? And does practical experience influence how an authentic assessment affects student learning? Mixed methods design yielded insight into the answers to these questions. This article presents the results of a study on the relationships between authenticity perceptions of different cohorts of students, who differed in the amount of practical experience, their study approach and their perceived degree of professional skill development. The results showed some salient differences in how freshman- and senior-student groups perceive the same authentic assessment and how this assessment influences their learning. These results suggest possible guidelines for developing and using authentic assessments during a curriculum in which learning and working are intertwined. }}
@article{Reimann2003245,
title = {Multimedia learning: beyond modality },
journal = {Learning and Instruction },
volume = {13},
number = {2},
pages = {245 - 252},
year = {2003},
note = {External and Internal Representations in Multimedia Learning },
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/S0959-4752(02)00024-5},
url = {http://www.sciencedirect.com/science/article/pii/S0959475202000245},
author = {P Reimann}}
@article{Gonida2014120,
title = {Perceived parent goals and student goal orientations as predictors of seeking or not seeking help: Does age matter? },
journal = {Learning and Instruction },
volume = {33},
number = {},
pages = {120 - 130},
year = {2014},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2014.04.007},
url = {http://www.sciencedirect.com/science/article/pii/S0959475214000413},
author = {Eleftheria N. Gonida and Stuart A. Karabenick and Kara A. Makara and Glykeria A. Hatzikyriakou},



abstract = {Abstract To study the contribution of perceived parent achievement goals to students' attitudes towards academic help seeking, 4th, 6th, 7th, and 9th grade students in Greece (n = 712) reported perceptions of their parents' achievement goals, personal achievement goal orientations, and help-seeking beliefs and intentions. Students' mastery goal orientation positively predicted their help-seeking attitudes (perceived benefits and intentions to seek help) and negatively predicted their help-seeking avoidance attitudes (perceived costs and intentions to avoid seeking help), whereas performance-avoidance orientation directly predicted their help-seeking avoidance attitudes. Multiple-group path analysis indicated that perceived parent goals predicted student help seeking and help avoidance attitudes through students' own achievement goal orientations. Further, the pattern of relations varied by grade level. Results are discussed in light of current theory and research on the developmental phases of parental influence on student motivation and self-regulated learning. }}
@article{Khan2014138,
title = {Actual friends matter: An internet skills perspective on teens' informal academic collaboration on Facebook },
journal = {Computers & Education },
volume = {79},
number = {},
pages = {138 - 147},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.08.001},
url = {http://www.sciencedirect.com/science/article/pii/S0360131514001730},
author = {M. Laeeq Khan and Donghee Yvette Wohn and Nicole B. Ellison},
abstract = {Abstract Social media platforms such as Facebook enable adolescents to collaborate on academic activities, but this kind of participation may require a set of higher-order Internet skills. This study explores the factors that predict informal academic collaboration on Facebook, such as seeking help, discussing schoolwork, and finding class-related resources. Based on survey data collected from high school students (N = 690), we found that academic performance, perceived support from ‘actual’ Facebook friends, higher order Internet skills (especially information seeking skills), and instrumental support from Facebook friends predicted academic collaboration on Facebook. In light of these findings, theoretical and practical implications are discussed. }}
@article{Siniscalchi2014326,
title = {An artificial neural network approach to automatic speech processing },
journal = {Neurocomputing },
volume = {140},
number = {},
pages = {326 - 338},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.03.005},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214004007},
author = {Sabato Marco Siniscalchi and Torbjørn Svendsen and Chin-Hui Lee},
abstract = {Abstract An artificial neural network (ANN) is a powerful mathematical framework used to either model complex relationships between inputs and outputs or find patterns in data. It is based on an interconnected group of artificial neurons, and it employs a connectionist approach to computation when processing information. ANNs have been successfully used for a great variety of applications, such as decision making, quantum chemistry, radar systems, face identification, gesture recognition, handwritten text recognition, medical diagnosis, financial applications, robotics, data mining, and e-spam filtering. In the speech community, neural architectures have been used since the beginning of the 1980s, and ANNs have been proven useful to accomplish several speech processing tasks, e.g., to extract linguistically motivated features, to perform speech detection, and to generate local scores to be used for different goals. In recent years, there has been a renewed interest in the use of ANNs for speech applications due to a major advance made in pre-training the weights in deep neural networks (DNNs). It seems that a new trend to move the speech technology forward through the use of NNs has begun, and it can therefore be instructive to review key ANN applications to automatic speech processing. In this paper, several ANN-based applications for speech processing will be presented, ranging from speech attribute extraction to phoneme estimation and/or classification. Furthermore, it will be shown that ANNs play a key role in several important speech applications, such as large vocabulary continuous speech recognition (LVCSR) and automatic language recognition. The goal of the paper is to summarize chief ANN approaches to speech processing using the experience gathered in the last seven years in our laboratories. }}
@article{Hamlen2012534,
title = {Stochastic frontier estimation of efficient learning in video games },
journal = {Computers & Education },
volume = {58},
number = {1},
pages = {534 - 541},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.09.006},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511002235},
author = {Karla R. Hamlen},abstract = {Stochastic Frontier Regression Analysis was used to investigate strategies and skills that are associated with the minimization of time required to achieve proficiency in video games among students in grades four and five. Students self-reported their video game play habits, including strategies and skills used to become good at the video games they play. Results indicated an association between game play time spent during vacation weeks and proficiency at the game, but no such association existed with game play time during typical weeks when school is in session. Several strategies and skills were associated with the minimization of time spent to achieve proficiency at the game, while a few strategies and skills held a negative association with efficient learning in games. Some of the findings paralleled those of prior research on formal education. Gender differences, as well as implications for games and learning are discussed. }}
@article{Chandra2012631,
title = {Re-thinking physics teaching with web-based learning },
journal = {Computers & Education },
volume = {58},
number = {1},
pages = {631 - 640},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.09.010},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511002272},
author = {Vinesh Chandra and James J. Watters},
abstract = {There is extensive uptake of ICT in the teaching of science but more evidence is needed on how ICT impacts on the learning practice and the learning outcomes at the classroom level. In this study, a physics website (Getsmart) was developed using the cognitive apprenticeship framework for students at a high school in Australia. This website was designed to enhance students’ knowledge of concepts in physics. Reflexive pedagogies were used in the delivery learning materials in a blended learning environment. The students in the treatment group accessed the website over a 10 week period. Pre and post-test results of the treatment (N = 48) and comparison group (N = 32) were compared. The MANCOVA analysis showed that the web-based learning experience benefitted the students in the treatment group. It not only impacted on the learning outcomes, but qualitative data from the students suggested that it had a positive impact on their attitudes towards studying physics in a blended environment. }}
@article{Kopp201212,
title = {E-tutorial support for collaborative online learning: An explorative study on experienced and inexperienced e-tutors },
journal = {Computers & Education },
volume = {58},
number = {1},
pages = {12 - 20},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.08.019},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511001977},
author = {Birgitta Kopp and Maria Cristina Matteucci and Carlo Tomasetto},



abstract = {The e-tutor plays a major role in supporting virtual collaborative learning, as he/she supervises learners in collaboratively solving tasks, acquiring new skills, and applying new knowledge. This study is aimed at gaining further insights into the daily support practices of e-tutors. Seventy-six e-tutors from 17 different European countries were invited to fill in an online questionnaire to evaluate collaborative activities, and to answer yes/no-questions regarding their intervention to support these collaborative activities. A cluster analysis identified two profiles of e-tutors according to the importance ascribed to collaborative activities, and to the number of times they intervened to foster such activities. The cluster validation revealed a difference between experienced and inexperienced European e-tutors in their support of online collaboration: e-tutors with experience considered specific cognitive activities to be more important for effective online collaboration, and they seemed to be more familiar in detecting and adequately intervening to avoid dysfunctional social phenomena. Thus, experience in supporting online collaboration seems to be a useful precondition for successfully intervening to stimulate necessary learning activities and to avoid dysfunctional collaborative activities. }}
@article{Scheirer20142721,
title = {Good recognition is non-metric },
journal = {Pattern Recognition },
volume = {47},
number = {8},
pages = {2721 - 2731},
year = {2014},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2014.02.018},
url = {http://www.sciencedirect.com/science/article/pii/S0031320314000703},
author = {Walter J. Scheirer and Michael J. Wilber and Michael Eckmann and Terrance E. Boult},

abstract = {Abstract Recognition is the fundamental task of visual cognition, yet how to formalize the general recognition problem for computer vision remains an open issue. The problem is sometimes reduced to the simplest case of recognizing matching pairs, often structured to allow for metric constraints. However, visual recognition is broader than just pair-matching: what we learn and how we learn it has important implications for effective algorithms. In this review paper, we reconsider the assumption of recognition as a pair-matching test, and introduce a new formal definition that captures the broader context of the problem. Through a meta-analysis and an experimental assessment of the top algorithms on popular data sets, we gain a sense of how often metric properties are violated by recognition algorithms. By studying these violations, useful insights come to light: we make the case for local distances and systems that leverage outside information to solve the general recognition problem. }}
@article{Theodorakopoulos20142367,
title = {HEp-2 cells classification via sparse representation of textural features fused into dissimilarity space },
journal = {Pattern Recognition },
volume = {47},
number = {7},
pages = {2367 - 2378},
year = {2014},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2013.09.026},
url = {http://www.sciencedirect.com/science/article/pii/S0031320313003981},
author = {Ilias Theodorakopoulos and Dimitris Kastaniotis and George Economou and Spiros Fotopoulos},



abstract = {Abstract Autoimmune diseases are proven to be connected with the occurrence of autoantibodies in patient serum. Antinuclear autoantibodies (ANAs) identification can be accomplished in a laboratory using indirect immunofluorescence (IIF) imaging. In this paper a system for automatic classification of staining patterns on HEp-2 fluorescence images is proposed. Our method utilizes two descriptors in order to encode gradient and textural characteristics of the depicted patterns. Along with distribution of SIFT features, we propose the new GoC-LBP descriptor based on co-occurrences of uniform Local Binary Patterns along directions dictated by the orientation of local gradient. At a second stage, the descriptors are fused while creating a dissimilarity representation of an image. A powerful classification scheme is incorporated, utilizing a discriminative sparse representation-based scheme for the classification. Experiments were conducted using a publicly available dataset, comparing the obtained performance to recently reported results of a relevant contest, demonstrating the effectives of the proposed method. }}
@article{Rodrigues201430,
title = {A system for formative assessment and monitoring of students' progress },
journal = {Computers & Education },
volume = {76},
number = {},
pages = {30 - 41},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.03.001},
url = {http://www.sciencedirect.com/science/article/pii/S0360131514000517},
author = {Fátima Rodrigues and Paulo Oliveira},
abstract = {Abstract Assessment plays a central role in any educational process as a way of evaluating the students' knowledge on the concepts associated with learning objectives. The assessment of free-text answers is a process that, besides being very costly in terms of time spent by teachers, may lead to inequities due to the difficulty in applying the same evaluation criteria to all answers. This paper describes a system composed by several modules whose main goal is to work as a formative assessment tool for students and to help teachers creating and assessing exams as well monitoring students' progress. The system automatically creates training exams for students to practice based on questions from previous exams and assists teachers in the creation of evaluation exams with various kinds of information about students' performance. The system automatically assesses training exams to give automatic feedback to students. The correction of free-text answers is based on the syntactic and semantic similarity between the student answers and various reference answers, thus going beyond the simple lexical matching. For this, several pre-processing tasks are performed in order to reduce each answer to its more manageable canonical form. Besides the syntactic and semantic similarity between answers, the way the teacher evaluates the answers is also acquired. To accomplish that, the assessment is done using sub scores defined by the teacher concerning parts of the answer or its subgoals. The system has been trained and tested on exams manually graded by History teachers. There is a good correlation between the evaluation of the instructors and the evaluation performed by our system. }}
@article{Bourgonjon20111434,
title = {Parental acceptance of digital game-based learning },
journal = {Computers & Education },
volume = {57},
number = {1},
pages = {1434 - 1444},
year = {2011},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.12.012},
url = {http://www.sciencedirect.com/science/article/pii/S036013151100008X},
author = {Jeroen Bourgonjon and Martin Valcke and Ronald Soetaert and Bram de Wever and Tammy Schellens},abstract = {In research about digital game-based learning, the likely negative perceptions of parents are often enlisted as a barrier toward the adoption of games in classroom settings. Teachers, students and policy makers appear to be influenced by what parents think about games in the classroom. Therefore, it is important to study these parental beliefs about games. The present research develops and validates a path model to explain and predict parental acceptation of video games in the classrooms of their children. The hypothetical model was found reliable and valid, based on a survey of 858 parents with at least one child in secondary education. Overall, the results show that 59% of the variance in parents’ preference for video games can be explained by the model comprising hypotheses about learning opportunities, subjective norm, perceived negative effects of gaming, experience with video games, personal innovativeness, and gender. }}
@article{Wei2014148,
title = {An experimental study of online chatting and notetaking techniques on college students’ cognitive learning from a lecture },
journal = {Computers in Human Behavior },
volume = {34},
number = {},
pages = {148 - 156},
year = {2014},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2014.01.019},
url = {http://www.sciencedirect.com/science/article/pii/S0747563214000247},
author = {Fang-Yi Flora Wei and Y. Ken Wang and Warren Fass},
abstract = {Abstract This experimental study investigated the effects of college students’ online chatting behavior and notetaking techniques (handwritten vs. computer-mediated) on their cognitive learning. The results showed that regardless of notetaking technique, students who did not participate in off-learning online chatting during class, compared to those who did, demonstrated better recall of lecture content and higher quality of note. In terms of cognitive learning, students who used laptops to take notes were least negatively affected by online chatting during class than those who took handwritten notes or took no notes during the lecture. The findings suggest that task switching and interruption result in reduced effectiveness of learning and notetaking; moreover, switching from handwriting on notepads to typing chat messages on computer keyboards demonstrated a motor delay compared to students who used the same devices to multitask. }}
@article{Yin201468,
title = {Colbar: A collaborative location-based regularization framework for QoS prediction },
journal = {Information Sciences },
volume = {265},
number = {},
pages = {68 - 84},
year = {2014},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2013.12.007},
url = {http://www.sciencedirect.com/science/article/pii/S0020025513008517},
author = {Jianwei Yin and Wei Lo and Shuiguang Deng and Ying Li and Zhaohui Wu and Naixue Xiong},abstract = {Abstract Quality-of-Service (QoS) is a fundamental element in Service-Oriented Computing (SOC) domain. At the ongoing age of Web 2.0, predicting the missing QoS values becomes more and more important since it is an indispensable preprocess of numerous service-oriented applications. Previous research works on this task underestimate the importance of users’ geographical information, which we argue would contribute to improving prediction accuracy in Web services invocation process. In this paper, we propose a novel collaborative location-based regularization framework (Colbar) to address the problem of personalized QoS prediction. We first leverage the personal geographical and QoS information to identify robust neighborhoods. And then, we collect the wisdom of crowds to construct two location-based regularization terms, which are integrated to build up an unified Matrix Factorization framework. Finally we make intermediate fusions to generate better prediction results. The experimental analysis on a large-scale real-world QoS dataset shows that the prediction accuracy of Colbar outperforms other state-of-the-art approaches in various criteria. }}
@article{Boyle20141,
title = {A narrative literature review of games, animations and simulations to teach research methods and statistics },
journal = {Computers & Education },
volume = {74},
number = {},
pages = {1 - 14},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.01.004},
url = {http://www.sciencedirect.com/science/article/pii/S0360131514000141},
author = {Elizabeth A. Boyle and Ewan W. MacArthur and Thomas M. Connolly and Thomas Hainey and Madalina Manea and Anne Kärki and Peter van Rosmalen},
abstract = {Abstract Basic competence in research methods and statistics is core for many undergraduates but many students experience difficulties in acquiring knowledge and skills in this area. Interest has recently turned to serious games as providing engaging ways of learning. The CHERMUG project was developed against this background to develop games to support students in learning about research methods and statistics. As a first step in designing the CHERMUG games a narrative literature review was carried out to establish whether similar games, animations and simulations already existed. Search terms used in the literature review included varied terms for digital games, simulations and animations, terms relevant to the twin goals of learning and engagement in games and terms for research methods and statistics. Application of the inclusion criteria led to 26 papers which were considered relevant. Synthesis of the papers suggested that there is reason to be optimistic that a game-based approach might be effective in learning in this area. }}
@article{Zhan2011961,
title = {Effects of an online learning community on active and reflective learners’ learning performance and attitudes in a face-to-face undergraduate course },
journal = {Computers & Education },
volume = {56},
number = {4},
pages = {961 - 968},
year = {2011},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.11.012},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510003337},
author = {Zehui Zhan and Fuyin Xu and Huiwen Ye},
abstract = {The purpose of this study was to examine the effects of an Online Learning Community (OLC) on active and reflective learners’ learning performance and attitude in a face-to-face undergraduate digital design course. 814 freshmen in an introductory digital design course were randomly assigned to one of two treatments: one offered students an OLC, which required students to discuss their assignments and readings online and participate in certain online learning activities; the other one did not offer the OLC (NC: no online learning community), but required involving students in face-to-face discussion. Individual students’ learning styles were measured using Felder and Solomon’s Index of Learning Styles Questionnaire. Results indicated that both active and reflective learners in the OLC intervention performed significantly better than those who were in the NC intervention. Results also indicated that active learners performed significantly better than reflective learners in the NC intervention; however, reflective learners performed significantly better than active learners in the OLC intervention. No significant difference between active and reflective learners’ attitudes was found. These findings indicated that OLC might be an effective means for improving both active and reflective learners’ learning performance and attitudes; however, its effects on active learners might not be as great as on reflective learners. }}
@article{Lester20144,
title = {Designing game-based learning environments for elementary science education: A narrative-centered learning perspective },
journal = {Information Sciences },
volume = {264},
number = {},
pages = {4 - 18},
year = {2014},
note = {Serious Games },
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2013.09.005},
url = {http://www.sciencedirect.com/science/article/pii/S0020025513006385},
author = {James C. Lester and Hiller A. Spires and John L. Nietfeld and James Minogue and Bradford W. Mott and Eleni V. Lobene},abstract = {Abstract Game-based learning environments hold significant promise for STEM education, yet they are enormously complex. Crystal Island: Uncharted Discovery, is a game-based learning environment designed for upper elementary science education that has been under development in our laboratory for the past four years. This article discusses curricular and narrative interaction design requirements, presents the design of the Crystal Island learning environment, and describes its evolution through a series of pilots and field tests. Additionally, a classroom integration study was conducted to initiate a shift towards ecological validity. Results indicated that Crystal Island produced significant learning gains on both science content and problem-solving measures. Importantly, gains were consistent for gender across studies. This finding is key in light of past studies that revealed disproportionate participation by boys within game-based learning environments. }}
@article{Walter2015152,
title = {Neuromorphic implementations of neurobiological learning algorithms for spiking neural networks },
journal = {Neural Networks },
volume = {72},
number = {},
pages = {152 - 167},
year = {2015},
note = {Neurobiologically Inspired Robotics: Enhanced Autonomy through Neuromorphic Cognition },
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2015.07.004},
url = {http://www.sciencedirect.com/science/article/pii/S0893608015001410},
author = {Florian Walter and Florian Röhrbein and Alois Knoll},

abstract = {Abstract The application of biologically inspired methods in design and control has a long tradition in robotics. Unlike previous approaches in this direction, the emerging field of neurorobotics not only mimics biological mechanisms at a relatively high level of abstraction but employs highly realistic simulations of actual biological nervous systems. Even today, carrying out these simulations efficiently at appropriate timescales is challenging. Neuromorphic chip designs specially tailored to this task therefore offer an interesting perspective for neurorobotics. Unlike Von Neumann CPUs, these chips cannot be simply programmed with a standard programming language. Like real brains, their functionality is determined by the structure of neural connectivity and synaptic efficacies. Enabling higher cognitive functions for neurorobotics consequently requires the application of neurobiological learning algorithms to adjust synaptic weights in a biologically plausible way. In this paper, we therefore investigate how to program neuromorphic chips by means of learning. First, we provide an overview over selected neuromorphic chip designs and analyze them in terms of neural computation, communication systems and software infrastructure. On the theoretical side, we review neurobiological learning techniques. Based on this overview, we then examine on-die implementations of these learning algorithms on the considered neuromorphic chips. A final discussion puts the findings of this work into context and highlights how neuromorphic hardware can potentially advance the field of autonomous robot systems. The paper thus gives an in-depth overview of neuromorphic implementations of basic mechanisms of synaptic plasticity which are required to realize advanced cognitive capabilities with spiking neural networks. }}
@article{Loncar201493,
title = {Towards the refinement of forum and asynchronous online discussion in educational contexts worldwide: Trends and investigative approaches within a dominant research paradigm },
journal = {Computers & Education },
volume = {73},
number = {},
pages = {93 - 110},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.12.007},
url = {http://www.sciencedirect.com/science/article/pii/S036013151300331X},
author = {Michael Loncar and Neil E. Barrett and Gi-Zen Liu},
abstract = {Abstract The growth of asynchronous online discussion (AOD) in primary, secondary, undergraduate, and post-graduate contexts and courses has resulted in a growing body of literature that provides valuable insights into the issues surrounding the use of online writing, online discussion, and distance and blended learning in formal education worldwide. This phenomenological critical literature review provides an overview of research focused on forum use and AOD published from 2008 to 2012. Papers were chosen based on a selection process suggested by Wu et al. (2012), where nine of the most influential e-learning education and educational review journals were searched according to year, 2008–2012, and the following  involved in forum and AOD use in educational contexts globally. }}
@article{Adams2014149,
title = {Integrating self-explanation functionality into a complex game environment: Keeping gaming in motion },
journal = {Computers & Education },
volume = {73},
number = {},
pages = {149 - 159},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2014.01.002},
url = {http://www.sciencedirect.com/science/article/pii/S0360131514000128},
author = {Deanne M. Adams and Douglas B. Clark},abstract = {Abstract Previous research has shown that either asking students to explain their answers or providing explanatory feedback can be effective ways to increase learning from an educational game. This study focused on an educational physics game about Newton's 3 Laws of Motion called SURGE: The Fuzzy Chronicles. Eighty-six middle school students played one of three versions of the game: (1) the base version with no tips or questions, (2) the self-explanation version with self-explanation questions prompts, and (3) the explanatory feedback version with gameplay tips. There were no significant overall learning differences between the three groups, but students in the base version successfully answered more questions about Newton's second law than students in the self-explanation group. This may have been due to students in the base condition progressing significantly further through the game than students in the self-explanation group. The results suggest that the cognitive load for gameplay as well as game flow must be managed in order for students to take advantage of explanation functionality in educational tools designed to increase deeper, germane processing. }}
@article{Huang2011694,
title = {Evaluating learners’ motivational and cognitive processing in an online game-based learning environment },
journal = {Computers in Human Behavior },
volume = {27},
number = {2},
pages = {694 - 704},
year = {2011},
note = {Web 2.0 in Travel and Tourism: Empowering and Changing the Role of Travelers },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2010.07.021},
url = {http://www.sciencedirect.com/science/article/pii/S0747563210002177},
author = {Wen-Hao Huang},abstract = {This paper describes the process and results of an evaluation on an online game-based learning environment (GBLE) by focusing on learners’ motivational processing and cognitive processing. The goal is to explore how online GBLE might initiate and support learners’ goal-setting activities and impact learners’ cognitive loads. The study surveyed 144 undergraduate students after their autonomous participation in the online game available at the Nobel Prize Foundation website teaching the Heckscher–Ohlin Theory on international trade. Grounded in the integrative theory of motivation, volition, and performance (MVP), the evaluation indicated that participants felt significantly confident in learning the subject. The perceived satisfaction, however, was lower than the rest of motivational components possibly due to heavy cognitive processing. The finding of cognitive load reported that learners perceived a significantly higher level of intrinsic load than the germane load due to the novelty of the subject matter. Data analysis further indicated a significant canonical correlation between learners’ motivational and cognitive processing. This particular finding could inform future research to investigate specific motivational processing components’ effects on learners’ cognitive load levels in online GBLEs. }}
@article{Lust2012795,
title = {Content Management Systems: Enriched learning opportunities for all? },
journal = {Computers in Human Behavior },
volume = {28},
number = {3},
pages = {795 - 808},
year = {2012},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2011.12.009},
url = {http://www.sciencedirect.com/science/article/pii/S0747563211002779},
author = {Griet Lust and Norma A. Juarez Collazo and Jan Elen and Geraldine Clarebout},
abstract = {This article examines the popular claim of Content Management Systems (CMSs) that providing a rich toolset and leaving the use under learner control is beneficial to learning. By means of a literature review, the current contribution examines whether all students are capable of using CMS tools so that their learning is enhanced. In contrast to what is assumed, the study conceptualizes tool use as a complex self-regulation strategy that cannot be taken for granted. Specifically, the article reviews empirical studies in relation to three topics: (a) personal agency in tool use, (b) performance effects of tool use and (c) influencing tool use variables. Findings reveal that not every student profited from the CMS learning opportunities; in multiple studies students differed in their tool use, and these differences had significant performance effects. Hence, these findings suggest that the pedagogical claim CMSs make is problematic. Besides this accumulated corpus of knowledge, the review revealed serious limitations in the retrieved studies which could hamper our findings. As a consequence, the review establishes a need for further research into students’ CMS tool use from an instructional design perspective. In addition to the theoretical framework, several directions for future research are given. }}
@article{Schweizer201168,
title = {The structure of research methodology competency in higher education and the role of teaching teams and course temporal distance },
journal = {Learning and Instruction },
volume = {21},
number = {1},
pages = {68 - 76},
year = {2011},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2009.11.002},
url = {http://www.sciencedirect.com/science/article/pii/S0959475209001133},
author = {Karl Schweizer and Merle Steinwascher and Helfried Moosbrugger and Siegbert Reiss},



abstract = {The development of research methodology competency is a major aim of the psychology curriculum at universities. Usually, three courses concentrating on basic statistics, advanced statistics and experimental methods, respectively, serve the achievement of this aim. However, this traditional curriculum-based course structure gives rise to the question whether an integrative research methodology competency is actually achieved or whether independent course-specific sub-competencies are established instead. To find out whether the course structure is favourable for the development of research methodology competency, items representing the contents of the three courses were applied to a sample of university students. Content validity was assured by a close relationship of the items with course contents and course tests. The investigation revealed a three-dimensional first-order structure in combination with a common second-order dimension. Differences between teaching teams and course temporal distance showed to have no influence. }}
@article{Konak201411,
title = {Using Kolb's Experiential Learning Cycle to improve student learning in virtual computer laboratories },
journal = {Computers & Education },
volume = {72},
number = {},
pages = {11 - 22},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.10.013},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513002984},
author = {Abdullah Konak and Tricia K. Clark and Mahdi Nasereddin},abstract = {Abstract In information security education, learning experiences that involve hands-on experimentation are extremely important. However, information security topics are challenging to teach in traditional computer laboratories mainly due to restrictive information technology policies. In the literature, virtual computer laboratories have been proposed to address the challenges of providing students with hands-on learning experiences in information security. While the literature mainly focuses on technical aspects of virtual computer laboratories and related hands-on activities, pedagogical aspects of hands-on activities are overlooked. Our experiences with a virtual computer laboratory have shown that hands-on activities which are designed based on a prescriptive, step-by-step approach do not always achieve the expected learning outcomes. In this paper, we propose Kolb's Experiential Learning Cycle as a framework to design hands-on activities in virtual computer laboratories, and we argue that hands-on activities designed based on this framework enhance student learning outcomes. We illustrate how the stages of Kolb's model can be incorporated into hands-on activities and present results from two empirical studies to test the effectiveness of the proposed framework. The empirical findings in the first study suggest that hands-on activities designed based on the proposed framework are more likely to increase student interest and competency compared to step-by-step hands-on activities. In the second study, the collected data is analyzed using structural equation modeling to determine the relationships among the factors affecting student learning outcomes as a result of hands-on activities. The results of the second study show that student-to-student interaction is an important factor determining student learning experiences. }}
@article{Chakrabarti20156878,
title = {Artificial conversations for customer service chatter bots: Architecture, algorithms, and evaluation metrics },
journal = {Expert Systems with Applications },
volume = {42},
number = {20},
pages = {6878 - 6897},
year = {2015},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2015.04.067},
url = {http://www.sciencedirect.com/science/article/pii/S0957417415003097},
author = {Chayan Chakrabarti and George F. Luger},

abstract = {Abstract Chatter bots are software programs that engage in artificial conversations through a text-based input medium. They are extensively deployed in customer service applications. Existing approaches to artificial conversation generation emphasize grammatical and linguistic modeling techniques. They focus on generation of discrete sentence-level utterances. These approaches perform poorly in conversational situations requiring contextual continuity over a series of utterances. We present an approach that combines pragmatics with content semantics to generate artificial conversations in the customer service domain. A conversation is a process that adheres to well-defined semantic conventions and is contextually grounded in domain-specific knowledge. We model this using stochastic finite state machines, where the parameters of the model are learned from a corpus of human conversations. We present a specific set of criteria which we then use to evaluate the quality of artificial conversations in the customer service domain. We also compare chatter bot generated artificial conversations with human generated natural conversations in this domain. }}
@article{DeWever20066,
title = {Content analysis schemes to analyze transcripts of online asynchronous discussion groups: A review },
journal = {Computers & Education },
volume = {46},
number = {1},
pages = {6 - 28},
year = {2006},
note = {Methodological Issues in Researching CSCL },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2005.04.005},
url = {http://www.sciencedirect.com/science/article/pii/S0360131505000552},
author = {B. De Wever and T. Schellens and M. Valcke and H. Van Keer},
abstract = {Research in the field of Computer Supported Collaborative Learning (CSCL) is based on a wide variety of methodologies. In this paper, we focus upon content analysis, which is a technique often used to analyze transcripts of asynchronous, computer mediated discussion groups in formal educational settings. Although this research technique is often used, standards are not yet established. The applied instruments reflect a wide variety of approaches and differ in their level of detail and the type of analysis categories used. Further differences are related to a diversity in their theoretical base, the amount of information about validity and reliability, and the choice for the unit of analysis. This article presents an overview of different content analysis instruments, building on a sample of models commonly used in the CSCL-literature. The discussion of 15 instruments results in a number of critical conclusions. There are questions about the coherence between the theoretical base and the operational translation of the theory in the instruments. Instruments are hardly compared or contrasted with one another. As a consequence the empirical base of the validity of the instruments is limited. The analysis is rather critical when it comes to the issue of reliability. The authors put forward the need to improve the theoretical and empirical base of the existing instruments in order to promote the overall quality of CSCL-research. }}
@article{Pereira2014580,
title = {Student-generated online videos to develop cross-curricular and curricular competencies in Nursing Studies },
journal = {Computers in Human Behavior },
volume = {31},
number = {},
pages = {580 - 590},
year = {2014},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2013.06.011},
url = {http://www.sciencedirect.com/science/article/pii/S0747563213002033},
author = {Juanan Pereira and Leyre Echeazarra and Silvia Sanz-Santamaría and Julián Gutiérrez},

abstract = {Abstract In response to the necessity of implementing innovative strategies and new teaching methodologies for the design of University degrees curricula according to the new educational model put forward by the European Space of Higher Education, we launched a pilot project in the Department of Nursing Studies of a university of the north of Spain based on the use of three technological tools (Power point, OpenMeetings and Babelium). Nursing students (n = 29) were asked to create video recorded oral presentations about different techniques of diagnosis in medical imaging that were peer-, self- and teacher assessed. Self-report questionnaires were used to assess the effectiveness of the experiment and Kappa statistic analysis was used to determine the suitability of the assessment method. The results of the study showed that working with self and peer recorded videos proves to be a better didactic method to develop both cross-curricular competencies (intrapersonal, interpersonal and instrumental) and curricular specific competencies (in this case, knowledge about different techniques of diagnosis in medical imaging) than traditional methodologies. The data also suggest that there is an acceptable correspondence between self-, peer- and hetero-assessment. }}
@article{Magner2014141,
title = {Triggering situational interest by decorative illustrations both fosters and hinders learning in computer-based learning environments },
journal = {Learning and Instruction },
volume = {29},
number = {},
pages = {141 - 152},
year = {2014},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2012.07.002},
url = {http://www.sciencedirect.com/science/article/pii/S0959475212000515},
author = {Ulrike I.E. Magner and Rolf Schwonke and Vincent Aleven and Octav Popescu and Alexander Renkl},abstract = {Do decorative illustrations in computer-based learning environments trigger interest and engagement in learning or do they distract? In a pre-study (N = 87 8th grade students) we tested the effects of decorative illustrations on situational interest and we selected highly interesting illustrations for our main study. In the latter study (N = 52) we tested the influence of interesting decorative illustrations on immediate learning outcomes in geometry (near and far transfer) and on further learning. Decorative illustrations hindered near transfer for students with low prior knowledge; students with very high prior knowledge levels profited from this kind of illustrations. Although, we did not find an overall effect on far transfer, decorative illustrations foster far transfer via enhanced situational interest. There were no effects on further learning. Overall, our findings suggest that the dominating cognitive interpretations of multimedia effects should be supplemented by considering the interplay between cognitive and motivational factors. }}
@article{Kim2014758,
title = {Sentiment visualization and classification via semi-supervised nonlinear dimensionality reduction },
journal = {Pattern Recognition },
volume = {47},
number = {2},
pages = {758 - 768},
year = {2014},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2013.07.022},
url = {http://www.sciencedirect.com/science/article/pii/S003132031300321X},
author = {Kyoungok Kim and Jaewook Lee},abstract = {Abstract Sentiment analysis, which detects the subjectivity or polarity of documents, is one of the fundamental tasks in text data analytics. Recently, the number of documents available online and offline is increasing dramatically, and preprocessed text data have more features. This development makes analysis more complex to be analyzed effectively. This paper proposes a novel semi-supervised Laplacian eigenmap (SS-LE). The SS-LE removes redundant features effectively by decreasing detection errors of sentiments. Moreover, it enables visualization of documents in perceptible low dimensional embedded space to provide a useful tool for text analytics. The proposed method is evaluated using multi-domain review data set in sentiment visualization and classification by comparing other dimensionality reduction methods. SS-LE provides a better similarity measure in the visualization result by separating positive and negative documents properly. Sentiment classification models trained over reduced data by SS-LE show higher accuracy. Overall, experimental results suggest that SS-LE has the potential to be used to visualize documents for the ease of analysis and to train a predictive model in sentiment analysis. SS-LE can also be applied to any other partially annotated text data sets. }}
@article{Ibáñez20141,
title = {Experimenting with electromagnetism using augmented reality: Impact on flow student experience and educational effectiveness },
journal = {Computers & Education },
volume = {71},
number = {},
pages = {1 - 13},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.09.004},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513002571},
author = {María Blanca Ibáñez and Ángela Di Serio and Diego Villarán and Carlos Delgado Kloos},
abstract = {Abstract Educational researchers have recognized Augmented Reality (AR) as a technology with great potential to impact affective and cognitive learning outcomes. However, very little work has been carried out to substantiate these claims. The purpose of this study was to assess to which extent an AR learning application affects learners' level of enjoyment and learning effectiveness. The study followed an experimental/control group design using the type of the application (AR-based, web-based) as independent variable. 64 high school students were randomly assigned to the experimental or control group to learn the basic principles of electromagnetism. The participants' knowledge acquisition was evaluated by comparing pre- and post-tests. The participants' level overall-state perception on flow was measured with the Flow State Scale and their flow states were monitored throughout the learning activity. Finally, participants' perceptions of benefits and difficulties of using the augmented reality application in this study were qualitatively identified. The results showed that the augmented reality approach was more effective in promoting students' knowledge of electromagnetic concepts and phenomena. The analysis also indicated that the augmented reality application led participants to reach higher flow experience levels than those achieved by users of the web-based application. However, not all the factors seem to have influence on learners' flow state, this study found that they were limited to: concentration, distorted sense of time, sense of control, clearer direct feedback, and autotelic experience. A deeper analysis of the flow process showed that neither of the groups reported being in flow in those tasks that were very easy or too difficult. However, for those tasks that were not perceived as difficult and included visualization clues, the experimental group showed higher levels of flow that the control group. The study suggests that augmented reality can be exploited as an effective learning environment for learning the basic principles of electromagnetism at high school provided that learning designers strike a careful balance between AR support and task difficulty. }}
@article{Kong201516,
title = {An experience of a three-year study on the development of critical thinking skills in flipped secondary classrooms with pedagogical and technological support },
journal = {Computers & Education },
volume = {89},
number = {},
pages = {16 - 31},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.08.017},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515300373},
author = {Siu Cheung Kong},
abstract = {Abstract The aim of this study was attempting to investigate the outcome of critical thinking achievement of learners when its development is infused into subject teaching with pedagogical and technological support. A total of 124 junior secondary students participated in the three-year trial teaching in Integrated Humanities subject. Flipped classroom strategy was implemented to engage learners in online pre-lesson learning preparation, in-class group discussion inside digital classroom and after-class extended learning using social learning platform. The critical thinking tests found that the students had good performance in the tasks on hypothesis identification, induction and deduction; and some achievements in the tasks on explanation and evaluation. It was found that students needed more time to develop capacities of deduction, explanation and evaluation. The semi-structured interviews found that the teachers and students valued the pedagogical way of providing guidance for students' group sharing for fostering critical thinking skills development. Three implications are discussed to shed light on the infusion of critical thinking skills development into the process of domain knowledge learning, the deployment of appropriate pedagogy to mobilize learners to engage in learning process, and the use of appropriate technology to facilitate learning process inside and outside of classroom. }}
@article{Barzilai201465,
title = {Scaffolding game-based learning: Impact on learning achievements, perceived learning, and game experiences },
journal = {Computers & Education },
volume = {70},
number = {},
pages = {65 - 79},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.08.003},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513002224},
author = {Sarit Barzilai and Ina Blau},
abstract = {Abstract One of the central challenges of integrating game-based learning in school settings is helping learners make the connections between the knowledge learned in the game and the knowledge learned at school, while maintaining a high level of engagement with game narrative and gameplay. The current study evaluated the effect of supplementing a business simulation game with an external conceptual scaffold, which introduces formal knowledge representations, on learners' ability to solve financial-mathematical word problems following the game, and on learners' perceptions regarding learning, flow, and enjoyment in the game. Participants (Mage = 10.10 years) were randomly assigned to three experimental conditions: a study and play condition that presented the scaffold first and then the game, a play and study condition, and a play only condition. Although no significant gains in problem-solving were found following the intervention, learners who studied with the external scaffold before the game performed significantly better in the post-game problem-solving assessment. Adding the external scaffold before the game reduced learners' perceived learning. However, the scaffold did not have a negative impact on reported flow and enjoyment. Flow was found to significantly predict perceived learning and enjoyment. Yet, perceived learning and enjoyment did not predict problem-solving and flow directly predicted problem solving only in the play and study condition. We suggest that presenting the scaffold may have problematized learners' understandings of the game by connecting them to disciplinary knowledge. Implications for the design of scaffolds for game-based learning are discussed. }}
@article{Burguillo2010566,
title = {Using game theory and Competition-based Learning to stimulate student motivation and performance },
journal = {Computers & Education },
volume = {55},
number = {2},
pages = {566 - 575},
year = {2010},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.02.018},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510000527},
author = {Juan C. Burguillo},abstract = {This paper introduces a framework for using Game Theory tournaments as a base to implement Competition-based Learning (CnBL), together with other classical learning techniques, to motivate the students and increase their learning performance. The paper also presents a description of the learning activities performed along the past ten years of a course where, in five of them, Competition-based Learning has been used. Finally, the experience gained is described together with an analysis of the feedback obtained from the students' surveys. The good survey results, and their similarity along the years, suggest that the combination of game theory with the use of friendly competitions provides a strong motivation for students; helping to increase their performance. }}
@article{Thomas2013199,
title = {Exploring the use of asynchronous online discussion in health care education: A literature review },
journal = {Computers & Education },
volume = {69},
number = {},
pages = {199 - 215},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.07.005},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513001723},
author = {Jenny Thomas},
abstract = {Abstract This paper highlights the different options associated with asynchronous online discussion (AOD) use in health care education which may have an impact on their effectiveness. The review was carried out following a search of specific databases, websites, key journals, references and key authors. All studies published between 2006 and 2012 that met specific inclusion/exclusion criteria were subject to quality appraisal. Fourteen studies met the quality appraisal criteria: six qualitative, four quasi-experimental, one observational and three mixed methods. Data extraction coupled with narrative synthesis enabled the description of options that emerged and exploration of the relationships within and between studies. Study design as well as methodological quality was mixed. However, several useful factors emerged which may impact on effectiveness. These include (a) the mode of e-moderation (b) provision of AOD for participants in the clinical setting to critically reflect, analyse and resolve clinical issues and (c) increased amount of time spent reading the AOD (but not the number of discussion ‘hits’). Research in this area appears to be in its infancy and one of the main recommendations is that further studies are required which focus on comparing the same type of AOD with and without a specific intervention in order to make any robust conclusions. }}
@article{Bujak2013536,
title = {A psychological perspective on augmented reality in the mathematics classroom },
journal = {Computers & Education },
volume = {68},
number = {},
pages = {536 - 544},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.02.017},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513000560},
author = {Keith R. Bujak and Iulian Radu and Richard Catrambone and Blair MacIntyre and Ruby Zheng and Gary Golubski},
abstract = {Physical objects and virtual information are used as teaching aids in classrooms everywhere, and until recently, merging these two worlds has been difficult at best. Augmented reality offers the combination of physical and virtual, drawing on the strengths of each. We consider this technology in the realm of the mathematics classroom, and offer theoretical underpinnings for understanding the benefits and limitations of AR learning experiences. The paper presents a framework for understanding AR learning from three perspectives: physical, cognitive, and contextual. On the physical dimension, we argue that physical manipulation affords natural interactions, thus encouraging the creation of embodied representations for educational concepts. On the cognitive dimension, we discuss how spatiotemporal alignment of information through AR experiences can aid student's symbolic understanding by scaffolding the progression of learning, resulting in improved understanding of abstract concepts. Finally, on the contextual dimension, we argue that AR creates possibilities for collaborative learning around virtual content and in non-traditional environments, ultimately facilitating personally meaningful experiences. In the process of discussing these dimensions, we discuss examples from existing AR applications and provide guidelines for future AR learning experiences, while considering the pragmatic and technological concerns facing the widespread implementation of augmented reality inside and outside the classroom. }}
@article{Lin2013416,
title = {Podcasting acceptance on campus: The differing perspectives of teachers and students },
journal = {Computers & Education },
volume = {68},
number = {},
pages = {416 - 428},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.06.003},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513001541},
author = {Shinjeng Lin and J. Christopher Zimmer and Velma Lee},
abstract = {Abstract Combining the Web and mobile technology, podcasting can be an effective tool for mobile and electronic learning, as it provides a learning environment anytime and anywhere. This research investigated how the Unified Theory of Acceptance and Use of Technology (UTAUT) (Venkatesh, Thong, &amp; Xu, 2012) can be applied to study the adoption of podcasting in higher education. Specifically, it examined whether and how user type (teachers or students) may affect differently adoption patterns of podcasting for educational purposes. The key findings include that for intent to adopt podcasting, effort expectancy is more important to students than teachers, while facilitating conditions factors such as copyright clearance and technical support availability are more important to teachers than students. The overall results are expected to contribute to theoretical development and industrial practices in promoting the acceptance of podcasting for educational purposes. }}
@article{Lombardi201350,
title = {Plausibility reappraisals and shifts in middle school students' climate change conceptions },
journal = {Learning and Instruction },
volume = {27},
number = {},
pages = {50 - 62},
year = {2013},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2013.03.001},
url = {http://www.sciencedirect.com/science/article/pii/S0959475213000285},
author = {Doug Lombardi and Gale M. Sinatra and E. Michael Nussbaum},
abstract = {Plausibility is a central but under-examined topic in conceptual change research. Climate change is an important socio-scientific topic; however, many view human-induced climate change as implausible. When learning about climate change, students need to make plausibility judgments but they may not be sufficiently critical or reflective. The purpose of this study was to examine how students' plausibility judgments and knowledge about human-induced climate change transform during instruction promoting critical evaluation. The results revealed that treatment group participants who engaged in critical evaluation experienced a significant shift in their plausibility judgments toward the scientifically accepted model of human-induced climate change. This shift was accompanied by significant conceptual change postinstruction that was maintained after a six-month delay. A comparison group who experienced a climate change activity that is part of their normal curriculum did not experience statistically significant changes. }}
@article{Cline20102282,
title = {A rule-based system for automatically evaluating student concept maps },
journal = {Expert Systems with Applications },
volume = {37},
number = {3},
pages = {2282 - 2291},
year = {2010},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2009.07.044},
url = {http://www.sciencedirect.com/science/article/pii/S095741740900712X},
author = {Ben E. Cline and Carlyle C. Brewster and Richard D. Fell},



abstract = {Concept maps have been heralded as an effective learning tool to help students integrate new concepts into their existing set of knowledge. They are also useful for evaluating student learning and helping to illuminate where learning has occurred and where invalid or incomplete ideas are held by the student. We have developed a web-based concept map construction and rule-based evaluation system called the Concept Mapping Tool (CMT) that is being deployed at the university level. After students use the drawing facility of CMT to construct individual concept maps for a particular topic that was presented in a course, they can then use the rule-based evaluation system to grade their concept maps against a criterion concept map created by the course instructor. Students are given immediate feedback on how to improve their concept maps, and they can use CMT iteratively to improve their understanding of the topic at hand. The rule-based evaluation or grading system is modeled in part on a manual system for the consistent scoring of concept maps. Our tests of the system show that there is a strong positive correlation (&gt;0.80) between the scores on students’ concept maps given by the course instructor grading manually and by the CMT rule-based evaluation system. }}
@article{Klois20132047,
title = {How hypertext fosters children’s knowledge acquisition: The roles of text structure and graphical overview },
journal = {Computers in Human Behavior },
volume = {29},
number = {5},
pages = {2047 - 2057},
year = {2013},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2013.03.013},
url = {http://www.sciencedirect.com/science/article/pii/S0747563213001027},
author = {Sabine Salome Klois and Eliane Segers and Ludo Verhoeven},
abstract = {Abstract Children in primary and secondary school are asked to go on the Internet for school purposes while research on hypertext has scarcely investigated how children process and learn from hypertext. We therefore examined how hypertext influences children’s knowledge acquisition from expository text. A group of 71 Dutch children (13 years old) from one secondary school for pre-university education participated in the study. In a within-subjects design with four conditions, we compared: regular linear text, regular text with overview, hypertext, and hypertext with overview. Children’s (a) navigation (i.e., reading time and navigation pattern) and (b) learning (i.e., multiple choice knowledge questions and mind maps) was measured. Although reading times did not differ, the children navigated less linearly in both hypertext conditions than in the regular text with overview condition. The four types of text led to the same deep understanding as measured on the text base level. Analyses of the mind maps, however, showed the children to construct richer situation models after reading hypertext or hypertext with an overview relative to regular linear text and regular text with overview. We therefore conclude that hypertext fosters a deeper level of information processing when appropriately designed relative to regular linear text. }}
@article{UrquizaFuentes2013178,
title = {Toward the effective use of educational program animations: The roles of student's engagement and topic complexity },
journal = {Computers & Education },
volume = {67},
number = {},
pages = {178 - 192},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.02.013},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513000523},
author = {Jaime Urquiza-Fuentes and J. Ángel Velázquez-Iturbide},
abstract = {Programming is one of the most complex subjects in computer science degrees. Program visualization is one of the approaches adopted to make programming concepts more accessible to students. In this work we study the educational impact of an active and highly engaging approach, namely the construction of program animations by students. We systematically compared this approach with two instructional scenarios, based on viewing animations and on the traditional instruction without systematic use of animations. A general conclusion of this work is that animations actually improve learning in terms of some educational aspects: short-term and long-term knowledge acquisition, and drop-out rates. Short-term improvements depend on the complexity level of the topic: while there is no impact for simple topics, there is a learning improvement in complex topics using the viewing and constructing approaches, and there is a learning improvement for highly complex topics using the viewing approach. In the long-term, drop-out rates were significantly decreased for students involved in the two most engaging approaches. In addition, both animation viewing and animation construction improved students' passing-rate in the term exam. Nevertheless, we were unable to prove in the long term that students involved in construction tasks yielded higher grades than those involved in viewing tasks. }}
@article{ThaiNghe20102811,
title = {Recommender system for predicting student performance },
journal = {Procedia Computer Science },
volume = {1},
number = {2},
pages = {2811 - 2819},
year = {2010},
note = {Proceedings of the 1st Workshop on Recommender Systems for Technology Enhanced Learning (RecSysTEL 2010)Proceedings of the 1st Workshop on Recommender Systems for Technology Enhanced Learning (RecSysTEL 2010) },
issn = {1877-0509},
doi = {http://dx.doi.org/10.1016/j.procs.2010.08.006},
url = {http://www.sciencedirect.com/science/article/pii/S1877050910003194},
author = {Nguyen Thai-Nghe and Lucas Drumond and Artus Krohn-Grimberghe and Lars Schmidt-Thieme},abstract = {Recommender systems are widely used in many areas, especially in e-commerce. Recently, they are also applied in e-learning tasks such as recommending resources (e.g. papers, books,..) to the learners (students). In this work, we propose a novel approach which uses recommender system techniques for educational data mining, especially for predicting student performance. To validate this approach, we compare recommender system techniques with traditional regression methods such as logistic/linear regression by using educational data for intelligent tutoring systems. Experimental results show that the proposed approach can improve prediction results. }}
@article{Ozcelik2010110,
title = {Why does signaling enhance multimedia learning? Evidence from eye movements },
journal = {Computers in Human Behavior },
volume = {26},
number = {1},
pages = {110 - 117},
year = {2010},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2009.09.001},
url = {http://www.sciencedirect.com/science/article/pii/S0747563209001459},
author = {Erol Ozcelik and Ismahan Arslan-Ari and Kursat Cagiltay},abstract = {Previous studies have suggested that signaling enhances multimedia learning. However, there is not enough evidence showing why signaling leads to better performance. The goal of this study was to examine the effects of signaling on learning outcomes and to reveal the underlying reasons for this effect by using eye movement measures. The participants were 40 undergraduate students who were presented with either signaled or nonsignaled multimedia materials. Labels in the illustration were signaled by temporarily changing the color of the items. The results suggest that the signaled group outperformed the nonsignaled group on transfer and matching tests. Eye movement data shows that signaling guided attention to relevant information and improved the efficiency and effectiveness of finding necessary information. }}
@article{Sánchez20131,
title = {Using online measures to determine how learners process instructional explanations },
journal = {Learning and Instruction },
volume = {26},
number = {},
pages = {1 - 11},
year = {2013},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2012.12.003},
url = {http://www.sciencedirect.com/science/article/pii/S0959475212001077},
author = {Emilio Sánchez and Héctor García-Rodicio},
abstract = {The goal of the present study was to examine the mechanisms underlying a strategy that we developed to make instructional explanations effective. In two experiments participants learned about plate tectonics from a multimedia material, including adjunct explanations that revised common misunderstandings. These explanations were either marked (including a device that pointed out the misunderstanding that the explanation was intended to revise) or unmarked. In both experiments participants receiving marked revising explanations outperformed those receiving unmarked ones in retention and transfer. In Experiment 1, think-aloud protocols revealed that marked revising explanations enabled learners to detect and repair flaws in their understanding more frequently than unmarked explanations. In Experiment 2, time recordings revealed that participants in the marked condition spent more time processing the revising explanations. Overall, the results mean that the revising instructional explanations that point out learners' misunderstandings promote a revision-oriented processing, in which learners monitor and revise their own understanding. }}
@article{Huk2009495,
title = {Combining cognitive and affective support in order to promote learning },
journal = {Learning and Instruction },
volume = {19},
number = {6},
pages = {495 - 505},
year = {2009},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2008.09.001},
url = {http://www.sciencedirect.com/science/article/pii/S0959475208000911},
author = {Thomas Huk and Stefan Ludwigs},abstract = {The present study investigated the impact of cognitive and affective support intervention on the learning outcomes of learners working with a simulation in economics. Cognitive support was given by statements in order to increase reflection and self-explanation in learners. Affective support was given by a goal-based scenario. Participants were 104 students of social science classes who were randomly allocated to a variant with cognitive and/or affective support as well as a basal variant without affective and cognitive support. Perceived germane cognitive load was increased by cognitive support but not by affective support. Understanding, as measured by posttest performance, was significantly increased by a combination of affective and cognitive support as compared to the basal variant without any support, while a single support intervention had no significant impact. The need for an augmented Cognitive Load Theory by the inclusion of affective factors is applied. }}
@article{Brinson2015218,
title = {Learning outcome achievement in non-traditional (virtual and remote) versus traditional (hands-on) laboratories: A review of the empirical research },
journal = {Computers & Education },
volume = {87},
number = {},
pages = {218 - 237},
year = {2015},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2015.07.003},
url = {http://www.sciencedirect.com/science/article/pii/S0360131515300087},
author = {James R. Brinson},
abstract = {Abstract This review presents the first attempt to synthesize recent (post-2005) empirical studies that focus on directly comparing learning outcome achievement using traditional lab (TL; hands-on) and non-traditional lab (NTL; virtual and remote) participants as experimental groups. Findings suggest that most studies reviewed (n = 50, 89%) demonstrate student learning outcome achievement is equal or higher in NTL versus TL across all learning outcome categories (knowledge and understanding, inquiry skills, practical skills, perception, analytical skills, and social and scientific communication), though the majority of studies (n = 53, 95%) focused on outcomes related to content knowledge, with most studies (n = 40, 71%) employing quizzes and tests as the assessment instrument. Scientific inquiry skills was the least assessed learning objective (n = 4, 7%), and lab reports/written assignments (n = 5, 9%) and practical exams (n = 5, 9%) were the least common assessment instrument. The results of this review raise several important concerns and questions to be addressed by future research. }}
@article{Jarodzka201362,
title = {Learning to see: Guiding students' attention via a Model's eye movements fosters learning },
journal = {Learning and Instruction },
volume = {25},
number = {},
pages = {62 - 70},
year = {2013},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2012.11.004},
url = {http://www.sciencedirect.com/science/article/pii/S0959475212000990},
author = {Halszka Jarodzka and Tamara van Gog and Michael Dorr and Katharina Scheiter and Peter Gerjets},
abstract = {This study investigated how to teach perceptual tasks, that is, classifying fish locomotion, through eye movement modeling examples (EMME). EMME consisted of a replay of eye movements of a didactically behaving domain expert (model), which had been recorded while he executed the task, superimposed onto the video stimulus. Seventy-five students were randomly assigned to one of three conditions: In two experimental conditions (EMME) the model's eye movements were superimposed onto the video either as a dot or as a spotlight, whereas the control group studied only the videos without the model's eye movements. In all conditions, students listened to the expert's verbal explanations. Results showed that both types of EMME guided students' attention during example study. Subsequent to learning, students performed a classification task for novel test stimuli without any support. EMME improved visual search and enhanced interpretation of relevant information for those novel stimuli compared to the control group; these effects were further moderated by the specific display. Thus, EMME during training can foster learning and improve performance on novel perceptual stimuli. }}
@article{Annetta200974,
title = {Investigating the impact of video games on high school students’ engagement and learning about genetics },
journal = {Computers & Education },
volume = {53},
number = {1},
pages = {74 - 85},
year = {2009},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2008.12.020},
url = {http://www.sciencedirect.com/science/article/pii/S0360131509000049},
author = {Leonard A. Annetta and James Minogue and Shawn Y. Holmes and Meng-Tzu Cheng},
abstract = {The popularity of video games has transcended entertainment crossing into the world of education. While the literature base on educational gaming is growing, there is still a lack of systematic study of this emerging technology’s efficacy. This quasi-experimental study evaluated a teacher created video game on genetics in terms of its affective and cognitive impact on student users. While statistical results indicated no differences (p &gt; .05) in student learning as measured by our instrument, there were significant differences (p &lt; .05) found in the participants’ level of engagement while interfacing with the video game. Implications on this emerging line of inquiry are discussed. }}
@article{vanderMeij2013845,
title = {Motivating agents in software tutorials },
journal = {Computers in Human Behavior },
volume = {29},
number = {3},
pages = {845 - 857},
year = {2013},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2012.10.018},
url = {http://www.sciencedirect.com/science/article/pii/S0747563212002981},
author = {H. van der Meij},abstract = {Abstract Pedagogical agents can provide important support for the user in human–computer interaction systems. This paper examines whether a supplementary, motivating agent in a print tutorial can enhance student motivation and learning in software training. The agent served the role of motivator, attending the students to issues of task relevance and self-efficacy. The agent was presented in the tutorial by means of images and written messages. An experiment compared the agent condition with a no-agent (control) condition. Participants were 49 students (mean age 11.3 years) from the upper grades of elementary school. Data on motivation and learning were gathered before, during and after training. The findings revealed that students in the agent condition did significantly better on skills measures during and after training (i.e., performance indicators, posttest, and retention test). In addition, marginally significant differences favoring these students were found for flow experience during training and for motivational gains on task relevance and self-efficacy after training. The design strategies of the motivating agent are considered relevant for the creation of Animated Pedagogical Agents. }}
@article{Gunn1996157,
title = {CAL evaluation: What questions are being answered? A response to the article integrative evaluation by Draper et al. },
journal = {Computers & Education },
volume = {27},
number = {3–4},
pages = {157 - 160},
year = {1996},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/S0360-1315(96)00028-0},
url = {http://www.sciencedirect.com/science/article/pii/S0360131596000280},
author = {Cathy Gunn}}
@article{Tomašev2015157,
title = {Hubness-aware kNN classification of high-dimensional data in presence of label noise },
journal = {Neurocomputing },
volume = {160},
number = {},
pages = {157 - 172},
year = {2015},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2014.10.084},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215001228},
author = {Nenad Tomašev and Krisztian Buza},

abstract = {Abstract Learning with label noise is an important issue in classification, since it is not always possible to obtain reliable data labels. In this paper we explore and evaluate a new approach to learning with label noise in intrinsically high-dimensional data, based on using neighbor occurrence models for hubness-aware k-nearest neighbor classification. Hubness is an important aspect of the curse of dimensionality that has a negative effect on many types of similarity-based learning methods. As we will show, the emergence of hubs as centers of influence in high-dimensional data affects the learning process in the presence of label noise. We evaluate the potential impact of hub-centered noise by defining a hubness-proportional random label noise model that is shown to induce a significantly higher kNN misclassification rate than the uniform random label noise. Real-world examples are discussed where hubness-correlated noise arises either naturally or as a consequence of an adversarial attack. Our experimental evaluation reveals that hubness-based fuzzy k-nearest neighbor classification and Naive Hubness-Bayesian k-nearest neighbor classification might be suitable for learning under label noise in intrinsically high-dimensional data, as they exhibit robustness to high levels of random label noise and hubness-proportional random label noise. The results demonstrate promising performance across several data domains. }}
@article{Yang2009848,
title = {Examining high-school students’ preferences toward learning environments, personal beliefs and concept learning in web-based contexts },
journal = {Computers & Education },
volume = {52},
number = {4},
pages = {848 - 857},
year = {2009},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2008.12.008},
url = {http://www.sciencedirect.com/science/article/pii/S0360131508001991},
author = {Fang-Ying Yang and Cheng-Chieh Chang},abstract = {The purpose of the study is to explore three kinds of personal affective traits among high-school students and their effects on web-based concept learning. The affective traits include personal preferences about web-based learning environments, personal epistemological beliefs, and beliefs about web-based learning. One hundred 11th graders participated in the study. Three questionnaires were developed to assess these affective characteristics. An online test and the flow-map technique were employed to probe concept achievements that indicated the learning outcome. Descriptive statistics, t-tests, correlation and regression analyses were conducted to present trends and relations among variables. It was found that participants of the study who mostly had not developed sophisticated epistemological beliefs displayed only moderate preferences toward explorative and interactive web-based learning environments, and they seemed to be conservative about the effectiveness of the new type of learning. According to the flow-map technique, the serial form of concept achievements was the main product of concept learning in the explorative web-based environments defined in the study. Regression analyses indicated that while preferences toward inquiry-based instructional designs and outward interactions, and the simple form of personal epistemology predicted concept achievements, beliefs about effectiveness of web-based learning resulted in a negative impact on concept learning. }}
@article{deFrança20155065,
title = {A biclustering approach for classification with mislabeled data },
journal = {Expert Systems with Applications },
volume = {42},
number = {12},
pages = {5065 - 5075},
year = {2015},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2015.02.045},
url = {http://www.sciencedirect.com/science/article/pii/S0957417415001529},
author = {Fabrício O. de França and André L.V. Coelho},abstract = {Abstract Labeling samples on large data sets is a demanding task prone to different sources of errors. Those errors, denoted as noise, can significantly impact the performance of a classification algorithm due to overfitting of wrongly labeled data. So far, this problem has been treated by avoiding the overfitting and correcting mislabeled data through similarity analysis. The former approach can be affected by the curse of dimensionality and some mislabeled data will not be corrected. In this paper, we investigate the use of a biclustering approach to capture local models of coherence across subsets of instances and attributes. Those models are used to replace and augment the attributes of the original dataset. Through a systematic series of experiments, we have assessed the performance of the proposed approach, referred to as BicNoise, by considering different rates and types of label noise, and also different types of classifiers, binary datasets, and evaluation metrics. The good results achieved suggest that the transformed data can alleviate the dimensionality problem, reduce the redundancy of correlated features and improve the separability of the data, thus improving the classifier performance (most noticeably, in the highest noise settings). }}
@article{Amadieu2009381,
title = {Prior knowledge in learning from a non-linear electronic document: Disorientation and coherence of the reading sequences },
journal = {Computers in Human Behavior },
volume = {25},
number = {2},
pages = {381 - 388},
year = {2009},
note = {Including the Special Issue: State of the Art Research into Cognitive Load Theory },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2008.12.017},
url = {http://www.sciencedirect.com/science/article/pii/S0747563208002288},
author = {Franck Amadieu and André Tricot and Claudette Mariné},

abstract = {A study was carried out to investigate the effects of prior knowledge on learning with a non-linear electronic document including an interactive conceptual map. Cognitive Load Theory was used as theoretical framework to investigate effects on cognitive load and disorientation in learning from non-linear documents. Forty-four future high school biology teachers were required to learn the multiplication cycle of a virus from either a hierarchical structure (organisational links) or a network structure (relational links). For the low prior knowledge learners, the results showed that the hierarchical structure supported better free recall performance and reduced feelings of disorientation. In contrast, the high prior knowledge learners performed better and followed more coherent reading sequences in the network structure. However, no interaction effect between prior knowledge and the type of structure was observed on mental effort and disorientation ratings. The results and the construct of disorientation are discussed in light of the processing demands in non-linear documents. }}
@article{Limniou200945,
title = {Integration of simulation into pre-laboratory chemical course: Computer cluster versus WebCT },
journal = {Computers & Education },
volume = {52},
number = {1},
pages = {45 - 52},
year = {2009},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2008.06.006},
url = {http://www.sciencedirect.com/science/article/pii/S0360131508000961},
author = {Maria Limniou and Nikos Papadopoulos and Christopher Whitehead},
abstract = {Pre-laboratory activities have been known to improve students’ preparation before their practical work as they assist students to make available more working memory capacity for actual learning during the laboratory. The aim of this investigation was to compare two different teaching approaches which supported a pre-laboratory session by using the same simulation program. The investigation was conducted in two countries (Greece and UK). The Greek students attended the course in a computer cluster, where the teacher and the students had a face-to-face communication, while the English students participated in the on-line WebCT course, where there was an on-line asynchronous discussion. A crucial point which emerged from this investigation was that the simulation program in the two different pre-laboratory training sessions gave the same learning outcome; however, the learning characteristics and the teacher’s effort were different. Thus, the teacher could adopt both the two teaching approaches depending on the university facilities, the staff’s time and the students’ familiarity with virtual learning environments. However, in each case of students followed a different way (collaboration or/and independent learning) to obtain the similar learning outcome. In all cases after their pre-laboratory training session they entered the laboratory performing the experiments without any further instructions. Additionally, the teacher’s role was slight difference in the two teaching approaches. In the computer cluster, the teacher had a more active role guiding students to obtain the expected learning outcome through face-to-face discussion and interaction, whereas in the case of the virtual learning environment (WebCT), the teacher had a more of a facilitator role focused on posing questions to the students and collecting the resources promoting the independent learning. }}
@article{Shaw200992,
title = {The impact of information richness on information security awareness training effectiveness },
journal = {Computers & Education },
volume = {52},
number = {1},
pages = {92 - 100},
year = {2009},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2008.06.011},
url = {http://www.sciencedirect.com/science/article/pii/S0360131508001012},
author = {R.S. Shaw and Charlie C. Chen and Albert L. Harris and Hui-Jou Huang},

abstract = {In recent years, rapid progress in the use of the internet has resulted in huge losses in many organizations due to lax security. As a result, information security awareness is becoming an important issue to anyone using the Internet. To reduce losses, organizations have made information security awareness a top priority. The three main barriers to information security awareness are: (1) general security awareness, (2) employees’ computer skills, and (3) organizational budgets. Online learning appears a feasible alternative to providing information security awareness and countering these three barriers. Research has identified three levels of security awareness: perception, comprehension and projection. This paper reports on a laboratory experiment that investigates the impacts of hypermedia, multimedia and hypertext to increase information security awareness among the three awareness levels in an online training environment. The results indicate that: (1) learners who have the better understanding at the perception and comprehension levels can improve understanding at the projection level; (2) learners with text material perform better at the perception level; and (3) learners with multimedia material perform better at the comprehension level and projection level. The results could be used by educators and training designers to create meaningful information security awareness materials. }}
@article{Leijen2009169,
title = {Streaming video to enhance students’ reflection in dance education },
journal = {Computers & Education },
volume = {52},
number = {1},
pages = {169 - 176},
year = {2009},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2008.07.010},
url = {http://www.sciencedirect.com/science/article/pii/S0360131508001097},
author = {Äli Leijen and Ineke Lam and Liesbeth Wildschut and P. Robert-Jan Simons and Wilfried Admiraal},



abstract = {This paper presents an evaluation case study that describes the experiences of 15 students and 2 teachers using a video-based learning environment, DiViDU, to facilitate students’ daily reflection activities in a composition course and a ballet course. To support dance students’ reflection processes streaming video was applied as follows: video editing and viewing for facilitating students in describing their practice; writing online self-assessments about the experiences captured on video to support students in evaluating their practice; online peer-feedback activities concerning the recorded practice for facilitating students in learning from multiple perspectives. In the composition course eight students reflected on their choreographic work, which was performed by their peer students. In the ballet course seven students reflected on themselves practicing the ballet technique. Data about the streaming video facilitation were collected after the completion of the reflection assignments using semi-structured interviews. The results revealed that students in both courses considered steaming video as effective for carrying out self-evaluations. The usefulness of video and online peer-feedback for other reflection processes differed among the courses in students’ view. The teachers considered streaming video generally useful for all the reflection processes of their students; however they also indicated some shortcomings. }}
@article{Andrade20081510,
title = {Guidelines for the development of e-learning systems by means of proactive questions },
journal = {Computers & Education },
volume = {51},
number = {4},
pages = {1510 - 1522},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2008.02.002},
url = {http://www.sciencedirect.com/science/article/pii/S0360131508000389},
author = {Javier Andrade and Juan Ares and Rafael García and Santiago Rodríguez and María Seoane and Sonia Suárez},
abstract = {The current development approaches for e-learning systems fail to explain in a clear and consistent way the pedagogical principles that support them. Moreover, decisions with regard to the structuration of each component proposed by these approaches are mainly taken by the designer/developer. As a result, the ensuing e-learning systems reflect common sense rather than a theoretically informed and systematic design. The present paper proposes a global architecture model for any e-learning system whose blocks are extracted from the analysis of the main approaches that currently guide the development of these kinds of systems. We use Kipling’s famous questions to define and structure the blocks of the proposed model, and we base the answers to these questions on two disciplines that are closed to e-learning: presential education (i.e., its pedagogical theories) and knowledge management. }}
@article{Sun2013171,
title = {Effect of interactivity on learner perceptions in Web-based instruction },
journal = {Computers in Human Behavior },
volume = {29},
number = {1},
pages = {171 - 184},
year = {2013},
note = {Including Special Section Youth, Internet, and Wellbeing },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2012.08.002},
url = {http://www.sciencedirect.com/science/article/pii/S0747563212002373},
author = {Jui-ni Sun and Yu-chen Hsu},
abstract = {The capacities of the Internet provide a flexible platform for learning that has overcome the limitations of time and space. To compensate for the lack of face-to-face communication in online education, interactivity design has become an important factor affecting online learning. This study examines how different levels of interactivity in Web-based instruction (WBI) influence learners’ perceptions of using WBI systems with a comprehensive interaction design. Three WBI systems were developed with low, medium, and high levels of interactivity, and the effect of interactivity on learners’ perceptions was investigated in a real class. The findings suggest a relationship between the interactivity level and learners’ attitudes, learning, and satisfaction, but not perceived interactivity. The results indicated that the learners required a certain amount of mental effort to access the system initially; however, repeated exposure to the WBI systems increased their ability to operate the systems, which in turn increased the similarity of the interactivity perceptions of the three groups. Although the learners felt no differences in the interactivity toward the end of the 6-week class owing to familiarity with the system, the benefits of higher interactivity remained. This indicates that learners’ interactivity perceptions may change as their experience increases, but different interactivity designs do indeed influence their performance and attitudes in learning. }}
@article{Bailey199575,
title = {CBL in engineering: Students' use of a learning resource on phase diagrams },
journal = {Computers & Education },
volume = {25},
number = {1–2},
pages = {75 - 80},
year = {1995},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/0360-1315(95)00043-7},
url = {http://www.sciencedirect.com/science/article/pii/0360131595000437},
author = {J.D. Bailey and J.L. Hall and P.A.S. Reed and C.J. Colbourn},
abstract = {Part of the Engineering Materials course at the University of Southampton has been replaced by a computer package. A resource-based approach to system design has been implemented using Microcosm, an open architecture, Microsoft Windows based, hypermedia environment. Asymetrix Toolbook has been used in conjunction with Microcosm to produce a tutorial shell. Evaluation of the students' response to the application has been carried out in collaboration with the Department of Psychology at Southampton. Aeronautical and Ship Science engineering students completed the Revised Approaches to Studying Inventory (RASI) which indicates the characteristics of the students' learning approaches. Some of the students then had two traditional tutorial sessions replaced by tutorials during which they used the new application. The application was implemented as part of the students' general education on phase diagrams. Responses from a Phase Diagrams Inventory, which included comments on both content and application usability, revealed that the students felt positively about using the package. These responses have been examined in relation to the students' initial responses to the RASI. Overall, surprizingly little relationship was revealed between the RASI and the attitude inventory. Students' performance in assessment tests later in the course revealed no adverse learning outcome from using the computer-based learning resource. The application has been further developed in response to results from this study, and is now replacing a laboratory class that previously covered the same topic for all first year engineers taking this course, approx. 300 students. This project has demonstrated that resource-based learning can provide an effective learning environment for studying engineering materials. }}
@article{Boullé20124389,
title = {Functional data clustering via piecewise constant nonparametric density estimation },
journal = {Pattern Recognition },
volume = {45},
number = {12},
pages = {4389 - 4401},
year = {2012},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2012.05.016},
url = {http://www.sciencedirect.com/science/article/pii/S0031320312002464},
author = {Marc Boullé},
abstract = {In this paper, we present a novel way of analyzing and summarizing a collection of curves, based on piecewise constant density estimation. The curves are partitioned into clusters, and the dimensions of the curves points are discretized into intervals. The cross-product of these univariate partitions forms a data grid of cells, which represents a nonparametric estimator of the joint density of the curves and point dimensions. The best model is selected using a Bayesian model selection approach and retrieved using combinatorial optimization algorithms. The proposed method requires no parameter setting and makes no assumption regarding the curves; beyond functional data, it can be applied to distributional data. The practical interest of the approach for functional data and distributional data exploratory analysis is presented on two real world datasets. }}
@article{So20121234,
title = {Little experience with ICT: Are they really the Net Generation student-teachers? },
journal = {Computers & Education },
volume = {59},
number = {4},
pages = {1234 - 1245},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.05.008},
url = {http://www.sciencedirect.com/science/article/pii/S0360131512001297},
author = {Hyo-Jeong So and Hyungshin Choi and Wei Ying Lim and Yao Xiong},
abstract = {The aim of this study is to investigate the complexity of past experiences with ICT, pedagogical beliefs, and attitude toward ICT in education that the Net Generation student teachers have about their intention to teach and learn with technology. This study has a particular focus on their lived experiences as school students where ICT related policies were actively enacted in Korea and Singapore for the past decade. To unpack the profile of the Net Generation student teachers, we selected six factors (i.e., past ICT experiences, personal computer use, constructivist belief, computer efficacy, attitude toward computer in education, and prospective computer use) related to ICT use and examined them empirically with 225 first- or second-year student teachers in Korea and Singapore. Overall, our findings indicate that student teachers in both countries tend to hold fairly constructivist beliefs and positive computer efficacy and attitude; attributes that teacher educators can tap on. Student teachers' perceptions about their use of computers for personal purposes and their past experiences with ICT were not relatively high compared to the other variables examined. This study also provides empirical evidence that students teachers who hold constructivist beliefs, have strong computer efficacy, and show positive attitudes toward computers in education are more interested in using computers in future teaching practices. As a conclusion, we argue that the profile of the Net Generation student teachers shows a more heterogeneous composition than we initially expected, and that teacher educators need to be cautious about making generational assumptions solely based on the structural and technological changes. }}
@article{Jang2008646,
title = {Innovations in science teacher education: Effects of integrating technology and team-teaching strategies },
journal = {Computers & Education },
volume = {51},
number = {2},
pages = {646 - 659},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2007.07.001},
url = {http://www.sciencedirect.com/science/article/pii/S0360131507000784},
author = {Syh-Jong Jang},
abstract = {The purpose of this study was to integrate technology and team-teaching techniques into science teacher education method courses in order to explore the effects of such integration on preservice teachers. The participants included one instructor and a total of 42 preservice teachers. A technology team-teaching model (TTT) was designed in this study to restructure science method courses with technology. This study used a mixed-method design, incorporating both quantitative and qualitative techniques. The results revealed that there were significant differences in designing an appropriate science topic to be taught with technology and integrating computer activities with appropriate pedagogy in classroom instruction (F = 5.260, p &lt; 0.05, and F = 10.260, p &lt; 0.01, respectively). The results also showed that the TTT model could enhance the integration of science teaching theories and practice. Team-teaching technique facilitated the integration of technology in science lesson design and teaching practice, and enhanced friendship through interaction. The TTT model could better the science learning experience of preservice teachers and serve as useful reference for other teacher education institutes. }}
@article{Govender2008874,
title = {Pre-service and in-service teachers’ experiences of learning to program in an object-oriented language },
journal = {Computers & Education },
volume = {51},
number = {2},
pages = {874 - 885},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2007.09.004},
url = {http://www.sciencedirect.com/science/article/pii/S0360131507001030},
author = {Irene Govender and Diane J. Grayson},abstract = {This paper presents the results of an investigation into the various ways in which pre-service and in-service teachers experience learning to program in an object-oriented language. Both groups of teachers were enrolled in university courses. In most cases, the pre-service teachers were learning to program for the first time, while the in-service teachers had previously programmed using a procedural programming language. Phenomenography was used to identify categories of description of learning to program. From these categories an outcome space was created that shows the relationship between different experiences of learning to program. The outcome space can be represented as circles inscribed within one another, where the innermost circle represents a lower level of cognitive accomplishment and the outer circles subsume the inner circles. The five levels of the outcome space are: meeting the requirements, learning the syntax/learning by comparison, understanding and assimilating, problem solving and programming in the large. Implications of the findings for teaching are discussed. }}
@article{Stark200239,
title = {Conditions and effects of example elaboration },
journal = {Learning and Instruction },
volume = {12},
number = {1},
pages = {39 - 60},
year = {2002},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/S0959-4752(01)00015-9},
url = {http://www.sciencedirect.com/science/article/pii/S0959475201000159},
author = {Robin Stark and Heinz Mandl and Hans Gruber and Alexander Renkl},
abstract = {The re-analysis is aimed at extending earlier findings on example-based learning and to draw consequences for further research and instructional practice. Based on an earlier experimental study on learning with worked-out examples in the domain of accounting (n=56 students of a vocational school), we re-analysed the effects of an intervention means (elaboration training) on learning behaviour (aspects of example elaboration). In a further step, different ways of dealing with worked-out examples (elaboration profiles) were identified and related to the subsequent learning outcomes and to the learners' mental effort. We explained the formation of different elaboration profiles by various learner characteristics (prior knowledge, interest and tolerance of ambiguity). It was shown that the elaboration training had a positive effect on the quality of example elaboration. Two ways of learning-effective example elaboration were identified. Subgroups of learners with different elaboration profiles differed in mental effort and in tolerance of ambiguity, but not with respect to prior knowledge and interest. High tolerance of ambiguity concurred with high mental effort and resulted in effective, meta-cognitively accentuated example elaboration. By integrating cognitive and motivational characteristics in the analysis of elaboration patterns, new insights concerning example-based learning and the role mental effort plays in this context could be won. Consequences for research and instructional practice were drawn. }}
@article{Kopp2012320,
title = {Improving the efficiency of dialogue in tutoring },
journal = {Learning and Instruction },
volume = {22},
number = {5},
pages = {320 - 330},
year = {2012},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2011.12.002},
url = {http://www.sciencedirect.com/science/article/pii/S0959475211001010},
author = {Kristopher J. Kopp and M. Anne Britt and Keith Millis and Arthur C. Graesser},abstract = {The current studies investigated the efficient use of dialogue in intelligent tutoring systems that use natural language interaction. Such dialogues can be relatively time-consuming. This work addresses the question of how much dialogue is needed to produce significant learning gains. In Experiment 1, a full dialogue condition and a read-only control condition were compared with a mixed dialogue condition in which students engaged in full dialogue for half the problems followed by problems requiring only a limited engagement. We found that the mixed dialogue condition produced results as impressive as the full dialogue condition and took less time. Experiment 2 replicated these findings and further examined issues of time engaged in learning, quality of instruction, and learning gains. Overall, these results show that dialogue-based intelligent tutoring systems could be designed in a more efficient manner to maximize learning and minimize the cost of time-on-task. }}
@article{Retelsdorf201030,
title = {Teachers' goal orientations for teaching: Associations with instructional practices, interest in teaching, and burnout },
journal = {Learning and Instruction },
volume = {20},
number = {1},
pages = {30 - 46},
year = {2010},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2009.01.001},
url = {http://www.sciencedirect.com/science/article/pii/S0959475209000024},
author = {Jan Retelsdorf and Ruth Butler and Lilian Streblow and Ulrich Schiefele},abstract = {Two studies (one longitudinal) were designed to extend Butler's model of teachers' goal orientations for teaching. In Study 1, results from 281 teachers in Germany confirmed the predicted four-factor model comprising mastery, ability-approach, ability-avoidance, and work-avoidance goal orientations. As expected, mastery orientation and work avoidance emerged as positive and negative predictors, respectively, of adaptive patterns of instruction (mastery-oriented practices and cognitive stimulation) and high interest in teaching and low burnout; associations for both ability orientations were less consistent. In Study 2, 69 Israeli teachers completed the measures of instructional practices, interest in teaching and burnout several months after reporting their goal orientations. Results were very similar to those of Study 1. The two studies confirm that research on teachers' goal orientation is promising and has implications for understanding how teacher motivation might influence both teachers and their students. }}
@article{Wopereis2008738,
title = {The effect of embedded instruction on solving information problems },
journal = {Computers in Human Behavior },
volume = {24},
number = {3},
pages = {738 - 752},
year = {2008},
note = {Instructional Support for Enhancing Students' Information Problem Solving Ability },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2007.01.024},
url = {http://www.sciencedirect.com/science/article/pii/S0747563207000374},
author = {Iwan Wopereis and Saskia Brand-Gruwel and Yvonne Vermetten},
abstract = {In higher education students are often faced with information problems: tasks or assignments that require them to identify information needs, locate corresponding information sources, extract and organize relevant information from each source, and synthesize information from a variety of sources. Explicit and intensive instruction is necessary, because solving information problems is a complex cognitive skill. In this study instruction for information problem solving (IPS) was embedded in a competence and web-based course for distance education students about research methodology in the field of Psychology. Eight of the 16 students following this course received a version of the course with embedded IPS instruction. The other half received a variant of the course without extra IPS instruction. The analysis of the thinking aloud protocols revealed that after the course students in the experimental condition regulate the IPS process more often than students in the control condition. They also judged the information found more often. }}
@article{Jeong201084,
title = {Productive use of learning resources in an online problem-based learning environment },
journal = {Computers in Human Behavior },
volume = {26},
number = {1},
pages = {84 - 99},
year = {2010},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2009.08.001},
url = {http://www.sciencedirect.com/science/article/pii/S074756320900123X},
author = {Heisawn Jeong and Cindy E. Hmelo-Silver},
abstract = {This study examined students’ use of learning resources in a technologically-mediated online learning environment. Undergraduate student groups were engaged in an online problem-based learning (PBL) environment, rich with pre-selected video and knowledge resources. Quantitative and qualitative analyses showed that students accessed resources fairly frequently and benefited from them. Resources helped students construct a rich understanding of the problem and provided ideas for problem solutions. Detailed analyses of resource exploration along with contrasting case analyses between high-achieving and low-achieving student groups suggested that for learning to be effective in resource-rich environments, students first need to develop an understanding of the resources and learn how to access them efficiently. Second, students need to learn to process the contents of resources in meaningful ways so that they can integrate diverse resources to form a coherent understanding and apply them to solve problems. Finally, students need to develop knowledge and skills to use resources collaboratively, such as sharing and relating to each other’s resources. The results indicated that students, especially low-achieving students, need guidance to use resources effectively in resource-rich learning environments. }}
@article{Terzis20121985,
title = {How student’s personality traits affect Computer Based Assessment Acceptance: Integrating BFI with CBAAM },
journal = {Computers in Human Behavior },
volume = {28},
number = {5},
pages = {1985 - 1996},
year = {2012},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2012.05.019},
url = {http://www.sciencedirect.com/science/article/pii/S0747563212001471},
author = {Vasileios Terzis and Christos N. Moridis and Anastasios A. Economides},
abstract = {Researchers in the Information Systems (IS) field have put considerable effort on identifying how personality affects technology acceptance. This study is a further step towards this direction within the context of Computer Based Assessment (CBA). Particularly, it investigates how the five personality factors affect the most important variables regarding CBA’s acceptance. For this purpose, 117 participants were required to complete a survey questionnaire. The questionnaire included the Big Five Inventory (BFI) questions in order to measure the five personality traits, and 23 items regarding student’s perceptions. Partial Least Squares (PLS) was used to test the measurement and the structural model. Results underline that Neuroticism has significant negative effect on Perceived Usefulness and on Goal Expectancy, Agreeableness determines Social Influence and Perceived Ease of Use, Conscientiousness defines Perceived Ease of Use, while Extroversion and Openness explain Perceived Importance. Important implications of these results are discussed. }}
@article{Bouyias2012236,
title = {Peer-monitoring vs. micro-script fading for enhancing knowledge acquisition when learning in computer-supported argumentation environments },
journal = {Computers & Education },
volume = {59},
number = {2},
pages = {236 - 249},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.01.001},
url = {http://www.sciencedirect.com/science/article/pii/S0360131512000024},
author = {Yannis Bouyias and Stavros Demetriadis},abstract = {Research on computer-supported collaborative learning (CSCL) has strongly emphasized the value of providing student support with micro-scripts, which should withdraw (fade-out) allowing students to practice the acquired skills. However, research on fading shows conflicting results and some researchers suggest that the impact of fading is enhanced when the peer-monitoring technique is additionally implemented. This study investigates the effectiveness of micro-script fading in computer-supported argumentation activity in contrast to the peer-monitoring technique, as a means to enhance students’ learning outcomes. Thirty four (34) students collaborated remotely in dyads (in lab conditions) on a task guided by a micro-script for argumentation. The dyads were divided in (a) the control group (with continuous script support); (b) the fading group (with the script fading-out after some student posts), and (c) the peer-monitoring group (with continuous script support and with prompts that students monitor their peer contributions). Students in the peer-monitoring group outperformed those in both the control group and the fading group in domain-specific knowledge acquisition post-test items. Overall, this study provides evidence that enriching argumentation scripts with the peer-monitoring technique can substantially improve learning outcomes, while simply fading-out the micro-script does not seem to improve student learning in any aspect. }}
@article{Jamet2008135,
title = {Attention guiding in multimedia learning },
journal = {Learning and Instruction },
volume = {18},
number = {2},
pages = {135 - 145},
year = {2008},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2007.01.011},
url = {http://www.sciencedirect.com/science/article/pii/S095947520700014X},
author = {Eric Jamet and Monica Gavota and Christophe Quaireau},
abstract = {Comprehension of an illustrated document can involve complex visual scanning in order to locate the relevant information on the screen when this is evoked in spoken explanations. The present study examined the effects of two types of attention-guiding means (color change or step-by-step presentation of diagram elements synchronized with a spoken explanation) on multimedia learning. These attention-guiding means were expected to facilitate selection of the illustrated information that corresponded to the spoken explanations. The results indicated positive, and in some cases additive, effects on a retention task and on the perceived ease of learning but not on a transfer task. These results are discussed in light of models of multimedia learning. }}
@article{Oosterheert2001133,
title = {Individual differences in learning to teach: relating cognition, regulation and affect },
journal = {Learning and Instruction },
volume = {11},
number = {2},
pages = {133 - 156},
year = {2001},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/S0959-4752(00)00019-0},
url = {http://www.sciencedirect.com/science/article/pii/S0959475200000190},
author = {Ida E Oosterheert and Jan D Vermunt},
abstract = {The purpose of this study was to describe individual differences in learning to teach. Thirty secondary student teachers were interviewed about several components of their learning: mental models of learning to teach, learning activities, regulation in general, emotion regulation in particular, ideal self as a teacher and concerns. The interviews were qualitatively analysed, resulting in the identification of three to five categories per component. Homogeneity analysis demonstrated that many of these categories are related within individuals. Five orientations to learning to teach were discerned; an open meaning orientation, a closed meaning orientation, an open reproduction orientation, a closed reproduction orientation, and a survival orientation. The five orientations may be indicative of how progress in the quality of individual learning evolves. }}
@article{Kong200837,
title = {A study of building a resource-based learning environment with the inquiry learning approach: Knowledge of family trees },
journal = {Computers & Education },
volume = {50},
number = {1},
pages = {37 - 60},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2006.03.006},
url = {http://www.sciencedirect.com/science/article/pii/S0360131506000625},
author = {Siu Cheung Kong and Wing Mui Winnie So},
abstract = {This study aims to provide teachers with ways and means to facilitate learners to develop nomenclature knowledge of family trees through the establishment of resource-based learning environments (RBLEs). It discusses the design of an RBLE in the classroom by selecting an appropriate context with the assistance of computer-mediated learning resources and tools and employing the inquiry learning approach as the pedagogy. This study reports on the creation of the RBLE within the learning context of family trees. The computer-mediated learning resources and tools comprise three components: an audio-visual database for guided and coupled inquiry, an interactive interface for conceptualising the nomenclature and a tool for learners to construct their own family trees. Scaffolds were designed for an inquiry mode of learning and teaching to support the use of the resources and tools in learning about family trees. The learning and teaching process, including the outcomes for learners, through the RBLE with inquiry learning approach are studied. The findings of an interview and a pre-test/post-test study indicate that the RBLE can assist learners to build knowledge of family trees. The role of teachers in such an environment is to guide and encourage learners to inquire during the learning process. }}
@article{Chen20152287,
title = {An approach to complex agent-based negotiations via effectively modeling unknown opponents },
journal = {Expert Systems with Applications },
volume = {42},
number = {5},
pages = {2287 - 2304},
year = {2015},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2014.10.048},
url = {http://www.sciencedirect.com/science/article/pii/S0957417414006800},
author = {Siqi Chen and Gerhard Weiss},
abstract = {Abstract Negotiation among computational autonomous agents has gained rapidly growing interest in previous years, mainly due to its broad application potential in many areas such as e-commerce and e-business. This work deals with automated bilateral multi-issue negotiation in complex environments. Although tremendous progress has been made, available algorithms and techniques typically are limited in their applicability for more complex situations, in that most of them are based on simplifying assumptions about the negotiation complexity such as simple or partially known opponent behaviors and availability of negotiation history. We propose a negotiation approach called OMAC★ that aims at tackling these problems. OMAC★ enables an agent to efficiently model opponents in real-time through discrete wavelet transformation and non-linear regression with Gaussian processes. Based on the approximated model the decision-making component of OMAC★ adaptively adjusts its utility expectations and negotiation moves. Extensive experimental results are provided that demonstrate the negotiation qualities of OMAC★, both from the standard mean-score performance perspective and the perspective of empirical game theory. The results show that OMAC★ outperforms the top agents from the 2012, 2011 and 2010 International Automated Negotiating Agents Competition (ANAC) in a broad range of negotiation scenarios. }}
@article{Yang20121500,
title = {Quadratic nonnegative matrix factorization },
journal = {Pattern Recognition },
volume = {45},
number = {4},
pages = {1500 - 1510},
year = {2012},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2011.10.014},
url = {http://www.sciencedirect.com/science/article/pii/S0031320311004389},
author = {Zhirong Yang and Erkki Oja},
abstract = {In Nonnegative Matrix Factorization (NMF), a nonnegative matrix is approximated by a product of lower-rank factorizing matrices. Most NMF methods assume that each factorizing matrix appears only once in the approximation, thus the approximation is linear in the factorizing matrices. We present a new class of approximative NMF methods, called Quadratic Nonnegative Matrix Factorization (QNMF), where some factorizing matrices occur twice in the approximation. We demonstrate QNMF solutions to four potential pattern recognition problems in graph partitioning, two-way clustering, estimating hidden Markov chains, and graph matching. We derive multiplicative algorithms that monotonically decrease the approximation error under a variety of measures. We also present extensions in which one of the factorizing matrices is constrained to be orthogonal or stochastic. Empirical studies show that for certain application scenarios, QNMF is more advantageous than other existing nonnegative matrix factorization methods. }}
@article{Chu2012989,
title = {Using blogs to support learning during internship },
journal = {Computers & Education },
volume = {58},
number = {3},
pages = {989 - 1000},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.08.027},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511002053},
author = {Samuel K.W. Chu and Carol K.K. Chan and Agnes F.Y. Tiwari},abstract = {Blogging has been recommended as a suitable tool for learning during internship due to its associated usefulness in collaborative learning, reflection, communication, and social support. In this study, blogging was incorporated into the internship activities of two discipline-specific groups of interns: information management (n = 53) and nursing (n = 28). In examining the behavior, perceptions and processes of blogging among interns from the two disciplines, a mixed-methods design was used to obtain quantitative and qualitative data through structured interviews and blogging entries. Results revealed that the interns engaged regularly in the writing and reading of their own blogs, and commented on others’ blog-writing. The interns perceived blogs to be useful during internship in providing an avenue for knowledge construction, problem solving, reflection, and communicating their emotions. Positive perceptions were not influenced by discipline background, frequency of use, or blogging platform. Qualitative analyses of blog contents indicated that the students engaged in cognitive, metacognitive-reflective, affective, and social-collaborative learning processes in blogging. Higher engagement was found in cognitive and metacognitive processes. Responses to open-ended probes suggest that pedagogical factors (e.g., grading system, supervision) may also have influenced students’ blogging behaviors and perceptions. Overall, this study offers evidence to support the use of blogging during internship as computer-based support for learning. }}
@article{Zhang20158678,
title = {Intelligent affect regression for bodily expressions using hybrid particle swarm optimization and adaptive ensembles },
journal = {Expert Systems with Applications },
volume = {42},
number = {22},
pages = {8678 - 8697},
year = {2015},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2015.07.022},
url = {http://www.sciencedirect.com/science/article/pii/S0957417415004820},
author = {Yang Zhang and Li Zhang and Siew Chin Neoh and Kamlesh Mistry and Mohammed Alamgir Hossain},
abstract = {Abstract This research focuses on continuous dimensional affect recognition from bodily expressions using feature optimization and adaptive regression. Both static posture and dynamic motion bodily features are extracted in this research. A hybrid particle swarm optimization (PSO) algorithm is proposed for feature selection, which overcomes premature convergence and local optimum trap encountered by conventional PSO. It integrates diverse jump-out mechanisms such as the genetic algorithm (GA) and mutation techniques of Gaussian, Cauchy and Levy distributions to balance well between convergence speed and swarm diversity, thus called GM-PSO. The proposed PSO variant employs the subswarm concept and a cooperative strategy to enable mutation mechanisms of each subswarm, i.e. the GA and the probability distributions, to work in a collaborative manner to enhance the exploration and exploitation capability of the swarm leader, sustain the population diversity and guide the search toward an ultimate global optimum. An adaptive ensemble regression model is subsequently proposed to robustly map subjects’ emotional states onto a continuous arousal–valence affective space using the identified optimized feature subsets. This regression model also shows great adaption to newly arrived bodily expression patterns to deal with data stream regression. Empirical findings indicate that the proposed hybrid PSO optimization algorithm outperforms other state-of-the-art PSO variants, conventional PSO and classic GA significantly in terms of catching global optimum and discriminative feature selection. The system achieves the best performance for the regression of arousal and valence when ensemble regression model is applied, in terms of both mean squared error (arousal: 0.054, valence: 0.08) and Pearson correlation coefficient (arousal: 0.97, valence: 0.91) and outperforms other state-of-the-art PSO-based optimization combined with ensemble regression and related bodily expression perception research by a significant margin. }}
@article{Sung2012473,
title = {Affective impact of navigational and signaling aids to e-learning },
journal = {Computers in Human Behavior },
volume = {28},
number = {2},
pages = {473 - 483},
year = {2012},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2011.10.019},
url = {http://www.sciencedirect.com/science/article/pii/S0747563211002366},
author = {Eunmo Sung and Richard E. Mayer},
abstract = {College students had 30 min to study a 17-frame online lesson on distance learning that included navigational aids (for showing the learner’s location in the lesson), signaling aids (for highlighting the important content), both aids, or no aids. On a 30-item usability survey consisting of 8 usability scales, students who received navigational aids produced significantly higher mean ratings on each of the 8 usability scales—ease of use, satisfaction of use, awareness of lesson structure, awareness of lesson length, awareness of location, ease of navigation, lesson comprehension, and lesson learning—with effect sizes ranging from d = 0.50 to d = 1.35. Students who received signaling aids produced significantly higher ratings on 4 of the 8 usability scales—ease of use, satisfaction of use, lesson comprehension, and lesson learning with effect sizes ranging from d = 0.39 to d = 2.15. Results help to clarify the mechanism underlying previous findings showing that students learned more from e-lessons that contained navigational aids. In the present study, there was a significant positive correlation between usability rating and recall test score for 5 of the 8 usability scales (particularly for ease of use), indicating partial support for the prediction that learners’ satisfaction with an e-learning system is related to their learning outcome. Results support the predictions of the emotional design hypothesis and have implications for the design of e-learning interfaces. }}
@article{Schrader2012648,
title = {The influence of virtual presence: Effects on experienced cognitive load and learning outcomes in educational computer games },
journal = {Computers in Human Behavior },
volume = {28},
number = {2},
pages = {648 - 658},
year = {2012},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2011.11.011},
url = {http://www.sciencedirect.com/science/article/pii/S074756321100255X},
author = {Claudia Schrader and Theo J. Bastiaens},
abstract = {Does the immersive design of an educational gaming environment affect learners’ virtual presence and how much do they learn? Does virtual presence affect learning? This study tries to answer these questions by examining the differences in virtual presence and learning outcomes in two different computer-based multimedia environments: a gaming environment with high immersive design vs. hypertext learning environment with low immersive design. As the main focus, the effect of virtual presence on learning is also explained and tested. By identifying virtual presence as a variable that may determine learning, it is argued that computer gaming environments present a new challenge for researchers to investigate, particularly, the effects of virtual presence on the immersive design of games in order to help designers to predict which instructional configurations will maximize learning performance. In general, results revealed that the high-immersive gaming environment leads to the strongest form of virtual presence but also decreased learning. Although regression analyses indicate that virtual presence positively influences trivial- and non-trivial learning outcomes, learners who learned in a low-immersive environment outperformed the gaming group. A mediation analysis showed that the relation between virtual presence and non-trivial learning outcomes is partly mediated through increased cognitive load. }}
@article{Boyd199223,
title = {How can intelligent CAL better adapt to learners? },
journal = {Computers & Education },
volume = {18},
number = {1–3},
pages = {23 - 28},
year = {1992},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/0360-1315(92)90032-Z},
url = {http://www.sciencedirect.com/science/article/pii/036013159290032Z},
author = {Gary McI. Boyd and P.David Mitchell},
abstract = {Tutoring is assumed to be a conversational activity shared among the learner, the machine tutor and the educator/developer. The sort of student model that the machine should build, update and run simulations on, to help all three to be effective, is then derived. This derivation amounts to a demand for a new and different architecture for intelligent computer aided learning support systems. It is argued from cybernetic theory, and on the basis of empirical attribute-treatment results, that the student model must be a dynamic multi-level, and multi-personae model that also incorporates in rudimentary form the student's model of the teacher. Human tutors use multi-level models of learners' various characteristics to advantage. The promise of doing this in intelligent CAL systems is evaluated. Specific learner characteristics (including aspirations, expectations and cognitive style) are considered as elements of intelligent CAL student models. Since little is known yet about the moment-by-moment variability of many important learner characteristics, an intelligent CAL system is arguably a better laboratory for studying them. A formal connexion-matrix based language, and a fuzzy-logic based lesson planner, are advocated as a means for implementing and exploiting more adequate learner models in intelligent CAL systems. }}
@article{Junco2012187,
title = {Too much face and not enough books: The relationship between multiple indices of Facebook use and academic performance },
journal = {Computers in Human Behavior },
volume = {28},
number = {1},
pages = {187 - 198},
year = {2012},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2011.08.026},
url = {http://www.sciencedirect.com/science/article/pii/S0747563211001932},
author = {Reynol Junco},
abstract = {Because of the social media platform’s widespread adoption by college students, there is a great deal of interest in how Facebook use is related to academic performance. A small number of prior studies have examined the relationship between Facebook use and college grade point average (GPA); however, these studies have been limited by their measures, sampling designs and failure to include prior academic ability as a control variable. For instance, previous studies used non-continuous measures of time spent on Facebook and self-reported GPA. This paper fills a gap in the literature by using a large sample (N = 1839) of college students to examine the relationship among multiple measures of frequency of Facebook use, participation in Facebook activities, and time spent preparing for class and actual overall GPA. Hierarchical (blocked) linear regression analyses revealed that time spent on Facebook was strongly and significantly negatively related to overall GPA, while only weakly related to time spent preparing for class. Furthermore, using Facebook for collecting and sharing information was positively predictive of the outcome variables while using Facebook for socializing was negatively predictive. }}
@article{Zydney201277,
title = {Creating a community of inquiry in online environments: An exploratory study on the effect of a protocol on interactions within asynchronous discussions },
journal = {Computers & Education },
volume = {58},
number = {1},
pages = {77 - 87},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.07.009},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511001679},
author = {Janet Mannheimer Zydney and Aimee deNoyelles and Kay Kyeong-Ju Seo},abstract = {The purpose of our research was to examine the influence of an online protocol on asynchronous discussions. A mixed-methods study compared two online graduate classes: one that used a protocol and one that did not use a protocol for the same discussion about a complex reading. Analysis of the data revealed that the online protocol more evenly distributed the presence of cognitive, social, and teaching elements necessary to create and sustain an online community of inquiry. Use of the protocol also promoted more shared group cognition and more student ownership of the discussion and empowered students to facilitate themselves, helping to reduce the instructor workload. These findings may enable educators to provide more dynamic interaction and richer learning experiences in asynchronous online environments. }}
@article{GuillénNieto2012435,
title = {Serious games and learning effectiveness: The case of It’s a Deal! },
journal = {Computers & Education },
volume = {58},
number = {1},
pages = {435 - 448},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.07.015},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511001734},
author = {Victoria Guillén-Nieto and Marian Aleson-Carbonell},
abstract = {Although the value of serious games in education is undeniable and the potential benefits of using video games as ideal companions to classroom instruction is unquestionable, there is still little consensus on the game features supporting learning effectiveness, the process by which games engage learners, and the types of learning outcomes that can be achieved through game play. Our aim in this discussion is precisely to advance in this direction by providing evidence of some of the factors influencing the learning effectiveness of a serious game called It’s a Deal! This serious game was created for the purpose of teaching intercultural business communication between Spaniards and Britons in business settings in which English is used as the lingua franca. This paper hypothesizes that the immersive, all-embracing and interactive learning environment provided by the video game to its users may contribute to develop and enhance their intercultural communicative competence. The study attempts to answer three main research questions: (a) after playing It’s a Deal!, did the students sampled improve their intercultural awareness, intercultural knowledge and intercultural communicative competence in business English? (b) If they improved their intercultural learning, what are the factors influencing such improvement? And (c) if they did not improve their intercultural learning, what are the factors influencing such failure? The game participants who volunteered to take part in the study were all students of English Studies at the University of Alicante in the academic year 2010–2011. One hundred and six students completed both the pre-test and the post-test questionnaires, and played It’s a Deal! A sample of fifty students was selected randomly for the empirical study. The results obtained in the tests performed were compared and contrasted intra-group, both qualitatively and quantitatively, for the purpose of finding any statistically significant difference that may confirm whether or not there was an improvement in the students’ intercultural communicative competence in business English as a result of the implementation of the It’s a Deal! serious game. Findings of this study demonstrate that the video game is an effective learning tool for the teaching of intercultural communication between Spaniards and Britons in business settings in which English is used as the lingua franca. In particular, whereas the game had a small learning effect on intercultural awareness and a medium learning effect on intercultural knowledge, it had a large learning effect on intercultural communicative competence. The study also documents correlating factors that make serious games effective, since it shows that the learning effectiveness of It’s a Deal! stems from the correct balance of the different dimensions involved in the creation of serious games, specifically instructional content, game dimensions, game cycle, debriefing, perceived educational value, transfer of learnt skills and intrinsic motivation. }}
@article{KhadjehNassirtoussi2015306,
title = {Text mining of news-headlines for FOREX market prediction: A Multi-layer Dimension Reduction Algorithm with semantics and sentiment },
journal = {Expert Systems with Applications },
volume = {42},
number = {1},
pages = {306 - 324},
year = {2015},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2014.08.004},
url = {http://www.sciencedirect.com/science/article/pii/S0957417414004801},
author = {Arman Khadjeh Nassirtoussi and Saeed Aghabozorgi and Teh Ying Wah and David Chek Ling Ngo},
abstract = {Abstract In this paper a novel approach is proposed to predict intraday directional-movements of a currency-pair in the foreign exchange market based on the text of breaking financial news-headlines. The motivation behind this work is twofold: First, although market-prediction through text-mining is shown to be a promising area of work in the literature, the text-mining approaches utilized in it at this stage are not much beyond basic ones as it is still an emerging field. This work is an effort to put more emphasis on the text-mining methods and tackle some specific aspects thereof that are weak in previous works, namely: the problem of high dimensionality as well as the problem of ignoring sentiment and semantics in dealing with textual language. This research assumes that addressing these aspects of text-mining have an impact on the quality of the achieved results. The proposed system proves this assumption to be right. The second part of the motivation is to research a specific market, namely, the foreign exchange market, which seems not to have been researched in the previous works based on predictive text-mining. Therefore, results of this work also successfully demonstrate a predictive relationship between this specific market-type and the textual data of news. Besides the above two main components of the motivation, there are other specific aspects that make the setup of the proposed system and the conducted experiment unique, for example, the use of news article-headlines only and not news article-bodies, which enables usage of short pieces of text rather than long ones; or the use of general financial breaking news without any further filtration. In order to accomplish the above, this work produces a multi-layer algorithm that tackles each of the mentioned aspects of the text-mining problem at a designated layer. The first layer is termed the Semantic Abstraction Layer and addresses the problem of co-reference in text mining that is contributing to sparsity. Co-reference occurs when two or more words in a text corpus refer to the same concept. This work produces a custom approach by the name of Heuristic-Hypernyms Feature-Selection which creates a way to recognize words with the same parent-word to be regarded as one entity. As a result, prediction accuracy increases significantly at this layer which is attributed to appropriate noise-reduction from the feature-space. The second layer is termed Sentiment Integration Layer, which integrates sentiment analysis capability into the algorithm by proposing a sentiment weight by the name of SumScore that reflects investors’ sentiment. Additionally, this layer reduces the dimensions by eliminating those that are of zero value in terms of sentiment and thereby improves prediction accuracy. The third layer encompasses a dynamic model creation algorithm, termed Synchronous Targeted Feature Reduction (STFR). It is suitable for the challenge at hand whereby the mining of a stream of text is concerned. It updates the models with the most recent information available and, more importantly, it ensures that the dimensions are reduced to the absolute minimum. The algorithm and each of its layers are extensively evaluated using real market data and news content across multiple years and have proven to be solid and superior to any other comparable solution. The proposed techniques implemented in the system, result in significantly high directional-accuracies of up to 83.33%. On top of a well-rounded multifaceted algorithm, this work contributes a much needed research framework for this context with a test-bed of data that must make future research endeavors more convenient. The produced algorithm is scalable and its modular design allows improvement in each of its layers in future research. This paper provides ample details to reproduce the entire system and the conducted experiments. }}
@article{Lowerison2006465,
title = {Student perceived effectiveness of computer technology use in post-secondary classrooms },
journal = {Computers & Education },
volume = {47},
number = {4},
pages = {465 - 489},
year = {2006},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2004.10.014},
url = {http://www.sciencedirect.com/science/article/pii/S0360131504001733},
author = {Gretchen Lowerison and Jennifer Sclater and Richard F. Schmid and Philip C. Abrami},abstract = {This study investigated the relationship between the amount of computer technology used in post-secondary education courses, students’ perceived effectiveness of technology use, and global course evaluations. Survey data were collected from 922 students in 51 courses at both the graduate and undergraduate levels. The survey consisted of 65 items broken down into seven areas, namely: (1) student characteristics, (2) learning experiences and course evaluations, (3) learning strategies, (4) instructional techniques, (5) computer use in course, (6) perceived effectiveness of computer use and (7) personal computer use. Contrary to expectations, no significant relationship was found between computer use and global course evaluations, nor was there a relationship between perceived effectiveness of computer use and global course evaluations. However, the results did yield a positive relationship between global course evaluations and the learning experiences that students engaged in. Students also indicated that they valued the use of computer technology for learning. Descriptive statistics on questions related to personal computer use show a strong favorable response to computer use and: facilitation of learning, value-added aspects such as usefulness to other classes and/or career, learning material in a more meaningful way, and working in groups with other students. }}
@article{Liu20111907,
title = {The effect of simulation games on the learning of computational problem solving },
journal = {Computers & Education },
volume = {57},
number = {3},
pages = {1907 - 1918},
year = {2011},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.04.002},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511000832},
author = {Chen-Chung Liu and Yuan-Bang Cheng and Chia-Wen Huang},abstract = {Simulation games are now increasingly applied to many subject domains as they allow students to engage in discovery processes, and may facilitate a flow learning experience. However, the relationship between learning experiences and problem solving strategies in simulation games still remains unclear in the literature. This study, thus, analyzed the feedback and problem solving behaviors of 117 students in a simulation game, designed to assist them to learn computational problem solving. It was found that students when learning computational problem solving with the game were more likely to perceive a flow learning experience than in traditional lectures. The students’ intrinsic motivation was also enhanced when they learned with the simulation game. In particular, the results of the study found a close association between the students’ learning experience states and their problem solving strategies. The students who perceived a flow experience state frequently applied trial-and-error, learning-by-example, and analytical reasoning strategies to learn the computational problem solving skills. However, a certain portion of students who experienced states of boredom and anxiety did not demonstrate in-depth problem solving strategies. For instance, the students who felt anxious in the simulation game did not apply the learning-by-example strategy as frequently as those in the flow state. In addition, the students who felt bored in the simulation game only learned to solve the problem at a superficial level. }}
@article{Seidel2006228,
title = {Stability of teaching patterns in physics instruction: Findings from a video study },
journal = {Learning and Instruction },
volume = {16},
number = {3},
pages = {228 - 240},
year = {2006},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2006.03.002},
url = {http://www.sciencedirect.com/science/article/pii/S0959475206000284},
author = {Tina Seidel and Manfred Prenzel},abstract = {The study investigated variant and invariant physics teaching patterns across time and topics. It is assumed that the analysis perspective is decisive for identifying variant and invariant teaching patterns. Therefore, we focused on three perspectives: (1) organisation of activities, (2) quality of teacher–student interactions, and (3) students' perception of learning conditions. The design included three lessons of two topics (13 classes × 2 topics × 3 lessons) that were videotaped in each class. The findings indicate variants in teaching for the organisation of activities. Invariants were identified for teacher–student interactions and the students' perception of learning conditions. }}
@article{Pasin20111240,
title = {The impact of a simulation game on operations management education },
journal = {Computers & Education },
volume = {57},
number = {1},
pages = {1240 - 1254},
year = {2011},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.12.006},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511000029},
author = {Federico Pasin and Hélène Giroux},abstract = {This study presents a new simulation game and analyzes its impact on operations management education. The proposed simulation was empirically tested by comparing the number of mistakes during the first and second halves of the game. Data were gathered from 100 teams of four or five undergraduate students in business administration, taking their first course in operations management. To assess learning, instead of relying solely on an overall performance measurement, as is usually done in the skill-based learning literature, we analyzed the evolution of different types of mistakes that were made by students in successive rounds of play. Our results show that although simple decision-making skills can be acquired with traditional teaching methods, simulation games are more effective when students have to develop decision-making abilities for managing complex and dynamic situations. }}
@article{Tang201418,
title = {Slice representation of range data for head pose estimation },
journal = {Computer Vision and Image Understanding },
volume = {128},
number = {},
pages = {18 - 35},
year = {2014},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2014.05.008},
url = {http://www.sciencedirect.com/science/article/pii/S1077314214001271},
author = {Yunqi Tang and Zhenan Sun and Tieniu Tan},
abstract = {Abstract Visual estimation of head pose is desirable for computer vision applications such as face recognition, human computer interaction, and affective computing. However, accurate estimation of head pose in uncontrolled environment is still a grand challenge. This paper proposes a novel feature representation model for accurate pose estimation. In this model, a range image is divided into a set of simple slices that contain abundant geometric cues can be used to accurately describe the poses of a subject. This model provides a general framework for designing new features for head pose estimation. According to this model, design of a new feature model for describing a slice, then a new set of features is generated by combining all slices for describing range images. Due to the huge number of slices that can be generated from single range image, even a simple description model of slice can achieve robust performance. With the guide of this model, two novel range image representation models, which are Local Slice Depth (LSD) and Local Slice Orientation (LSO), are designed. LSD can be used for coarse estimation of head poses, while LSO can achieve accurate results. Moreover, in order to evaluate the performance of proposed representation model, an automatic head pose estimation method is implemented using a Kinect sensor. Firstly both color and range images captured by a Kinect sensor are used to localize and segment the facial region from background. Secondly, two novel integral images, namely slice depth integral image and slice coordinates integral image, are proposed to achieve real-time feature extraction. Finally, random forests are used to learn a stable relationship between slice feature descriptors and head pose parameters. Experiments on both low-quality depth data set Biwi and high-quality depth data set ETH demonstrate state-of-the-art performance of our method. }}
@article{Hwang2006105,
title = {Development and evaluation of multimedia whiteboard system for improving mathematical problem solving },
journal = {Computers & Education },
volume = {46},
number = {2},
pages = {105 - 121},
year = {2006},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2004.05.005},
url = {http://www.sciencedirect.com/science/article/pii/S0360131504000971},
author = {Wu-Yuin Hwang and Nian-Shing Chen and Rueng-Lueng Hsu},abstract = {This study developed a web-based multimedia whiteboard system to help students learning with mathematical problem solving. The purpose is to promote a new online mathematical learning model that students not only use electronic whiteboard to write down their mathematical problem solving solutions but also use voice recording tool to give oral explanations about their thinking behind the solutions. To cultivate students’ critical thinking capability and encourage collaborative peer learning, the new learning model also requests students to criticize others’ solutions and reply to others’ arguments. With the multimedia supporting tools, students can communicate easily with each other about what they think and how they solve mathematical problems. We have conducted an experiment with sixth grade primary school students for evaluation. After the experiment, a questionnaire about students’ attitude toward the multimedia whiteboard system for math learning was then held. The results show that students were satisfied with the use of the multimedia whiteboard system for helping them with learning fractional division. Most students were interested in studying mathematics with the multimedia whiteboard system and thought this tool is particularly useful for doing collaborative learning. After analyzing the recorded solving processes and discussions content of students, we found that the performance of female students was superior to male students in communications and mathematical problem solving. Additionally, students with higher final exam grades had better mathematical abilities for doing critiques, arguments and communications. }}
@article{Berger2011416,
title = {Motivation and students’ use of learning strategies: Evidence of unidirectional effects in mathematics classrooms },
journal = {Learning and Instruction },
volume = {21},
number = {3},
pages = {416 - 428},
year = {2011},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2010.06.002},
url = {http://www.sciencedirect.com/science/article/pii/S0959475210000460},
author = {Jean-Louis Berger and Stuart A. Karabenick},abstract = {Considerable evidence indicates that student motivation and use of learning strategies are related. There is insufficient understanding, however, about their reciprocal effects—whether motivation affects strategy use, the converse, or whether the effects are bidirectional—and which components of motivation and strategies are involved. A two-wave longitudinal design was used to examine this issue among 9th grade students (N = 306) enrolled in high school mathematics classes during an academic term. A cross-lagged structural model found that students’ self-efficacy in mathematics and value predicted their reported use of learning strategies. There was no evidence, however, that learning strategy use predicted motivation and, thus, support for unidirectional effect of motivation during that time interval. Implications for models of self-regulated learning and instruction are discussed. }}
@article{Prichard2011429,
title = {Evaluating the effects of team-skills training on subjective workload },
journal = {Learning and Instruction },
volume = {21},
number = {3},
pages = {429 - 440},
year = {2011},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2010.06.003},
url = {http://www.sciencedirect.com/science/article/pii/S0959475210000472},
author = {Jane S. Prichard and L.A. Bizo and R.J. Stratford},
abstract = {This study evaluated the impact of a team-skills training intervention on students’ subjective experience of workload when working in collaborative groups. Three cohorts of students (N = 295) taking an undergraduate degree unit were compared across three successive years, in which presence or absence of training was varied. Students in trained groups reported lower levels of subjective workload than those in untrained groups and also performed better across a range of academic exercises. This effect was moderated by whether students were regrouped half-way through the academic year. Results are discussed in terms of theories of team-skill acquisition and issues in skill transferability caused by regrouping. }}
@article{Shneiderman199825,
title = {Relate–Create–Donate: a teaching/learning philosophy for the cyber-generation },
journal = {Computers & Education },
volume = {31},
number = {1},
pages = {25 - 39},
year = {1998},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/S0360-1315(98)00014-1},
url = {http://www.sciencedirect.com/science/article/pii/S0360131598000141},
author = {Ben Shneiderman}}
@article{Admiraal20111185,
title = {The concept of flow in collaborative game-based learning },
journal = {Computers in Human Behavior },
volume = {27},
number = {3},
pages = {1185 - 1194},
year = {2011},
note = {Group Awareness in CSCL Environments },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2010.12.013},
url = {http://www.sciencedirect.com/science/article/pii/S0747563210003808},
author = {Wilfried Admiraal and Jantina Huizenga and Sanne Akkerman and Geert ten Dam},abstract = {Generally, high-school students have been characterized as bored and disengaged from the learning process. However, certain educational designs promote excitement and engagement. Game-based learning is assumed to be such a design. In this study, the concept of flow is used as a framework to investigate student engagement in the process of gaming and to explain effects on game performance and student learning outcome. Frequency 1550, a game about medieval Amsterdam merging digital and urban play spaces, has been examined as an exemplar of game-based learning. This 1-day game was played in teams by 216 students of three schools for secondary education in Amsterdam. Generally, these students show flow with their game activities, although they were distracted by solving problems in technology and navigation. Flow was shown to have an effect on their game performance, but not on their learning outcome. Distractive activities and being occupied with competition between teams did show an effect on the learning outcome of students: the fewer students were distracted from the game and the more they were engaged in group competition, the more students learned about the medieval history of Amsterdam. Consequences for the design of game-based learning in secondary education are discussed. }}
@article{Taub2014356,
title = {Can the use of cognitive and metacognitive self-regulated learning strategies be predicted by learners’ levels of prior knowledge in hypermedia-learning environments? },
journal = {Computers in Human Behavior },
volume = {39},
number = {},
pages = {356 - 367},
year = {2014},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2014.07.018},
url = {http://www.sciencedirect.com/science/article/pii/S0747563214003926},
author = {Michelle Taub and Roger Azevedo and François Bouchet and Babak Khosravifar},abstract = {Abstract Research on self-regulated learning (SRL) in hypermedia-learning environments is a growing area of interest, and prior knowledge can influence how students interact with these systems. One hundred twelve (N = 112) undergraduate students’ interactions with MetaTutor, a multi-agent, hypermedia-based learning environment, were investigated, including how prior knowledge affected their use of SRL strategies. We expected that students with high prior knowledge would engage in significantly more cognitive and metacognitive SRL strategies, engage in different sequences of SRL strategies, spend more time engaging in SRL processes, and visit more pages that were relevant to their sub-goals than students with low prior knowledge. Results showed significant differences in the total use of SRL strategies between prior knowledge groups, and more specifically, revealed significant differences in the use of each metacognitive strategy (e.g., judgment of learning), but not each cognitive strategy (e.g., taking notes) between prior knowledge groups. Results also revealed different sequences of use of SRL strategies between prior knowledge groups, and that students spent different amounts of time engaging in SRL processes; however, all students visited similar numbers of relevant pages. These results have important implications on designing multi-agent, hypermedia environments; we can design pedagogical agents that adapt to students’ learning needs, based on their prior knowledge levels. }}
@article{Hoogerheide2014108,
title = {Effects of creating video-based modeling examples on learning and transfer },
journal = {Learning and Instruction },
volume = {33},
number = {},
pages = {108 - 119},
year = {2014},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2014.04.005},
url = {http://www.sciencedirect.com/science/article/pii/S0959475214000395},
author = {Vincent Hoogerheide and Sofie M.M. Loyens and Tamara van Gog},abstract = {Abstract Two experiments investigated whether acting as a peer model for a video-based modeling example, which entails studying a text with the intention to explain it to others and then actually explaining it on video, would foster learning and transfer. In both experiments, novices were instructed to study a text, either with the intention of being able to complete a test (condition A), or being able to explain the content to others (condition B and C). Moreover, students in condition C actually had to explain the text by creating a webcam-video. In Experiment 1 (N = 76 secondary education students) there was no effect of study intention on learning (A = B), but explaining during video creation significantly fostered transfer performance (C &gt; B; C &gt; A). In Experiment 2 (N = 95 university students), study intention did have an effect on learning (C &gt; A; B &gt; A), but only actual video creation significantly fostered transfer performance (C &gt; A). }}
@article{Levy2011556,
title = {Mining students’ inquiry actions for understanding of complex systems },
journal = {Computers & Education },
volume = {56},
number = {3},
pages = {556 - 573},
year = {2011},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.09.015},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510002782},
author = {Sharona T. Levy and Uri Wilensky},
abstract = {This study lies at an intersection between advancing educational data mining methods for detecting students’ knowledge-in-action and the broader question of how conceptual and mathematical forms of knowing interact in exploring complex chemical systems. More specifically, it investigates students’ inquiry actions in three computer-based models of complex chemical systems when their goal is to construct an equation relating physical variables of the system. The study’s participants were 368 high-school students who interacted with the Connected Chemistry (CC111CC1 denotes Connected Chemistry, Chapter 1, a unit devoted to the topic of gas laws and kinetic molecular theory. Under the umbrella of Connected Chemistry, the Center for Connected Learning and Computer-based Modeling (CCL) has created several curricular units. ) curriculum and completed identical pre- and post-test content knowledge questionnaires. The study explores whether and how students adapt to different mathematical behaviors of the system, examines how these explorations may relate to prior knowledge and learning in terms of conceptual and mathematical models, as well as components relating to understanding systems. Students’ data-collection choices were mined and analyzed showing: (1) In about half the cases, mainly for two out of the three models explored, students conduct mathematically-astute (fit) explorations; (2) A third of the students consistently adapt their strategies to the models’ mathematical behavior; (3) Fit explorations are associated with prior conceptual knowledge, specifically understanding of the system as complex, however, the three explorations’ fitness is predicted by the understanding of distinct sets of systems’ components; (4) Fit explorations are only somewhat associated with learning along complementary dimensions. These results are discussed with respect to 1) the importance of a conceptual understanding regarding individual system elements even when engaged in large-scale quantitative problem solving, 2) how distinct results for the different models relate to previous literature on conceptual understanding and particular affordances of the models, 3) the importance of engaging students in creating mathematical representations of scientific phenomena, as well as 4) educational applications of these results in learning environments. }}
@article{McLaren2011574,
title = {Polite web-based intelligent tutors: Can they improve learning in classrooms? },
journal = {Computers & Education },
volume = {56},
number = {3},
pages = {574 - 584},
year = {2011},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.09.019},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510002824},
author = {Bruce M. McLaren and Krista E. DeLeeuw and Richard E. Mayer},abstract = {Should an intelligent software tutor be polite, in an effort to motivate and cajole students to learn, or should it use more direct language? If it should be polite, under what conditions? In a series of studies in different contexts (e.g., lab versus classroom) with a variety of students (e.g., low prior knowledge versus high prior knowledge), the politeness effect was investigated in the context of web-based intelligent tutoring systems, software that runs on the Internet and employs artificial intelligence and learning science techniques to help students learn. The goal was to pinpoint the appropriate conditions for having the web-based tutors provide polite feedback and hints (e.g., Let’s convert the units of the first item) versus direct feedback and hints (e.g., Convert the units of the first item now). In the study presented in this paper, 132 high school students in a classroom setting, grouped as low and high prior knowledge learners according to a pre-intervention knowledge questionnaire, did not benefit more from polite feedback and hints than direct feedback and hints on either an immediate or delayed posttest, both of which contained near transfer and conceptual test items. Of particular interest and contrary to an earlier lab study, low prior knowledge students did not benefit more from using the polite version of a tutor. On the other hand, a politeness effect was observed for the students who made the most errors during the intervention, a different proxy for low prior knowledge, hinting that even in a classroom setting, politeness may be beneficial for more needy students. This article presents and discusses these results, as well as discussing the politeness effect more generally, its theoretical underpinnings, and future directions. }}
@article{Goh200557,
title = {GeogDL: a web-based approach to geography examination revision },
journal = {Computers & Education },
volume = {45},
number = {1},
pages = {57 - 73},
year = {2005},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2004.04.011},
url = {http://www.sciencedirect.com/science/article/pii/S0360131504000739},
author = {Dion H. Goh and Rebecca P. Ang and Yin-Leng Theng and Ee-Peng Lim},
abstract = {The traditional educational approach with students as passive recipients has been the subject of criticism. A constructivist learner-centered approach towards education has been argued to produce greater internalization and application of knowledge compared to the traditional teacher-centered, transmission-oriented approach. Nevertheless, contemporary instructional design models argue for the use and integration of both approaches especially in complex learning tasks. This paper describes GeogDL, a Web-based application developed above a digital library of geographical resources for Singapore students preparing to take a national examination in geography. GeogDL is unique in that it not only provides an environment for active learning, it also adopts a pragmatic approach to learning that recognizes the importance of examinations especially in the Singapore education system. The paper discusses the components within the system that permit teachers to facilitate active student learning, to draw interconnections, and to promote knowledge sharing and collaboration. GeogDL was pilot-tested on a group of secondary school students in Singapore and the results suggested the viability of the system and also provided direction for future development. }}
@article{Watson2011466,
title = {A case study of the in-class use of a video game for teaching high school history },
journal = {Computers & Education },
volume = {56},
number = {2},
pages = {466 - 474},
year = {2011},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.09.007},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510002599},
author = {William R. Watson and Christopher J. Mong and Constance A. Harris},abstract = {This study examines the case of a sophomore high school history class where Making History, a video game designed with educational purposes in mind, is used in the classroom to teach about World War II. Data was gathered using observation, focus group and individual interviews, and document analysis. The high school was a rural school located in a small town in the Midwestern United States. The teacher had been teaching with the game for several years and spent one school week teaching World War II, with students playing the game in class for three days of that week. The purpose of this study was to understand teacher and student experiences with and perspectives on the in-class use of an educational video game. Results showed that the use of the video game resulted in a shift from a traditional teacher-centered learning environment to a student-centered environment where the students were much more active and engaged. Also, the teacher had evolved implementation strategies based on his past experiences using the game to maximize the focus on learning. }}
@article{Westelinck2005555,
title = {Multimedia learning in social sciences: limitations of external graphical representations },
journal = {Computers in Human Behavior },
volume = {21},
number = {4},
pages = {555 - 573},
year = {2005},
note = {Learning in Innovative Learning Environments },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2004.10.030},
url = {http://www.sciencedirect.com/science/article/pii/S0747563204001852},
author = {Katrien De Westelinck and Martin Valcke and Brigitte De Craene and Paul Kirschner},
abstract = {In a series of six experimental studies, each consisting of three sub-studies, the central question was researched whether adding external graphical representations to printed or electronic learning materials improves retention and transfer scores. These studies research the degree of generalizability of Mayer’s cognitive theory of multimedia learning (CTML) to the knowledge domain of the social sciences. The research hypotheses build on the assumption that this knowledge domain differs in the way instructional designers are able to develop adequate depictive external graphical representations. Earlier CTML-research was mostly carried out in the field of the natural sciences, where graphical representations are depictive in nature and/or where representations can be developed from existing or acquired iconic sign systems. The results indicate that alternative guidelines might need to be considered when learners study learning materials with external graphical representations that reflect low levels of repleteness and do not build on an iconic sign system previously mastered or acquired by the learners. The research results reveal that studying this type of representation does not result in higher test performance and does not result in lower levels of mental load. }}
@article{Banerjee201441,
title = {SELP: A general-purpose framework for learning the norms from saliencies in spatiotemporal data },
journal = {Neurocomputing },
volume = {138},
number = {},
pages = {41 - 60},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.02.044},
url = {http://www.sciencedirect.com/science/article/pii/S0925231213007273},
author = {Bonny Banerjee and Jayanta K. Dutta},
abstract = {Abstract Sensors that monitor around the clock are everywhere. Due to the sheer amount of data these sensors can generate, the resources required to store, protect personal information, and analyze them are enormous. Since noteworthy events happen only occasionally, it is not necessary to store or analyze the data generated at every instant of time. Rather, it is imperative for a smart memory to learn the norms in such data so that only the abnormal (or salient) events may be stored. We present a general-purpose biologically plausible computational framework, called SELP, for learning the norms (or invariances) as a hierarchy of features from space- and time-varying data in an unsupervised and online manner from saliencies or surprises in the data. Given streaming data, this framework runs a relentless cycle – detect unexpected or Salient event, Explain the salient event, Learn from its explanation, Predict the future events – involving the real external world and its internal model, and hence the name. Experimental results from different functions of this framework are presented with a particular emphasis on the role of lateral connections in each layer. }}
@article{PhilipChen2014314,
title = {Data-intensive applications, challenges, techniques and technologies: A survey on Big Data },
journal = {Information Sciences },
volume = {275},
number = {},
pages = {314 - 347},
year = {2014},
note = {},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2014.01.015},
url = {http://www.sciencedirect.com/science/article/pii/S0020025514000346},
author = {C.L. Philip Chen and Chun-Yang Zhang},
abstract = {Abstract It is already true that Big Data has drawn huge attention from researchers in information sciences, policy and decision makers in governments and enterprises. As the speed of information growth exceeds Moore’s Law at the beginning of this new century, excessive data is making great troubles to human beings. However, there are so much potential and highly useful values hidden in the huge volume of data. A new scientific paradigm is born as data-intensive scientific discovery (DISD), also known as Big Data problems. A large number of fields and sectors, ranging from economic and business activities to public administration, from national security to scientific researches in many areas, involve with Big Data problems. On the one hand, Big Data is extremely valuable to produce productivity in businesses and evolutionary breakthroughs in scientific disciplines, which give us a lot of opportunities to make great progresses in many fields. There is no doubt that the future competitions in business productivity and technologies will surely converge into the Big Data explorations. On the other hand, Big Data also arises with many challenges, such as difficulties in data capture, data storage, data analysis and data visualization. This paper is aimed to demonstrate a close-up view about Big Data, including Big Data applications, Big Data opportunities and challenges, as well as the state-of-the-art techniques and technologies we currently adopt to deal with the Big Data problems. We also discuss several underlying methodologies to handle the data deluge, for example, granular computing, cloud computing, bio-inspired computing, and quantum computing. }}
@article{Bromme2005115,
title = {Is a hypertext a book or a space? The impact of different introductory metaphors on hypertext construction },
journal = {Computers & Education },
volume = {44},
number = {2},
pages = {115 - 133},
year = {2005},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2004.01.003},
url = {http://www.sciencedirect.com/science/article/pii/S0360131504000089},
author = {Rainer Bromme and Elmar Stahl},abstract = {This study examines the impact of different metaphors on the process of hypertext construction. Two groups of 20 college students with no experience in hypertext construction received introductory explanations on the text format hypertext based on either a book or a space metaphor. Then they had to construct hypertexts by linking prepared nodes on the topic of the Internet. The different metaphors had significant effects on the constructed hypertexts, the construction process, and knowledge acquisition. The book metaphor encouraged a more linear way of viewing hypertexts that conflicted with the complexity of the contents to be processed. The space metaphor permitted a correspondence between complex semantic structures and complex hypertext structures. Hence, the space metaphor seems to be more appropriate for explaining the text format hypertext to students. }}
@article{Lee20101145,
title = {The interactions between problem solving and conceptual change: System dynamic modelling as a platform for learning },
journal = {Computers & Education },
volume = {55},
number = {3},
pages = {1145 - 1158},
year = {2010},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.05.012},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510001442},
author = {Chwee Beng Lee},abstract = {This study examines the interactions between problem solving and conceptual change in an elementary science class where students build system dynamic models as a form of problem representations. Through mostly qualitative findings, we illustrate the interplay of three emerging intervening conditions (epistemological belief, structural knowledge and domain knowledge), the choice of learning strategy and the learning outcomes through a theoretical model. }}
@article{Bruinsma2004549,
title = {Motivation, cognitive processing and achievement in higher education },
journal = {Learning and Instruction },
volume = {14},
number = {6},
pages = {549 - 568},
year = {2004},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2004.09.001},
url = {http://www.sciencedirect.com/science/article/pii/S0959475204000702},
author = {Marjon Bruinsma},
abstract = {This study investigated the question of whether a student's expectancy, values and negative affect influenced their deep information processing approach and achievement at the end of the first and second academic year. Five hundred and sixty-five first-year students completed a self-report questionnaire on three different occasions. The departmental administrations provided data on the students' achievement. Covariance analysis indicated that student's expectancy and values positively affected the total number of credits. However, the expected relationship through the deep information processing approach was not found. Even though the analysis showed a relationship between students' expectancy, values and the deep information processing approach, this approach did not affect academic achievement. }}
@article{Tang2014328,
title = {Improving invariance in visual classification with biologically inspired mechanism },
journal = {Neurocomputing },
volume = {133},
number = {},
pages = {328 - 341},
year = {2014},
note = {},
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2013.11.003},
url = {http://www.sciencedirect.com/science/article/pii/S0925231213011466},
author = {Tang Tang and Hong Qiao},abstract = {Abstract A computational model of visual cortex has raised great interest in developing algorithms mimicking human visual systems. The max-operation is employed in the model to emulate the scale and position invariant responses of the visual cells. We further extend this idea to enhance the tolerance of visual classification against the general intra-class variability. A general architecture of the basic block constituting the model is first presented. The architecture adaptively chooses the best matching template from a set of competing templates to predict the label of the incoming sample. To optimize the non-convex and non-smooth objective function resulted, we develop an algorithm to train each template alternately. Experiments show that the proposed method significantly outperforms linear classifiers as a template matching method in several image classification tasks, and is much more computationally efficient than other commonly used non-linear classifiers. In the image classification task on the Caltech 101 database, the performance of the biologically inspired model is obviously boosted by incorporating the proposed method. }}
@article{Berger2010320,
title = {Using CAS to solve a mathematics task: A deconstruction },
journal = {Computers & Education },
volume = {55},
number = {1},
pages = {320 - 332},
year = {2010},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.01.018},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510000321},
author = {Margot Berger},abstract = {I investigate how and whether a heterogeneous group of first-year university mathematics students in South Africa harness the potential power of a computer algebra system (CAS) when doing a specific mathematics task. In order to do this, I develop a framework for deconstructing a mathematics task requiring the use of CAS, into its primary components. This framework is based on the semiotic notion of diagrammatic reasoning whereby reasoning consists of construction of signs, transformation of signs, and observation and interpretation of signs. I use the framework to distinguish between the activities of students who were computer literate on entry to university and those who were not computer literate. The analysis suggests that formerly non-computer literate students are no worse than computer literate students in using CAS to construct various representations of signs, but that they are less able to interpret these signs. I propose that, in the South African context, this is largely due to inequities in prior mathematical education, rather than a lack of computer literacy per se. }}
@article{Moos2010265,
title = {Multimedia, hypermedia, and hypertext: Motivation considered and reconsidered },
journal = {Computers in Human Behavior },
volume = {26},
number = {3},
pages = {265 - 276},
year = {2010},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2009.11.004},
url = {http://www.sciencedirect.com/science/article/pii/S0747563209001757},
author = {Daniel C. Moos and Elizabeth Marroquin},
abstract = {Computer-based instruction (CBI) is becoming increasingly popular in the classroom, particularly because the latest technological advancements allow for visually rich and interactive environments. While the inherent nature of CBIs is often thought to engage learners, research examining the role of motivation in learning with these environments has resulted in mixed findings. These findings are further complicated by unique design characteristics of distinct CBIs. This literature review synthesizes research that has examined the role of theoretically-grounded constructs of motivation in the context of three popular CBIs, multimedia, hypermedia, and hypertext. Specifically, this literature review considered empirical studies that examined the effect of these CBIs on motivation, in addition to the effect of motivation on learning outcomes and the learning process within the context of these environments. The literature review concludes with a theoretical consideration of previous research and a discussion of a framework for future directions. }}
@article{Looi20091120,
title = {Anatomy of a mobilized lesson: Learning my way },
journal = {Computers & Education },
volume = {53},
number = {4},
pages = {1120 - 1132},
year = {2009},
note = {Learning with ICT: New perspectives on help seeking and information searching },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2009.05.021},
url = {http://www.sciencedirect.com/science/article/pii/S036013150900133X},
author = {Chee-Kit Looi and Lung-Hsiang Wong and Hyo-Jeong So and Peter Seow and Yancy Toh and Wenli Chen and Baohui Zhang and Cathie Norris and Elliot Soloway},
abstract = {With the mass adoption of mobile computing devices by the current school generation, significant opportunities have emerged for genuinely supporting differentiated and personalized learning experiences through mobile devices. In our school-based research work in introducing mobilized curricula to a class, we observe one compelling mobilized lesson that exploits the affordances of mobile learning to provide multiple learning pathways for elementary grade (primary) 2 students. Through the lesson, students move beyond classroom activities that merely mimic what the teacher says and does in the classroom, and yet they still learn in personally meaningful ways. In deconstructing the lesson, we provide an in-depth analysis of how the affordances of mobile computing enable personalized learning from four facets: (a) allowing multiple entry points and learning pathways, (b) supporting multi-modality, (c) enabling student improvisation in situ, and (d) supporting the sharing and creation of student artifacts on the move. A key property of mobile technology that enables these affordances lies with the small form factor and the lightweightness of these devices which make them non-obtrusive in the learning spaces of the student. This article makes a contribution on the design aspects of mobilized lessons, namely, what the affordances of mobile technologies can enable. }}
@article{Chen20091155,
title = {The use of online synchronous discussion for web-based professional development for teachers },
journal = {Computers & Education },
volume = {53},
number = {4},
pages = {1155 - 1166},
year = {2009},
note = {Learning with ICT: New perspectives on help seeking and information searching },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2009.05.026},
url = {http://www.sciencedirect.com/science/article/pii/S0360131509001377},
author = {Yihsuan Chen and Nian-Shing Chen and Chin-Chung Tsai},abstract = {This article described the experiences of an inservice professional development program for teachers with a focus on online synchronous discussions. Transcripts of six online synchronous discussions containing 3600 messages from an online teacher professional development course were analyzed. In addition, the researchers interviewed 10 participating teachers in order to understand their perceptions toward online synchronous discussions. According to the online discourse data, the online synchronous discussions served not only as a learning tool, but also an avenue for teachers to request and provide information, socialize and support each other. The analyses also revealed that the teachers posted more social messages in the beginning and the end of discussion, and most messages did not involve any cognitive and metacognitive skills. Moreover, the interview results showed that the information exchange during online synchronous discussion was not effective for some participating teachers. Based on the interview data, synchronous discussions appeared to hold little advantage when compared to face-to-face discussions for several participating teachers that we interviewed. The problem may be resulted from lack of self-regulated skills by the participants or from the role played by the moderator. }}
@article{Govender20091218,
title = {The learning context: Influence on learning to program },
journal = {Computers & Education },
volume = {53},
number = {4},
pages = {1218 - 1230},
year = {2009},
note = {Learning with ICT: New perspectives on help seeking and information searching },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2009.06.005},
url = {http://www.sciencedirect.com/science/article/pii/S0360131509001523},
author = {Irene Govender},
abstract = {In this paper the influence of the learning context is considered when learning to program. For the purposes of this study, the lectures, study process, previous knowledge or teaching experience and tests comprised the learning context. The article argues that students’ experiences of the learning context have important implications for teaching and learning. Therefore, the solutions that most students work towards in order to solve a problem are an indication of an essential aspect: the learning context. The study attempts to understand the influence that the learning context has on pre- and in-service teachers learning to program. The participants who took a course in Java programming were asked to keep a journal, which indicated their reflections throughout the course. These reflections together with interview transcripts of some participants were used in the analysis. The instructors of the course were also part of this qualitative study. Activity theory was used as a basis for the analysis. It was found that both the problem and the learning context have a profound effect on students’ understanding and performance. }}
@article{Austin20091339,
title = {Multimedia learning: Cognitive individual differences and display design techniques predict transfer learning with multimedia learning modules },
journal = {Computers & Education },
volume = {53},
number = {4},
pages = {1339 - 1354},
year = {2009},
note = {Learning with ICT: New perspectives on help seeking and information searching },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2009.06.017},
url = {http://www.sciencedirect.com/science/article/pii/S0360131509001638},
author = {Katherine A. Austin},
abstract = {In the wake of the information explosion and rapidly progressing technology [Mayer, R. E. (2001). Multimedia learning. Cambridge: University Press] formulated a theory that focused on human cognition, rather than technology capacity and features. By measuring the effect of cognitive individual differences and display design manipulations on performance, the current research evaluates the impact of multimedia combinations on college student transfer test performance. Results indicated that multimedia combination accounted for variance in transfer test scores beyond the impact of relevant cognitive individual differences. Findings demonstrated that text positioning and motion distraction accounted for the inferiority of transfer test performance in certain multimedia conditions. Research yields support for the notion that display design can split attention, increase cognitive load, and reduce transfer learning. Key design principles must be evaluated further before prescriptive guidelines for educational multimedia can be solidified. }}
@article{Plass2014128,
title = {Emotional design in multimedia learning: Effects of shape and color on affect and learning },
journal = {Learning and Instruction },
volume = {29},
number = {},
pages = {128 - 140},
year = {2014},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2013.02.006},
url = {http://www.sciencedirect.com/science/article/pii/S0959475213000273},
author = {Jan L. Plass and Steffi Heidig and Elizabeth O. Hayward and Bruce D. Homer and Enjoon Um},
abstract = {Abstract We examine design factors that may evoke positive emotions in learners and investigate the effects of these positive emotions on learning. Recent research showed that the emotional design of multimedia learning material can induce positive emotions in learners that in turn facilitate comprehension and transfer. We sought to replicate these results with a different population and different mood induction procedure and examine individual emotions, and to decompose the effects of the design elements of color and shape. Study 1 showed that well-designed materials induced positive emotions and facilitated comprehension, though transfer performance was not affected by emotional design. Study 2 found that round face-like shapes both alone and in conjunction with warm color induced positive emotions. Warm colors alone, however, did not affect learners' emotions. Comprehension was facilitated by warm colors and round face-like shapes, independently as well as together. Transfer was facilitated by round face-like shapes when used with neutral colors. }}
@article{Kreijns2003335,
title = {Identifying the pitfalls for social interaction in computer-supported collaborative learning environments: a review of the research },
journal = {Computers in Human Behavior },
volume = {19},
number = {3},
pages = {335 - 353},
year = {2003},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/S0747-5632(02)00057-2},
url = {http://www.sciencedirect.com/science/article/pii/S0747563202000572},
author = {Karel Kreijns and Paul A. Kirschner and Wim Jochems},
abstract = {Computer-mediated world-wide networks have enabled a shift from contiguous learning groups to asynchronous distributed learning groups utilizing computer-supported collaborative learning environments. Although these environments can support communication and collaboration, both research and field observations are not always positive about their working. This article focuses on factors which may cause this discrepancy, centering on two pitfalls that appear to impede achieving the desired results, namely taking for granted that participants will socially interact simply because the environment makes it possible and neglecting the social (psychological) dimension of the desired social interaction. It examines the social interactions which determine how groups develop, how sound social spaces characterized by group cohesion, trust, respect and belonging are established, and how a sense of community of learning is established. It concludes with an evaluation of educational techniques proposed by instructors and educators, as well as the findings of educational researchers and guidelines for avoiding the pitfalls. }}
@article{Moreno2009433,
title = {Constructing knowledge with an agent-based instructional program: A comparison of cooperative and individual meaning making },
journal = {Learning and Instruction },
volume = {19},
number = {5},
pages = {433 - 444},
year = {2009},
note = {Cognitive load in interactive knowledge construction },
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2009.02.018},
url = {http://www.sciencedirect.com/science/article/pii/S095947520900019X},
author = {Roxana Moreno},abstract = {Participants in the present study were 87 college students who learned about botany using an agent-based instructional program with three different learning approaches: individual, jigsaw, or cooperative learning. Results showed no differences among learning approaches on retention. Students in jigsaw groups reported higher cognitive load during learning than students who learned individually; scored lower on a problem-solving transfer test than students in individual and cooperative learning groups; and were less likely to produce elaborated explanations and co-construct knowledge with their peers than students in cooperative groups. Students in cooperative groups reported higher situational interest than their counterparts. Implications for cooperative and individual meaning making in agent-based instructional programs are discussed and future research directions are suggested. }}
@article{Segers2009423,
title = {Learning in a sheltered Internet environment: The use of WebQuests },
journal = {Learning and Instruction },
volume = {19},
number = {5},
pages = {423 - 432},
year = {2009},
note = {Cognitive load in interactive knowledge construction },
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2009.02.017},
url = {http://www.sciencedirect.com/science/article/pii/S0959475209000188},
author = {Eliane Segers and Ludo Verhoeven},
abstract = {The present study investigated the effects on learning in a sheltered Internet environment using so-called WebQuests in elementary school classrooms in the Netherlands. A WebQuest is an assignment presented together with a series of web pages to help guide children's learning. The learning gains and quality of the work of 229 sixth graders participating in either a free-search Google condition or a closed-search WebQuest condition were compared. The closed-search condition showed the highest learning gains for boys. Children's information processing and linguistic skills generally influenced their learning gains and did not interact with condition. A difference in the quality of writing for the two conditions was also found with the language quality being higher in the free-search condition. }}
@article{Fischer201425,
title = {Training restricted Boltzmann machines: An introduction },
journal = {Pattern Recognition },
volume = {47},
number = {1},
pages = {25 - 39},
year = {2014},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2013.05.025},
url = {http://www.sciencedirect.com/science/article/pii/S0031320313002495},
author = {Asja Fischer and Christian Igel},
abstract = {Abstract Restricted Boltzmann machines (RBMs) are probabilistic graphical models that can be interpreted as stochastic neural networks. They have attracted much attention as building blocks for the multi-layer learning systems called deep belief networks, and variants and extensions of RBMs have found application in a wide range of pattern recognition tasks. This tutorial introduces RBMs from the viewpoint of Markov random fields, starting with the required concepts of undirected graphical models. Different learning algorithms for RBMs, including contrastive divergence learning and parallel tempering, are discussed. As sampling from RBMs, and therefore also most of their learning algorithms, are based on Markov chain Monte Carlo (MCMC) methods, an introduction to Markov chains and MCMC techniques is provided. Experiments demonstrate relevant aspects of RBM training. }}
@article{Jamaludin2009317,
title = {Fostering argumentative knowledge construction through enactive role play in Second Life },
journal = {Computers & Education },
volume = {53},
number = {2},
pages = {317 - 329},
year = {2009},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2009.02.009},
url = {http://www.sciencedirect.com/science/article/pii/S0360131509000487},
author = {Azilawati Jamaludin and Yam San Chee and Caroline Mei Lin Ho},abstract = {This paper examines how pre-university students shared and constructed knowledge in the context of GP (general paper) by interacting through individual virtual characters across five cycles of enactive role play sessions. Contextualized scenarios on the topic of euthanasia were developed in Second Life. Role-playing the virtual characters through three-dimensional avatars, 45 students from two different classes grappled and dealt with issues related to euthanasia such as ethics, morality, and religion. The enactment log transcripts of 10 student groups across five enactment sessions were analyzed using an adapted collaborative argumentation framework. We present the results from two types of data analysis: a macro quantitative analysis of students’ enactment log transcripts and a qualitative analysis of their open-ended responses. Our quantitative analysis at the class level revealed salient differences in the nature of epistemic interactions, the patterns of argumentative moves, and the patterns of social interactions between students from two classes. The findings from the qualitative analysis of students’ open-ended responses indicate that students valued the embodied experience afforded by the immersive virtual environment. We discuss the findings of our research in terms of important pedagogical implications and the factors that influence argumentative knowledge sharing and constructing activities. }}
@article{Scarselli201378,
title = {Solving graph data issues using a layered architecture approach with applications to web spam detection },
journal = {Neural Networks },
volume = {48},
number = {},
pages = {78 - 90},
year = {2013},
note = {},
issn = {0893-6080},
doi = {http://dx.doi.org/10.1016/j.neunet.2013.07.007},
url = {http://www.sciencedirect.com/science/article/pii/S0893608013001937},
author = {Franco Scarselli and Ah Chung Tsoi and Markus Hagenbuchner and Lucia Di Noi},abstract = {Abstract This paper proposes the combination of two state-of-the-art algorithms for processing graph input data, viz., the probabilistic mapping graph self organizing map, an unsupervised learning approach, and the graph neural network, a supervised learning approach. We organize these two algorithms in a cascade architecture containing a probabilistic mapping graph self organizing map, and a graph neural network. We show that this combined approach helps us to limit the long-term dependency problem that exists when training the graph neural network resulting in an overall improvement in performance. This is demonstrated in an application to a benchmark problem requiring the detection of spam in a relatively large set of web sites. It is found that the proposed method produces results which reach the state of the art when compared with some of the best results obtained by others using quite different approaches. A particular strength of our method is its applicability towards any input domain which can be represented as a graph. }}
@article{Kirschner2009306,
title = {Individual and group-based learning from complex cognitive tasks: Effects on retention and transfer efficiency },
journal = {Computers in Human Behavior },
volume = {25},
number = {2},
pages = {306 - 314},
year = {2009},
note = {Including the Special Issue: State of the Art Research into Cognitive Load Theory },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2008.12.008},
url = {http://www.sciencedirect.com/science/article/pii/S0747563208002227},
author = {Femke Kirschner and Fred Paas and Paul A. Kirschner},
abstract = {The effects of individual versus group learning (in triads) on efficiency of retention and transfer test performance in the domain of biology (heredity) among 70 high-school students were investigated. Applying cognitive load theory, the limitations of the working memory capacity at the individual level were considered an important reason to assign complex learning tasks to groups rather than to individuals. It was hypothesized that groups will have more processing capacity available for relating the information elements to each other and by doing so for constructing higher quality cognitive schemata than individuals if the high cognitive load imposed by complex learning tasks could be shared among group members. In contrast, it was expected that individuals who learn from carrying out the same complex tasks would need all available processing capacity for remembering the interrelated information elements, and, consequently, would not be able to allocate resources to working with them. This interaction hypothesis was confirmed by the data on efficiency of retention and transfer test performance; there was a favorable relationship between mental effort and retention test performance for the individual learners as opposed to a favorable relationship between transfer test performance and mental effort for the students who learned in groups. }}
@article{Akkerman2009449,
title = {Storification in History education: A mobile game in and about medieval Amsterdam },
journal = {Computers & Education },
volume = {52},
number = {2},
pages = {449 - 459},
year = {2009},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2008.09.014},
url = {http://www.sciencedirect.com/science/article/pii/S0360131508001498},
author = {Sanne Akkerman and Wilfried Admiraal and Jantina Huizenga},
abstract = {A mobile and multimedia game designed for History education was analyzed in terms of how it is designed and how it was applied as a narrative learning environment. In History education, narrative can be argued to be very useful to overcome fragmentation of the knowledge of historical characters and events, by relating these with meaningful connections of temporality and sequence (storification). In the game studied, students explore the history of Amsterdam by walking in the city, experiencing characters, buildings, and events, while using UMTS/GPS phones for communication and exchange of information. The History game was played during one day by 216 students, spread over 10 secondary school classes, in groups of four or five students. All information exchanged during the games was collected, and the game play and introduction of the game was observed by team coaches and researchers. The design of the game as well as the actual gaming process was analyzed with respect to how it evoked three types of storification: receiving (spectator), constructing (director) and participating in (actor) the story. Results show that the game evoked a mixture of these three types of storification. Moreover, these types of storification processes differently affected students’ engagement. Participating in the story evoked high activity in the game but less awareness of the whole story, whereas constructing the story triggered awareness of the whole story. Compared to receiving the story, both these types positively affected the engagement of the students being active and motivated during the game. }}
@article{Chrysafiadi20134715,
title = {Student modeling approaches: A literature review for the last decade },
journal = {Expert Systems with Applications },
volume = {40},
number = {11},
pages = {4715 - 4729},
year = {2013},
note = {},
issn = {0957-4174},
doi = {http://dx.doi.org/10.1016/j.eswa.2013.02.007},
url = {http://www.sciencedirect.com/science/article/pii/S095741741300122X},
author = {Konstantina Chrysafiadi and Maria Virvou},abstract = {This paper constitutes a literature review on student modeling for the last decade. The review aims at answering three basic questions on student modeling: what to model, how and why. The prevailing student modeling approaches that have been used in the past 10 years are described, the aspects of students’ characteristics that were taken into consideration are presented and how a student model can be used in order to provide adaptivity and personalisation in computer-based educational software is highlighted. This paper aims to provide important information to researchers, educators and software developers of computer-based educational software ranging from e-learning and mobile learning systems to educational games including stand alone educational applications and intelligent tutoring systems. In addition, this paper can be used as a guide for making decisions about the techniques that should be adopted when designing a student model for an adaptive tutoring system. One significant conclusion is that the most preferred technique for representing the student’s mastery of knowledge is the overlay approach. Also, stereotyping seems to be ideal for modeling students’ learning styles and preferences. Furthermore, affective student modeling has had a rapid growth over the past years, while it has been noticed an increase in the adoption of fuzzy techniques and Bayesian networks in order to deal the uncertainty of student modeling. }}
@article{Ke20081609,
title = {A case study of computer gaming for math: Engaged learning from gameplay? },
journal = {Computers & Education },
volume = {51},
number = {4},
pages = {1609 - 1620},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2008.03.003},
url = {http://www.sciencedirect.com/science/article/pii/S0360131508000523},
author = {Fengfeng Ke},
abstract = {Employing mixed-method approach, this case study examined the in situ use of educational computer games in a summer math program to facilitate 4th and 5th graders’ cognitive math achievement, metacognitive awareness, and positive attitudes toward math learning. The results indicated that students developed more positive attitudes toward math learning through five-week computer math gaming, but there was no significant effect of computer gaming on students’ cognitive test performance or metacognitive awareness development. The in-field observation and students’ think-aloud protocol informed that not every computer math drill game would engage children in committed learning. The study findings have highlighted the value of situating learning activities within the game story, making games pleasantly challenging, scaffolding reflections, and designing suitable off-computer activities. }}
@article{Hutchings1992171,
title = {Authoring and evaluation of hypermedia for education },
journal = {Computers & Education },
volume = {18},
number = {1–3},
pages = {171 - 177},
year = {1992},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/0360-1315(92)90051-6},
url = {http://www.sciencedirect.com/science/article/pii/0360131592900516},
author = {G.A. Hutchings and W. Hall and J. Briggs and N.V. Hammond and M.R. Kibby and C. McKnight and D. Riley},
abstract = {Hypermedia encompasses the modes of learning and interaction associated with conventional CAL, but it also allows greater learner control, access to multimedia learning materials and a variety of modalities of interaction with the learning material which are only now becoming apparent. Nevertheless, for a hypermedia document to be educationally effective, the author must consider the learning goals and activities it must support, how the nature of the domain will relate to the learning activities, and how learners will differ, and then provide appropriate support tools. Authoring large hypermedia documents demands facilities to manage links, and to create them automatically. Methods considered included the creation of generic links, applicable to more than one document, use of knowledge-based rules to generate links, and the use of file interchange formats for reusability of information. Authors should avoid the dominant browse and retrieve model and consider a range of activities—in any case simple hypertext has been shown to be insufficient for effective learning. Evaluation of such systems and materials in use has many facets, including usability, the effectiveness of guidance tools, the learning achieved. Evaluation of hypermedia systems is different from CAL because of the new vocabulary and syntax of interaction which is required. }}
@article{Mumtaz2001347,
title = {Children's enjoyment and perception of computer use in the home and the school },
journal = {Computers & Education },
volume = {36},
number = {4},
pages = {347 - 362},
year = {2001},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/S0360-1315(01)00023-9},
url = {http://www.sciencedirect.com/science/article/pii/S0360131501000239},
author = {Shazia Mumtaz},
abstract = {This paper seeks to examine the nature and experiences of children's computer use in the home and school. Past research suggests a growing gap between computer use in the home and the school. This study was conducted to find out how children perceive and enjoy computer use in these two environments. Using a sample of year 3 and 5 pupils in three primary schools, qualitative and quantitative data were gathered. The results suggest that children make more use of the computer at home than at school. The most popular activity on the home computer which all children enjoyed was playing games. The most frequent activity at the school computer was word processing which pupils considered boring. Interesting gender differences showed that boys spent more time playing computer games whereas girls spent more time on the Internet emailing friends. The study concludes that schools should learn from what works at home and enable children to work on activities they find valuable, motivational and worthwhile. }}
@article{Zhang20131772,
title = {Sparse coding based visual tracking: Review and experimental comparison },
journal = {Pattern Recognition },
volume = {46},
number = {7},
pages = {1772 - 1788},
year = {2013},
note = {},
issn = {0031-3203},
doi = {http://dx.doi.org/10.1016/j.patcog.2012.10.006},
url = {http://www.sciencedirect.com/science/article/pii/S0031320312004396},
author = {Shengping Zhang and Hongxun Yao and Xin Sun and Xiusheng Lu},
abstract = {Recently, sparse coding has been successfully applied in visual tracking. The goal of this paper is to review the state-of-the-art tracking methods based on sparse coding. We first analyze the benefits of using sparse coding in visual tracking and then categorize these methods into appearance modeling based on sparse coding (AMSC) and target searching based on sparse representation (TSSR) as well as their combination. For each categorization, we introduce the basic framework and subsequent improvements with emphasis on their advantages and disadvantages. Finally, we conduct extensive experiments to compare the representative methods on a total of 20 test sequences. The experimental results indicate that: (1) AMSC methods significantly outperform TSSR methods. (2) For AMSC methods, both discriminative dictionary and spatial order reserved pooling operators are important for achieving high tracking accuracy. (3) For TSSR methods, the widely used identity pixel basis will degrade the performance when the target or candidate images are not aligned well or severe occlusion occurs. (4) For TSSR methods, ℓ 1 norm minimization is not necessary. In contrast, ℓ 2 norm minimization can obtain comparable performance but with lower computational cost. The open questions and future research topics are also discussed. }}
@article{Wang2008262,
title = {A blog-based dynamic learning map },
journal = {Computers & Education },
volume = {51},
number = {1},
pages = {262 - 278},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2007.06.005},
url = {http://www.sciencedirect.com/science/article/pii/S036013150700053X},
author = {Kun Te Wang and Yueh-Min Huang and Yu-Lin Jeng and Tzone-I Wang},abstract = {Problem-based learning is a goal directed and constructive process for learners. When meeting problems, learners usually force themselves to form work groups in order to find a solution. Currently, blogs are becoming more popular and in fact has formed a community wherein people can share their learning experiences with others. Many pedagogical applications have adopted what are posted in the community for supplementary learning. Integrating blogs in an intelligent tutoring system means that learners can better regulate and enhance their own learning. In this study, a novel learning device, a blog-based dynamic learning map, which employs both information retrieval and automated scheduling techniques, is designed to provide useful blog articles to help learning. The relevant articles in blogs are used to promote learner engagement in their interactions with the learning map and hence achieve their goals more easily. An experimental course has been implemented and the results show that learners make use of the blog-based learning aid in a very positive way and can eventually cross the specified threshold in a test. The proposed approach can encapsulate the dynamic learning principles in cohesive and supportive ways. Thus it can lead learners to gain useful supplementary materials, shorten the learning time and offering expanded alternative viewpoints to use in the solution of assigned problems. Our results show that both the learners and lectures are very positive to the design of our blog-based dynamic learning map. }}
@article{Yang20081284,
title = {Investigating university student preferences and beliefs about learning in the web-based context },
journal = {Computers & Education },
volume = {50},
number = {4},
pages = {1284 - 1303},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2006.12.009},
url = {http://www.sciencedirect.com/science/article/pii/S0360131506001941},
author = {Fang-Ying Yang and Chin-Chung Tsai},
abstract = {Psychological studies have shown that personal beliefs about learning and environmental preferences affect learning behaviors. However, these learner characteristics have not been widely discussed in the web-based context. By developing questionnaires, this study attempted to detect learners’ web-based learning environmental preferences (WLEP) and beliefs about web-based learning (BWL). The scope of WLEP focused on the pedagogical dimension of the web-based learning environment, while BWL concerned the attributes and control factors of the web-based learning. There were about five hundreds of Taiwan university students participating in the study. Through factor analysis, the scales discussed in the study revealed a satisfactory validity and reliability in assessing students’ preferences and beliefs. Further analyses showed that university students preferred more of individual and structured instructional configurations while expected the outward mode of interaction. In general, students held a rather contextual belief about web-based learning, which was found to be correlated with their environmental preferences. }}
@article{Mackey2008386,
title = {Exploring the relationships between Web usability and students’ perceived learning in Web-based multimedia (WBMM) tutorials },
journal = {Computers & Education },
volume = {50},
number = {1},
pages = {386 - 409},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2006.08.006},
url = {http://www.sciencedirect.com/science/article/pii/S0360131506001126},
author = {Thomas P. Mackey and Jinwon Ho},
abstract = {The purpose of this case study is to better understand the relationships between Web usability and students’ perceived learning in the design and implementation of Web-based multimedia (WBMM) tutorials in blended courses. Much of the current research in this area focuses on the use of multimedia as a replacement for classroom instruction rather than as a complement to teaching practices in courses that meet face-to-face. This study analyzed data collected from 41 undergraduate students who accessed a series of WBMM tutorials to learn Web design in an upper-level undergraduate information science course that combines both in-class and online instruction. We provide a descriptive analysis of student survey responses and apply Kendall’s rank correlation coefficient to examine significant relationships (p &lt; 0.05) between usability factors and students’ perceived learning performance. We also explore the impact of WBMM on other aspects of the course, such as readings, email, office hours, and computer lab. Findings indicate that students responded favorably to most of the usability factors defined in this study and that course lectures and readings may have been enhanced by this virtual resource. In addition, we identified a significant correlation between usability factors of the WBMM tutorials and how students perceive their own learning. This study suggests that multimedia instruction is an effective approach to teaching Web design in blended learning environments that include both face-to-face and Web-based resources. }}
@article{Müller20071175,
title = {The socio-economic dimensions of ICT-driven educational change },
journal = {Computers & Education },
volume = {49},
number = {4},
pages = {1175 - 1188},
year = {2007},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2006.01.006},
url = {http://www.sciencedirect.com/science/article/pii/S0360131506000315},
author = {Jörg Müller and Juana M. Sancho Gil and Fernando Hernández and Xavier Giró and Alejandra Bosco},
abstract = {This paper analyses the varied socio-economic implications of ICT-based educational change. Drawing from a rich, 3-year long research project with 20 secondary schools throughout Europe, the social, human, professional, institutional, and economic costs for building the school of tomorrow in close alliance with ICT are discussed. The aim of this paper is to show the real costs involved in such a comprehensive model of educational change, which cannot be reduced to the cost of installing computers in classrooms. Rather, it must aim at capturing the varied long-term requirements necessary for educational change in conjunction with ICT. Great emphasis is placed on questions concerning the very sustainability of innovation and the necessity to adopt a long-term perspective that provides us with a realistic socio-economic evaluation. We argue that the real costs of educational change only become apparent when short-term improvements have been converted into sustainable changes that last beyond a project’s life-time. Key aspects for lasting contributions are identified, among which network building and applying a bottom-up strategy for change are given particular importance. }}
@article{Aiton1989229,
title = {A CTI project on the co-operative development of CAL in physiology at the Universities of Aberdeen, Dundee and St Andrews },
journal = {Computers & Education },
volume = {13},
number = {3},
pages = {229 - 234},
year = {1989},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/0360-1315(89)90020-1},
url = {http://www.sciencedirect.com/science/article/pii/0360131589900201},
author = {J.F. Aiton and W. Boyd and A.R. Chipperfield and M. Goldsmith and C.G. Ingram and C. Kidd and P.G. Newman and N.J. Part},
abstract = {This paper reports on the progress of a collaborative Computers in Teaching Initiative project between Aberdeen, St Andrews and Dundee Universities for the development of CAL for the teaching of elementary physiology. The aims of this project are stated. The historical background to the project, stemming from the use of BBC networks at St Andrews and Dundee, is presented. The project uses systems of networked PCs which give a number of advantages over the BBC systems. The thinking of the group on the best model for the development of CAL in physiology and the choice of Microtext as the authoring system are discussed. Working in a group of three departments offers several advantages for the development of high quality software. These advantages are discussed. The physiological Society Bulletin Board as a means of distributing information about physiology CAL via the JANET network is described. }}
@article{SaadaRobert1999189,
title = {Effective means for learning to manage cognitive load in second grade school writing: a case study },
journal = {Learning and Instruction },
volume = {9},
number = {2},
pages = {189 - 208},
year = {1999},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/S0959-4752(98)00044-9},
url = {http://www.sciencedirect.com/science/article/pii/S0959475298000449},
author = {Madelon Saada-Robert},abstract = {In recent years, many school writing studies have been carried out within the framework of metacognitive processes. Only a few studies have included cognitive load as a frame of analysis. In addition to components and processes, mental operations (identifying relevant knowledge or procedures, selecting them from long-term memory, and so on) contribute to cognitive overload. In the present study, we focus on spelling in text production, particularly in the translation process. The didactic sequences designed by both teachers and researchers for the second grade allow the learner to work on spelling while still maintaining the entire cognitive field of authentic learning to write in school. The spelling objectives are worked on primarily in complex composition tasks but are also consolidated in specific follow-up tasks linked to the former. The didactic sequences are analysed in terms of cognitive load, then observations of two second-grade learners are analysed in terms of cognitive resources management: how they use previously planned knowledge in writing, how they form a limited number of their own cognitive work-units in spelling among the potential units of the whole writing field, how children manage searching in reference documents, and how they acquire fluency in the writing translation process. Managing one's cognitive resources in learning to spell integrated in the authentic school setting, without detrimental overload, becomes possible under specific conditions that concern both learner resource management and structures of didactic situations. }}
@article{Russell1997137,
title = {The reflective colleague in e-mail cyberspace: A means for improving university instruction },
journal = {Computers & Education },
volume = {29},
number = {4},
pages = {137 - 145},
year = {1997},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/S0360-1315(97)00040-7},
url = {http://www.sciencedirect.com/science/article/pii/S0360131597000407},
author = {Anne L. Russell and Leonora M. Cohen},
abstract = {Two university academics living in countries on different sides of the world captured their e-mail communications during a ten-week teaching course. The power of e-mail over face-to-face conversation was explored as Nora, living in Oregon, U.S.A., contemplated her struggle to teach a new subject and Anne, living in Queensland, Australia, responded to Nora's introspections. As the terms coach and mentor did not represent the reciprocal nature of the interactions, the term reflective colleague was used to explain the mirror-like role. The reflective colleague provided: supportive affirmation, belief clarifications, alternative perspectives, and future and global projections. The role of e-mail in the process of journalizing together was non-hierarchical and became symmetrical in a short space of time. Both colleagues found value in exploring together the teaching of a new course. Benefits to Nora were: being heard, feeling support when things were difficult, getting new ideas and alternative viewpoints, and transforming the experience to one focusing on her own learning. Benefits to Anne were strengthening her own understandings of data she had previously collected as well as applying strategies discussed to her own teaching. The value of e-mail over other types of media or interpersonal interactions involved two paradoxes: it was rapid, yet allowed time for deep reflection, and it was spontaneous, yet permitted an accurate and permanent record, one that could be reviewed again and again. E-mail as a medium for reflective dialogue has considerable potential for use in improving university instruction. }}
@article{Clark20121207,
title = {Bilingual language supports in online science inquiry environments },
journal = {Computers & Education },
volume = {58},
number = {4},
pages = {1207 - 1224},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.11.019},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511003046},
author = {Douglas B. Clark and Stephanie Touchman and Mario Martinez-Garza and Frank Ramirez-Marin and Tina Skjerping Drews},
abstract = {Research over the past fifteen years has investigated and developed online science inquiry environments to support students engaging in authentic scientific inquiry practices. This research has focused on developing activity structures and tools to scaffold students in engaging in different aspects of these practices, but relatively little of this research has explored linguistic supports for language minority students studying science in their non-native language. These students are simultaneously learning science and the surrounding academic language in their second language. This study investigates the potential value of providing 8th grade Spanish-speaking English language learners access to content and supports in both English and Spanish as opposed to an English-only format in an online science inquiry environment. Learning outcomes are compared between the two conditions on an immediate post-test in English, a delayed post-test in English, a delayed post-test in Spanish, and a written essay in English in the form of a letter to the governor. The outcomes suggest significant benefits for providing ELL students with access to content and supports in both English and Spanish as opposed to the English-only format. The findings of this study carry important policy implications in light of the growing English-only political movements in the United States and similar political movements in other countries. }}
@article{Moreno2006170,
title = {When worked examples don't work: Is cognitive load theory at an Impasse? },
journal = {Learning and Instruction },
volume = {16},
number = {2},
pages = {170 - 181},
year = {2006},
note = {Recent Worked Examples Research: Managing Cognitive Load to Foster Learning and TransferRecent Worked Examples Research: Managing Cognitive Load to Foster Learning and Transfer },
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2006.02.006},
url = {http://www.sciencedirect.com/science/article/pii/S095947520600020X},
author = {Roxana Moreno}}
@article{Lo201289,
title = {A cortex-like learning machine for temporal hierarchical pattern clustering, detection, and recognition },
journal = {Neurocomputing },
volume = {78},
number = {1},
pages = {89 - 103},
year = {2012},
note = {Selected papers from the 8th International Symposium on Neural Networks (ISNN 2011) },
issn = {0925-2312},
doi = {http://dx.doi.org/10.1016/j.neucom.2011.04.046},
url = {http://www.sciencedirect.com/science/article/pii/S0925231211004826},
author = {James Ting-Ho Lo},
abstract = {A learning machine, called a clustering interpreting probabilistic associative memory (CIPAM), is proposed. CIPAM consists of a clusterer and an interpreter. The clusterer is a recurrent hierarchical neural network of unsupervised processing units (UPUs). The interpreter is a number of supervised processing units (SPUs) that branch out from the clusterer. Each processing unit (PU), UPU or SPU, comprises dendritic encoders for encoding inputs to the PU, synapses for storing resultant codes, a nonspiking neuron for generating inhibitory graded signals to modulate neighboring spiking neurons, spiking neurons for computing the subjective probability distribution (SPD) or the membership function, in the sense of fuzzy logic, of the label of said inputs to the PU and generating spike trains with the SPD or membership function as the firing rates, and a masking matrix for maximizing generalization. While UPUs employ unsupervised covariance learning mechanisms, SPUs employ supervised ones. They both also have unsupervised accumulation learning mechanisms. The clusterer of CIPAM clusters temporal and spatial data. The interpreter interprets the resultant clusters, effecting detection and recognition of temporal and hierarchical causes. }}
@article{Brom2014339,
title = {Personalized messages in a brewery educational simulation: Is the personalization principle less robust than previously thought? },
journal = {Computers & Education },
volume = {72},
number = {},
pages = {339 - 366},
year = {2014},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2013.11.013},
url = {http://www.sciencedirect.com/science/article/pii/S0360131513003242},
author = {Cyril Brom and Edita Bromová and Filip Děchtěrenko and Michaela Buchtová and Martin Pergel},
abstract = {Abstract The personalization principle, one of the design principles of multimedia learning, states that people learn better from multimedia presentations when instructions are in a conversational style rather than a formal style, possibly due to learners' increased interest. This principle was shown to be robust in short interventions that could be completed within minutes or a few dozen minutes; however, complex digital simulations and games that support the acquisition of complex mental models usually take longer to complete. In this study, we investigate the personalization principle in a new context: in an interactive simulation on the topic of beer brewing, which lasts 2–3 h. Instructions were presented in the Czech language, either in a personalized style, where learners were addressed conversationally by their grandpa, an owner of the family brewery, or in a non-personalized, more formal style without the grandpa. In Experiment 1, 26 college students, who interacted with both simulation versions, expressed on average a preference for the personalized version of the simulation. However, some of them worried that personalization could distract them. In Experiment 2 with a between-subject design, the knowledge of 75 predominantly college students was tested by means of retention and transfer tests immediately after completing the simulation and also a month later. Contrary to most previous works, our results showed no difference between the personalized and non-personalized groups in learning achievement, despite the fact that learners who received the personalized treatment voluntarily spent about 20% more time on the simulation. We also applied various measures of the learner's affective state, including Flow Short Scale and PANAS, but – again – no between-group differences were observed. These results indicate that personalization is not always beneficial to learning, which raises important questions for future research. Additional findings suggest that the simulation, no matter the treatment type, was most beneficial to learners with high mathematical abilities and who play computer games frequently, and also to those who liked the simulation more. }}
@article{Rutten2012136,
title = {The learning effects of computer simulations in science education },
journal = {Computers & Education },
volume = {58},
number = {1},
pages = {136 - 153},
year = {2012},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.07.017},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511001758},
author = {Nico Rutten and Wouter R. van Joolingen and Jan T. van der Veen},
abstract = {This article reviews the (quasi)experimental research of the past decade on the learning effects of computer simulations in science education. The focus is on two questions: how use of computer simulations can enhance traditional education, and how computer simulations are best used in order to improve learning processes and outcomes. We report on studies that investigated computer simulations as a replacement of or enhancement to traditional instruction. In particular, we consider the effects of variations in how information is visualized, how instructional support is provided, and how computer simulations are embedded within the lesson scenario. The reviewed literature provides robust evidence that computer simulations can enhance traditional instruction, especially as far as laboratory activities are concerned. However, in most of this research the use of computer simulations has been approached without consideration of the possible impact of teacher support, the lesson scenario, and the computer simulation’s place within the curriculum. }}
@article{Steeples199671,
title = {Technological support for teaching and learning: computer-mediated communications in higher education (CMC in HE) },
journal = {Computers & Education },
volume = {26},
number = {1–3},
pages = {71 - 80},
year = {1996},
note = {Computer Assisted Learning Selected Contributions from the CAL 95 Symposium },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/0360-1315(95)00082-8},
url = {http://www.sciencedirect.com/science/article/pii/0360131595000828},
author = {Christine Steeples and Christopher Unsworth and Mark Bryson and Peter Goodyear and Phillip Riding and Susan Fowell and Philippa Levy and Celia Duffy},
abstract = {This paper arises from a workshop at the CAL '95 conference. It attempts to share practical experience with both successes and problems in the use of computer-mediated communications (CMC), to support flexible patterns of teaching and learning within higher education. The workshop was based around the CMC in HE project at Lancaster University, with accounts from Lancaster and the University of Derby that have been actively exploring the use of CMC in their teaching. Several participants at the workshop (including from Sheffield University and Glasgow University) also reported on their own experiences. Their contributions are included here and collectively have provided stimulus to the issues that are addressed. This paper's main function is to crystallize some reflections from these perspectives around the important issues of flexible access and opportunities for women, establishing use and sustaining participation in CMC-based learning environments. }}
@article{Nicol2005459,
title = {Using a shared workspace and wireless laptops to improve collaborative project learning in an engineering design class },
journal = {Computers & Education },
volume = {44},
number = {4},
pages = {459 - 475},
year = {2005},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2004.04.008},
url = {http://www.sciencedirect.com/science/article/pii/S0360131504000624},
author = {David J. Nicol and Iain A. MacLeod},
abstract = {Two different technologies, groupware (a shared workspace) and shared wireless laptop computers, were implemented in a project design class in a civil engineering course. The research interest was in the way these technologies supported resource sharing within and across project groups and in the forms of group collaboration that resulted. The initiative was evaluated using both qualitative (e.g. pyramid discussion) and quantitative methods (e.g. survey, logs of usage). The results showed that these technologies helped improve group sharing of resources and supported different kinds of group collaboration. The shared workspace provided a location-independent central repository of resources around which group activities were coordinated whereas the laptops provided a focal point for the face-to-face discussion of these resources. The paper discusses the importance of embedding supportive technologies and the different forms of learner collaboration mediated by each technology. }}
@article{Clark20112178,
title = {Exploring Newtonian mechanics in a conceptually-integrated digital game: Comparison of learning and affective outcomes for students in Taiwan and the United States },
journal = {Computers & Education },
volume = {57},
number = {3},
pages = {2178 - 2195},
year = {2011},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2011.05.007},
url = {http://www.sciencedirect.com/science/article/pii/S0360131511001084},
author = {Douglas B. Clark and Brian C. Nelson and Hsin-Yi Chang and Mario Martinez-Garza and Kent Slack and Cynthia M. D’Angelo},
abstract = {This study investigates the potential of a digital game that overlays popular game-play mechanics with formal physics representations and terminology to support explicit learning and exploration of Newtonian mechanics. The analysis compares test data, survey data, and observational data collected during implementations in Taiwan and the United States with students in grades 7–9. Results demonstrate learning on some core disciplinary measures and high levels of learner engagement, indicating the potential benefits of this genre of conceptually-integrated games, but also suggesting that further research and development will be needed to more fully harness this potential. Encouragingly, striking similarities were observed across the two countries in terms of learning and engagement, suggesting that this genre of learning games may prove suitable for engaging students in active exploration of core science concepts across multiple countries. }}
@article{Tavakoli2013966,
title = {A survey of shaped-based registration and segmentation techniques for cardiac images },
journal = {Computer Vision and Image Understanding },
volume = {117},
number = {9},
pages = {966 - 989},
year = {2013},
note = {},
issn = {1077-3142},
doi = {http://dx.doi.org/10.1016/j.cviu.2012.11.017},
url = {http://www.sciencedirect.com/science/article/pii/S1077314213000775},
author = {Vahid Tavakoli and Amir A. Amini},
abstract = {Abstract Heart disease is the leading cause of death in the modern world. Cardiac imaging is routinely applied for assessment and diagnosis of cardiac diseases. Computerized image analysis methods are now widely applied to cardiac segmentation and registration in order to extract the anatomy and contractile function of the heart. The vast number of recent papers on this topic point to the need for an up to date survey in order to summarize and classify the published literature. This paper presents a survey of shape modeling applications to cardiac image analysis from MRI, CT, echocardiography, PET, and SPECT and aims to (1) introduce new methodologies in this field, (2) classify major contributions in image-based cardiac modeling, (3) provide a tutorial to beginners to initiate their own studies, and (4) introduce the major challenges of registration and segmentation and provide practical examples. The techniques surveyed include statistical models, deformable models/level sets, biophysical models, and non-rigid registration using basis functions. About 130 journal articles are categorized based on methodology, output, imaging system, modality, and validations. The advantages and disadvantages of the registration and validation techniques are discussed as appropriate in each section. }}
@article{AiLimLee20101424,
title = {How does desktop virtual reality enhance learning outcomes? A structural equation modeling approach },
journal = {Computers & Education },
volume = {55},
number = {4},
pages = {1424 - 1442},
year = {2010},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2010.06.006},
url = {http://www.sciencedirect.com/science/article/pii/S0360131510001661},
author = {Elinda Ai-Lim Lee and Kok Wai Wong and Chun Che Fung},
abstract = {This study examined how desktop virtual reality (VR) enhances learning and not merely does desktop VR influence learning. Various relevant constructs and their measurement factors were identified to examine how desktop VR enhances learning and the fit of the hypothesized model was analyzed using structural equation modeling. The results supported the indirect effect of VR features to the learning outcomes, which was mediated by the interaction experience and the learning experience. Learning experience which was individually measured by the psychological factors, that is, presence, motivation, cognitive benefits, control and active learning, and reflective thinking took central stage in affecting the learning outcomes in the desktop VR-based learning environment. The moderating effect of student characteristics such as spatial ability and learning style was also examined. The results show instructional designers and VR software developers how to improve the learning effectiveness and further strengthen their desktop VR-based learning implementation. Through this research, an initial theoretical model of the determinants of learning effectiveness in a desktop VR-based learning environment is contributed. }}
@article{Yang2003299,
title = {Computer-mediated history learning: spanning three centuries project },
journal = {Computers in Human Behavior },
volume = {19},
number = {3},
pages = {299 - 318},
year = {2003},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/S0747-5632(02)00060-2},
url = {http://www.sciencedirect.com/science/article/pii/S0747563202000602},
author = {Shu Ching Yang},
abstract = {This article demonstrates how learners used a project-based approach to engage in authentic historical inquiry. The Spanning Three Centuries Project (STC) was predicated upon the premise that education should encourage students' disposition toward thoughtfulness and reflection. The project encouraged learners' writing with technology as a way of learning one's own culture, through investigation of societal issues, in history, politics, and sociology, with the aim of inspiring creative historical inquiry, and self-reflection. A number of themes were drawn from this data. The STC project promotes disciplined inquiry and enhances learners' historical thinking. It nurtures learners' sense of authorship and enhances their information literacy. The study showed that learners found the experience generally positive. Students, in general, have taken to the project enthusiastically and report that they benefited from this contact and exposure with centenarians. Connecting history to personal experience made them feel the past was real. They particularly enjoyed the use of multimedia technology in supporting projects in the study of history. From this study, it could be concluded that the project-based STC project has the potential to empower students to use multimedia technology in support of social studies projects. The STC project provided an opportunity to develop learners' historical knowledge and thinking skills, as well as their interest in studying history. }}
@article{Sclater2003285,
title = {User requirements of the ultimate online assessment engine },
journal = {Computers & Education },
volume = {40},
number = {3},
pages = {285 - 306},
year = {2003},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/S0360-1315(02)00132-X},
url = {http://www.sciencedirect.com/science/article/pii/S036013150200132X},
author = {Niall Sclater and Karen Howie},
abstract = {As online computer assisted assessment (CAA) is adopted throughout education, the number of CAA systems proliferates. While a number of commercial systems are gaining in sophistication, no single package is universally appropriate. For those implementing online assessment, selecting appropriate systems or indeed building them, it may be helpful to consider the ultimate online CAA system. This combination of web server software, middleware and database package does everything required of it for all possible users of the system. In this paper we take a step back from developments and re-evaluate the requirements of CAA systems for users with 21 possible roles. These user requirements are then mapped onto two leading online assessment systems to analyse how close we are to achieving the ultimate CAA system. }}
@article{Okita2013176,
title = {Learning by teaching with virtual peers and the effects of technological design choices on learning },
journal = {Computers & Education },
volume = {63},
number = {},
pages = {176 - 196},
year = {2013},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2012.12.005},
url = {http://www.sciencedirect.com/science/article/pii/S0360131512002898},
author = {Sandra Y. Okita and Selen Turkay and Mihwa Kim and Yumiko Murai},
abstract = {Advancements in technology have brought about new forms of learning and online instruction that allow communication through virtual representations without physically meeting in person. This study builds on previous work involving recursive feedback that tests the hypothesis that an important facet of learning-by-teaching is the opportunity to watch one's pupil perform. Sixty graduate students examined the value of recursive feedback that occurred when tutors observed their pupil subsequently apply what they had been taught. The study took place in the virtual environment Second Life where adults tutored another adult about human biology through their virtual representations. The tutors who observed their pupil avatar interact with an examiner exhibited superior learning relative to several control conditions that included learning-by-teaching elements but not recursive feedback. The second study examined the effect of popular design choices on recursive feedback during learning-by-teaching (e.g., customization, look-alike features). The customization condition involved tutoring a pupil avatar that the participant customized prior to the study and observing the pupil avatar answer questions. The doppelgänger look-alike condition involved tutoring a pupil avatar that looked like the participant and observing the pupil avatar answer questions. Results showed that conscious awareness of look-alike features and the extent to which one customizes the pupil avatar influences learning. }}
@article{Vermetten2002263,
title = {Powerful learning environments? How university students differ in their response to instructional measures },
journal = {Learning and Instruction },
volume = {12},
number = {3},
pages = {263 - 284},
year = {2002},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/S0959-4752(01)00013-5},
url = {http://www.sciencedirect.com/science/article/pii/S0959475201000135},
author = {Yvonne J Vermetten and Jan D Vermunt and Hans G Lodewijks},
abstract = {This study aimed at measuring the effects of a university educational reform project on student learning, and individual differences in students' responses to similar instructional measures. The reforms mainly failed to influence reported learning strategies in the direction of more deep and self-regulated learning. One explanation for this could be that the instructional measures were not powerful enough to create more deep-level learning strategies. In a second study, a different explanation was explored. It was found that student groups with different learner characteristics tend to use instructional measures in different ways, such that they suit their own habits, ideas and preferences of learning well. This makes it quite clear that direct influence of instructional measures on learning processes does not take place. We explore suggestions for adapting instructional practice. }}
@article{Ting2009762,
title = {Factors influencing the performance of Dynamic Decision Network for INQPRO },
journal = {Computers & Education },
volume = {52},
number = {4},
pages = {762 - 780},
year = {2009},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2008.12.003},
url = {http://www.sciencedirect.com/science/article/pii/S0360131508001929},
author = {Choo-Yee Ting and Somnuk Phon-Amnuaisuk},
abstract = {There has been an increasing interest in employing decision-theoretic framework for learner modeling and provision of pedagogical support in Intelligent Tutoring Systems (ITSs). Much of the existing learner modeling research work focuses on identifying appropriate learner properties. Little attention, however, has been given to leverage Dynamic Decision Network (DDN) as a dynamic learner model to reason and intervene across time. Employing a DDN-based learner model in a scientific inquiry learning environment, however, remains at infant stage because there are factors contributed to the performance the learner model. Three factors have been identified to influence the matching accuracy of INQPRO’s learner model. These factors are the structure of DDN model, the variable instantiation approach, and the weights assignment method for two consecutive Decision Networks (DNs). In this research work, a two-phase empirical study involving 107 learners and six domain experts was conducted to determine the optimal conditions for the INQPRO’s dynamic learner model. The empirical results suggested each time-slice of the INQPRO’s DDN should consist of a DN, and that DN should correspond to the Graphical User Interface (GUI) accessed. In light of evidence, observable variables should be instantiated to their observed states; leaving the remaining observable nodes uninstantiated. The empirical results also indicated that varying weights between two consecutive DNs could optimize the matching accuracy of INQPRO’s dynamic learner model. }}
@article{Hull2009624,
title = {Negotiation of meaning and co-construction of knowledge: An experimental analysis of asynchronous online instruction },
journal = {Computers & Education },
volume = {52},
number = {3},
pages = {624 - 639},
year = {2009},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2008.11.005},
url = {http://www.sciencedirect.com/science/article/pii/S0360131508001681},
author = {Darrell M. Hull and Terrill F. Saxon},
abstract = {Variations in group co-construction of knowledge and the extent to which participants engaged in negotiating meaning were directly related to instruction. The authors examined social interaction resulting from controlled variation in instruction using a counter-balanced design in two professional development courses for teachers. Both courses were held at the same time, included the same content with the same instructor, and were held in an asynchronous online format. Twenty-four subjects were randomly assigned to the two courses. Using socio-historical constructivist theory to guide instruction interventions, instruction frequency and questioning were intentionally manipulated during one-half of each course. The variations in instruction were hypothesized to promote negotiation of meaning and co-construction of knowledge within both groups. Transcript analysis using a dependent measure of social interaction was applied to the 782 utterances of the participants. Multiple comparisons revealed significant differences in the dependent measure in portions of the course where modified instructional strategies were implemented. The results show that relatively simple alterations in instructional practice (e.g., increasing instructional statements from once to twice per week and engaging participants in dialogue through open-ended questioning) yields a substantially enhanced learning outcome within this environment. Strong evidence suggests that online learning groups depend heavily on instruction to facilitate negotiation of meaning and co-construction of knowledge. This research raises concerns about whether or not instructors employ instructional strategies that influence social knowledge construction and subsequent learning outcomes from asynchronous online courses. In addition, the study demonstrates the utility of a previously published measure for social interaction in CMC. }}
@article{Lim20081073,
title = {Global citizenship education, school curriculum and games: Learning Mathematics, English and Science as a global citizen },
journal = {Computers & Education },
volume = {51},
number = {3},
pages = {1073 - 1093},
year = {2008},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/j.compedu.2007.10.005},
url = {http://www.sciencedirect.com/science/article/pii/S0360131507001327},
author = {Cher Ping Lim},
abstract = {Based on an account of how two classes of primary five students in Singapore engage in the learning of English, Mathematics and Science by playing the role of global citizens, the paper suggests an alternative but realistic approach to teaching global citizenship education. Set against the back story of Atlantis facing ecological, social and cultural decay due to the blind pursuit of prosperity and modernisation by its rulers, each student became a quester called on to save Atlantis. Throughout the mission they were presented with different problems in Atlantis (similar to existing global issues) and were expected to research and suggest solutions to the problems by alone or with fellow questers. These problems were tied to the primary five English, Mathematics and Science curriculum. Through documenting and making sense of these activities via observations, interviews and pre-post questionnaire surveys, the paper shows how the new approach may enhance the learning engagement, academic motivation and social commitments among the students. We also explore the sustainability and scalability of such an approach in the school system and highlight constraints. The paper then draws implications for global citizenship education in schools that include designing a meaningful context for engaged learning in schools with components of global citizenship, developing a research culture in schools as a stepping stone for global citizenship education and building capacity of teachers and school leaders in global citizenship. }}
@article{Antonietti20082172,
title = {Undergraduates’ metacognitive knowledge about the psychological effects of different kinds of computer-supported instructional tools },
journal = {Computers in Human Behavior },
volume = {24},
number = {5},
pages = {2172 - 2198},
year = {2008},
note = {Including the Special Issue: Internet Empowerment },
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/j.chb.2007.10.004},
url = {http://www.sciencedirect.com/science/article/pii/S0747563207001598},
author = {Alessandro Antonietti and Barbara Colombo and Yuri Lozotsev},
abstract = {Literature about metacognition suggests that learners develop personal beliefs about the educational technologies that they are asked to employ and that such beliefs can influence learning outcomes. In this perspective, opinions about the psychological effects of computer-supported instructional tools were analysed by means of a questionnaire which included items about the motivational and emotional aspects of learning, the behaviour to have during the learning process, the mental abilities and the style of thinking required, and the cognitive benefits. Items were presented five times: each time they made reference to a different kind of tool (online courses, hypertexts, Web forums, multimedia presentations, and virtual simulations). The questionnaire was filled out by 99 undergraduates attending engineering courses. Results showed that students ranked the psychological effects of the computer-supported tools in a relative different order according to the kind of tool and attributed distinctive effects to each tool. Gender and expertise played a minor role in modulating undergraduates’ beliefs. Implications for instruction were discussed. }}
@article{Calverley1998151,
title = {Modernisation of a traditional physics course },
journal = {Computers & Education },
volume = {31},
number = {2},
pages = {151 - 169},
year = {1998},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/S0360-1315(98)00018-9},
url = {http://www.sciencedirect.com/science/article/pii/S0360131598000189},
author = {Gayle Calverley and David Fincham and Dick Bacon},
abstract = {The introduction of Computer-Aided Learning resources in an individual university is frequently driven by external impetus for change from a number of distinct sources. The starting point for implementing such material is mainly determined by the local teaching situation and institutional resources. At present, the advice for including such materials within existing courses has often been derived from the principles and preferences of the developers, rather than from a sound basis in educational theory. This study illustrates the process of introducing such material into an existing traditionally taught university physics course and documents the difficulties encountered. Continuous evaluation of the course observed the gradual changes that occurred in the style of presentation, which in fact ultimately led the new course to coincide with scenarios predicted from current thinking in educational theory. }}
@article{Tynjälä1997277,
title = {Developing education students' conceptions of the learning process in different learning environments },
journal = {Learning and Instruction },
volume = {7},
number = {3},
pages = {277 - 292},
year = {1997},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/S0959-4752(96)00029-1},
url = {http://www.sciencedirect.com/science/article/pii/S0959475296000291},
author = {Päivi Tynjälä},
abstract = {Changes in conceptions of the learning process of 31 educational psychology students were examined in a constructivist and in a traditional learning environment. The study was carried out in a course which dealt with theories of learning and development and consisted of three text books. At the beginning of the course all students wrote a short essay, My conception of learning, after which the participants were divided in two groups. The traditional learning group studied the books individually, listened to the lectures and took an exam while the constructive learning group worked with different writing assignments, discussed the topics in groups and wrote an extensive essay instead of taking an exam. After the course all students again wrote a short essay about their learning conceptions. The essays written before and after the course were analyzed qualitatively using a phenomenographic procedure. As a result of the study, seven categories of description of the students' conceptions of the learning process are presented. The students' conceptions appeared to change similarly in both groups with the exception that at the end of the course the students in the constructive learning group emphasized more often the role of critical thinking and other student activity in learning. }}
@article{Sims1997157,
title = {Interactivity: A forgotten art? },
journal = {Computers in Human Behavior },
volume = {13},
number = {2},
pages = {157 - 180},
year = {1997},
note = {},
issn = {0747-5632},
doi = {http://dx.doi.org/10.1016/S0747-5632(97)00004-6},
url = {http://www.sciencedirect.com/science/article/pii/S0747563297000046},
author = {Rod Sims},
abstract = {Interactivity has received a great deal of attention in the instructional science literature and has been a much discussed topic on ITFORUM. The attention is well deserved since, by most accounts, interactivity plays a crucial role in knowledge acquisition and the development of cognitive skills. Nevertheless, there has been inadequate analysis of the ways interactivity can be effectively achieved in learning environments. This paper is intended to promote further discussion and analysis of interactivity in learning environments and contains a classification of interaction types appropriate for consideration in multimedia settings. Through an examination of related factors associated with navigation and control, a matrix of interactive dimensions is proposed. }}
@article{Molinari2007304,
title = {Integration of new domain-related states and events from texts and illustrations by subjects with high and low prior knowledge },
journal = {Learning and Instruction },
volume = {17},
number = {3},
pages = {304 - 321},
year = {2007},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/j.learninstruc.2007.02.005},
url = {http://www.sciencedirect.com/science/article/pii/S095947520700031X},
author = {Gaëlle Molinari and Isabelle Tapiero},
abstract = {The aim of this article is to investigate with high and low knowledge subjects in the scientific domain of the neuron, the way information should be presented and illustrated to promote the integration of new information. This fundamental process for learning was examined in two experiments using a primed recognition task. In the first study, the nature of domain-specific information depicted (states or events) was manipulated while in the second, the temporal position of illustrations (before or after textual information) was also considered. The main result showed that when presented before the text, illustrations allow easier retrieval from memory (a) when they represent states for beginners, and (b) when they represent events for experts. Within the theoretical framework of text and picture comprehension (Schnotz, W., &amp; Bannert, M. (2003). Construction and interference in teaming from multiple representation. Learning and Instruction, 13, 141–156), our results offer a more precise definition of the conditions under which the addition of illustrations for a text is beneficial to the learning process. }}
@article{Draper199617,
title = {Integrative evaluation: an emerging role for classroom studies of CAL },
journal = {Computers & Education },
volume = {26},
number = {1–3},
pages = {17 - 32},
year = {1996},
note = {Computer Assisted Learning Selected Contributions from the CAL 95 Symposium },
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/0360-1315(95)00068-2},
url = {http://www.sciencedirect.com/science/article/pii/0360131595000682},
author = {Stephen W. Draper and Margaret I. Brown and Fiona P. Henderson and Erica McAteer},
abstract = {This paper reviews the work of a team over two and a half years whose remit has been to evaluate a diverse range of CAL—computer assisted learning—in use in a university setting. It gives an overview of the team's current method, including some of the instruments most often used, and describes some of the painful lessons from early attempts. It then offers a critical discussion of what the essential features of the method are, and of what such studies are and are not good for. One of the main conclusions, with hindsight, is that its main benefit is as integrative evaluation: to help teachers make better use of the CAL by adjusting how it is used, rather than by changing the software or informing purchasing decisions. }}
@article{Long1995259,
title = {New Tools vs Old Methods: A description of the CHEMCONF '93 discussion },
journal = {Computers & Education },
volume = {24},
number = {4},
pages = {259 - 269},
year = {1995},
note = {},
issn = {0360-1315},
doi = {http://dx.doi.org/10.1016/0360-1315(95)00042-K},
url = {http://www.sciencedirect.com/science/article/pii/036013159500042K},
author = {George Long and Harry Pence and Theresa Julia Zielinski},
abstract = {During the on-line conference on Applications of Technology in Teaching Chemistry held between 12 June and 20 August 1993 the topic New Tools vs Old Methods generated wide interest. This paper is based on the discussions surrounding this topic during the conference and on participants' reactions to a document that summarized the major points made during that discussion. The conference consensus and necessity for using new computer tools in chemical education are supplemented with ideas drawn from the literature. The integration of new pedagogical techniques with the new technology is seen as essential for effective use of computer tools in chemical education. Participants responded very enthusiastically to CHEMCONF. The advantage of computer conferencing as a new tool for educators lies in the opportunity for wide, in depth participation in an adventure of ideas. }}
@article{Stathacopoulou2005273,
abstract = {In this paper, a neural network implementation for a fuzzy logic-based model of the diagnostic process is proposed as a means to achieve accurate student diagnosis and updates of the student model in Intelligent Learning Environments. The neuro-fuzzy synergy allows the diagnostic model to some extent imitate teachers in diagnosing students' characteristics, and equips the intelligent learning environment with reasoning capabilities that can be further used to drive pedagogical decisions depending on the student learning style. The neuro-fuzzy implementation helps to encode both structured and non-structured teachers' knowledge: when teachers' reasoning is available and well defined, it can be encoded in the form of fuzzy rules; when teachers' reasoning is not well defined but is available through practical examples illustrating their experience, then the networks can be trained to represent this experience. The proposed approach has been tested in diagnosing aspects of student's learning style in a discovery-learning environment that aims to help students to construct the concepts of vectors in physics and mathematics. The diagnosis outcomes of the model have been compared against the recommendations of a group of five experienced teachers, and the results produced by two alternative soft computing methods. The results of our pilot study show that the neuro-fuzzy model successfully manages the inherent uncertainty of the diagnostic process; especially for marginal cases, i.e. where it is very difficult, even for human tutors, to diagnose and accurately evaluate students by directly synthesizing subjective and, some times, conflicting judgments.},
title = {Neuro-fuzzy knowledge processing in intelligent learning environments for improved student diagnosis},
journal = {Information Sciences },
volume = {170},
number = {2–4},
pages = {273 - 307},
year = {2005},
issn = {0020-0255},
doi = {http://dx.doi.org/10.1016/j.ins.2004.02.026},
url = {http://www.sciencedirect.com/science/article/pii/S0020025504000702},
author = {Regina Stathacopoulou and George D. Magoulas and Maria Grigoriadou and Maria Samarakou}}
@article{Glaser1991129,
title = {The maturing of the relationship between the science of learning and cognition and educational practice },
journal = {Learning and Instruction },
volume = {1},
number = {2},
pages = {129 - 144},
year = {1991},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/0959-4752(91)90023-2},
url = {http://www.sciencedirect.com/science/article/pii/0959475291900232},
author = {Robert Glaser},
abstract = {Advances in our understanding of cognition have brought into reach the aim of fostering students' ability to become architects of their own knowledge and made the study of learning under instructional conditions an integral aspect of psychological as well as educational research. Work on the application of psychological science to education now focusses on the details of teaching activities and programs that aim to foster students' knowledge construction abilities. After a sketch of the American research on cognition that has set a framework for educational practice, attention is given to trends in the design of instructional innovation. The research considered includes analyses of textbook structure and problem exercises, teacher explanations, and structured classroom interactions.}}
@article{Marton199721,
title = {Discontinuities and continuities in the experience of learning: An interview study of high-school students in Hong Kong },
journal = {Learning and Instruction },
volume = {7},
number = {1},
pages = {21 - 48},
year = {1997},
note = {},
issn = {0959-4752},
doi = {http://dx.doi.org/10.1016/S0959-4752(96)00009-6},
url = {http://www.sciencedirect.com/science/article/pii/S0959475296000096},
author = {Ference Marton and David Watkins and Catherine Tang},
abstract = {An interview study was carried out with 43 high-school students with the dual aim of: (a) exploring the dimensionality of learning; and (b) investigating the nature of the relationship between memorisation and understanding as experienced by Chinese learners. The different ways of experiencing learning found in the group participating in the investigation are described within a two-dimensional outcome space. There is a temporal dimension of variation, comprised of acquiring, knowing and making use of. The other dimension is that of depth, ranging over seeing learning as committing words to memory, committing meaning to memory, understanding meaning and understanding phenomena. Concerning the second question this study sets out to illuminate some of our findings point to the possibility of the experience of understanding being developmentally preceded by, and differentiated from, the experience of committing to memory. In the context of similar studies carried out in other cultures, this investigation contributes to our understanding of an evolving culturally distributed universal structure of conceptions of learning grounded in overlapping and complementary views.}
}